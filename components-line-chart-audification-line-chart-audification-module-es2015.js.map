{"version":3,"sources":["./node_modules/@babel/runtime/helpers/arrayLikeToArray.js","./node_modules/@babel/runtime/helpers/arrayWithHoles.js","./node_modules/@babel/runtime/helpers/classCallCheck.js","./node_modules/@babel/runtime/helpers/createClass.js","./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js","./node_modules/@babel/runtime/helpers/nonIterableRest.js","./node_modules/@babel/runtime/helpers/slicedToArray.js","./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js","./node_modules/automation-events/build/es5/bundle.js","./node_modules/standardized-audio-context/build/es2019/constants.js","./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js","./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js","./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js","./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js","./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js","./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js","./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js","./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js","./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js","./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js","./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js","./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js","./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js","./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js","./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js","./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js","./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js","./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js","./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js","./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js","./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js","./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js","./node_modules/standardized-audio-context/build/es2019/factories/get-backup-native-context.js","./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js","./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js","./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js","./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js","./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js","./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js","./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js","./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js","./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js","./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js","./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js","./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js","./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js","./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js","./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js","./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js","./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js","./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js","./node_modules/standardized-audio-context/build/es2019/factories/native-audio-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js","./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js","./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js","./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js","./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js","./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js","./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-source-node-start-method-consecutive-calls-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-source-node-start-method-duration-parameter-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-source-node-start-method-offset-clamping-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-scheduled-source-node-start-method-negative-parameters-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js","./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js","./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js","./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/factories/window.js","./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js","./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js","./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js","./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js","./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js","./node_modules/standardized-audio-context/build/es2019/globals.js","./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js","./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js","./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js","./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js","./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js","./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js","./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js","./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js","./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js","./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js","./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js","./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js","./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js","./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js","./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js","./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js","./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js","./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js","./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js","./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js","./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js","./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js","./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js","./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js","./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js","./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js","./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js","./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js","./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js","./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js","./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js","./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js","./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js","./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js","./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js","./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js","./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js","./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js","./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js","./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js","./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js","./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-duration-parameter.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js","./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js","./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js","./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js","./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js","./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js","./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js","./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js","./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/index.js","./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js","./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js","./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js","./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js","./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js","./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js","./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js","./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js","./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js","./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js","./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js","./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js","./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js","./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js","./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js","./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js","./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js","./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js","./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js","./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js","./node_modules/standardized-audio-context/build/es2019/module.js","./node_modules/standardized-audio-context/build/es2019/read-only-map.js","./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js","./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js","./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js","./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js","./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js","./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js","./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js","./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js","./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js","./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js","./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js","./node_modules/standardized-audio-context/build/es2019/types/any-context.js","./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js","./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js","./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js","./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js","./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js","./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js","./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js","./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/auxiliary-gain-node-store.js","./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js","./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js","./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js","./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js","./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js","./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js","./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js","./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js","./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js","./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/types/constructor.js","./node_modules/standardized-audio-context/build/es2019/types/context-store.js","./node_modules/standardized-audio-context/build/es2019/types/context.js","./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js","./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js","./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js","./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js","./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js","./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js","./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js","./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js","./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js","./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js","./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js","./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js","./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js","./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js","./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js","./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js","./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js","./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js","./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js","./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js","./node_modules/standardized-audio-context/build/es2019/types/event-handler.js","./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js","./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js","./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js","./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js","./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-backup-native-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/get-backup-native-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js","./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js","./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js","./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js","./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js","./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js","./node_modules/standardized-audio-context/build/es2019/types/index.js","./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js","./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js","./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js","./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js","./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js","./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js","./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js","./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js","./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-context.js","./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-faker-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js","./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js","./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js","./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js","./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js","./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js","./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js","./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js","./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js","./node_modules/standardized-audio-context/build/es2019/types/output-connection.js","./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js","./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js","./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js","./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js","./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js","./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js","./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js","./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js","./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js","./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js","./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js","./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js","./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js","./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-source-node-start-method-consecutive-calls-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-source-node-start-method-duration-parameter-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-source-node-start-method-offset-clamping-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-source-node-stop-method-nullified-buffer-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-scheduled-source-node-start-method-consecutive-calls-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-scheduled-source-node-stop-method-consecutive-calls-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-scheduled-source-node-stop-method-negative-parameters-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js","./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js","./node_modules/standardized-audio-context/build/es2019/types/typed-array.js","./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js","./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js","./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js","./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js","./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js","./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js","./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/window-factory.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-factory.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js","./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js","./node_modules/tone/build/esm/classes.js","./node_modules/tone/build/esm/component/analysis/Analyser.js","./node_modules/tone/build/esm/component/analysis/DCMeter.js","./node_modules/tone/build/esm/component/analysis/FFT.js","./node_modules/tone/build/esm/component/analysis/Follower.js","./node_modules/tone/build/esm/component/analysis/Meter.js","./node_modules/tone/build/esm/component/analysis/MeterBase.js","./node_modules/tone/build/esm/component/analysis/Waveform.js","./node_modules/tone/build/esm/component/channel/Channel.js","./node_modules/tone/build/esm/component/channel/CrossFade.js","./node_modules/tone/build/esm/component/channel/Merge.js","./node_modules/tone/build/esm/component/channel/MidSideMerge.js","./node_modules/tone/build/esm/component/channel/MidSideSplit.js","./node_modules/tone/build/esm/component/channel/MultibandSplit.js","./node_modules/tone/build/esm/component/channel/PanVol.js","./node_modules/tone/build/esm/component/channel/Panner.js","./node_modules/tone/build/esm/component/channel/Panner3D.js","./node_modules/tone/build/esm/component/channel/Recorder.js","./node_modules/tone/build/esm/component/channel/Solo.js","./node_modules/tone/build/esm/component/channel/Split.js","./node_modules/tone/build/esm/component/channel/Volume.js","./node_modules/tone/build/esm/component/dynamics/Compressor.js","./node_modules/tone/build/esm/component/dynamics/Gate.js","./node_modules/tone/build/esm/component/dynamics/Limiter.js","./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js","./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js","./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js","./node_modules/tone/build/esm/component/envelope/Envelope.js","./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js","./node_modules/tone/build/esm/component/filter/Convolver.js","./node_modules/tone/build/esm/component/filter/EQ3.js","./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js","./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js","./node_modules/tone/build/esm/component/filter/Filter.js","./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js","./node_modules/tone/build/esm/component/filter/OnePoleFilter.js","./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js","./node_modules/tone/build/esm/component/index.js","./node_modules/tone/build/esm/core/Global.js","./node_modules/tone/build/esm/core/Tone.js","./node_modules/tone/build/esm/core/clock/Clock.js","./node_modules/tone/build/esm/core/clock/TickParam.js","./node_modules/tone/build/esm/core/clock/TickSignal.js","./node_modules/tone/build/esm/core/clock/TickSource.js","./node_modules/tone/build/esm/core/clock/Ticker.js","./node_modules/tone/build/esm/core/clock/Transport.js","./node_modules/tone/build/esm/core/clock/TransportEvent.js","./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js","./node_modules/tone/build/esm/core/context/AudioContext.js","./node_modules/tone/build/esm/core/context/BaseContext.js","./node_modules/tone/build/esm/core/context/Context.js","./node_modules/tone/build/esm/core/context/ContextInitialization.js","./node_modules/tone/build/esm/core/context/Delay.js","./node_modules/tone/build/esm/core/context/Destination.js","./node_modules/tone/build/esm/core/context/DummyContext.js","./node_modules/tone/build/esm/core/context/Gain.js","./node_modules/tone/build/esm/core/context/Listener.js","./node_modules/tone/build/esm/core/context/Offline.js","./node_modules/tone/build/esm/core/context/OfflineContext.js","./node_modules/tone/build/esm/core/context/Param.js","./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js","./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js","./node_modules/tone/build/esm/core/context/ToneAudioNode.js","./node_modules/tone/build/esm/core/context/ToneWithContext.js","./node_modules/tone/build/esm/core/index.js","./node_modules/tone/build/esm/core/type/Conversions.js","./node_modules/tone/build/esm/core/type/Frequency.js","./node_modules/tone/build/esm/core/type/Midi.js","./node_modules/tone/build/esm/core/type/Ticks.js","./node_modules/tone/build/esm/core/type/Time.js","./node_modules/tone/build/esm/core/type/TimeBase.js","./node_modules/tone/build/esm/core/type/TransportTime.js","./node_modules/tone/build/esm/core/type/Units.js","./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js","./node_modules/tone/build/esm/core/util/Debug.js","./node_modules/tone/build/esm/core/util/Decorator.js","./node_modules/tone/build/esm/core/util/Defaults.js","./node_modules/tone/build/esm/core/util/Draw.js","./node_modules/tone/build/esm/core/util/Emitter.js","./node_modules/tone/build/esm/core/util/Interface.js","./node_modules/tone/build/esm/core/util/IntervalTimeline.js","./node_modules/tone/build/esm/core/util/Math.js","./node_modules/tone/build/esm/core/util/StateTimeline.js","./node_modules/tone/build/esm/core/util/Timeline.js","./node_modules/tone/build/esm/core/util/TimelineValue.js","./node_modules/tone/build/esm/core/util/TypeCheck.js","./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js","./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js","./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js","./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js","./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js","./node_modules/tone/build/esm/effect/AutoFilter.js","./node_modules/tone/build/esm/effect/AutoPanner.js","./node_modules/tone/build/esm/effect/AutoWah.js","./node_modules/tone/build/esm/effect/BitCrusher.js","./node_modules/tone/build/esm/effect/BitCrusher.worklet.js","./node_modules/tone/build/esm/effect/Chebyshev.js","./node_modules/tone/build/esm/effect/Chorus.js","./node_modules/tone/build/esm/effect/Distortion.js","./node_modules/tone/build/esm/effect/Effect.js","./node_modules/tone/build/esm/effect/FeedbackDelay.js","./node_modules/tone/build/esm/effect/FeedbackEffect.js","./node_modules/tone/build/esm/effect/Freeverb.js","./node_modules/tone/build/esm/effect/FrequencyShifter.js","./node_modules/tone/build/esm/effect/JCReverb.js","./node_modules/tone/build/esm/effect/LFOEffect.js","./node_modules/tone/build/esm/effect/MidSideEffect.js","./node_modules/tone/build/esm/effect/Phaser.js","./node_modules/tone/build/esm/effect/PingPongDelay.js","./node_modules/tone/build/esm/effect/PitchShift.js","./node_modules/tone/build/esm/effect/Reverb.js","./node_modules/tone/build/esm/effect/StereoEffect.js","./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js","./node_modules/tone/build/esm/effect/StereoWidener.js","./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js","./node_modules/tone/build/esm/effect/Tremolo.js","./node_modules/tone/build/esm/effect/Vibrato.js","./node_modules/tone/build/esm/effect/index.js","./node_modules/tone/build/esm/event/Loop.js","./node_modules/tone/build/esm/event/Part.js","./node_modules/tone/build/esm/event/Pattern.js","./node_modules/tone/build/esm/event/PatternGenerator.js","./node_modules/tone/build/esm/event/Sequence.js","./node_modules/tone/build/esm/event/ToneEvent.js","./node_modules/tone/build/esm/event/index.js","./node_modules/tone/build/esm/index.js","./node_modules/tone/build/esm/instrument/AMSynth.js","./node_modules/tone/build/esm/instrument/DuoSynth.js","./node_modules/tone/build/esm/instrument/FMSynth.js","./node_modules/tone/build/esm/instrument/Instrument.js","./node_modules/tone/build/esm/instrument/MembraneSynth.js","./node_modules/tone/build/esm/instrument/MetalSynth.js","./node_modules/tone/build/esm/instrument/ModulationSynth.js","./node_modules/tone/build/esm/instrument/MonoSynth.js","./node_modules/tone/build/esm/instrument/Monophonic.js","./node_modules/tone/build/esm/instrument/NoiseSynth.js","./node_modules/tone/build/esm/instrument/PluckSynth.js","./node_modules/tone/build/esm/instrument/PolySynth.js","./node_modules/tone/build/esm/instrument/Sampler.js","./node_modules/tone/build/esm/instrument/Synth.js","./node_modules/tone/build/esm/instrument/index.js","./node_modules/tone/build/esm/signal/Abs.js","./node_modules/tone/build/esm/signal/Add.js","./node_modules/tone/build/esm/signal/AudioToGain.js","./node_modules/tone/build/esm/signal/GainToAudio.js","./node_modules/tone/build/esm/signal/GreaterThan.js","./node_modules/tone/build/esm/signal/GreaterThanZero.js","./node_modules/tone/build/esm/signal/Multiply.js","./node_modules/tone/build/esm/signal/Negate.js","./node_modules/tone/build/esm/signal/Pow.js","./node_modules/tone/build/esm/signal/Scale.js","./node_modules/tone/build/esm/signal/ScaleExp.js","./node_modules/tone/build/esm/signal/Signal.js","./node_modules/tone/build/esm/signal/SignalOperator.js","./node_modules/tone/build/esm/signal/Subtract.js","./node_modules/tone/build/esm/signal/SyncedSignal.js","./node_modules/tone/build/esm/signal/ToneConstantSource.js","./node_modules/tone/build/esm/signal/WaveShaper.js","./node_modules/tone/build/esm/signal/Zero.js","./node_modules/tone/build/esm/signal/index.js","./node_modules/tone/build/esm/source/Noise.js","./node_modules/tone/build/esm/source/OneShotSource.js","./node_modules/tone/build/esm/source/Source.js","./node_modules/tone/build/esm/source/UserMedia.js","./node_modules/tone/build/esm/source/buffer/GrainPlayer.js","./node_modules/tone/build/esm/source/buffer/Player.js","./node_modules/tone/build/esm/source/buffer/Players.js","./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js","./node_modules/tone/build/esm/source/index.js","./node_modules/tone/build/esm/source/oscillator/AMOscillator.js","./node_modules/tone/build/esm/source/oscillator/FMOscillator.js","./node_modules/tone/build/esm/source/oscillator/FatOscillator.js","./node_modules/tone/build/esm/source/oscillator/LFO.js","./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js","./node_modules/tone/build/esm/source/oscillator/Oscillator.js","./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js","./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js","./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js","./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js","./node_modules/tone/build/esm/version.js","./src/components/line-chart-audification/line-chart-audification.component.ts","./src/components/line-chart-audification/line-chart-audification.component.html","./src/components/line-chart-audification/line-chart-audification.module.ts","./src/components/screen-reader/screen-reader.component.ts","./src/components/screen-reader/screen-reader.component.html","./src/components/screen-reader/screen-reader.module.ts","./src/models/melody/melody.model.ts","./src/utils/comparators.ts"],"names":[],"mappings":";;;;;;;;;AAAA;AACA;;AAEA,wCAAwC,SAAS;AACjD;AACA;;AAEA;AACA;;AAEA,mC;;;;;;;;;;;ACVA;AACA;AACA;;AAEA,iC;;;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;AAEA,iC;;;;;;;;;;;ACNA;AACA,iBAAiB,kBAAkB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,8B;;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,6CAA6C,+BAA+B;AAC5E;;AAEA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;;AAEA,uC;;;;;;;;;;;AC3BA;AACA;AACA;;AAEA,kC;;;;;;;;;;;ACJA,qBAAqB,mBAAO,CAAC,iFAAkB;;AAE/C,2BAA2B,mBAAO,CAAC,6FAAwB;;AAE3D,iCAAiC,mBAAO,CAAC,yGAA8B;;AAEvE,sBAAsB,mBAAO,CAAC,mFAAmB;;AAEjD;AACA;AACA;;AAEA,gC;;;;;;;;;;;ACZA,uBAAuB,mBAAO,CAAC,qFAAoB;;AAEnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,6C;;;;;;;;;;;ACXA;AACA,IAAI,KAA4D,oBAAoB,mBAAO,CAAC,oGAAsC,GAAG,mBAAO,CAAC,sGAAuC,GAAG,mBAAO,CAAC,gGAAoC;AACnO,IAAI,SACoI;AACxI,CAAC,2EAA2E;;AAE5E;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa;;AAEb;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,aAAa;;AAEb;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,aAAa;AACb;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,WAAW;;AAEX;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,WAAW;;AAEX;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,OAAO;;AAEP;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kDAAkD,cAAc;;AAEhE,CAAC;;;;;;;;;;;;;ACnWD;AAAA;AAAA;AAAO;AACA;AACP,mD;;;;;;;;;;;;ACFA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+D;;;;;;;;;;;;ACXA;AAAA;AAAO;AACP;AACA;AACA,uBAAuB,oCAAoC;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,8E;;;;;;;;;;;;ACdA;AAAA;AAAO;AACP;AACA,oDAAoD,sFAAsF;AAC1I;AACA;AACA,+E;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAA;AAAA;AAAqE;AACP;AACa;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,iFAAe;AACxB;AACA;AACA;AACA;AACA;AACA;AACO;AACP,2CAA2C,sBAAsB;AACjE;AACA;AACA;AACA;AACA;AACA;AACA,0EAA0E,8FAAqB;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB;AACtB,4CAA4C,EAAE;AAC9C,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,yCAAyC,kBAAkB,qBAAqB,EAAE;AAClF,CAAC,6CAA6C,eAAe,kEAAkE,IAAI;AACnI,wDAAwD,+BAA+B,iBAAiB;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,8FAAqB;AAC3F;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA,qCAAqC,kBAAkB,SAAS,+FAA+F,EAAE;AACjK,CAAC,EAAE;AACH;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,0DAA0D,gFAAuC;AACjG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gFAAuC;AAC3D;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,0BAA0B,EAAE;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,4E;;;;;;;;;;;;AC/JA;AAAA;AAAO;AACP;AACA,oEAAoE,4FAA4F;AAChK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yE;;;;;;;;;;;;AClBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,qF;;;;;;;;;;;;ACNA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6E;;;;;;;;;;;;AC1EA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA,uDAAuD,qFAAgB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kF;;;;;;;;;;;;ACnCA;AAAA;AAAA;AAAA;AAA8I;AACnC;AAC3G;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,uCAAuC,IAAI;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,uCAAuC;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8HAAmC;AACnD;AACA;AACA,sCAAsC,yJAAmD,QAAQ,iKAAmD;AACpJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4E;;;;;;;;;;;;ACnDA;AAAA;AAAA;AAAA;AAAA;AAAsF;AACH;AACE;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6GAA6G,qEAA0B,EAAE,qEAA0B;AACnK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,sBAAsB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sGAAwB;AACxC;AACA;AACA;AACA,qCAAqC,wGAAyB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wF;;;;;;;;;;;;AC3HA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,qFAAgB;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6F;;;;;;;;;;;;AC9DA;AAAA;AAAA;AAAsE;AAC/D;AACP;AACA,gCAAgC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,yFAAkB;AACnC,2DAA2D,oBAAoB;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,cAAc;AACjC,mBAAmB,aAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,eAAe;AACpF;AACA;AACA;AACA;AACA;AACA,oEAAoE,cAAc;AAClF;AACA;AACA,yEAAyE,mBAAmB;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,6E;;;;;;;;;;;;ACpIA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sF;;;;;;;;;;;;AC3CA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2F;;;;;;;;;;;;AChBA;AAAA;AAAA;AAAsF;AAC/E;AACP;AACA;AACA;AACA;AACA,oFAAoF,sGAAsG;AAC1L;AACA;AACA;AACA,0FAA0F,kGAAkG;AAC5L;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,yCAAyC,UAAU,wCAAwC,qEAA0B,EAAE,qEAA0B;AACjJ;AACA;AACA;AACA,mDAAmD,cAAc;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,+EAA+E;AAC9F;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,0E;;;;;;;;;;;;ACjGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+D;AACZ;AACkC;AACnB;AACkD;AACnB;AAC6B;AAC9C;AACE;AACU;AACtB;AACE;AACV;AACQ;AACF;AACL;AACO;AACA;AACa;AAC8B;AACL;AAC7B;AACc;AAC7F;AACA,IAAI,0FAAkB;AACtB;AACA;AACA,IAAI,0FAAkB;AACtB;AACA;AACA,WAAW,0FAAkB;AAC7B;AACA;AACA,WAAW,0FAAkB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0FAAkB;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0FAAkB;AAC1B;AACA;AACA;AACA,oCAAoC,kFAAc;AAClD,+BAA+B,0FAAkB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,kFAAc;AAClD,+BAA+B,0FAAkB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,8BAA8B,GAAG,mGAAuB;AACnE,WAAW,UAAU,GAAG,mGAAuB;AAC/C,2BAA2B,+GAA4B;AACvD;AACA,2CAA2C,0FAAkB;AAC7D,sCAAsC,0FAAkB;AACxD;AACA;AACA;AACA,iBAAiB,mFAAc;AAC/B,gBAAgB,uIAAuC;AACvD;AACA,gBAAgB,0FAAkB;AAClC,gBAAgB,uGAAwB;AACxC;AACA;AACA;AACA;AACA;AACA,iBAAiB,mFAAc;AAC/B,gBAAgB,iJAA4C;AAC5D;AACA,gBAAgB,wFAAiB;AACjC,gBAAgB,qIAAsC;AACtD;AACA;AACA,KAAK;AACL,QAAQ,0FAAkB;AAC1B;AACA,YAAY,wFAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,UAAU,GAAG,mGAAuB;AAC/C,QAAQ,0FAAkB;AAC1B,eAAe,eAAe,GAAG,mGAAuB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,8BAA8B,GAAG,qGAAwB;AACpE,WAAW,UAAU,GAAG,mGAAuB;AAC/C,2BAA2B,+GAA4B;AACvD;AACA,gCAAgC,0FAAkB;AAClD,iCAAiC,4FAAmB;AACpD;AACA;AACA;AACA,iBAAiB,mFAAc;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,mFAAc;AAC/B;AACA;AACA;AACA,KAAK;AACL,QAAQ,0FAAkB;AAC1B;AACA,YAAY,wFAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,UAAU,GAAG,mGAAuB;AAC/C,QAAQ,0FAAkB;AAC1B,eAAe,eAAe,GAAG,qGAAwB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,8BAA8B,GAAG,mGAAuB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,8BAA8B,GAAG,qGAAwB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oHAA8B;AACtC,yBAAyB,mFAAc;AACvC,YAAY,iJAA4C,CAAC,0FAAkB,UAAU,0FAAkB;AACvG;AACA;AACA,QAAQ,wFAAiB;AACzB,eAAe,eAAe,GAAG,mGAAuB;AACxD,QAAQ,qIAAsC;AAC9C;AACA;AACA;AACA;AACA;AACA,QAAQ,oHAA8B;AACtC,yBAAyB,mFAAc;AACvC,YAAY,0FAAkB;AAC9B,4BAA4B,4FAAmB;AAC/C;AACA;AACA;AACA;AACA,yCAAyC,mGAAuB;AAChE;AACA;AACA,YAAY,wGAA2B;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,mGAAuB;AAChE;AACA;AACA;AACA,gBAAgB,wGAA2B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,mGAAuB;AAChE;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,wGAA2B;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gFAAgF,wHAAoC;AACpH,uBAAuB,gIAAoC;AAC3D,aAAa;AACb,gBAAgB,iHAA6B;AAC7C;AACA,YAAY,yDAAgB;AAC5B,YAAY,wDAAe;AAC3B;AACA,gBAAgB,uGAAwB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sEAAW;AAC3B,mDAAmD,0FAAkB;AACrE;AACA,uCAAuC,uIAAuC;AAC9E,qCAAqC,0FAAkB;AACvD;AACA;AACA,6BAA6B,0FAAkB;AAC/C,wBAAwB,uGAAwB;AAChD;AACA;AACA;AACA,wBAAwB,qFAAkB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,mGAAsB;AAC1C;AACA;AACA;AACA,qCAAqC,4FAAmB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,0FAAkB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mGAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sEAAW;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mGAAsB;AACtC;AACA;AACA;AACA;AACA,0E;;;;;;;;;;;;ACzaA;AAAA;AAAA;AAAA;AAAwD;AACjD;AACP;AACA,wCAAwC,qEAAmB;AAC3D;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,gCAAgC;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uE;;;;;;;;;;;;ACtJA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,2BAA2B,iBAAiB;AAC5C;AACA;AACA;AACA,2BAA2B,iBAAiB;AAC5C;AACA;AACA;AACA,2BAA2B,kCAAkC;AAC7D;AACA;AACA;AACA,2BAA2B,mBAAmB;AAC9C;AACA;AACA;AACA,2BAA2B,8BAA8B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wE;;;;;;;;;;;;AC/BA;AAAA;AAAA;AAAA;AAAqE;AACtB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,mBAAmB,YAAY;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,oDAAoD,iCAAiC;AACrF,sDAAsD,gFAAuC;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,mCAAmC,0DAAW;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kF;;;;;;;;;;;;AC/FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+D;AACJ;AACU;AACW;AACE;AAChB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,mGAAuB;AACxD,wCAAwC,qGAAwB;AAChE,mBAAmB,wFAAkB;AACrC,oBAAoB,wFAAkB;AACtC;AACA;AACA,oCAAoC,2CAA2C,KAAK;AACpF,mBAAmB,YAAY;AAC/B;AACA,2BAA2B,4BAA4B;AACvD,+BAA+B,0BAA0B;AACzD,oBAAoB,kFAAe;AACnC;AACA;AACA;AACA;AACA,gEAAgE,OAAO;AACvE,gBAAgB,kFAAe;AAC/B,aAAa;AACb;AACA,uBAAuB,4BAA4B;AACnD,2BAA2B,mCAAmC;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,oEAAoE,6BAA6B;AACjG,mCAAmC,mCAAmC;AACtE,wBAAwB,8EAAa;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,QAAQ;AAC1E;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,qFAAgB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,+BAA+B,2BAA2B;AAC1D;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,4BAA4B;AACnE;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,uCAAuC,4BAA4B;AACnE;AACA,2CAA2C,0BAA0B;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,oEAAoE,2BAA2B;AAC/F;AACA,mCAAmC,mCAAmC;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uF;;;;;;;;;;;;AC/OA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,uCAAuC;AACtF;AACA;AACA;AACA;AACA;AACA,2DAA2D,iBAAiB;AAC5E;AACA;AACA,6DAA6D,kBAAkB;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,eAAe;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,wBAAwB;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,8BAA8B;AACpF,sDAAsD,6BAA6B;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,kF;;;;;;;;;;;;ACpFA;AAAA;AAAA;AAAsF;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA,kFAAkF,qEAA0B,EAAE,qEAA0B;AACxI;AACA,6GAA6G,qEAA0B,qBAAqB,qEAA0B;AACtL;AACA;AACA;AACA;AACA;AACA;AACA,wGAAwG,qEAA0B,GAAG,qEAA0B;AAC/J;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kF;;;;;;;;;;;;AC5DA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,qFAAgB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uF;;;;;;;;;;;;ACnDA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qE;;;;;;;;;;;;AC/BA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mF;;;;;;;;;;;;ACnBA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA,oDAAoD,qFAAgB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wF;;;;;;;;;;;;AChCA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACO;AACP;AACA;AACA;AACA,oDAAoD,iCAAiC;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qF;;;;;;;;;;;;ACtBA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA,oDAAoD,qFAAgB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0F;;;;;;;;;;;;AChCA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,uE;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAgE;AACzD;AACP;AACA;AACA;AACA;AACA;AACA,YAAY,mFAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA,4E;;;;;;;;;;;;ACbA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qG;;;;;;;;;;;;ACvBA;AAAA;AAAA;AAAA;AAAA;AAAsF;AACH;AACE;AACrF;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8FAA8F,qEAA0B,EAAE,qEAA0B;AACpJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sGAAwB;AACxC;AACA;AACA;AACA,qCAAqC,wGAAyB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oF;;;;;;;;;;;;AClEA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,qFAAgB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yF;;;;;;;;;;;;ACvDA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,mF;;;;;;;;;;;;ACNA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8E;;;;;;;;;;;;AC7CA;AAAA;AAAA;AAAA;AAA2E;AACT;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA,wDAAwD,qFAAgB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8FAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mF;;;;;;;;;;;;ACvCA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uF;;;;;;;;;;;;ACnBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oE;;;;;;;;;;;;ACXA;AAAA;AAAA;AAAA;AAAmE;AACwC;AACpG;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sFAAiB;AACrC;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,8HAAmC;AAC3D;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,qE;;;;;;;;;;;;ACtFA;AAAA;AAAA;AAAqF;AAC9E;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,UAAU;AACjC;AACA,wBAAwB,wGAA2B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2E;;;;;;;;;;;;AC/BA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0E;;;;;;;;;;;;AC1BA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA,oDAAoD,qFAAgB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+E;;;;;;;;;;;;ACvCA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,wF;;;;;;;;;;;;ACNA;AAAA;AAAA;AAAA;AAAmD;AACA;AAC5C;AACP;AACA,2BAA2B,sEAAW;AACtC;AACA;AACA,YAAY,sEAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,UAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,iE;;;;;;;;;;;;ACvBA;AAAA;AAAA;AAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mFAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+E;;;;;;;;;;;;ACtCA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wF;;;;;;;;;;;;ACnFA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,qFAAgB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6F;;;;;;;;;;;;ACrDA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kE;;;;;;;;;;;;ACXA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF;AACrF,6CAA6C,iCAAiC;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,mE;;;;;;;;;;;;AC7CA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4E;;;;;;;;;;;;AC3BA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yF;;;;;;;;;;;;AC3BA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uBAAuB;AACtC;AACA;AACA;AACA,gE;;;;;;;;;;;;ACZA;AAAA;AAAA;AAAsF;AACtF;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA,gFAAgF,qEAA0B,EAAE,qEAA0B;AACtI;AACA;AACA;AACA;AACA;AACA;AACA,yE;;;;;;;;;;;;ACxBA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA,mDAAmD,qFAAgB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8E;;;;;;;;;;;;ACtCA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2E;;;;;;;;;;;;ACTA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4E;;;;;;;;;;;;ACTA;AAAA;AAAA;AAAyD;AAClD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,oEAA2B;AACvE;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oEAA2B;AAC/C;AACA;AACA;AACA;AACA,4CAA4C,oEAA2B;AACvE;AACA;AACA;AACA;AACA;AACA,gBAAgB,oEAA2B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,6E;;;;;;;;;;;;ACpCA;AAAA;AAAA;AAAgE;AACzD;AACP;AACA;AACA;AACA,kBAAkB,oFAAuB;AACzC;AACA;AACA;AACA;AACA,sE;;;;;;;;;;;;ACVA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sF;;;;;;;;;;;;ACTA;AAAA;AAAA;AAA4H;AAC5H;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,+IAA2C;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+E;;;;;;;;;;;;AC3BA;AAAA;AAAA;AAAA;AAAwD;AACU;AAClE;AACA;AACA;AACA;AACA;AACA,uBAAuB,oBAAoB;AAC3C;AACA;AACA,uBAAuB,uBAAuB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sBAAsB;AACzC;AACA;AACA;AACA;AACA,QAAQ,2EAAY;AACpB;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,qFAAgB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oF;;;;;;;;;;;;AC3FA;AAAA;AAAA;AAAqF;AAC9E;AACP;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,UAAU;AACrC;AACA,4BAA4B,wGAA2B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mF;;;;;;;;;;;;AC5BA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oE;;;;;;;;;;;;ACXA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wE;;;;;;;;;;;;ACXA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uE;;;;;;;;;;;;ACXA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,wE;;;;;;;;;;;;ACNA;AAAA;AAAO;AACP;AACA;AACA,qE;;;;;;;;;;;;ACHA;AAAA;AAAO;AACP;AACA;AACA,sE;;;;;;;;;;;;ACHA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,gF;;;;;;;;;;;;ACNA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,2E;;;;;;;;;;;;ACLA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,wE;;;;;;;;;;;;ACLA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,yE;;;;;;;;;;;;ACLA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,qE;;;;;;;;;;;;ACLA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,mF;;;;;;;;;;;;ACLA;AAAA;AAAO;AACP,qE;;;;;;;;;;;;ACDA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wE;;;;;;;;;;;;ACrBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+F;;;;;;;;;;;;ACrBA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mG;;;;;;;;;;;;ACvBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8F;;;;;;;;;;;;ACjBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oG;;;;;;;;;;;;ACTA;AAAA;AAAA;AAAsE;AAC/D;AACP;AACA,gCAAgC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,yFAAkB;AACnC,2DAA2D,oBAAoB;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,cAAc;AACjC,mBAAmB,aAAa;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,qF;;;;;;;;;;;;ACxHA;AAAA;AAAA;AAA2C;AACpC;AACP;AACA;AACA;AACA;AACA,YAAY,sDAAa;AACzB;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0F;;;;;;;;;;;;AC/CA;AAAA;AAAA;AAAqE;AACrE;AACA;AACA;AACO;AACP;AACA;AACA,mBAAmB,uCAAuC,IAAI;AAC9D;AACA;AACA,iCAAiC,gFAAkB,QAAQ,wFAAkB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6F;;;;;;;;;;;;ACjFA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,uE;;;;;;;;;;;;ACjEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAyF;AACE;AACmD;AACf;AACxH;AACP;AACA;AACA;AACA,QAAQ,8GAA4B;AACpC;AACA;AACA;AACA;AACA,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC;AACA,6BAA6B,yJAAmD,QAAQ,iKAAmD;AAC3I,YAAY,kJAA4C;AACxD;AACA;AACA;AACA;AACA,gF;;;;;;;;;;;;ACxBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mF;;;;;;;;;;;;ACTA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6G;AACpB;AACE;AACoD;AACE;AACQ;AACF;AAChJ;AACP;AACA;AACA,QAAQ,8GAA4B;AACpC,QAAQ,gIAAoC;AAC5C;AACA,QAAQ,4GAA2B;AACnC;AACA,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC;AACA;AACA,YAAY,kKAAoD;AAChE;AACA;AACA;AACA,YAAY,oKAAqD;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4KAAyD;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0KAAwD;AACpE;AACA;AACA;AACA;AACA;AACA;AACA,2F;;;;;;;;;;;;ACnDA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oF;;;;;;;;;;;;ACTA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,iF;;;;;;;;;;;;ACzDA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6E;;;;;;;;;;;;ACVA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,yF;;;;;;;;;;;;ACNA;AAAA;AAAA;AAAqH;AAC9G;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,wDAAwD;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wFAAwF,2CAA2C;AACnI;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,gFAAgF,4FAA4F;AAC5K;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,wIAAwC;AAChD;AACA;AACA;AACA,qF;;;;;;;;;;;;ACrHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAsF;AACnB;AACJ;AACJ;AAC6B;AACnB;AACtB;AACxC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,4BAA4B;AACnD;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,wBAAwB,yCAAyC;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,qBAAqB;AACrB;AACA,8DAA8D,qEAA0B;AACxF,qBAAqB;AACrB;AACA,8DAA8D,qEAA0B;AACxF;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,2BAA2B,sFAAiB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,uBAAuB,6BAA6B;AACpD;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,uBAAuB,4BAA4B;AACnD;AACA,2BAA2B,0BAA0B;AACrD;AACA;AACA;AACA,iCAAiC,0DAAW;AAC5C;AACA;AACA,uBAAuB,OAAO;AAC9B;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6CAA6C,2GAA2B;AACxE;AACA;AACA,uBAAuB,wFAAkB;AACzC,wBAAwB,wFAAkB;AAC1C;AACA;AACA;AACA,kCAAkC,OAAO,OAAO,2CAA2C,KAAK;AAChG;AACA;AACA;AACA;AACA;AACA,gEAAgE,6BAA6B;AAC7F;AACA,+BAA+B,mCAAmC;AAClE;AACA;AACA;AACA;AACA;AACA,+CAA+C,4BAA4B;AAC3E;AACA,+BAA+B,gBAAgB;AAC/C,mCAAmC,4BAA4B;AAC/D,uCAAuC,0BAA0B;AACjE,4BAA4B,kFAAe;AAC3C;AACA;AACA;AACA,4EAA4E,OAAO;AACnF,4BAA4B,kFAAe;AAC3C,yBAAyB;AACzB;AACA,mCAAmC,4BAA4B;AAC/D,uCAAuC,mCAAmC;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA,4EAA4E,6BAA6B;AACzG,2CAA2C,mCAAmC;AAC9E,gCAAgC,8EAAa;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA,oGAAoG,QAAQ;AAC5G;AACA;AACA,uCAAuC,4BAA4B;AACnE;AACA,2CAA2C,0BAA0B;AACrE;AACA;AACA;AACA;AACA;AACA,2CAA2C,YAAY;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oEAAoE,4FAA4F;AAChK;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oEAAoE,6BAA6B;AACjG;AACA,mCAAmC,mCAAmC;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2F;;;;;;;;;;;;AC3XA;AAAA;AAAA;AAAA;AAAA;AAA6G;AACpB;AACE;AACpF;AACP;AACA;AACA,QAAQ,8GAA4B;AACpC,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,4GAA2B;AACnC;AACA;AACA;AACA,qF;;;;;;;;;;;;ACfA;AAAA;AAAA;AAA2F;AACpF;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8GAA4B;AACpC;AACA;AACA;AACA,sF;;;;;;;;;;;;AChBA;AAAA;AAAA;AAAA;AAA2F;AACX;AACzE;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,8GAA4B;AACpC;AACA,QAAQ,mGAAuB;AAC/B;AACA;AACA;AACA,wF;;;;;;;;;;;;AChBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6G;AAClB;AAC8D;AACF;AAChJ;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,8GAA4B;AACpC,QAAQ,gIAAoC;AAC5C;AACA;AACA,YAAY,4KAAyD;AACrE;AACA;AACA;AACA,YAAY,0KAAwD;AACpE;AACA;AACA;AACA;AACA;AACA;AACA,uF;;;;;;;;;;;;AC5BA;AAAA;AAAA;AAAwE;AACjE;AACP,4BAA4B,8BAA8B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,8DAA8D,oCAAoC;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,2FAAoB;AACtD;AACA;AACA,6F;;;;;;;;;;;;ACxFA;AAAA;AAAA;AAAA;AAAyF;AACE;AACpF;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8GAA4B;AACpC;AACA;AACA;AACA;AACA,QAAQ,4GAA2B;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,iF;;;;;;;;;;;;ACzCA;AAAA;AAAA;AAAA;AAA2F;AACnB;AACjE;AACP,4BAA4B,sFAAsF;AAClH;AACA,QAAQ,8GAA4B;AACpC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,8DAA8D,iEAAiE;AAC/H;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,2FAAoB;AACtD;AACA;AACA,uF;;;;;;;;;;;;AC1FA;AAAA;AAAA;AAAA;AAA6G;AAClB;AACpF;AACP;AACA;AACA,QAAQ,8GAA4B;AACpC,QAAQ,gIAAoC;AAC5C;AACA;AACA;AACA,6E;;;;;;;;;;;;ACVA;AAAA;AAAA;AAAA;AAA6G;AAClB;AACpF;AACP;AACA;AACA,QAAQ,8GAA4B;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C;AACA;AACA;AACA,2F;;;;;;;;;;;;ACtBA;AAAA;AAAA;AAAA;AAA6G;AAClB;AACpF;AACP;AACA;AACA,QAAQ,8GAA4B;AACpC,QAAQ,gIAAoC;AAC5C;AACA;AACA;AACA,4E;;;;;;;;;;;;ACVA;AAAA;AAAA;AAA2F;AACpF;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,8GAA4B;AACpC;AACA;AACA;AACA,kF;;;;;;;;;;;;ACdA;AAAA;AAAA;AAAA;AAAA;AAAmE;AACX;AACgB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,QAAQ;AAChD;AACA;AACA;AACA;AACA;AACO;AACP,yCAAyC,+EAA+E;AACxH,2BAA2B,sFAAiB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,uBAAuB;AAClD;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,kBAAkB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sBAAsB;AACjD;AACA;AACA,mCAAmC,2EAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,+BAA+B,YAAY;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,eAAe,2FAAoB;AACnC;AACA;AACA,wF;;;;;;;;;;;;ACvIA;AAAA;AAAO;AACP;AACA;AACA,KAAK;AACL;AACA,kG;;;;;;;;;;;;ACLA;AAAA;AAAA;AAA2F;AACpF;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,8GAA4B;AACpC;AACA;AACA,6FAA6F,eAAe;AAC5G;AACA;AACA;AACA;AACA,sG;;;;;;;;;;;;AClBA;AAAA;AAAO;AACP,iCAAiC,cAAc;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,gFAAgF,qBAAqB;AACrG;AACA;AACA;AACA,iG;;;;;;;;;;;;AClBA;AAAA;AAAO;AACP,iCAAiC,mBAAmB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,uG;;;;;;;;;;;;ACrBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4F;;;;;;;;;;;;ACTA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6G;AACpB;AACE;AAC8D;AACF;AAChJ;AACP;AACA;AACA,QAAQ,8GAA4B;AACpC,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C;AACA;AACA;AACA;AACA,YAAY,4GAA2B;AACvC;AACA;AACA;AACA,YAAY,4KAAyD;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0KAAwD;AACpE;AACA;AACA;AACA;AACA;AACA;AACA,kF;;;;;;;;;;;;AClCA;AAAA;AAAA;AAAA;AAAA;AAA6G;AACpB;AACE;AACpF;AACP;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8GAA4B;AACpC,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,gIAAoC;AAC5C,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC;AACA;AACA;AACA,8E;;;;;;;;;;;;AC5BA;AAAA;AAAA;AAAA;AAA2F;AACnB;AACjE;AACP,4BAA4B,sNAAsN;AAClP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8GAA4B;AACpC;AACA;AACA;AACA;AACA;AACA,gFAAgF,kFAAkF;AAClK,mEAAmE,+BAA+B;AAClG,0EAA0E,qCAAqC;AAC/G,0EAA0E,qCAAqC;AAC/G,0EAA0E,qCAAqC;AAC/G,uEAAuE,qCAAqC;AAC5G,uEAAuE,qCAAqC;AAC5G,uEAAuE,qCAAqC;AAC5G;AACA,0EAA0E,iFAAiF;AAC3J;AACA;AACA,+CAA+C,cAAc;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA;AACA;AACA,0EAA0E,eAAe;AACzF,0EAA0E,eAAe;AACzF,uEAAuE,eAAe;AACtF,uEAAuE,eAAe;AACtF,uEAAuE,eAAe;AACtF;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA;AACA,oDAAoD;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,2FAAoB;AACtD;AACA;AACA,oF;;;;;;;;;;;;ACrSA;AAAA;AAAO;AACP,4BAA4B,mCAAmC;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA,qFAAqF,uBAAuB;AAC5G;AACA,2EAA2E,uBAAuB;AAClG;AACA;AACA,gF;;;;;;;;;;;;ACbA;AAAA;AAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,wF;;;;;;;;;;;;ACPA;AAAA;AAAA;AAAA;AAA6G;AAClB;AACpF;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8GAA4B;AACpC,QAAQ,gIAAoC;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA,qF;;;;;;;;;;;;AClCA;AAAA;AAAA;AAAwE;AACjE;AACP;AACA;AACA;AACA;AACA,oCAAoC;AACpC,gDAAgD;AAChD;AACA;AACA;AACA,uBAAuB,gBAAgB;AACvC;AACA;AACA;AACA;AACA,kEAAkE,qCAAqC;AACvG;AACA,8EAA8E,oEAAoE;AAClJ;AACA,6EAA6E,yDAAyD;AACtI,mEAAmE,qCAAqC;AACxG;AACA,+EAA+E,qEAAqE;AACpJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,gBAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,oFAAoF,qCAAqC;AACzH;AACA,gGAAgG,sFAAsF;AACtL,qFAAqF,qCAAqC;AAC1H;AACA,iGAAiG,uFAAuF;AACxL;AACA,6EAA6E,yDAAyD;AACtI,qFAAqF,qCAAqC;AAC1H;AACA,iGAAiG,uFAAuF;AACxL,sFAAsF,qCAAqC;AAC3H;AACA,kGAAkG,wFAAwF;AAC1L;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,2DAA2D;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,mEAAmE,+DAA+D;AAClI;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,aAAa,gCAAgC;AAC7C,iEAAiE,eAAe;AAChF;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,sBAAsB,gCAAgC;AACtD;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,2FAAoB;AACtD;AACA;AACA,2F;;;;;;;;;;;;AC7OA;AAAA;AAAA;AAAA;AAAyF;AACE;AACpF;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf,QAAQ,8GAA4B;AACpC;AACA;AACA;AACA;AACA;AACA,QAAQ,4GAA2B;AACnC,QAAQ,4GAA2B;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mF;;;;;;;;;;;;ACnDA;AAAA;AAAA;AAAA;AAA2F;AACnB;AACjE;AACP,4BAA4B,yCAAyC;AACrE;AACA;AACA,QAAQ,8GAA4B;AACpC,QAAQ,8GAA4B;AACpC,mEAAmE,+BAA+B;AAClG,oEAAoE,gCAAgC;AACpG,oEAAoE,+BAA+B;AACnG,oEAAoE,gCAAgC;AACpG;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,YAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,2FAAoB;AACtD;AACA;AACA,yF;;;;;;;;;;;;ACrKA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uE;;;;;;;;;;;;ACXA;AAAA;AAAA;AAAqE;AACrE;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,uCAAuC,IAAI;AAC9D;AACA;AACA,iCAAiC,gFAAkB,QAAQ,wFAAkB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qF;;;;;;;;;;;;AC3FA;AAAA;AAAA;AAAA;AAAmF;AACE;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sGAAwB;AACxC;AACA;AACA;AACA,qCAAqC,wGAAyB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+E;;;;;;;;;;;;AC3FA;AAAA;AAAA;AAAkE;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,qFAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oF;;;;;;;;;;;;AC7DA;AAAA;AAAA;AAAsF;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,kGAAkG,qEAA0B,EAAE,qEAA0B;AACxJ,kGAAkG,qEAA0B,EAAE,qEAA0B;AACxJ,kGAAkG,qEAA0B,EAAE,qEAA0B;AACxJ,4FAA4F,qEAA0B,EAAE,qEAA0B;AAClJ,4FAA4F,qEAA0B,EAAE,qEAA0B;AAClJ,4FAA4F,qEAA0B,EAAE,qEAA0B;AAClJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2E;;;;;;;;;;;;AC1GA;AAAA;AAAA;AAAA;AAA2E;AACT;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,qFAAgB;AACrE;AACA;AACA,kFAAkF,qCAAqC;AACvH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,yBAAyB;AACzB,uCAAuC,OAAO;AAC9C;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,uFAAuF,qCAAqC;AAC5H;AACA;AACA,+BAA+B,qCAAqC;AACpE;AACA;AACA;AACA;AACA,oFAAoF,qCAAqC;AACzH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,iCAAiC,2BAA2B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wFAAwF,qCAAqC;AAC7H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8FAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gF;;;;;;;;;;;;AC5KA;AAAA;AAAA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6E;;;;;;;;;;;;ACnBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,qE;;;;;;;;;;;;ACPA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,+E;;;;;;;;;;;;ACpBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,gF;;;;;;;;;;;;ACfA;AAAA;AAAA;AAAqE;AAC9D;AACP;AACA;AACA,4BAA4B,gFAAkB,QAAQ,wFAAkB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE;AAClE;AACA;AACA,qGAAqG;AACrG;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,uF;;;;;;;;;;;;ACtCA;AAAA;AAAA;AAA2G;AACpG;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8HAAmC;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,mE;;;;;;;;;;;;AC9BA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kF;;;;;;;;;;;;AC3BA;AAAA;AAAA;AAAA;AAA2E;AACT;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,qFAAgB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8FAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uF;;;;;;;;;;;;AC/CA;AAAA;AAAA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,8CAA8C,+BAA+B,EAAE;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yF;;;;;;;;;;;;ACfA;AAAA;AAAA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2G;;;;;;;;;;;;ACzBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wH;;;;;;;;;;;;ACbA;AAAA;AAAA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,iBAAiB;AAChE;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,yH;;;;;;;;;;;;ACvBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sH;;;;;;;;;;;;ACdA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sH;;;;;;;;;;;;ACbA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2F;;;;;;;;;;;;ACrBA;AAAA;AAAA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,kH;;;;;;;;;;;;ACxCA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,0BAA0B;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sF;;;;;;;;;;;;AChBA;AAAA;AAAA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0F;;;;;;;;;;;;ACbA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6H;;;;;;;;;;;;ACZA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0H;;;;;;;;;;;;AChBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4H;;;;;;;;;;;;ACZA;AAAA;AAAA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,UAAU,0BAA0B,6BAA6B,+BAA+B,iBAAiB;AACvL;AACA;AACA;AACA;AACA;AACA;AACA,sGAAsG,qBAAqB;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mG;;;;;;;;;;;;AClCA;AAAA;AAAA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kG;;;;;;;;;;;;AC1BA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yG;;;;;;;;;;;;AClBA;AAAA;AAAA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sG;;;;;;;;;;;;AClBA;AAAA;AAAO;AACP;AACA;AACA,kF;;;;;;;;;;;;ACHA;AAAA;AAAA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gI;;;;;;;;;;;;AChBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,mG;;;;;;;;;;;;ACvBA;AAAA;AAAA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iG;;;;;;;;;;;;AClCA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iE;;;;;;;;;;;;ACVA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gF;;;;;;;;;;;;AClDA;AAAA;AAAA;AAAA;AAA2E;AACT;AAC3D;AACP;AACA;AACA;AACA;AACA;AACA,yDAAyD,qFAAgB;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,8FAAsB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qF;;;;;;;;;;;;ACvCA;AAAA;AAAO;AACP,0D;;;;;;;;;;;;ACDA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,wG;;;;;;;;;;;;ACtBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,+DAA+D;AAC/H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,0DAA0D;AAC1H;AACA;AACA;AACA;AACA;AACA,0F;;;;;;;;;;;;AC9BA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA,8G;;;;;;;;;;;;ACdA;AAAA;AAAA;AAAwE;AACjE;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,QAAQ,2FAAoB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,kH;;;;;;;;;;;;ACjCA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,2BAA2B,YAAY;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4E;;;;;;;;;;;;AC5BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAO;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACP;AACO;AACA;AACP,iD;;;;;;;;;;;;ACZA;AAAA;AAAA;AAA2C;AACpC;AACP,WAAW,+DAAW;AACtB;AACA,6E;;;;;;;;;;;;ACJA;AAAA;AAAO;AACP;AACA;AACA,2D;;;;;;;;;;;;ACHA;AAAA;AAAO;AACP;AACA;AACA,mE;;;;;;;;;;;;ACHA;AAAA;AAAO;AACP;AACA;AACA,2D;;;;;;;;;;;;ACHA;AAAA;AAAO;AACP;AACA;AACA,wE;;;;;;;;;;;;ACHA;AAAA;AAAO;AACP;AACA;AACA,kE;;;;;;;;;;;;ACHA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,4F;;;;;;;;;;;;ACNA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,iF;;;;;;;;;;;;ACNA;AAAA;AAAA;AAAgF;AACzE;AACP,IAAI,oGAA2B;AAC/B,IAAI,oGAA2B;AAC/B,IAAI,oGAA2B;AAC/B;AACA,kF;;;;;;;;;;;;ACNA;AAAA;AAAO;AACP;AACA,eAAe,eAAe;AAC9B,4BAA4B,OAAO;AACnC;AACA;AACA;AACA;AACA,iCAAiC,OAAO;AACxC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,kF;;;;;;;;;;;;ACjBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA,qE;;;;;;;;;;;;ACNA;AAAA;AAAA;AAA2E;AACpE;AACP,QAAQ,8FAAsB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gG;;;;;;;;;;;;ACVA;AAAA;AAAO;AACP,6DAA6D;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mE;;;;;;;;;;;;ACvBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iE;;;;;;;;;;;;ACjBA;AAAA;AAAA;AAAkF;AAC3E;AACP,gDAAgD,sGAA4B;AAC5E;AACA;AACA,wF;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAA;AAAoD;AAC0C;AACvF;AACP,6BAA6B,+DAAsB;AACnD;AACA;AACA,QAAQ,+DAAsB;AAC9B;AACA,yCAAyC,kHAAkC;AAC3E;AACA;AACA;AACA,gF;;;;;;;;;;;;ACZA;AAAA;AAAO;AACP;AACA,mBAAmB,OAAO;AAC1B;AACA;AACA,uBAAuB,YAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,sE;;;;;;;;;;;;ACZA;AAAA;AAAA;AAAmF;AAC5E;AACP,2BAA2B,uGAA4B;AACvD;AACA;AACA;AACA;AACA,sF;;;;;;;;;;;;ACPA;AAAA;AAAO;AACP,WAAW,QAAQ;AACnB;AACA;AACA,qE;;;;;;;;;;;;ACJA;AAAA;AAAA;AAA2E;AACpE;AACP,QAAQ,8FAAsB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA,qG;;;;;;;;;;;;ACTA;AAAA;AAAA;AACA;AACA,IAAI,8IAA8I;AAC3I;AACP;AACA;AACA,mBAAmB,iBAAiB;AACpC;AACA,uBAAuB,eAAe;AACtC,mDAAmD;AACnD;AACA;AACA;AACA,+BAA+B,uBAAuB;AACtD,wEAAwE;AACxE;AACA,+BAA+B,oBAAoB;AACnD,qEAAqE;AACrE;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA,+D;;;;;;;;;;;;AC1BA;AAAA;AAAA;AAAA;AAA0D;AACL;AAC9C;AACP,WAAW,yEAAc,CAAC,qEAA4B;AACtD;AACA,4E;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAA;AAA2D;AACN;AAC9C;AACP,WAAW,yEAAc,CAAC,sEAA6B;AACvD;AACA,6E;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAA;AAAA;AAAoD;AACS;AACR;AAC9C;AACP,+BAA+B,yEAAc,CAAC,+DAAsB;AACpE,mCAAmC,iFAAkB;AACrD,WAAW,yEAAc;AACzB;AACA,6E;;;;;;;;;;;;ACRA;AAAA;AAAA;AAAA;AAA6C;AACQ;AAC9C;AACP,WAAW,yEAAc,CAAC,wDAAe;AACzC;AACA,mF;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAA;AAA8C;AACO;AAC9C;AACP,WAAW,yEAAc,CAAC,yDAAgB;AAC1C;AACA,uE;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAA;AAA+C;AACM;AAC9C;AACP,WAAW,yEAAc,CAAC,0DAAiB;AAC3C;AACA,wE;;;;;;;;;;;;ACLA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,mE;;;;;;;;;;;;ACPA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uE;;;;;;;;;;;;ACZA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,uE;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAqD;AAC9C,yCAAyC,gEAAuB;AACvE,sE;;;;;;;;;;;;ACFA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,kE;;;;;;;;;;;;ACfA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6D;;;;;;;;;;;;ACVA;AAAA;AAAO;AACP;AACA;AACA,qE;;;;;;;;;;;;ACHA;AAAA;AAAA;AAA4C;AACrC;AACP,WAAW,uDAAc;AACzB;AACA,oE;;;;;;;;;;;;ACJA;AAAA;AAAA;AAAqD;AAC9C;AACP,YAAY,gEAAuB;AACnC;AACA,uE;;;;;;;;;;;;ACJA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,uE;;;;;;;;;;;;ACLA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,WAAW,WAAW;AACtB,6CAA6C,iDAAiD;AAC9F;AACA,qE;;;;;;;;;;;;ACRA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uE;;;;;;;;;;;;ACdA;AAAA;AAAA;AAAA;AAAqD;AAC8B;AAC5E;AACP,QAAQ,gEAAuB;AAC/B;AACA;AACA,IAAI,gEAAuB;AAC3B,IAAI,uGAA4B;AAChC;AACA;AACA,8E;;;;;;;;;;;;ACVA;AAAA;AAAA;AAAA;AAAkE;AACU;AAC5E;AACO;AACP,SAAS,qFAAkB;AAC3B,QAAQ,gGAAyB;AACjC;AACA;AACA,8F;;;;;;;;;;;;ACRA;AAAA;AAAA;AAAA;AAAqD;AAC8B;AAC5E;AACP,SAAS,gEAAuB;AAChC;AACA;AACA,IAAI,gEAAuB;AAC3B,IAAI,uGAA4B;AAChC;AACA;AACA,+E;;;;;;;;;;;;ACVA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,gCAAgC;AAC3C;AACA,0BAA0B,cAAc;AACxC,0BAA0B,gCAAgC;AAC1D;AACA;AACA,oFAAoF,iFAAiF,8GAA8G,GAAG;AAC/Q;AACP;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA,yE;;;;;;;;;;;;AC9BA;AAAA;AAAO;AACP;AACA;AACA,8G;;;;;;;;;;;;ACHA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8G;;;;;;;;;;;;ACTA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,2F;;;;;;;;;;;;ACjCA;AAAA;AAAO;AACP,WAAW,QAAQ;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gG;;;;;;;;;;;;ACVA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sE;;;;;;;;;;;;AClCA;AAAA;AAAA;AACO;AACP;AACA,WAAW,eAAe;AAC1B,wBAAwB,OAAO;AAC/B;AACA,CAAC;AACD,4E;;;;;;;;;;;;ACPA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4E;;;;;;;;;;;;ACVA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA,uBAAuB,YAAY;AACnC;AACA;AACA;AACA;AACA;AACA,sG;;;;;;;;;;;;ACXA;AAAA;AAAA;AAAqE;AAC9D;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,wFAAoB;AAC9C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,2F;;;;;;;;;;;;AChBA;AAAA;AAAA;AAA2E;AACpE;AACP;AACA;AACA;AACA;AACA,sBAAsB,8FAAuB;AAC7C;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,8G;;;;;;;;;;;;ACbA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,+G;;;;;;;;;;;;ACtBA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,4G;;;;;;;;;;;;AChBA;AAAA;AAAA;AAAgE;AACzD;AACP;AACA;AACA;AACA,iCAAiC,mFAAiB;AAClD;AACA;AACA;AACA;AACA;AACA,+CAA+C,gBAAgB;AAC/D;AACA;AACA;AACA,mDAAmD,gBAAgB;AACnE;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,mFAAiB;AACzC;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,KAAK;AACL;AACA,mF;;;;;;;;;;;;ACvEA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,mH;;;;;;;;;;;;ACXA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,kH;;;;;;;;;;;;ACVA;AAAA;AAAA;AAA2E;AACpE;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8FAAuB;AAC7C;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8FAAuB;AAC7C;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8FAAuB;AAC7C;AACA;AACA,KAAK;AACL;AACA,4E;;;;;;;;;;;;ACrCA;AAAA;AAAO;AACP;AACA,4BAA4B;AAC5B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,qE;;;;;;;;;;;;ACbA;AAAA;AAAA;AAA6E;AACtE;AACP;AACA;AACA;AACA,sBAAsB,gGAAwB;AAC9C;AACA;AACA;AACA,KAAK;AACL;AACA,oG;;;;;;;;;;;ACXA,kE;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,iE;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA,+D;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,gE;;;;;;;;;;;ACAA,0F;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,+D;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,+D;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,8D;;;;;;;;;;;ACAA,iE;;;;;;;;;;;ACAA,oE;;;;;;;;;;;ACAA,uE;;;;;;;;;;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAgC;AACG;AACJ;AACQ;AACI;AACS;AACN;AACd;AACQ;AACC;AACR;AACJ;AACQ;AACC;AACR;AACW;AACF;AACO;AACU;AACxB;AACK;AACU;AACF;AACH;AACY;AACzB;AACQ;AACA;AACG;AACC;AACE;AACJ;AACQ;AACR;AACS;AACN;AACT;AACG;AACP;AACG;AACW;AACG;AAClB;AACG;AACG;AACG;AACa;AACG;AACC;AACL;AACG;AACG;AACG;AAClB;AACK;AACU;AACP;AACN;AACQ;AACE;AACN;AACC;AACJ;AACO;AACF;AACC;AACT;AACY;AACJ;AACd;AACS;AACN;AACP;AACG;AACD;AACY;AACJ;AACR;AACK;AACG;AACL;AACG;AACJ;AAClC,0D;;;;;;;;;;;ACnFA,oF;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,oE;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,gE;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA;AACA,oE;;;;;;;;;;;;ACDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA2S;AAChP;AAC4B;AACE;AACN;AACL;AACsB;AACd;AACS;AACX;AACsB;AACS;AAC7B;AACiB;AACE;AACzB;AACA;AACN;AACE;AACmB;AACS;AACT;AACA;AACS;AAClC;AAC2B;AACS;AACL;AACS;AACpC;AACU;AAC8C;AAC/B;AACS;AACZ;AACR;AACS;AACO;AACpC;AACE;AACY;AACF;AACS;AACiB;AAC3C;AAC2B;AACiB;AACS;AACnD;AACE;AACiB;AACuB;AAC9C;AACiB;AACS;AACN;AACE;AACE;AACb;AAC8B;AACb;AACS;AACD;AAC7B;AACQ;AACF;AACC;AACN;AACE;AACmB;AACT;AACN;AACE;AACP;AAC0B;AAC1B;AACM;AAC2C;AACQ;AACV;AACW;AAC3B;AACS;AACM;AACzC;AACgB;AACM;AACc;AACZ;AACC;AACf;AACuB;AACR;AACW;AACX;AACE;AACI;AACF;AACW;AACtB;AACW;AACnB;AAC2B;AAC7B;AACW;AACW;AACmB;AACQ;AACV;AACW;AACnB;AACnB;AACR;AACW;AACP;AACe;AACN;AACW;AACf;AACW;AACjC;AAC2B;AACX;AACS;AACjB;AACS;AACL;AACf;AACiB;AACE;AACc;AACrC;AAC4B;AACS;AACI;AACiC;AACwB;AACE;AACN;AACA;AAClD;AAC0C;AACnD;AACO;AACkE;AACN;AACI;AAC/C;AACF;AACc;AACL;AACvC;AACqF;AACrD;AACJ;AAC3D;AAC4B;AACS;AAClD;AAC2D;AACyB;AACY;AACQ;AACvE;AACyE;AACzC;AACU;AAC9C;AACE;AACZ;AACE;AACV;AACQ;AACF;AACjB;AACY;AACK;AAC0E;AACzE;AACY;AAC0D;AACxE;AAClE;AACA;AACA;AACA;AACmC;AACL;AAC9B,wBAAwB,2FAAqB;AAC7C,eAAe,wEAAY;AAC3B,6CAA6C,wIAA0C;AACvF,oCAAoC,qHAAiC;AACrE,sCAAsC,wHAAmC;AACzE,+BAA+B,0GAA4B;AAC3D,8BAA8B,0GAA4B;AAC1D,iCAAiC,gHAA+B,kBAAkB,iFAAoB;AACtG,6BAA6B,sGAA0B,CAAC,6FAAuB;AAC/E,gCAAgC,8GAA6B,CAAC,6FAAuB,wBAAwB,4EAAc;AAC3H,mCAAmC,mHAAiC,2BAA2B,mFAAkB;AACjH;AACA,yBAAyB,6FAAsB,CAAC,wDAAa;AAC7D;AACA,+BAA+B,yGAA4B,CAAC,gFAAiB;AAC7E,6BAA6B,sGAA0B;AACvD,0BAA0B,gGAAuB;AACjD,2BAA2B,kGAAwB;AACnD,6BAA6B,qGAA0B,CAAC,2GAA6B,CAAC,uEAA4B,4CAA4C,sHAAkC,CAAC,yDAAc,EAAE,2IAA4C,EAAE,6FAAuB,EAAE,mFAAkB,EAAE,qFAAmB,EAAE,iFAAiB,GAAG,iFAAoB,EAAE,yFAAwB,EAAE,wFAAuB,EAAE,uGAA2B,CAAC,iIAAuC,EAAE,yDAAc,EAAE,6FAAuB,EAAE,mFAAkB,EAAE,qFAAmB,oBAAoB,iFAAiB,gCAAgC,oFAAkB,2BAA2B,6FAAuB,EAAE,2EAAc;AAC5sB,gCAAgC,0GAA6B,mDAAmD,iFAAoB;AACjF;AACnD;AACA,qCAAqC,sHAAkC;AACvE,oCAAoC,qHAAiC;AACrE,0CAA0C,mIAAuC,8BAA8B,iFAAoB;AACnI,qDAAqD,4JAAkD;AACvG,+BAA+B,wGAA4B,oCAAoC,wFAAuB,sEAAsE,kIAAuC;AAClL;AACjD,6BAA6B,yGAA2B;AACxD,4BAA4B,kGAAyB;AACrD,yEAAyE,qMAAsE;AAC/I,sEAAsE,+LAAmE;AACzI,wEAAwE,mMAAqE;AAC7I,+DAA+D,gLAA4D;AAC3H,iCAAiC,gHAA8B,uBAAuB,+FAAwB,EAAE,4EAAc;AAC9H,0BAA0B,+FAAuB;AACjD,0CAA0C,oIAAwC,8DAA8D,2LAAiE,yBAAyB,6LAAkE,wCAAwC,uLAA+D,yBAAyB,uLAA+D,2NAA2N,wJAAkD,EAAE,wKAAwD,CAAC,iFAAkB;AACr0B,yBAAyB,6FAAsB,CAAC,wGAA2B,CAAC,+FAAwB;AACpG,4CAA4C,wIAA0C,uDAAuD,mFAAkB;AAC/J,yBAAyB,+FAAuB,CAAC,6GAA8B,CAAC,wEAA6B,6BAA6B,4DAAiB,EAAE,yFAAwB,EAAE,oFAAkC,EAAE,4FAA0C,EAAE,6FAA2C,EAAE,wFAAsC,EAAE,gFAA8B,EAAE,+EAA6B,EAAE,oFAAkC;AAC7b,yCAAyC,+HAAsC,8EAA8E,uFAAuB,oFAAoF,gFAAiB;AACpN;AACrE,wCAAwC,4HAAqC,uBAAuB,sHAAkC,EAAE,iFAAoB,EAAE,uFAAuB,EAAE,yHAAuC,uBAAuB,iFAAkB;AACvQ,qCAAqC,yHAAmC;AACxE,uCAAuC,6HAAqC,kDAAkD,mFAAkB;AAChJ,oCAAoC,oHAAiC,yEAAyE,yFAAwB;AACtK,2BAA2B,gGAAwB,CAAC,mFAAkB;AACtE,8BAA8B,yGAA2B,CAAC,uFAAuB;AACjF,sCAAsC,2HAAoC;AAC1E,wCAAwC,+HAAsC,gCAAgC,mFAAkB;AAChI,qCAAqC,sHAAkC;AACvE,wCAAwC,+HAAsC;AAC9E,0CAA0C,mIAAwC,kCAAkC,mFAAkB;AACtI,uCAAuC,0HAAoC;AAC3E,4CAA4C,wIAA0C;AACtF,uCAAuC,6HAAqC;AAC5E,yCAAyC,iIAAuC,oDAAoD,mFAAkB;AACtJ,sCAAsC,wHAAmC,0JAA0J,gFAAiB;AACpP,uCAAuC,8HAAqC;AAC5E,kCAAkC,kHAAgC,wDAAwD,wFAAuB,EAAE,iFAAkB;AACrK,oCAAoC,sHAAkC,4BAA4B,mFAAkB;AACpH,iCAAiC,6GAA8B;AAC/D,8BAA8B,2GAA4B;AAC1D,gCAAgC,8GAA8B,2CAA2C,mFAAkB;AAC3H,6BAA6B,qGAA0B;AACvD,2CAA2C,sIAAyC,wBAAwB,wFAAuB;AACnI,6CAA6C,yIAA2C,wDAAwD,mFAAkB;AAClK,0CAA0C,gIAAuC,mHAAmH,wFAAuB;AAC3N,+BAA+B,4GAA6B,0CAA0C,mFAAkB;AACxH,4BAA4B,mGAAyB;AACrD,wCAAwC,gIAAsC;AAC9E,uCAAuC,+HAAqC,CAAC,yFAAwB,EAAE,uFAAuB,mCAAmC,wFAAuB;AACxL,wCAAwC,8HAAqC,yEAAyE,oJAA+C;AACrM,oCAAoC,uHAAkC,2DAA2D,mFAAkB;AACnJ,kCAAkC,oHAAgC;AAClE,iCAAiC,8GAA8B;AAC/D,4BAA4B,qGAA0B;AACtD;AACA,2CAA2C,mIAAwC,6IAA6I,gFAAiB;AACjP,mCAAmC,qHAAiC;AACpE,qCAAqC,yHAAmC,gDAAgD,mFAAkB;AAC1I,kCAAkC,gHAA+B,yCAAyC,uFAAuB,2GAA2G,gFAAiB;AAC7P,mDAAmD,uJAAiD;AACpG,wCAAwC,iIAAsC,6CAA6C,uFAAuB,+CAA+C,gEAAS;AAC1M,mCAAmC,sHAAiC,6CAA6C,uFAAuB,0DAA0D,gEAAS,sBAAsB,iFAAkB;AACnP,oCAAoC,wHAAkC,CAAC,iIAAuC,EAAE,uFAAuB,2IAA2I,wFAAuB,EAAE,2IAA4C;AACvV,+BAA+B,6GAA6B;AAC5D,iCAAiC,iHAA+B,iIAAiI,mFAAkB;AACnN,8BAA8B,wGAA2B;AACzD,iCAAiC,iHAA+B;AAChE,gCAAgC,4GAA6B;AAC7D,2CAA2C,qIAAwC,mHAAmH,wFAAuB;AAC7N,qCAAqC,0HAAmC,4DAA4D,wFAAuB;AAC3J,uCAAuC,8HAAqC,kDAAkD,mFAAkB;AAChJ,oCAAoC,qHAAiC;AACrE,qCAAqC,0HAAmC,6BAA6B,mFAAkB;AACvH,kCAAkC,iHAA+B,uBAAuB,uFAAuB;AAC/G,wBAAwB,2FAAqB;AAC7C,yCAAyC,gIAAsC;AAC/E;AACO;AACP,IAAI,uGAA2B,CAAC,wFAAuB,EAAE,wFAAoB,4CAA4C,kFAAiB,CAAC,uEAAgB;AAC3J;AACA;AACA;AACA,wBAAwB,2FAAqB;AACtC,wBAAwB,2FAAqB,oCAAoC,iFAAoB,EAAE,8EAAmB,uHAAuH,2JAAmD,EAAE,kFAAkB;AAC/T,oCAAoC,oHAAiC;AACrE,gDAAgD,kJAA8C;AAC9F,+CAA+C,4IAA4C;AAC3F,oDAAoD,0JAAkD,wBAAwB,wFAAuB;AACrJ,mDAAmD,oJAAgD;AACnG,+CAA+C,gJAA6C;AAC5F,8CAA8C,0IAA2C;AACzF,oDAAoD,2JAAkD,CAAC,uFAAuB;AAC9H,mDAAmD,qJAAgD;AACnG,gCAAgC,2GAA6B,8BAA8B,uFAAuB,EAAE,wFAAuB,EAAE,6EAAkB;AAC5G;AACnD,uCAAuC,2HAAoC;AAC3E,sCAAsC,wHAAmC;AACzE,+BAA+B,yGAA4B,CAAC,iFAAoB;AAChF,yCAAyC,+HAAsC;AAC/E,kCAAkC,+GAA+B,CAAC,iFAAoB;AACtF,0CAA0C,oIAAwC,iDAAiD,iFAAoB,EAAE,uFAAuB,yJAAyJ,wFAAuB;AAChW,qCAAqC,yHAAmC,CAAC,uFAAuB,kFAAkF,wFAAuB;AACzM,0CAA0C,iIAAuC;AACjF,uCAAuC,6HAAqC,oSAAoS,mFAAkB;AAClY;AACA;AACA,IAAI,oHAAiC,wNAAwN,gFAAiB;AAC9Q;AAC2D;AACA;AACE;AACI;AACZ;AACU;AAClB;AAC0B;AAC5B;AACU;AAC4B;AACQ;AACV;AACU;AACzF,uCAAuC,0HAAoC,CAAC,uFAAuB,EAAE,wFAAuB,EAAE,6EAAkB;AAC/E;AACjE,wCAAwC,6HAAqC,CAAC,wFAAuB;AACrG,uBAAuB,yFAAoB,2HAA2H,2JAAmD;AACzN,8CAA8C,yIAA2C,kBAAkB,uFAAuB;AACnD;AAC/E,uCAAuC,2HAAoC,+CAA+C,uFAAuB;AAChF;AACV;AACR;AACI;AACQ;AACJ;AAChD,0BAA0B,gGAAuB,CAAC,wDAAa;AAC/D,uBAAuB,0FAAoB,CAAC,2DAAgB;AAC5D,wBAAwB,4FAAqB,CAAC,4DAAiB;AAC/D,iCAAiC,+GAA8B,CAAC,wDAAa;AAC7E,0BAA0B,iGAAwB,kBAAkB,mKAAsD,wCAAwC,qIAAwC,iCAAiC,+KAA2D,wCAAwC,4HAAoC,iCAAiC,mIAAuC,wCAAwC,oJAA+C,2EAA2E,kJAA8C,+DAA+D,gKAAqD,+DAA+D,2JAAmD,wCAAwC,oHAAgC,UAAU,yMAAuE,iCAAiC,gJAA6C,wCAAwC,8FAAwB;AAC9pC,gD;;;;;;;;;;;;AC/VA;AAAA;AAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uD;;;;;;;;;;;AC1BA,mE;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,0F;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,gE;;;;;;;;;;;ACAA,2D;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,iG;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,0F;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,gE;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,+D;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,iE;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,8F;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,uG;;;;;;;;;;;ACAA,yG;;;;;;;;;;;ACAA,iG;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,6F;;;;;;;;;;;ACAA,qF;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,2D;;;;;;;;;;;ACAA,6D;;;;;;;;;;;ACAA,uD;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,8D;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,6F;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,4G;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,iG;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA,6D;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA,6F;;;;;;;;;;;ACAA,8F;;;;;;;;;;;ACAA,oE;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,0F;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,wE;;;;;;;;;;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAsC;AACI;AACW;AACC;AACA;AACC;AACJ;AACC;AACJ;AACC;AACW;AACC;AACjB;AACQ;AACH;AACQ;AACtB;AACL;AACa;AACQ;AACI;AACQ;AACX;AACQ;AACQ;AAC/B;AACO;AACQ;AACH;AACX;AACe;AACQ;AACH;AACjB;AACQ;AACR;AACM;AACN;AACQ;AACF;AACT;AACH;AACY;AACL;AACM;AACV;AACQ;AACZ;AACc;AACD;AACX;AACa;AACQ;AACH;AACQ;AAClB;AACK;AACQ;AACR;AACQ;AACH;AACQ;AACzB;AACA;AACI;AACS;AACQ;AACH;AACQ;AACX;AACQ;AACH;AACQ;AACrB;AACC;AACC;AACC;AACI;AACC;AACsB;AACN;AACQ;AACzB;AACQ;AACX;AACQ;AACQ;AAClC;AACJ;AACM;AAC0B;AACC;AACd;AACQ;AACH;AACQ;AACI;AACC;AAC9B;AACU;AACC;AACC;AACL;AACE;AACQ;AACC;AACV;AACQ;AACH;AACQ;AACS;AACC;AACxB;AACC;AACa;AACC;AACwB;AACzC;AACiB;AACQ;AACH;AACQ;AAC3B;AACH;AACyB;AACrB;AACC;AACX;AACW;AACQ;AACa;AACC;AAC1B;AACC;AACA;AACQ;AACH;AACQ;AACC;AACJ;AACC;AACI;AACJ;AACC;AACA;AACC;AACJ;AACC;AACJ;AACD;AACgB;AACC;AACjB;AACC;AACQ;AACH;AACQ;AACT;AACQ;AACP;AACR;AACM;AACD;AACD;AACD;AACE;AACD;AACC;AACJ;AACC;AACA;AACC;AACS;AACC;AACjB;AACW;AACC;AACJ;AACC;AACA;AACC;AACL;AACC;AACa;AACC;AACb;AACF;AACG;AACe;AACQ;AACJ;AACQ;AACb;AACQ;AACF;AACQ;AACvB;AACQ;AACH;AACQ;AACL;AACQ;AACtB;AACC;AACR;AACQ;AACQ;AACjB;AACY;AACQ;AACR;AACQ;AACQ;AAC3B;AACY;AACQ;AACX;AACQ;AACQ;AACxB;AACJ;AACQ;AACQ;AACf;AACI;AACF;AACK;AACY;AACQ;AACZ;AACQ;AACF;AACQ;AACd;AACR;AACQ;AACQ;AACf;AACQ;AACQ;AACd;AACQ;AACQ;AACjB;AACQ;AACQ;AACF;AACQ;AACnC;AACO;AACQ;AACQ;AACF;AACQ;AAClB;AACQ;AAChB;AACc;AACQ;AACQ;AAC5B;AACH;AACQ;AACQ;AACV;AACQ;AACQ;AACF;AACQ;AACN;AACQ;AACQ;AACZ;AACQ;AACQ;AACrB;AACQ;AACQ;AACV;AACQ;AACQ;AAC/B;AACY;AACQ;AAC1B;AACQ;AACQ;AACpB;AACQ;AACQ;AACF;AACQ;AACpB;AACQ;AACQ;AACR;AACQ;AACQ;AACnB;AACQ;AACQ;AACF;AACQ;AACxB;AACQ;AACQ;AACF;AACQ;AAClB;AACc;AACd;AACQ;AACX;AACQ;AACQ;AACzB;AACE;AACD;AACY;AACL;AACQ;AACH;AACQ;AAClB;AACiB;AACC;AACX;AACQ;AACR;AACC;AACS;AACC;AACA;AACC;AACM;AACC;AACrB;AACC;AACM;AACQ;AACK;AACR;AAC4B;AAClB;AAC+B;AACC;AACH;AACA;AAC3B;AACuB;AAC5B;AACI;AACiC;AACD;AACE;AACzB;AACD;AACO;AACH;AACpB;AACsC;AACrB;AACF;AAC1C;AACU;AACc;AACL;AACF;AACQ;AACK;AACR;AACnB;AACgC;AACC;AACa;AACC;AACM;AACD;AACC;AACG;AACC;AACvC;AACC;AACL;AAC/C,qD;;;;;;;;;;;AChYA,8E;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,qF;;;;;;;;;;;ACAA,oE;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,mG;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,uG;;;;;;;;;;;ACAA,+F;;;;;;;;;;;ACAA,kG;;;;;;;;;;;ACAA,0F;;;;;;;;;;;ACAA,wG;;;;;;;;;;;ACAA,gG;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,8F;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,iG;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,oE;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,+F;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,oE;;;;;;;;;;;ACAA,6F;;;;;;;;;;;ACAA,qF;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,iE;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,6F;;;;;;;;;;;ACAA,qF;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,+F;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,oE;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,0F;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,iG;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,8D;;;;;;;;;;;ACAA,qF;;;;;;;;;;;ACAA,6E;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,iE;;;;;;;;;;;ACAA,+F;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,mE;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA,gE;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,sG;;;;;;;;;;;ACAA,8F;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,0G;;;;;;;;;;;ACAA,kG;;;;;;;;;;;ACAA,0F;;;;;;;;;;;ACAA,qG;;;;;;;;;;;ACAA,6F;;;;;;;;;;;ACAA,qF;;;;;;;;;;;ACAA,2G;;;;;;;;;;;ACAA,mG;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,gG;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,sE;;;;;;;;;;;ACAA,kF;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,oE;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,+F;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,uF;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,6F;;;;;;;;;;;ACAA,qF;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,2E;;;;;;;;;;;ACAA,wF;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA,+D;;;;;;;;;;;ACAA,iE;;;;;;;;;;;ACAA,gE;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,+E;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,kE;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,yE;;;;;;;;;;;ACAA,0E;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,qF;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,4F;;;;;;;;;;;ACAA,uE;;;;;;;;;;;ACAA,wE;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,2F;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,6F;;;;;;;;;;;ACAA,+G;;;;;;;;;;;ACAA,4H;;;;;;;;;;;ACAA,6H;;;;;;;;;;;ACAA,0H;;;;;;;;;;;ACAA,0H;;;;;;;;;;;ACAA,+F;;;;;;;;;;;ACAA,sH;;;;;;;;;;;ACAA,0F;;;;;;;;;;;ACAA,8F;;;;;;;;;;;ACAA,+H;;;;;;;;;;;ACAA,8H;;;;;;;;;;;ACAA,gI;;;;;;;;;;;ACAA,uG;;;;;;;;;;;ACAA,sG;;;;;;;;;;;ACAA,6G;;;;;;;;;;;ACAA,0G;;;;;;;;;;;ACAA,sF;;;;;;;;;;;ACAA,4H;;;;;;;;;;;ACAA,uG;;;;;;;;;;;ACAA,qG;;;;;;;;;;;ACAA,2D;;;;;;;;;;;ACAA,qE;;;;;;;;;;;ACAA,mF;;;;;;;;;;;ACAA,8E;;;;;;;;;;;ACAA,oF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;ACAA,yF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,8D;;;;;;;;;;;ACAA,8F;;;;;;;;;;;ACAA,+F;;;;;;;;;;;ACAA,4G;;;;;;;;;;;ACAA,6G;;;;;;;;;;;ACAA,mH;;;;;;;;;;;ACAA,kH;;;;;;;;;;;ACAA,mH;;;;;;;;;;;ACAA,sH;;;;;;;;;;;ACAA,uH;;;;;;;;;;;ACAA,gF;;;;;;;;;;;ACAA,iF;;;;;;;;;;;ACAA,4E;;;;;;;;;;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6B;AACE;AACA;AACI;AACL;AACC;AACG;AAClC,mC;;;;;;;;;;;;ACPA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACD;AACvB;AACM;AACa;AAC5D;AACA;AACA;AACA;AACA;AACO,uBAAuB,yEAAa;AAC3C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,oDAAoD,uDAAI,EAAE,wBAAwB;AAClF,0BAA0B,oDAAK;AAC/B;AACA;AACA,SAAS;AACT;AACA,QAAQ,oEAAW;AACnB;AACA,6BAA6B,4BAA4B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM,mEAAmE,KAAK;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;ACvHA;AAAA;AAAA;AAAA;AAAgE;AACxB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,oDAAS;AACtC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;AC9BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACV;AACS;AACxB;AACxC;AACA;AACA;AACA;AACO,kBAAkB,oDAAS;AAClC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,uEAAQ;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+B;;;;;;;;;;;;ACrDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACD;AACR;AACjB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,yEAAa;AAC3C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,qCAAqC,+CAAG,EAAE,wBAAwB;AAClE,0CAA0C,mEAAa;AACvD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;AClDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAuD;AACS;AACxB;AACK;AACP;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,oDAAS;AACpC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,wDAAwD,kDAAQ;AAChE;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,6BAA6B,oDAAS;AACtC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,6DAAI;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,uEAAQ;AAC1D,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;ACzFA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACD;AAC1B;AACtC;AACA;AACA;AACO,wBAAwB,yEAAa;AAC5C;AACA,cAAc,gFAAoB;AAClC;AACA,wDAAwD,kDAAQ;AAChE;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;ACtBA;AAAA;AAAA;AAAA;AAAgE;AACxB;AACxC;AACA;AACA;AACA;AACO,uBAAuB,oDAAS;AACvC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA,6BAA6B,oDAAS;AACtC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;ACrCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACD;AAClC;AACI;AACmB;AACN;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,yEAAa;AAC1C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,sCAAsC,0CAAI;AAC1C;AACA;AACA,SAAS;AACT,yCAAyC,8CAAM;AAC/C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,uDAAI,EAAE,wBAAwB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uDAAI;AACjC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;ACzHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+C;AAC2B;AACV;AACX;AACE;AACV;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,yEAAa;AAC5C;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,+DAAW,EAAE,wBAAwB;AAC7D;AACA;AACA;AACA,qBAAqB,uDAAI;AACzB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,qBAAqB,uDAAI;AACzB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD;AACA,wBAAwB,gFAAoB;AAC5C,wBAAwB,qDAAM;AAC9B;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,2EAAO;AACf,QAAQ,2EAAO;AACf;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;ACzGA;AAAA;AAAA;AAAA;AAAiE;AACD;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,yEAAa;AACxC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;AC/BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACjC;AACO;AACU;AACA;AACF;AACiB;AAChE;AACA;AACA;AACA,8BAA8B;AAC9B,+BAA+B;AAC/B;AACA;AACO,2BAA2B,yEAAa;AAC/C;AACA,cAAc,gFAAoB;AAClC;AACA,uBAAuB,uDAAI,EAAE,wBAAwB;AACrD,wBAAwB,uDAAI,EAAE,wBAAwB;AACtD,yBAAyB,+CAAG,EAAE,wBAAwB;AACtD,6BAA6B,yDAAQ;AACrC;AACA;AACA,SAAS;AACT,0BAA0B,yDAAQ,EAAE,wBAAwB;AAC5D,8BAA8B,yDAAQ;AACtC;AACA;AACA,SAAS;AACT,wCAAwC,4CAAK,EAAE,wBAAwB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;ACnDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACjC;AACO;AACU;AACA;AACe;AAChE;AACA;AACA;AACA;AACA,8BAA8B;AAC9B,+BAA+B;AAC/B;AACA;AACO,2BAA2B,yEAAa;AAC/C;AACA,cAAc,gFAAoB;AAClC;AACA,uCAAuC,4CAAK;AAC5C;AACA;AACA,SAAS;AACT,2BAA2B,+CAAG,EAAE,wBAAwB;AACxD,uBAAuB,yDAAQ;AAC/B;AACA;AACA,SAAS;AACT,iCAAiC,yDAAQ,EAAE,wBAAwB;AACnE,wBAAwB,yDAAQ;AAChC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;ACjDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+C;AACkB;AACD;AACD;AAClB;AACH;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,6BAA6B,yEAAa;AACjD;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,qDAAM;AAC7B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,iCAAiC,qDAAM;AACvC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,uBAAuB,qDAAM;AAC7B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,wBAAwB,qDAAM;AAC9B;AACA;AACA;AACA,SAAS;AACT;AACA,wBAAwB,gFAAoB;AAC5C,gCAAgC,qDAAM;AACtC;AACA;AACA;AACA,SAAS;AACT,iCAAiC,qDAAM;AACvC;AACA;AACA;AACA,SAAS;AACT,qBAAqB,qDAAM;AAC3B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;;;;;;ACxHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAqD;AACY;AACD;AAC9B;AACA;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,yEAAa;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,wCAAwC,8CAAM;AAC9C;AACA;AACA;AACA,SAAS;AACT;AACA,yCAAyC,8CAAM;AAC/C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;AC5DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiD;AACgB;AACD;AACX;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,yEAAa;AACzC;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,uBAAuB,yDAAK;AAC5B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;ACrDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiD;AACgB;AACD;AAC3B;AACrC;AACA;AACA;AACA;AACO,uBAAuB,yEAAa;AAC3C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yDAAK;AAClC;AACA;AACA;AACA,SAAS;AACT,6BAA6B,yDAAK;AAClC;AACA;AACA;AACA,SAAS;AACT,6BAA6B,yDAAK;AAClC;AACA;AACA;AACA,SAAS;AACT,gCAAgC,yDAAK;AACrC;AACA;AACA;AACA,SAAS;AACT,gCAAgC,yDAAK;AACrC;AACA;AACA;AACA,SAAS;AACT,gCAAgC,yDAAK;AACrC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;AChLA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC+B;AAClB;AACA;AACa;AACI;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACO,uBAAuB,yEAAa;AAC3C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,yBAAyB,uDAAI;AAC7B;AACA,SAAS;AACT,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,eAAe,yEAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,oEAAS,yBAAyB,oEAAS;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,YAAY,+DAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,SAAS;AACT;AACA;AACA,eAAe,uDAAS;AACxB,YAAY,+DAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;ACpHA;AAAA;AAAA;AAAA;AAAA;AAA+C;AACkB;AACD;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,mBAAmB,yEAAa;AACvC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,uCAAuC,uDAAI;AAC3C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;ACxHA;AAAA;AAAA;AAAA;AAAiE;AACD;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,yEAAa;AACxC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;AC7BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+C;AACkB;AACD;AACX;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,yEAAa;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,uCAAuC,uDAAI;AAC3C;AACA;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;ACjEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiD;AACgB;AACD;AACX;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,yEAAa;AAC7C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,6BAA6B,yDAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,0BAA0B,yDAAK;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,2BAA2B,yDAAK;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,wBAAwB,yDAAK;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,yBAAyB,yDAAK;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;AClGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACV;AACR;AACC;AACgB;AACC;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,mBAAmB,yEAAa;AACvC;AACA,4BAA4B,gFAAoB;AAChD;AACA,wBAAwB,gFAAoB;AAC5C,6BAA6B,2DAAQ;AACrC;AACA;AACA,SAAS;AACT,uBAAuB,+DAAW;AAClC;AACA,mBAAmB,uEAAQ;AAC3B,SAAS;AACT,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD,uCAAuC,uDAAI,EAAE,wBAAwB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,eAAe,uEAAQ;AACvB;AACA;AACA,yBAAyB,uEAAQ;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;ACtEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACD;AACtB;AACW;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,yEAAa;AAC1C;AACA,4BAA4B,gFAAoB;AAChD;AACA,wBAAwB,gFAAoB;AAC5C,0DAA0D,sDAAU;AACpE;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;ACpDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACvB;AACsB;AACT;AACA;AACF;AACrD;AACA;AACA;AACA;AACO,gCAAgC,yEAAa;AACpD;AACA,4BAA4B,gFAAoB;AAChD;AACA,wBAAwB,gFAAoB;AAC5C,8CAA8C,kEAAY,EAAE,wBAAwB;AACpF,+CAA+C,kEAAY,EAAE,wBAAwB;AACrF,uBAAuB,sDAAU,6BAA6B,wBAAwB;AACtF,wBAAwB,sDAAU,8BAA8B,wBAAwB;AACxF;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6C;;;;;;;;;;;;AClDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACvB;AACsB;AACX;AACM;AACZ;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACO,kCAAkC,yEAAa;AACtD;AACA,4BAA4B,gFAAoB;AAChD;AACA,wBAAwB,gFAAoB;AAC5C,0CAA0C,sEAAc;AACxD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD,uBAAuB,sDAAU,6BAA6B,wBAAwB;AACtF,uBAAuB,sDAAU,6BAA6B,wBAAwB;AACtF,wBAAwB,sDAAU,8BAA8B,wBAAwB;AACxF;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+C;;;;;;;;;;;;AC7EA;AAAA;AAAA;AAAA;AAAA;AAA+C;AACiB;AAC1B;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACO,gCAAgC,kDAAQ;AAC/C;AACA,cAAc,gFAAoB;AAClC;AACA,6BAA6B,uDAAI;AACjC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6C;;;;;;;;;;;;AC/CA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACmB;AACD;AACQ;AACZ;AACO;AACpB;AACc;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO,uBAAuB,yEAAa;AAC3C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,wBAAwB,qDAAM;AAC9B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,qEAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,qEAAQ;AACpB;AACA,gBAAgB,qEAAQ;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oEAAO;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM,8EAA8E,MAAM;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kBAAkB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,+DAAM,CAAC,oEAAO;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA,gCAAgC,2EAAc;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA,wDAAU;AACV,IAAI,kEAAK;AACT;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,cAAc;AAC7B;AACA;AACA;AACA;AACA;AACA,eAAe,kBAAkB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,cAAc;AAC7B;AACA;AACA;AACA;AACA,eAAe,cAAc;AAC7B;AACA;AACA;AACA;AACA;AACA,eAAe,cAAc;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,kBAAkB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA,CAAC;AACD,oC;;;;;;;;;;;;ACjdA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAgE;AAC1B;AACK;AACJ;AACa;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO,gCAAgC,kDAAQ;AAC/C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA,0CAA0C,+CAAG;AAC7C;AACA;AACA,SAAS;AACT,wCAAwC,mDAAK;AAC7C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,6BAA6B,kDAAQ;AACrC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6C;;;;;;;;;;;;AC1FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC+B;AACI;AACL;AACjB;AACE;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,yEAAa;AAC5C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,2BAA2B,6EAAe;AAC1C;AACA;AACA,SAAS;AACT,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,oBAAoB,yDAAI;AACxB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;ACvGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+C;AACkB;AACD;AACD;AACJ;AAC3D;AACA;AACA;AACA;AACO,kBAAkB,yEAAa;AACtC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD;AACA,wBAAwB,gFAAoB;AAC5C,gDAAgD,sEAAc;AAC9D;AACA;AACA;AACA,SAAS;AACT,4BAA4B,uDAAI;AAChC;AACA;AACA;AACA,SAAS;AACT,4BAA4B,uDAAI;AAChC;AACA;AACA;AACA,SAAS;AACT,6BAA6B,uDAAI;AACjC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+B;;;;;;;;;;;;AChFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+C;AACE;AAC+B;AAChB;AACX;AACkB;AACZ;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,iCAAiC,+EAAgB;AACxD;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD,6BAA6B,yDAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,6BAA6B,yDAAK;AAClC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA,eAAe,uEAAW;AAC1B;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,iFAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8C;;;;;;;;;;;;ACvEA;AAAA;AAAA;AAAA;AAAA;AAAsD;AACR;AAC4B;AACnE;AACP;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0FAAiB;AACjB,sD;;;;;;;;;;;;AClCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+C;AACiC;AAChB;AACD;AACV;AACR;AACE;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,yEAAa;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD;AACA,wBAAwB,gFAAoB;AAC5C;AACA,qBAAqB,qDAAM;AAC3B;AACA;AACA;AACA,SAAS;AACT,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT,0BAA0B,qDAAM;AAChC;AACA;AACA;AACA,SAAS;AACT,wBAAwB,qDAAM;AAC9B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM,qDAAqD,KAAK;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,qEAAQ;AACnC;AACA;AACA;AACA,QAAQ,+DAAM,+CAA+C,yBAAyB;AACtF;AACA;AACA;AACA;AACA;AACA,2BAA2B,wBAAwB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iFAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,SAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;ACxJA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACD;AACN;AACV;AAChD;AACA;AACA;AACA;AACA;AACO,gCAAgC,yEAAa;AACpD;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,6CAA6C,sEAAkB;AAC/D;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,yCAAyC,4DAAa;AACtD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6C;;;;;;;;;;;;ACpDA;AAAA;AAAA;AAAA;AAAA;AAAiE;AACD;AACjB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,yEAAa;AAChD;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,SAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;ACvGA;AAAA;AAAA;AAAA;AAA+C;AACiC;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,gCAAgC,yEAAa;AACpD;AACA;AACA;AACA,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD;AACA;AACA;AACA,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD;AACA;AACA;AACA,4BAA4B,uDAAI,EAAE,wBAAwB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iFAAa;AACrB,QAAQ,iFAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6C;;;;;;;;;;;;ACrDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAoC;AACH;AACF;AACI;AACC;AACA;AACF;AACE;AACJ;AACO;AACA;AACE;AACR;AACE;AACF;AACE;AACJ;AACC;AACC;AACK;AACN;AACG;AACU;AACE;AACF;AACT;AACS;AAChB;AACG;AACO;AACK;AACD;AACR;AACnC,iC;;;;;;;;;;;;ACjCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAqC;AAC+B;AACxB;AACU;AACI;AACuB;AACjF;AACA;AACA;AACA,yBAAyB,kEAAY;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,0CAA0C,qEAAe;AACzD,uBAAuB,wDAAO;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,8EAAc;AACtB,4BAA4B,wDAAO;AACnC;AACA,aAAa,qFAAqB;AAClC,4BAA4B,sEAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,IAAI,+DAAS,KAAK,+DAAS;AAC3B;AACA,QAAQ,gDAAO;AACf;AACA;AACA,sCAAsC,OAAO,EAAE,gDAAO,CAAC;AACvD;AACA,qBAAqB,YAAY,qBAAqB;AACtD;AACA,kC;;;;;;;;;;;;ACpEA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACqC;AACc;AAChB;AACnC;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,+DAAS,wBAAwB,+DAAS;AACrE,YAAY,uDAAG;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gDAAO;AACtB,gC;;;;;;;;;;;;ACpFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACL;AACd;AACS;AACG;AACZ;AACW;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO,oBAAoB,wEAAe;AAC1C;AACA,cAAc,2EAAoB;AAClC;AACA;AACA;AACA;AACA,wBAAwB,oDAAI;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,iEAAa;AACvC;AACA;AACA;AACA;AACA;AACA,wBAAwB,2EAAoB;AAC5C;AACA,+BAA+B,sDAAU;AACzC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,gEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,wEAAe;AAC5C,sBAAsB,oDAAI;AAC1B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,wEAAoB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAO;AACP,iC;;;;;;;;;;;;AC1PA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAyC;AACe;AACZ;AACA;AAC5C;AACA;AACA;AACA;AACA;AACO,wBAAwB,oDAAK;AACpC;AACA,cAAc,2EAAoB;AAClC;AACA;AACA;AACA;AACA,2BAA2B,uDAAQ;AACnC;AACA;AACA;AACA;AACA,wBAAwB,2EAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,6BAA6B,oDAAK;AAClC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,eAAe;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,eAAe;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,+DAAO;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;AC5OA;AAAA;AAAA;AAAA;AAAA;AAA6C;AACW;AAChB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,qDAAM;AACtC;AACA,cAAc,2EAAoB;AAClC;AACA,wBAAwB,2EAAoB;AAC5C,uCAAuC,oDAAS;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;AC/DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACL;AACX;AACS;AACV;AACE;AACJ;AACR;AAClC;AACA;AACA;AACO,yBAAyB,wEAAe;AAC/C;AACA,cAAc,2EAAoB;AAClC;AACA;AACA;AACA;AACA,0BAA0B,iEAAa;AACvC;AACA;AACA;AACA,+BAA+B,uDAAQ;AACvC,wBAAwB,2EAAoB;AAC5C,6BAA6B,sDAAU;AACvC;AACA;AACA;AACA,SAAS;AACT,QAAQ,gEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,EAAE,wEAAe;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,iEAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,qDAAE;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;AC3RA;AAAA;AAAA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0BAA0B;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;AC7GA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiD;AACa;AACmB;AAC1C;AACsB;AAClB;AACgB;AACH;AACd;AACa;AACK;AAChB;AACW;AACvB;AACkB;AACY;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACO,wBAAwB,wEAAe;AAC9C;AACA,cAAc,2EAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sEAAa;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,wDAAQ;AACrC;AACA;AACA;AACA,mCAAmC,wEAAgB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2EAAoB;AAC5C;AACA;AACA,0BAA0B,6CAAK;AAC/B;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,QAAQ,gEAAQ;AAChB;AACA;AACA,2CAA2C;AAC3C;AACA;AACA,6BAA6B,wEAAe;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,sDAAU;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,0BAA0B,+DAAc;AACxC;AACA,sBAAsB,sEAAkB;AACxC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,0BAA0B,2EAAoB;AAC9C;AACA,0BAA0B,yDAAS;AACnC,0BAA0B,yDAAS;AACnC,sBAAsB,sEAAkB;AACxC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,+DAAc;AACxC;AACA;AACA,sBAAsB,sEAAkB;AACxC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sDAAU;AACnC;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kEAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA,YAAY,gEAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,yDAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,yDAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sDAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sDAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,kDAAI;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,QAAQ;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA,qDAAO;AACP;AACA;AACA;AACA,oFAAa;AACb,uCAAuC,UAAU;AACjD,CAAC;AACD,qFAAc;AACd;AACA,CAAC;AACD,qC;;;;;;;;;;;;AC5kBA;AAAA;AAAA;AAAyC;AACzC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,oDAAI;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;;;;;;ACpDA;AAAA;AAAA;AAAA;AAA2C;AACO;AAClD;AACA;AACA;AACA;AACO,mCAAmC,8DAAc;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,sDAAU;AACtC,6BAA6B,sDAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,EAAE,8DAAc;AAC/C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF,sDAAU;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kFAAkF,sDAAU;AAC5F;AACA,+EAA+E,sDAAU;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gD;;;;;;;;;;;;AC9FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAqK;AAC9H;AACO;AAC9C;AACA;AACA;AACO;AACP,eAAe,uEAAe;AAC9B;AACA;AACA;AACA;AACO;AACP,eAAe,8EAAsB;AACrC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACO;AACP,IAAI,0DAAM,CAAC,iEAAS,CAAC,2EAAmB;AACxC;AACA,eAAe,2EAAmB;AAClC;AACA;AACA;AACA;AACA;AACA;AACsE;AACtE,wC;;;;;;;;;;;;ACrCA;AAAA;AAAA;AAA0C;AACnC,0BAA0B,qDAAO;AACxC;AACA;AACA;AACA;AACA;AACA,uC;;;;;;;;;;;;ACPA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACO;AACkB;AACH;AACZ;AACY;AACoB;AACF;AAC9B;AACL;AACvC;AACA;AACA;AACA;AACO,sBAAsB,wDAAW;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,uDAAQ;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2EAAoB;AAC5C;AACA;AACA;AACA;AACA,4BAA4B,wEAAkB;AAC9C;AACA,aAAa;AACb;AACA,2BAA2B,oDAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gFAAiB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM,CAAC,8EAAc;AAC7B;AACA;AACA;AACA;AACA,QAAQ,0DAAM,CAAC,8EAAc;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,4EAAsB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,YAAY,0DAAM,CAAC,iEAAS;AAC5B;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,0BAA0B;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gEAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,8EAAc;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,gBAAgB,8EAAc;AAC9B;AACA;AACA;AACA,gBAAgB,2EAAY;AAC5B;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,gBAAgB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;AChdA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA,iD;;;;;;;;;;;;AClCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAyC;AACe;AACX;AACG;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,4DAAa;AACxC;AACA,cAAc,2EAAoB;AAClC;AACA,wBAAwB,2EAAoB;AAC5C;AACA;AACA;AACA,6BAA6B,oDAAK;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,gEAAQ;AAChB;AACA;AACA,6BAA6B,4DAAa;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;ACxDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAwD;AACA;AACgB;AAC1C;AACiC;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,0BAA0B,4DAAa;AAC9C;AACA,cAAc,2EAAoB;AAClC;AACA,yBAAyB,gEAAM,EAAE,wBAAwB;AACzD,0BAA0B,0CAAI,EAAE,wBAAwB;AACxD;AACA;AACA;AACA;AACA,wBAAwB,2EAAoB;AAC5C,QAAQ,oEAAa;AACrB;AACA;AACA;AACA;AACA,6BAA6B,4DAAa;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAAa;AACb,2CAA2C,UAAU;AACrD,CAAC;AACD,6EAAc;AACd;AACA,CAAC;AACD,uC;;;;;;;;;;;;ACnGA;AAAA;AAAA;AAAA;AAAkC;AACU;AACrC,2BAA2B,wDAAW;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;ACtIA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAyC;AACe;AACX;AACG;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,mBAAmB,4DAAa;AACvC;AACA,cAAc,2EAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2EAAoB;AAC5C,wBAAwB,oDAAK;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,gEAAQ;AAChB;AACA;AACA,6BAA6B,4DAAa;AAC1C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;ACxDA;AAAA;AAAA;AAAA;AAAA;AAAgD;AAChB;AACwC;AACxE;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,4DAAa;AAC3C;AACA;AACA;AACA,6BAA6B,4CAAK;AAClC;AACA;AACA,SAAS;AACT,6BAA6B,4CAAK;AAClC;AACA;AACA,SAAS;AACT,6BAA6B,4CAAK;AAClC;AACA;AACA,SAAS;AACT,4BAA4B,4CAAK;AACjC;AACA;AACA,SAAS;AACT,4BAA4B,4CAAK;AACjC;AACA;AACA,SAAS;AACT,4BAA4B,4CAAK;AACjC;AACA;AACA,SAAS;AACT,uBAAuB,4CAAK;AAC5B;AACA;AACA,SAAS;AACT,uBAAuB,4CAAK;AAC5B;AACA;AACA,SAAS;AACT,uBAAuB,4CAAK;AAC5B;AACA;AACA,SAAS;AACT;AACA;AACA,6BAA6B,4DAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAAa;AACb,qCAAqC,UAAU;AAC/C,CAAC;AACD,6EAAc;AACd;AACA,CAAC;AACD,oC;;;;;;;;;;;;ACtFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACiB;AACD;AACE;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,kBAAkB,YAAY;AAC9B;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,IAAI;AACJ;AACA;AACA,IAAI;AACJ;AACA;AACO,gEAAgE,0DAAU;AACjF,WAAW,uDAAS;AACpB;AACA,gCAAgC,0DAAU;AAC1C,4BAA4B,8DAAc;AAC1C,QAAQ,0DAAU;AAClB;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAU;AAClB;AACA;AACA;AACA,mBAAmB,gEAAe;AAClC,KAAK;AACL;AACA,mC;;;;;;;;;;;;ACvDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACkC;AACvB;AACqB;AACd;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,UAAU;AAC9C;AACA;AACA,IAAI;AACJ;AACO,6BAA6B,wDAAO;AAC3C;AACA;AACA;AACA,qBAAqB,qFAAqB;AAC1C,+BAA+B,uFAAyB;AACxD;AACA,4BAA4B,qFAAqB;AACjD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,qFAAqB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA;AACA,uBAAuB,gEAAe;AACtC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;;;;;;ACtFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAyD;AACA;AACD;AACZ;AACE;AACM;AAClB;AACkB;AACpD;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,gEAAe;AAC1C;AACA,cAAc,2EAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2EAAoB;AAC5C,QAAQ,0DAAM,CAAC,iEAAS;AACxB,aAAa,4EAAY;AACzB,gBAAgB,4EAAY;AAC5B;AACA;AACA,0BAA0B,iEAAS;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,uDAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,iEAAS;AACrB;AACA;AACA;AACA;AACA,6BAA6B,gEAAe;AAC5C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,iEAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,iEAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,iEAAS,mBAAmB,iEAAS;AACjD,YAAY,+DAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,kEAAQ;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,kEAAQ;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM,6FAA6F,sBAAsB,IAAI,qBAAqB;AAC1J;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM,sGAAsG,sBAAsB,IAAI,wBAAwB;AACtK;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM,2GAA2G,sBAAsB,IAAI,wBAAwB;AAC3K;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM;AACd;AACA;AACA,QAAQ,0DAAM,8FAA8F,sBAAsB,IAAI,0BAA0B;AAChK;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,mBAAmB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM,uEAAuE,qBAAqB;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM,qEAAqE,qBAAqB;AACxG;AACA;AACA;AACA;AACA;AACA,sBAAsB,qDAAE;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,aAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;AC3bA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACK;AACR;AAC2B;AACF;AACf;AACuB;AACzB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACO,8BAA8B,0CAAI;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,oDAAI;AAC1B,wBAAwB,2EAAoB;AAC5C;AACA;AACA,2BAA2B,6EAAa;AACxC;AACA;AACA,iBAAiB,gEAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,oDAAI;AACzB,oBAAoB,oDAAI;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,0DAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,+DAAO;AAC1C;AACA;AACA,wBAAwB,0DAAU;AAClC;AACA;AACA;AACA,uBAAuB,cAAc;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gEAAQ;AACpB;AACA;AACA;AACA;AACA;AACA,iCAAiC,uBAAuB;AACxD;AACA,+BAA+B,yBAAyB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gEAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,2BAA2B;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM;AACd;AACA,0BAA0B,0DAAU;AACpC,6BAA6B,iCAAiC;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,2BAA2B;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,IAAI;AAC3D;AACA;AACA,sCAAsC,0DAAU;AAChD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD,6DAA6D;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2C;;;;;;;;;;;;AC7WA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+B;AACyB;AACf;AACI;AACO;AACb;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,IAAI;AACJ;AACA;AACO,+BAA+B,0CAAI;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2EAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,qBAAqB,oDAAI;AACzB,oBAAoB,oDAAI;AACxB,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM,0DAA0D,KAAK;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,oDAAI,YAAY,oDAAI;AAClD,YAAY,gEAAQ;AACpB,mDAAmD,gEAAe;AAClE;AACA;AACA,mDAAmD,gEAAe;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;;AClHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAsE;AACxB;AACd;AACoB;AACP;AAC7C;AACA;AACA;AACO,4BAA4B,gEAAe;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,iEAAS;AACrB,gBAAgB,4EAAY,sCAAsC,4CAAK;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,iEAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,iEAAS,4CAA4C,2EAAW;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,eAAe;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,mBAAmB;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,wBAAwB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,wDAAI;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,iEAAS;AACrB;AACA;AACA;AACA,qBAAqB,2EAAW;AAChC;AACA;AACA;AACA,YAAY,iEAAS;AACrB;AACA;AACA;AACA,qBAAqB,2EAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,iBAAiB,2EAAW;AAC5B;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,IAAI,0DAAM,CAAC,iEAAS;AACpB,IAAI,0DAAM,CAAC,iEAAS;AACpB,4CAA4C,2EAAW;AACvD,QAAQ,0DAAM;AACd;AACA,IAAI,0DAAM;AACV;AACA,mEAAmE,4CAAK;AACxE,YAAY,iEAAS;AACrB;AACA;AACA;AACA;AACA,YAAY,iEAAS;AACrB;AACA;AACA;AACA;AACA,QAAQ,4EAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,QAAQ,iEAAS;AACjB;AACA;AACA;AACA;AACA;AACA,aAAa,2EAAW;AACxB,YAAY,iEAAS;AACrB;AACA;AACA;AACA,QAAQ,4EAAY;AACpB;AACA;AACA,aAAa,2EAAW;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;AC7TA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAuC;AACR;AACoB;AACV;AACkB;AACsB;AACc;AAC/F;AACA;AACA;AACO,8BAA8B,0CAAI;AACzC;AACA;AACA,wBAAwB,2EAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,0DAAU;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oDAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,8DAAc;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sEAAkB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,+DAAO;AACvB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,8EAAuB;AAChD;AACA;AACA;AACA,oBAAoB,iEAAS,YAAY,iEAAS,kBAAkB,iEAAS;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,+DAAO,YAAY,gEAAQ,YAAY,gEAAQ,YAAY,iEAAS;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,gDAAgD,iEAAS;AACzD,uCAAuC,iEAAS,2BAA2B,iEAAS;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,2C;;;;;;;;;;;;ACpKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8B;AACI;AACA;AACI;AACN;AACM;AACP;AACG;AACO;AACT;AACU;AACC;AACH;AACP;AACL;AACA;AACC;AACQ;AACT;AACG;AACS;AACH;AACL;AACC;AAC6D;AAC3B;AACnE;AACqC;AACrB;AAChB;AACsC;AACrB;AACjB,iC;;;;;;;;;;;;AChCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC,qCAAqC;AACrC,sCAAsC;AACtC;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACO;AACP;AACA;AACA,uC;;;;;;;;;;;;ACnEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAuC;AACwB;AACZ;AAChB;AACnC;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACO,6BAA6B,+CAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,0DAAK;AACpB;AACA;AACA,QAAQ,0DAAK;AACb;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,iCAAiC,EAAE;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA,iEAAiE,6EAAwB;AACzF;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,8BAA8B,0DAAU;AACxC;AACA,qC;;;;;;;;;;;;AC1NA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAuC;AACI;AACE;AAC7C;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,yDAAc;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,yBAAyB,0DAAU;AACnC;AACA,gC;;;;;;;;;;;;ACxEA;AAAA;AAAA;AAAA;AAAA;AAAuC;AACc;AACrD;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACO,yBAAyB,iEAAkB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,0BAA0B,0DAAU;AACpC;AACA,iC;;;;;;;;;;;;AC5DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAuC;AACF;AACM;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC;AACA;AACO,wBAAwB,uDAAa;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,2BAA2B,WAAW;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yDAAI;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,yBAAyB,0DAAU;AACnC;AACA,gC;;;;;;;;;;;;ACxIA;AAAA;AAAA;AAAA;AAA+B;AAC4C;AAC3E;AACA;AACA;AACO,4BAA4B,0CAAI;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,+DAAO;AACnB;AACA;AACA,iBAAiB,gEAAQ,eAAe,+DAAO;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,gEAAQ;AACzB;AACA;AACA,oBAAoB,iEAAS;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,iEAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,gEAAQ;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;AC1PA;AAAA;AAAA;AAAA;AAAA;AAAuC;AACJ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACO,iCAAiC,+CAAS;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,kCAAkC,0DAAU;AAC5C;AACA,yC;;;;;;;;;;;AC/BA,iC;;;;;;;;;;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA2H;AAC3H;AACA;AACA;AACO;AACP,WAAW,kFAAe;AAC1B;AACA;AACA;AACA;AACO;AACP,WAAW,iFAAc;AACzB;AACA;AACA;AACA;AACO;AACP,WAAW,2FAAwB;AACnC;AACA;AACA;AACA;AACO;AACP,WAAW,oFAAiB;AAC5B;AACA;AACA;AACA;AACO;AACP;AACA;AACA,6C;;;;;;;;;;;;AC/BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,sDAAsD,IAAI,IAAI,IAAI,UAAU,MAAM;AAClF;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,iC;;;;;;;;;;;;ACjDA;AAAA;AAAA;AAAA;AAAsC;AACtC;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,gBAAgB,0DAAW;AAC3B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,gBAAgB,0DAAW;AAC3B;AACA;AACA,SAAS;AACT;AACA;AACA,qC;;;;;;;;;;;;ACxCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+E;AACpB;AAC3D;AACA;AACA;AACA;AACA,8BAA8B,uEAAY,SAAS,sEAAW,SAAS,wEAAa;AACpF;AACO;AACP;AACA;AACA;AACA;AACA,QAAQ,2DAAQ,YAAY,2DAAQ;AACpC;AACA;AACA;AACA;AACA,qBAAqB,2DAAQ;AAC7B;AACA,2CAA2C,UAAU,EAAE;AACvD;AACA;AACA;AACA;AACA,uCAAuC,qBAAqB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,QAAQ,2DAAQ;AAChB;AACA;AACA;AACA;AACA,6BAA6B,oBAAoB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,2DAAQ;AACrC;AACA;AACA;AACA,uBAAuB,iBAAiB;AACxC,gBAAgB,4DAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,0DAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,oC;;;;;;;;;;;;AClGA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACvB;AAC2C;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;AACO,mBAAmB,wEAAe;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kDAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAa;AACb,6BAA6B,UAAU;AACvC,CAAC;AACD,qFAAc;AACd;AACA,CAAC;AACD,gC;;;;;;;;;;;;AC7GA;AAAA;AAAA;AAAA;AAA+B;AACO;AACtC;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,0CAAI;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,0DAAO;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,0DAAO;AACvB;AACA;AACA;AACA,oBAAoB,0DAAO;AAC3B;AACA;AACA;AACA;AACA,mCAAmC,sBAAsB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,SAAS;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;AC/GA;AAAA;AAAA;AAAA;AAAA;AAAsC;AACtC;AACA;AACA;AACO;AACP,QAAQ,0DAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,0DAAO;AACf;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACO;AACP;AACA;AACA,qC;;;;;;;;;;;;AC/BA;AAAA;AAAA;AAAA;AAAA;AAA+B;AACS;AACP;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,+BAA+B,0CAAI;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qDAAM,CAAC,4DAAS;AACxB,QAAQ,qDAAM,CAAC,4DAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,oBAAoB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;;AC1hBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,gC;;;;;;;;;;;;ACnCA;AAAA;AAAA;AAAA;AAAsC;AACA;AACtC;AACA;AACA;AACA;AACO,4BAA4B,kDAAQ;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0DAAW;AACnB,iCAAiC;AACjC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,2BAA2B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;AC7EA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+B;AACmB;AACjB;AACQ;AACzC;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,0CAAI;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sEAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qDAAM;AACd;AACA;AACA;AACA,YAAY,qDAAM,CAAC,iDAAG;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,OAAO;AACvB,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,OAAO;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gDAAE;AACtB;AACA,uCAAuC,QAAQ;AAC/C,4BAA4B,gDAAE;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,iDAAG;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,gDAAE;AAClB;AACA,sCAAsC,2BAA2B;AACjE;AACA,wBAAwB,gDAAE;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,gDAAE,wBAAwB,gDAAE;AACjD;AACA;AACA,qBAAqB,gDAAE;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,gDAAE;AACnC;AACA,oCAAoC,QAAQ;AAC5C,oBAAoB,gDAAE;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;AC9VA;AAAA;AAAA;AAAA;AAAsC;AACP;AAC/B;AACA;AACA;AACO,4BAA4B,0CAAI;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,kDAAQ,EAAE,aAAa;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;ACxCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,4DAA4D;AAC5D;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP,qCAAqC,EAAE;AACvC;AACA,qC;;;;;;;;;;;;ACvDA;AAAA;AAAoD;AACpD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,cAAc;AAChC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAY;AACZ,6C;;;;;;;;;;;;AC/CA;AAAA;AAAA;AAAA;AAA6C;AACO;AAC7C;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;;AAEA;AACA;AACA;AACA,wBAAwB,+BAA+B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,yBAAyB;AAChD;AACA,yBAAyB,wBAAwB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAY;AACZ,qD;;;;;;;;;;;;ACvEA;AAAA;AAAA;AAAA;AAAA;AAAyD;AAChB;AACoB;AACtD,+BAA+B,oEAAa;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,oDAAI;AACpC,sDAAsD,iFAAqB,MAAM,0BAA0B;AAC3G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;;ACvCA;AAAA;AAAoD;AACpD;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAY;AACZ,6D;;;;;;;;;;;;ACjCA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP,6DAA6D,KAAK,KAAK,UAAU;AACjF;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,8C;;;;;;;;;;;;ACvBA;AAAA;AAAA;AAAA;AAAA;AAAoD;AACS;AACrB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,oDAAS;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,0BAA0B,+DAAM;AAChC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,oDAAS;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;ACnEA;AAAA;AAAA;AAAA;AAAA;AAAqD;AACQ;AACrB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,oDAAS;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,2BAA2B,gEAAM;AACjC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,oDAAS;AACtC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;ACxCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACkB;AACM;AACG;AACjB;AACkB;AAChB;AACI;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,8CAAM;AACnC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,6BAA6B,qEAAQ;AACrC;AACA;AACA,SAAS;AACT,+BAA+B,yDAAQ;AACvC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,+BAA+B,uDAAI,EAAE,wBAAwB;AAC7D,6BAA6B,+DAAM;AACnC;AACA;AACA;AACA;AACA,SAAS;AACT,4BAA4B,+DAAM;AAClC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uEAAQ;AACvB;AACA;AACA,0CAA0C,uEAAQ;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;AClIA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAoE;AAClC;AACU;AACiB;AACC;AAChB;AACK;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,8CAAM;AACtC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,+EAAgB;AAChD;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD,0BAA0B,uDAAI,EAAE,wBAAwB;AACxD,wBAAwB,yDAAK;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6BAA6B,+EAAgB;AAC7C;AACA,SAAS;AACT;AACA;AACA,eAAe,+DAAW;AAC1B;AACA;AACA,QAAQ,iFAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;ACpFA;AAAA;AAAA;AAAA;AAAA;AAAmD;AACoB;AAChE;AACA;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0FAAiB;AACjB,8C;;;;;;;;;;;;ACvBA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC2B;AACX;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,8CAAM;AACrC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,2BAA2B,6DAAU;AACrC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;AC5FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAsE;AACT;AACd;AACD;AACI;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,iFAAoB;AAChD;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA,yBAAyB,0DAAG;AAC5B;AACA;AACA;AACA;AACA,SAAS;AACT,yBAAyB,0DAAG;AAC5B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,+BAA+B,yDAAK,EAAE,wBAAwB;AAC9D,+BAA+B,yDAAK,EAAE,wBAAwB;AAC9D;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iFAAoB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;AC5JA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACX;AAChB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,8CAAM;AACtC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,2BAA2B,6DAAU;AACrC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;ACpEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA2D;AACf;AACkB;AACZ;AAClD;AACA;AACA;AACA;AACA;AACO,qBAAqB,yEAAa;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,sEAAS,EAAE,wBAAwB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,uDAAI,EAAE,wBAAwB;AAC5D;AACA;AACA;AACA,gCAAgC,uDAAI,EAAE,wBAAwB;AAC9D;AACA;AACA;AACA,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;ACrEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACe;AACX;AACA;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO,4BAA4B,8DAAc;AACjD;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,8BAA8B,yDAAK;AACnC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,8DAAc;AAC3C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;AC9CA;AAAA;AAAA;AAAA;AAAA;AAA4C;AACM;AAChB;AAClC;AACA;AACA;AACA;AACO,6BAA6B,8CAAM;AAC1C;AACA;AACA;AACA,iCAAiC,uDAAI;AACrC;AACA;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;;;;;;ACjCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACe;AACX;AACR;AACgC;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,0DAAY;AAC1C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,4BAA4B,qDAAM;AAClC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6BAA6B,qFAAiB;AAC9C;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,0DAAY;AACzC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;ACvGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA0E;AACb;AACnB;AACN;AACU;AACJ;AACA;AACmB;AACgB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,+BAA+B,qDAAM;AAC5C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,yBAAyB,wFAAkB;AAC3C;AACA;AACA,SAAS;AACT,2BAA2B,wEAAU;AACrC;AACA;AACA;AACA,SAAS;AACT,iCAAiC,yDAAQ,EAAE,wBAAwB;AACnE,mCAAmC,yDAAQ,EAAE,wBAAwB;AACrE,2BAA2B,qDAAM,EAAE,wBAAwB;AAC3D,wBAAwB,+CAAG,EAAE,wBAAwB;AACrD,iCAAiC,qFAAiB,EAAE,wBAAwB;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,qDAAM;AACnC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;;ACvFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACe;AACrB;AACE;AACkC;AAC1B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,0DAAY;AAC1C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,4BAA4B,qDAAM;AAClC;AACA;AACA;AACA,SAAS;AACT,kCAAkC,mDAAK;AACvC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6BAA6B,uFAAkB;AAC/C;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,0DAAY;AACzC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;ACjGA;AAAA;AAAA;AAAA;AAAA;AAA0C;AACK;AACG;AAClD;AACA;AACA;AACO,wBAAwB,qDAAM;AACrC;AACA;AACA;AACA,wBAAwB,0DAAG;AAC3B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;AC5EA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC+B;AACA;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,8CAAM;AACzC;AACA;AACA;AACA,iCAAiC,4EAAY,EAAE,wBAAwB;AACvE,iCAAiC,4EAAY,EAAE,wBAAwB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;ACjDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACe;AACd;AACL;AACQ;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACO,qBAAqB,0DAAY;AACxC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,yBAAyB,0DAAG;AAC5B;AACA;AACA;AACA;AACA,SAAS;AACT,yBAAyB,0DAAG;AAC5B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,qBAAqB,qDAAM;AAC3B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,0DAAY;AACzC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,uBAAuB,YAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;ACtHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAgE;AACH;AACf;AACJ;AACQ;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,4EAAqB;AACxD;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,8BAA8B,yDAAK;AACnC;AACA;AACA,SAAS;AACT,+BAA+B,yDAAK;AACpC;AACA;AACA,SAAS;AACT,kCAAkC,yDAAK;AACvC;AACA;AACA,SAAS;AACT,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,4EAAqB;AAClD;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;ACjEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkD;AACW;AACd;AACD;AACa;AACjB;AACQ;AACkB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,8DAAc;AAC9C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,8BAA8B,qDAAM,EAAE,wBAAwB;AAC9D,2BAA2B,yDAAK;AAChC;AACA;AACA,SAAS;AACT,yBAAyB,0DAAG;AAC5B;AACA;AACA;AACA;AACA,SAAS;AACT,2BAA2B,yDAAK;AAChC;AACA;AACA,SAAS;AACT,yBAAyB,0DAAG;AAC5B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,8BAA8B,sEAAS,EAAE,wBAAwB;AACjE,iCAAiC,0DAAG;AACpC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,kCAAkC,yDAAK;AACvC;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,8DAAc;AAC3C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,uFAAwB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,uFAAwB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;AC3IA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACiB;AACP;AACiB;AACrB;AACN;AAC8B;AAClB;AACG;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,8CAAM;AAClC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA,gCAAgC,2EAAc;AAC9C,+BAA+B,mDAAK,EAAE,UAAU;AAChD,+BAA+B,mDAAK,EAAE,UAAU;AAChD,8BAA8B,8DAAK,EAAE,UAAU;AAC/C;AACA;AACA,iCAAiC,uDAAI,EAAE,UAAU;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,yDAAI;AAChD;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;AC9GA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAsF;AAC3B;AACR;AACP;AACO;AACD;AAClD;AACA;AACA;AACO,2BAA2B,yEAAa;AAC/C;AACA;AACA;AACA,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD;AACA;AACA;AACA,yCAAyC,sEAAS;AAClD;AACA;AACA,SAAS;AACT;AACA,0BAA0B,8DAAK,EAAE,qCAAqC;AACtE,0BAA0B,8DAAK,EAAE,qCAAqC;AACtE;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iFAAa;AACrB,QAAQ,2EAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iFAAa;AACrB,QAAQ,2EAAO;AACf;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;AC5DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACJ;AACE;AACM;AACC;AACA;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,mCAAmC,0DAAY;AACtD;AACA;AACA,4BAA4B,qDAAM;AAClC;AACA;AACA;AACA,SAAS;AACT,8BAA8B,uDAAI,EAAE,wBAAwB;AAC5D,8BAA8B,uDAAI,EAAE,wBAAwB;AAC5D,kCAAkC,8DAAK,EAAE,qCAAqC;AAC9E,kCAAkC,8DAAK,EAAE,qCAAqC;AAC9E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,0DAAY;AACzC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gD;;;;;;;;;;;;AC1DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAwD;AACd;AACI;AACA;AACe;AACX;AACM;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,mEAAa;AAChD;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,yBAAyB,qDAAM;AAC/B;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB,qCAAqC,yDAAQ;AAC7C;AACA;AACA,SAAS;AACT,sCAAsC,yDAAQ;AAC9C;AACA;AACA,SAAS;AACT,4BAA4B,yDAAQ,EAAE,wBAAwB;AAC9D;AACA;AACA,kCAAkC,yDAAQ,EAAE,wBAAwB;AACpE;AACA,QAAQ,2EAAO;AACf;AACA,6BAA6B,yDAAQ,EAAE,wBAAwB;AAC/D;AACA;AACA;AACA;AACA;AACA,6BAA6B,mEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;AChEA;AAAA;AAAA;AAAA;AAA8D;AACZ;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oCAAoC,0EAAoB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,iD;;;;;;;;;;;;AC3BA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACC;AACH;AACF;AACmB;AACX;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,0DAAY;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,yBAAyB,0DAAG;AAC5B;AACA;AACA;AACA;AACA,SAAS;AACT,yBAAyB,0DAAG;AAC5B;AACA;AACA;AACA;AACA,SAAS;AACT,+BAA+B,uDAAI,EAAE,wBAAwB;AAC7D,+BAA+B,uDAAI,EAAE,wBAAwB;AAC7D,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT,yBAAyB,qDAAM;AAC/B;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,0DAAY;AACzC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;AClIA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC2B;AACd;AACD;AACI;AAClD;AACA;AACA;AACA;AACA;AACO,sBAAsB,8CAAM;AACnC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,8BAA8B,yDAAK;AACnC;AACA;AACA;AACA,SAAS;AACT,wBAAwB,0DAAG;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;AC5DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6B;AACA;AACH;AACG;AACD;AACH;AACI;AACG;AACG;AACR;AACA;AACK;AACH;AACJ;AACA;AACO;AACN;AACA;AAC1B,iC;;;;;;;;;;;;AClBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAwC;AAC0B;AACL;AACf;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO,mBAAmB,6EAAe;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,0BAA0B,oDAAS;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,6BAA6B,6EAAe;AAC5C;AACA,sBAAsB,yDAAI;AAC1B;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;ACnKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAgD;AACgB;AACS;AACd;AACoB;AACvC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,KAAK,qCAAqC;AAC9C,KAAK;AACL;AACA;AACA;AACO,mBAAmB,oDAAS;AACnC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,0BAA0B,sEAAa;AACvC;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA,gBAAgB,oEAAO;AACvB;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6BAA6B,oDAAS;AACtC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,sEAAU;AAC/B;AACA,yBAAyB,sEAAU;AACnC;AACA;AACA,yBAAyB,sEAAU;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,2DAAU;AAC1C;AACA;AACA;AACA,gCAAgC,2DAAU;AAC1C;AACA;AACA;AACA,4BAA4B,2DAAU;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA,gCAAgC,2EAAkB;AAClD,6BAA6B,2DAAU;AACvC;AACA;AACA;AACA;AACA;AACA,oBAAoB,sEAAS;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,sEAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,oDAAS;AACtC;AACA;AACA;AACA;AACA,wBAAwB,oDAAS;AACjC;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,2DAAU;AACzC;AACA,SAAS;AACT;AACA;AACA;AACA,YAAY,qEAAQ;AACpB;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oEAAO,YAAY,sEAAS;AAChD;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2DAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2DAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gC;;;;;;;;;;;;AC9YA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8B;AACwB;AACO;AACf;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACO,sBAAsB,0CAAI;AACjC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA,wBAAwB,0EAAgB;AACxC;AACA;AACA;AACA,6BAA6B,0CAAI;AACjC;AACA;AACA,sBAAsB,yDAAI;AAC1B,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0EAAgB;AACxC;AACA;AACA,mC;;;;;;;;;;;;AClEA;AAAA;AAAA;AAAA;AAA4C;AACF;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,6DAAK;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mBAAmB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA,oBAAoB;AACpB;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,IAAI,+DAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;;ACpKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAgD;AAC6B;AAClB;AAC7B;AACU;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO,uBAAuB,oDAAS;AACvC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,yBAAyB,0CAAI;AAC7B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,0EAAc,CAAC,oDAAS;AACrD;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2DAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,oBAAoB,qEAAQ;AAC5B,wBAAwB,oEAAO;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,oEAAO;AACvB;AACA;AACA;AACA,sCAAsC,2DAAU;AAChD;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2DAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;ACtPA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAiC;AACiC;AAClB;AACyB;AAC3B;AACa;AACE;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACO,wBAAwB,6EAAe;AAC9C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,0BAA0B,sEAAa;AACvC;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,6EAAe;AAC5C,sBAAsB,yDAAI;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,qEAAQ;AACnD;AACA,wBAAwB,qEAAQ;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yFAAyF,SAAS;AAClG,uCAAuC,2DAAU;AACjD;AACA,yCAAyC,2DAAU;AACnD,0GAA0G,2DAAU;AACpH;AACA;AACA,0FAA0F,2DAAU;AACpG;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,SAAS;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sEAAU;AACzB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,sEAAS;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2DAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2DAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;AC5SA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAuB;AACA;AACG;AACC;AACC;AAC5B,iC;;;;;;;;;;;;ACLA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAuD;AAC7B;AACA;AACiB;AACsB;AAC3B;AACkB;AACxD;AACA;AACA;AACA;AACA;AACO,YAAY,+DAAU,YAAY,+DAAU;AACnD;AACA;AACA;AACA;AACA;AACO,kBAAkB,+DAAU,kBAAkB,+DAAU;AAC/D;AACA;AACA;AACA;AACA;AACO,kBAAkB,+DAAU;AACnC;AACA;AACA;AACA;AACA;AACO,oBAAoB,+DAAU;AACrC;AACA;AACA;AACA;AACO,iBAAiB,+DAAU;AAClC;AACA;AACA;AACA;AACA;AACO,aAAa,+DAAU;AAC9B;AACA;AACA;AACA;AACA;AACO,gBAAgB,+DAAU;AACjC;AACA;AACA;AACA;AACA;AACO,eAAe,6EAAe,aAAa,6EAAe;AACjE;AACmE;AACC;AAC7D,eAAe,6EAAe;AAC9B,gBAAgB,+EAAgB;AAChC,qBAAqB,gFAAgB;AAC5C,iC;;;;;;;;;;;;AC5DA;AAAA;AAAA;AAAA;AAAA;AAAoD;AACS;AACT;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,gEAAe;AAC5C;AACA,cAAc,gFAAoB;AAClC;AACA,oCAAoC,+DAAW;AAC/C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;ACpCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA0C;AACF;AACE;AACQ;AACH;AACF;AACC;AAC0C;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,sDAAU;AACxC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,0BAA0B,oDAAS;AACnC;AACA;AACA,SAAS;AACT,0BAA0B,oDAAS;AACnC;AACA,SAAS;AACT,+BAA+B,yDAAQ;AACvC;AACA;AACA;AACA,SAAS;AACT,4BAA4B,0DAAG;AAC/B;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,gCAAgC,uDAAI;AACpC;AACA;AACA;AACA,SAAS;AACT;AACA,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT,0BAA0B,qDAAM;AAChC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qEAAS,CAAC,sDAAU;AACnC;AACA;AACA;AACA,oBAAoB,qEAAS,CAAC,0EAAc,CAAC,oDAAS,4BAA4B,sDAAU;AAC5F;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,oBAAoB,qEAAS,CAAC,0EAAc,CAAC,oDAAS,4BAA4B,sDAAU;AAC5F;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;AC3IA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACf;AACM;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,sBAAsB,gEAAe;AAC5C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,mCAAmC,yDAAQ;AAC3C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,gEAAe;AAC5C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;AC5CA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAqD;AACS;AACD;AACX;AAClD;AACA;AACA;AACO,yBAAyB,yEAAa;AAC7C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,yCAAyC,gEAAM;AAC/C;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,WAAW;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;ACpHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAmC;AACqB;AACgB;AACtB;AACR;AACV;AAC0B;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,4CAAK;AACxC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,eAAe,qEAAS,CAAC,sDAAU,gBAAgB,4CAAK;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AACA,uDAAuD,mEAAc;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAU;AACV,IAAI,kEAAK;AACT;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA,yC;;;;;;;;;;;;ACpEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA0D;AACN;AACR;AACkB;AAC0B;AAC1C;AACA;AACN;AACE;AACuB;AACvB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,uDAAU;AAC1C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,0BAA0B,qDAAM;AAChC;AACA;AACA;AACA,SAAS;AACT,6BAA6B,qDAAM;AACnC;AACA;AACA,SAAS;AACT,8BAA8B,uDAAI;AAClC;AACA;AACA,SAAS;AACT,6BAA6B,+DAAM;AACnC;AACA;AACA;AACA;AACA,SAAS;AACT,uBAAuB,yBAAyB;AAChD,4BAA4B,4EAAY;AACxC;AACA;AACA;AACA;AACA,+DAA+D,yDAAI;AACnE;AACA,aAAa;AACb;AACA;AACA,6BAA6B,yDAAQ;AACrC;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,qCAAqC,mDAAK;AAC1C;AACA;AACA;AACA,SAAS;AACT,4BAA4B,qEAAQ;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qEAAS,CAAC,uDAAU;AACnC,oCAAoC,0EAAc,CAAC,qEAAQ,4BAA4B,yEAAa;AACpG;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;ACrMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA0C;AACI;AACF;AACc;AACI;AACpB;AAC2B;AAC3B;AACV;AACkB;AAC2B;AAC7E;AACA;AACA;AACO,8BAA8B,sDAAU;AAC/C;AACA,cAAc,iFAAoB;AAClC;AACA,wBAAwB,iFAAoB;AAC5C,4BAA4B,4CAAK;AACjC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,8BAA8B,4CAAK;AACnC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,6BAA6B,qDAAM;AACnC;AACA;AACA,SAAS;AACT,0BAA0B,qDAAM;AAChC;AACA;AACA;AACA,SAAS;AACT,+BAA+B,yDAAQ;AACvC;AACA;AACA;AACA,SAAS;AACT,mCAAmC,uDAAI;AACvC;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,sDAAU;AACvC;AACA,sCAAsC,2EAAc,CAAC,gFAAc;AACnE,+BAA+B,qDAAM;AACrC;AACA;AACA;AACA;AACA,aAAa;AACb,oCAAoC,2EAAc,CAAC,qEAAQ,4BAA4B,yEAAa;AACpG;AACA;AACA;AACA;AACA,aAAa;AACb,sCAAsC,2EAAc,CAAC,gFAAc;AACnE,+BAA+B,qDAAM;AACrC;AACA;AACA;AACA;AACA,aAAa;AACb,8CAA8C,2EAAc,CAAC,qEAAQ,4BAA4B,yEAAa;AAC9G;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2C;;;;;;;;;;;;ACzHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA4E;AAClB;AACN;AACyB;AAC3B;AACI;AACe;AAC3B;AACkC;AACd;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO,wBAAwB,iEAAU;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,8BAA8B,gFAAc;AAC5C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,0BAA0B,+DAAM,gCAAgC,wBAAwB;AACxF,kCAAkC,uFAAiB,wCAAwC,wBAAwB;AACnH,4BAA4B,uFAAiB,kCAAkC,wBAAwB;AACvG;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,iEAAU;AACvC,oCAAoC,0EAAc,CAAC,qEAAQ,4BAA4B,yEAAa;AACpG;AACA;AACA;AACA;AACA,aAAa;AACb,kCAAkC,0EAAc,CAAC,+DAAM,4BAA4B,yEAAa;AAChG;AACA;AACA;AACA,aAAa;AACb,0CAA0C,0EAAc,CAAC,uFAAiB,4BAA4B,yEAAa;AACnH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,sCAAsC,0EAAc,CAAC,gFAAc,4BAA4B,qDAAM;AACrG;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;AChHA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAmC;AACqB;AACK;AACf;AACQ;AACH;AACnD;AACA;AACA;AACO,yBAAyB,iEAAU;AAC1C;AACA,cAAc,gFAAoB;AAClC,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA,6BAA6B,iEAAU;AACvC;AACA,uBAAuB,yDAAI;AAC3B;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,mEAAc;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA,sC;;;;;;;;;;;;AClFA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA4E;AACC;AACrC;AACE;AACoB;AACJ;AAChB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,sDAAU;AAC1C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,yBAAyB,mDAAK;AAC9B;AACA,SAAS;AACT,4BAA4B,uFAAiB;AAC7C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,6BAA6B,sDAAU;AACvC,oCAAoC,0EAAc,CAAC,qEAAQ,4BAA4B,yEAAa;AACpG;AACA;AACA,aAAa;AACb,iCAAiC,0EAAc,CAAC,mDAAK,4BAA4B,qDAAM;AACvF;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;AC1FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA0E;AACxB;AACW;AACrB;AACE;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,sDAAU;AAC1C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,0BAA0B,mDAAK;AAC/B;AACA;AACA,SAAS;AACT;AACA,yBAAyB,qFAAiB;AAC1C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qEAAS,CAAC,sDAAU;AACnC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;AC/EA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AAC0C;AAC7B;AACjB;AACV;AACkB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,gBAAgB;AAC9B;AACA;AACA;AACA;AACO,wBAAwB,sDAAU;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA,QAAQ,+DAAM,EAAE,qEAAQ;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,sDAAU;AACvC;AACA,uBAAuB;AACvB,mBAAmB,4CAAK;AACxB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,YAAY,6DAAI;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,yDAAS;AAC1C;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,yDAAS;AAC1C,oDAAoD,iBAAiB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oEAAO;AACnB,YAAY,+DAAM,CAAC,oEAAO;AAC1B;AACA,2BAA2B,kBAAkB;AAC7C;AACA;AACA,gBAAgB,+DAAM;AACtB;AACA;AACA;AACA;AACA;AACA,YAAY,+DAAM;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,iCAAiC,0EAAc;AAC/C;AACA,uBAAuB,qEAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,QAAQ;AAC7C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qC;;;;;;;;;;;;AC1SA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAmC;AACiC;AACA;AACZ;AACK;AACf;AACqB;AACb;AACe;AAClB;AACP;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACO,sBAAsB,iEAAU;AACvC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA,YAAY,gEAAM,CAAC,mEAAM;AACzB,oBAAoB,qEAAQ,mFAAmF,KAAK;AACpH,gBAAgB,mEAAM;AACtB;AACA,gCAAgC,mEAAc;AAC9C;AACA;AACA,qBAAqB,qEAAQ;AAC7B;AACA;AACA;AACA,SAAS;AACT,4BAA4B,+EAAgB;AAC5C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iEAAU;AACvC;AACA;AACA;AACA,oBAAoB,yDAAI;AACxB,qBAAqB,yDAAI;AACzB;AACA,oBAAoB;AACpB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,KAAK;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mEAAc;AAC3C;AACA;AACA;AACA;AACA,iCAAiC,uFAAwB;AACzD;AACA,+BAA+B,gFAAgB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,iBAAiB,oEAAO;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mEAAc;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oEAAO;AACnB,YAAY,gEAAM,CAAC,oEAAO;AAC1B;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,gEAAM,CAAC,mEAAM,2DAA2D,KAAK;AACrF,YAAY,mEAAM;AAClB;AACA,4BAA4B,mEAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA,mC;;;;;;;;;;;;AC9PA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA4E;AAClB;AACI;AACe;AAC3B;AACmB;AAC3B;AACA;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,sDAAU;AACrC;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,8BAA8B,gFAAc;AAC5C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,4BAA4B,uFAAiB;AAC7C;AACA,SAAS;AACT;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,sDAAU;AACvC,oCAAoC,0EAAc,CAAC,qEAAQ,4BAA4B,yEAAa;AACpG;AACA;AACA;AACA;AACA,aAAa;AACb,sCAAsC,0EAAc,CAAC,gFAAc,gCAAgC,qDAAM;AACzG;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;AC1FA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA0B;AACC;AACD;AACG;AACG;AACJ;AACC;AACA;AACD;AACF;AACF;AACxB,iC;;;;;;;;;;;;ACXA;AAAA;AAAA;AAAA;AAAkD;AACR;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,kBAAkB,8DAAc;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,sDAAU;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+B;;;;;;;;;;;;ACjDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8D;AAClB;AACiB;AAC3B;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,kBAAkB,8CAAM;AAC/B;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA;AACA;AACA;AACA,wBAAwB,uDAAI,EAAE,wBAAwB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iFAAa;AACrB;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+B;;;;;;;;;;;;AC/CA;AAAA;AAAA;AAAA;AAAkD;AACR;AAC1C;AACA;AACA;AACA;AACA;AACO,0BAA0B,8DAAc;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sDAAU;AACnC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uC;;;;;;;;;;;;ACpCA;AAAA;AAAA;AAAA;AAAkD;AACR;AAC1C;AACA;AACA;AACA;AACA;AACO,0BAA0B,8DAAc;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sDAAU;AACnC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uC;;;;;;;;;;;;ACpCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACvB;AACJ;AACkB;AACF;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,0BAA0B,8CAAM;AACvC;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA,wBAAwB,gFAAoB;AAC5C,0CAA0C,kDAAQ;AAClD;AACA;AACA,SAAS;AACT,sCAAsC,gEAAe,EAAE,wBAAwB;AAC/E;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uC;;;;;;;;;;;;AC3CA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkD;AACZ;AACI;AACmB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,8BAA8B,8DAAc;AACnD;AACA,4BAA4B,gFAAoB;AAChD;AACA,yCAAyC,sDAAU;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT,uCAAuC,kDAAQ;AAC/C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2C;;;;;;;;;;;;AC1CA;AAAA;AAAA;AAAA;AAAA;AAA4C;AACiB;AAC3B;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,8CAAM;AACpC;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,oDAAoD,uDAAI;AACxD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;AClDA;AAAA;AAAA;AAAA;AAAsC;AACY;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,8DAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,kDAAQ;AACrC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,OAAO;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;ACtCA;AAAA;AAAA;AAAA;AAAA;AAA0C;AACmB;AACX;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,kBAAkB,8DAAc;AACvC;AACA,4BAA4B,gFAAoB;AAChD;AACA,wBAAwB,gFAAoB;AAC5C,8DAA8D,sDAAU;AACxE;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,6BAA6B,8DAAc;AAC3C;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+B;;;;;;;;;;;;ACzDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACjC;AACU;AACY;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,8DAAc;AACzC;AACA,4BAA4B,gFAAoB;AAChD;AACA,wBAAwB,gFAAoB;AAC5C,sCAAsC,kDAAQ;AAC9C;AACA;AACA,SAAS;AACT,sCAAsC,wCAAG;AACzC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,6BAA6B,8DAAc;AAC3C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iC;;;;;;;;;;;;ACxEA;AAAA;AAAA;AAAA;AAAA;AAAgC;AAC6B;AACjC;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,4CAAK;AACnC;AACA,4BAA4B,gFAAoB;AAChD;AACA,wBAAwB,gFAAoB;AAC5C,qCAAqC,wCAAG;AACxC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,6BAA6B,4CAAK;AAClC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;AC5CA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACgB;AACN;AACM;AACD;AACH;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACO,qBAAqB,yEAAa;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,iDAAiD,sEAAkB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,+BAA+B,yDAAK,IAAI,iFAAY;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,2EAAO;AACX;AACA,kC;;;;;;;;;;;;ACtLA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACC;AACrB;AACzC;AACA;AACA;AACO,6BAA6B,yEAAa;AACjD;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA,QAAQ,6DAAa;AACrB;AACA;AACA;AACA,0C;;;;;;;;;;;;ACfA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8D;AAClB;AACiB;AACnB;AACA;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,uBAAuB,qDAAM;AACpC;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA;AACA;AACA;AACA,wBAAwB,uDAAI,EAAE,wBAAwB;AACtD;AACA;AACA;AACA;AACA;AACA,wBAAwB,qDAAM,EAAE,wBAAwB;AACxD;AACA;AACA;AACA;AACA,QAAQ,iFAAa;AACrB;AACA;AACA,6BAA6B,qDAAM;AACnC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oC;;;;;;;;;;;;ACzDA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC2B;AACG;AACN;AAC1D;AACA;AACA;AACO,2BAA2B,8CAAM;AACxC;AACA,cAAc,gFAAoB,CAAC,8CAAM;AACzC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB,CAAC,8CAAM;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,sEAAkB;AACnE;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA,iCAAiC,2EAAkB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;AC3HA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAwD;AACV;AACe;AACL;AACxD;AACA;AACA;AACA;AACA;AACO,iCAAiC,mEAAa;AACrD;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,QAAQ,2EAAO;AACf,0BAA0B,yDAAK;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,6BAA6B,mEAAa;AAC1C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8C;;;;;;;;;;;;AC5DA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA6D;AACA;AACjB;AACV;AACgB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,8DAAc;AAC9C;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,YAAY,oEAAO;AACnB;AACA;AACA,iBAAiB,uEAAU;AAC3B;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;AClGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA4C;AACwB;AACP;AACX;AAClD;AACA;AACA;AACA;AACA;AACA;AACO,mBAAmB,8DAAc;AACxC;AACA,4BAA4B,gFAAoB;AAChD;AACA;AACA;AACA;AACA,yBAAyB,uDAAI,EAAE,wBAAwB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,2EAAO;AACf;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,8EAAU;AAClB;AACA;AACA;AACA,gC;;;;;;;;;;;;ACrCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAsB;AACA;AACQ;AACA;AACA;AACI;AACP;AACF;AACH;AACG;AACD;AACG;AACA;AACI;AACF;AACN;AACvB,iC;;;;;;;;;;;;AChBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkE;AACL;AACjB;AACF;AACmB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACO,oBAAoB,qDAAM;AACjC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,yEAAgB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,2BAA2B;AAC/D;AACA;AACA;AACA,+BAA+B,mBAAmB;AAClD;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA,oCAAoC,6EAAe;AACnD;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,oCAAoC,2BAA2B;AAC/D;AACA;AACA;AACA;AACA,+BAA+B,mBAAmB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA,mCAAmC,6EAAe;AAClD;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,oCAAoC,2BAA2B;AAC/D;AACA;AACA,+BAA+B,mBAAmB;AAClD;AACA;AACA;AACA,oCAAoC,6EAAe;AACnD;AACA;AACA,KAAK;AACL;AACA,iC;;;;;;;;;;;;AChOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA4C;AACkB;AAChB;AACF;AAC5C;AACA;AACA;AACO,4BAA4B,yEAAa;AAChD;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,yDAAI;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,uDAAI;AAC9B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA,qBAAqB,yDAAI;AACzB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,yDAAI;AACjC;AACA;AACA,2BAA2B,yDAAI;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;AC7KA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAqD;AAChB;AACJ;AAC6B;AACX;AACK;AACG;AACC;AACM;AAC3B;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,yEAAa;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,sEAAa;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,yDAAI;AAChC,2BAA2B,yDAAI;AAC/B;AACA;AACA,yCAAyC,gEAAM;AAC/C;AACA;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA,oBAAoB,yDAAI;AACxB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA,2BAA2B,oEAAO;AAClC;AACA;AACA;AACA;AACA,YAAY,+DAAM,CAAC,0DAAE;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,sEAAU;AAC5D;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,6EAAoB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA,2BAA2B,oEAAO;AAClC;AACA,sEAAsE,sEAAS;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,yDAAI;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,kC;;;;;;;;;;;;ACpRA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACqC;AAClB;AACQ;AACjB;AACM;AACW;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACO,wBAAwB,yEAAa;AAC5C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,yCAAyC,gEAAM;AAC/C;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,YAAY,+DAAM;AAClB;AACA;AACA;AACA;AACA;AACA,gBAAgB,qEAAQ;AACxB;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,gBAAgB,+DAAM,CAAC,sEAAS,sCAAsC,UAAU;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,2EAAO;AACvB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sEAAS;AACxB,YAAY,sEAAS;AACrB;AACA;AACA,qC;;;;;;;;;;;;AC9MA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAmC;AACc;AACoB;AACO;AAC7B;AACO;AACiB;AACnB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACO,0BAA0B,8CAAM;AACvC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,0BAA0B,6EAAe;AACzC;AACA;AACA;AACA;AACA,SAAS;AACT,0BAA0B,uDAAK;AAC/B;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC,oBAAoB,yDAAI;AACxB,qBAAqB,yDAAI;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,iBAAiB,sEAAU;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kEAAgB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,uFAAwB;AAClD,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oEAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oEAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uC;;;;;;;;;;;;ACxOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA8C;AACuB;AACO;AAC3B;AACG;AACjB;AACmB;AACF;AACE;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,qBAAqB,8CAAM;AAClC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,2BAA2B,6EAAe;AAC1C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,yDAAI;AACxB,qBAAqB,yDAAI;AACzB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,uBAAuB,yDAAI;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,sEAAU;AAC/B;AACA;AACA;AACA,qBAAqB,sEAAU;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sEAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kEAAgB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,0BAA0B,oEAAO;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oEAAW;AACvB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,oEAAW;AACvB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA,wDAAU;AACV,IAAI,sEAAS;AACb;AACA,kC;;;;;;;;;;;;ACpVA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAwD;AACe;AACN;AACD;AACjB;AACY;AACxB;AACD;AAClC;AACA;AACA;AACA;AACO,sBAAsB,yEAAa;AAC1C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C;AACA;AACA;AACA,yCAAyC,gEAAM;AAC/C;AACA;AACA,SAAS;AACT;AACA,QAAQ,qEAAQ;AAChB,4BAA4B,+EAAgB;AAC5C;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA;AACA;AACA,oBAAoB,yDAAI;AACxB,qBAAqB,yDAAI;AACzB,oBAAoB;AACpB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM,4CAA4C,KAAK;AAC/D;AACA,+BAA+B,8CAAM;AACrC;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mC;;;;;;;;;;;;AC3JA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA2D;AACV;AACoB;AACO;AAC3B;AACK;AACP;AACE;AACE;AACnD;AACA;AACA;AACA;AACO,+BAA+B,4DAAa;AACnD;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,QAAQ,2EAAO;AACf;AACA;AACA;AACA;AACA,gCAAgC,yDAAK;AACrC;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,2BAA2B,6EAAe;AAC1C;AACA;AACA;AACA,6BAA6B,4DAAa;AAC1C,qBAAqB,6EAAe;AACpC;AACA;AACA;AACA,oBAAoB,yDAAI;AACxB,qBAAqB,yDAAI;AACzB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAM;AACd;AACA;AACA;AACA;AACA;AACA,qBAAqB,sEAAU;AAC/B;AACA;AACA;AACA,qBAAqB,sEAAU;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,2DAAG;AACnB;AACA;AACA;AACA,gBAAgB,0DAAE;AAClB;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0DAAE;AACd;AACA;AACA;AACA;AACA,YAAY,sEAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4C;;;;;;;;;;;;ACnMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAwB;AACI;AACY;AACE;AACA;AACG;AACF;AACA;AACC;AACI;AACf;AACS;AACV;AACC;AACI;AACrC,iC;;;;;;;;;;;;ACfA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACa;AACiB;AACX;AACE;AACN;AACd;AACO;AACe;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,2BAA2B,8CAAM;AACxC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,oCAAoC,+DAAW,EAAE,wBAAwB;AACzE;AACA;AACA;AACA,mCAAmC,uDAAI;AACvC;AACA,SAAS;AACT,wBAAwB,gFAAoB;AAC5C,4BAA4B,sDAAU;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,8BAA8B,sDAAU;AACxC;AACA;AACA;AACA,SAAS;AACT,+BAA+B,yDAAQ;AACvC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,sDAAU;AACvC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,mBAAmB,6EAAgB;AACnC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;AC3JA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACa;AACiB;AACX;AACJ;AACJ;AACV;AACO;AACe;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACO,2BAA2B,8CAAM;AACxC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,mCAAmC,uDAAI;AACvC;AACA;AACA,SAAS;AACT,wBAAwB,gFAAoB;AAC5C,4BAA4B,sDAAU;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT,8BAA8B,sDAAU;AACxC;AACA;AACA;AACA,SAAS;AACT,+BAA+B,yDAAQ;AACvC;AACA;AACA;AACA,SAAS;AACT,mCAAmC,yDAAQ;AAC3C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,sDAAU;AACvC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,mBAAmB,6EAAgB;AACnC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wC;;;;;;;;;;;;AC1KA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC8B;AACL;AACd;AACV;AACO;AACe;AACL;AACpD;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,8CAAM;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT,0BAA0B,qDAAM;AAChC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,sDAAU;AACvC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,8BAA8B;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAW;AACnB;AACA;AACA;AACA;AACA,2BAA2B,WAAW;AACtC,gCAAgC,sDAAU;AAC1C;AACA;AACA;AACA;AACA;AACA,gEAAgE,yDAAI;AACpE,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,mBAAmB,6EAAgB;AACnC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;AClMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA+C;AACE;AACgB;AACD;AACX;AACE;AACZ;AACiB;AACnB;AACC;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,kBAAkB,yEAAa;AACtC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,yDAAK;AAC9B;AACA,uBAAuB,yDAAK;AAC5B;AACA,mBAAmB,yDAAK;AACxB;AACA,2BAA2B,yDAAK;AAChC,wBAAwB,gFAAoB;AAC5C;AACA,+BAA+B,sDAAU;AACzC;AACA;AACA;AACA,SAAS;AACT;AACA,kCAAkC,uDAAI;AACtC;AACA;AACA;AACA,SAAS;AACT;AACA,kCAAkC,qDAAM;AACxC;AACA;AACA;AACA,SAAS;AACT,0BAA0B,iDAAI,EAAE,wBAAwB;AACxD,wBAAwB,+DAAW,EAAE,wBAAwB;AAC7D,yCAAyC,mDAAK;AAC9C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA,6BAA6B,yEAAa;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,yDAAK,oBAAoB,qDAAM;AAC3D;AACA;AACA;AACA,QAAQ,oEAAa;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+B;;;;;;;;;;;;AC9NA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC8B;AACX;AACU;AAClB;AACV;AACW;AACE;AACF;AACJ;AACe;AACL;AACJ;AAChD;AACA,QAAQ,0DAAY;AACpB,SAAS,4DAAa;AACtB,QAAQ,0DAAY;AACpB,gBAAgB,sDAAU;AAC1B,WAAW,iEAAe;AAC1B,SAAS,6DAAa;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,6BAA6B,8CAAM;AAC1C;AACA,cAAc,gFAAoB;AAClC;AACA,wBAAwB,gFAAoB;AAC5C,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT,0BAA0B,qDAAM;AAChC;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA,6BAA6B,sDAAU,gBAAgB,0DAAY,gBAAgB,0DAAY,gBAAgB,4DAAa,gBAAgB,iEAAe,gBAAgB,6DAAa;AACxL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,qEAAQ;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,qEAAQ;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sGAAsG,qEAAQ;AAC9G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,mBAAmB,8EAAgB;AACnC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0C;;;;;;;;;;;;AC1VA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC0C;AACvB;AACC;AACT;AACV;AACsB;AACC;AACN;AACP;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,yBAAyB,8CAAM;AACtC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,6BAA6B,qDAAM;AACnC;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB,0BAA0B,qDAAM;AAChC;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,sEAAkB;AACjD;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,sEAAU;AAC9B,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sEAAS;AACzB,uBAAuB,iBAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAW;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,sBAAsB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,SAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,mBAAmB;AAC1C;AACA;AACA,eAAe,6DAAK;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,mBAAmB,6EAAgB;AACnC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sC;;;;;;;;;;;;AC1XA;AAAA;AAAA;AAAA;AAAkC;AACiC;AACnE;AACA;AACA;AACO;AACP,WAAW,uDAAS;AACpB;AACA,4BAA4B,2EAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA,+C;;;;;;;;;;;;ACrBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AAC8B;AACX;AACJ;AACd;AACO;AACe;AACL;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,4BAA4B,8CAAM;AACzC;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,yDAAQ;AAClC;AACA;AACA,SAAS;AACT,wBAAwB,gFAAoB;AAC5C,0BAA0B,gEAAe;AACzC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,8BAA8B,sDAAU;AACxC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,mBAAmB,6EAAgB;AACnC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yC;;;;;;;;;;;;ACtIA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAkC;AACa;AACiB;AACX;AACR;AACQ;AAClB;AACO;AACe;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,8BAA8B,8CAAM;AAC3C;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA,8BAA8B,uDAAI;AAClC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,2BAA2B,6DAAU;AACrC;AACA;AACA,SAAS;AACT,wBAAwB,gFAAoB;AAC5C,yBAAyB,qDAAM;AAC/B;AACA;AACA;AACA,SAAS;AACT,6BAA6B,sDAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,8CAAM;AACnC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uDAAS;AACxB,mBAAmB,6EAAgB;AACnC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2C;;;;;;;;;;;;AC7KA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAA2D;AACV;AACe;AACf;AACI;AACrD;AACA;AACA;AACA;AACA;AACA;AACO,iCAAiC,4DAAa;AACrD;AACA,cAAc,gFAAoB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,gFAAoB;AAC5C,QAAQ,2EAAO;AACf;AACA,6BAA6B,yDAAK;AAClC;AACA;AACA;AACA;AACA,SAAS;AACT,0BAA0B,yDAAK;AAC/B;AACA;AACA;AACA;AACA,SAAS;AACT,QAAQ,qEAAQ;AAChB;AACA;AACA,6BAA6B,4DAAa;AAC1C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8C;;;;;;;;;;;;ACzFA;AAAA;AAAO;AACP,mC;;;;;;;;;;;;;;;;;;;;;;;;;ACD0H;AAChE;AACN;AAC2B;AAEpC;AACZ;AAE0C;AACQ;;;;AAO1E,MAAM,8BAA8B;IAkBzC,YAC0B,IAAwB,EACxC,IAAY;QADI,SAAI,GAAJ,IAAI,CAAoB;QACxC,SAAI,GAAJ,IAAI,CAAQ;QARd,aAAQ,GAAG,IAAI,4CAAO,EAAE,CAAC;QAGc,aAAQ,GAAG,CAAC,CAAC;QACpD,oBAAe,GAAkB,IAAI,CAAC;QAM5C,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IAC/C,CAAC;IAED,IAAI,YAAY;QACd,OAAO,+CAAC,CAAC,kDAAY,CAAC,YAAY,CAAC,CAAC;IACtC,CAAC;IAED,IAAI,iBAAiB;QACnB,OAAO,mDAAK,CAAC,kDAAY,CAAC,YAAY,CAAC,CAAC;IAC1C,CAAC;IAED,IAAI,IAAI;QACN,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;IACxB,CAAC;IAED,IAAI,YAAY;QACd,OAAO,IAAI,CAAC,IAAI,CAAC,YAAY,CAAC;IAChC,CAAC;IAED,IAAI,WAAW,CAAC,WAAW;QACzB,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG,WAAW,CAAC;IACtC,CAAC;IAED,QAAQ;QACN,IAAI,CAAC,IAAI,CAAC,KAAK;aACZ,IAAI,CAAC,gEAAS,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;aAC9B,SAAS,CAAC,IAAI,CAAC,EAAE;;YAChB,MAAM,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;YAC9C,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,gEAAa,CAAC,CAAC;YACxD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,kEAAe,CAAC,CAAC;YAC1D,UAAI,CAAC,MAAM,0CAAE,OAAO,GAAG;YACvB,IAAI,CAAC,MAAM,GAAG,IAAI,kEAAM,CAAC,MAAM,EAAE,CAAC,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,YAAY,CAAC,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;QAC9G,CAAC,CAAC,CAAC;IACP,CAAC;IAED,WAAW;;QACT,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QACrB,IAAI,CAAC,QAAQ,CAAC,QAAQ,EAAE,CAAC;QACzB,UAAI,CAAC,MAAM,0CAAE,OAAO,GAAG;IACzB,CAAC;IAED,UAAU,CAAC,KAAK;QAEd,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,EAAE;YAClB,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACtC,CAAC,CAAC,CAAC,CAAC;IACN,CAAC;IAGK,aAAa,CAAC,MAAqB;;YACvC,MAAM,CAAC,cAAc,EAAE,CAAC;YACxB,MAAM,CAAC,eAAe,EAAE,CAAC;YACzB,MAAM,EAAE,GAAG,EAAE,QAAQ,EAAE,MAAM,EAAE,GAAG,MAAM,CAAC;YACzC,IAAI,CAAC,IAAI,CAAC,MAAM,IAAI,MAAM,EAAE;gBAC1B,OAAO;aACR;YACD,IAAI,GAAG,KAAK,GAAG,EAAE;gBACf,IAAI,CAAC,YAAY,CAAC,QAAQ,CAAC,CAAC;aAC7B;iBAAM,IAAI,GAAG,KAAK,GAAG,EAAE;gBACtB,IAAI,CAAC,aAAa,EAAE,CAAC;aACtB;iBAAM,IAAI,GAAG,KAAK,GAAG,EAAE;gBACtB,IAAI,CAAC,YAAY,EAAE,CAAC;aACrB;iBAAM,IAAI,GAAG,KAAK,GAAG,EAAE;gBACtB,IAAI,CAAC,cAAc,EAAE,CAAC;aACvB;iBAAM,IAAI,GAAG,IAAI,GAAG,IAAI,GAAG,IAAI,GAAG,EAAE;gBACnC,MAAM,UAAU,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,GAAG,GAAG,EAAE,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;gBAC5D,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC,UAAU,EAAE,IAAI,CAAC,CAAC;gBACrC,IAAI,CAAC,mBAAmB,EAAE,CAAC;aAC5B;QACH,CAAC;KAAA;IAGD,WAAW,CAAC,MAAqB;QAC/B,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YAChB,OAAO;SACR;QACD,MAAM,CAAC,cAAc,EAAE,CAAC;QACxB,MAAM,CAAC,eAAe,EAAE,CAAC;QACzB,MAAM,EAAE,GAAG,EAAE,GAAG,MAAM,CAAC;QACvB,IAAI,GAAG,KAAK,GAAG,EAAE;YACf,IAAI,CAAC,WAAW,EAAE,CAAC;SACpB;IACH,CAAC;IAGD,UAAU;;QACR,UAAI,CAAC,MAAM,0CAAE,KAAK,GAAG;IACvB,CAAC;IAEO,YAAY,CAAC,QAAiB;;QACpC,IAAI,IAAI,CAAC,UAAU,EAAE;YACnB,MAAM,KAAK,GAAG,IAAI,CAAC,mBAAmB,EAAE,CAAC;YACzC,MAAM,QAAQ,GAAG,IAAI,CAAC;YACtB,IAAI,CAAC,eAAe,GAAG,MAAM,CAAC,UAAU,CAAC,GAAS,EAAE,CAAC;;gBACnD,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;gBAC5B,UAAI,CAAC,MAAM,0CAAE,MAAM,CAAC,QAAQ,EAAE;YAChC,CAAC,GAAE,KAAK,GAAG,QAAQ,CAAC,CAAC;SACtB;aAAM;YACL,UAAI,CAAC,MAAM,0CAAE,MAAM,CAAC,QAAQ,EAAE;SAC/B;IACH,CAAC;IAEO,WAAW;;QACjB,IAAI,IAAI,CAAC,eAAe,KAAK,IAAI,EAAE;YACjC,MAAM,CAAC,YAAY,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC;YAC1C,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;SAC7B;aAAM;YACL,UAAI,CAAC,MAAM,0CAAE,KAAK,GAAG;YACrB,IAAI,IAAI,CAAC,SAAS,EAAE;gBAClB,IAAI,CAAC,mBAAmB,EAAE,CAAC;aAC5B;SACF;IACH,CAAC;IAEO,aAAa;QACnB,OAAO,IAAI,CAAC,qBAAqB,CAAC,OAAO,CAAC,+CAAC,CAAC,kDAAY,CAAC,MAAM,EAAE;YAC/D,GAAG,EAAE,iEAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;YAC5B,GAAG,EAAE,iEAAO,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;SAClD,CAAC,CAAC,CAAC;IACN,CAAC;IAEO,YAAY;QAClB,OAAO,IAAI,CAAC,qBAAqB,CAAC,OAAO,CAAC,+CAAC,CAAC,kDAAY,CAAC,KAAK,EAAE;YAC9D,GAAG,EAAE,iEAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAC3B,GAAG,EAAE,iEAAO,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;SAChD,CAAC,CAAC,CAAC;IACN,CAAC;IAEO,cAAc;QAEpB,OAAO,IAAI,CAAC,qBAAqB,CAAC,OAAO,CAAC,6EAAmB,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACvF,CAAC;IAEO,mBAAmB;QACzB,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YAChB,OAAO,CAAC,CAAC;SACV;QACD,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,iBAAiB,CAAC,CAAC;QACjE,OAAO,IAAI,CAAC,qBAAqB,CAAC,OAAO,CAAC,+CAAC,CAAC,kDAAY,CAAC,YAAY,EAAE;YACrE,CAAC,EAAE,iEAAO,CAAC,IAAI,CAAC;YAChB,CAAC,EAAE,iEAAO,CAAC,KAAK,CAAC;SAClB,CAAC,CAAC,CAAC;IACN,CAAC;;4GApKU,8BAA8B,kEAmB/B,MAAM;8GAnBL,8BAA8B;wEAC9B,4FAAqB;;;;;gKADrB,yBAAqB,gGAArB,uBAAmB,8FAAnB,sBAAkB;;;;QChB/B,oEAGM;QACN,+EAAuC;;QAHlC,qJAA0B;QAC1B,8FAAqC;;+EDc7B,8BAA8B;cAL1C,uDAAS;eAAC;gBACT,QAAQ,EAAE,6BAA6B;gBACvC,WAAW,EAAE,0CAA0C;gBACvD,SAAS,EAAE,CAAC,0CAA0C,CAAC;aACxD;;sBAoBI,oDAAM;uBAAC,MAAM;;kBAlBf,uDAAS;mBAAC,4FAAqB,EAAE,EAAE,MAAM,EAAE,IAAI,EAAE;;kBAGjD,mDAAK;;kBACL,mDAAK;;kBACL,mDAAK;;kBACL,mDAAK;;kBACL,mDAAK;;kBACL,mDAAK;;kBAML,yDAAW;mBAAC,eAAe;;kBAuD3B,0DAAY;mBAAC,SAAS,EAAE,CAAC,QAAQ,CAAC;;kBAuBlC,0DAAY;mBAAC,OAAO,EAAE,CAAC,QAAQ,CAAC;;kBAahC,0DAAY;mBAAC,MAAM,EAAE,CAAC,QAAQ,CAAC;;;;;;;;;;;;;;AE1HlC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAyC;AAC4C;AACtC;AAC4B;;AAepE,MAAM,2BAA2B;IAZxC;QAaE,kBAAa,GAAG,iGAA8B,CAAC;KAChD;;0GAFY,2BAA2B;gLAA3B,2BAA2B,kBAR7B;YACP,4DAAY;YACZ,sFAAkB;SACnB;mIAKU,2BAA2B,mBAVpC,iGAA8B,aAG9B,4DAAY;QACZ,sFAAkB,aAGlB,iGAA8B;+EAGrB,2BAA2B;cAZvC,sDAAQ;eAAC;gBACR,YAAY,EAAE;oBACZ,iGAA8B;iBAC/B;gBACD,OAAO,EAAE;oBACP,4DAAY;oBACZ,sFAAkB;iBACnB;gBACD,OAAO,EAAE;oBACP,iGAA8B;iBAC/B;aACF;;;;;;;;;;;;;;ACjBD;AAAA;AAAA;AAAiD;;AAO1C,MAAM,qBAAqB;IALlC;QAMW,oBAAe,GAAG,GAAG,CAAC;QAE/B,aAAQ,GAAkB,IAAI,CAAC;QACvB,qBAAgB,GAAkB,IAAI,CAAC;KAyBhD;IAjBC,OAAO,CAAC,IAAY;QAClB,IAAI,IAAI,CAAC,gBAAgB,KAAK,IAAI,EAAE;YAClC,MAAM,CAAC,YAAY,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;YAC3C,IAAI,CAAC,gBAAgB,GAAG,IAAI,CAAC;SAC9B;QACD,MAAM,UAAU,GAAG,IAAI,CAAC,QAAQ,KAAK,IAAI,CAAC;QAC1C,IAAI,UAAU,EAAE;YACd,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;YACrB,IAAI,CAAC,gBAAgB,GAAG,MAAM,CAAC,UAAU,CAAC,GAAG,EAAE;gBAC7C,IAAI,CAAC,gBAAgB,GAAG,IAAI,CAAC;gBAC7B,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAC;YACrB,CAAC,EAAE,IAAI,CAAC,eAAe,CAAC,CAAC;SAC1B;aAAM;YACL,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;SACtB;QACD,OAAO,UAAU,CAAC,CAAC,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC;IAC/C,CAAC;;0FA5BU,qBAAqB;qGAArB,qBAAqB;QCPlC,oEAA0E;;QAA7B,mFAAsB;;+EDOtD,qBAAqB;cALjC,uDAAS;eAAC;gBACT,QAAQ,EAAE,mBAAmB;gBAC7B,WAAW,EAAE,gCAAgC;gBAC7C,SAAS,EAAE,CAAC,gCAAgC,CAAC;aAC9C;;kBAEE,mDAAK;;;;;;;;;;;;;;AERR;AAAA;AAAA;AAAA;AAAyC;AACyB;;AAU3D,MAAM,kBAAkB;;iGAAlB,kBAAkB;8JAAlB,kBAAkB;mIAAlB,kBAAkB,mBAN3B,8EAAqB,aAGrB,8EAAqB;+EAGZ,kBAAkB;cAR9B,sDAAQ;eAAC;gBACR,YAAY,EAAE;oBACZ,8EAAqB;iBACtB;gBACD,OAAO,EAAE;oBACP,8EAAqB;iBACtB;aACF;;;;;;;;;;;;;;;;;;;ACV4B;AAItB,MAAM,MAAM;IAQjB,YACU,MAAgB,EAChB,cAAgC,EAChC,YAAoB,EACpB,MAAe;QAHf,WAAM,GAAN,MAAM,CAAU;QAChB,mBAAc,GAAd,cAAc,CAAkB;QAChC,iBAAY,GAAZ,YAAY,CAAQ;QACpB,WAAM,GAAN,MAAM,CAAS;QAXzB,sBAAiB,GAAG,CAAC,CAAC;QACd,UAAK,GAAG,IAAI,0CAAU,EAAE,CAAC,aAAa,EAAE,CAAC;QACzC,cAAS,GAAG,IAAI,CAAC;QACjB,aAAQ,GAAG,KAAK,CAAC;QAEjB,cAAS,GAAkB,IAAI,CAAC;QAQtC,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,MAAM,CAAC,CAAC;QACrC,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,MAAM,CAAC,CAAC;QACrC,MAAM,CAAC,YAAY,EAAE,YAAY,CAAC,GAAG,IAAI,CAAC,cAAc,CAAC;QACzD,MAAM,YAAY,GAAG,MAAM,CAAC,YAAY,CAAC,YAAY,CAAC,CAAC;QACvD,MAAM,YAAY,GAAG,MAAM,CAAC,YAAY,CAAC,YAAY,CAAC,CAAC;QACvD,IAAI,CAAC,WAAW,GAAG,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE;YACpC,MAAM,SAAS,GAAG,CAAC,KAAK,GAAG,QAAQ,CAAC,GAAG,CAAC,QAAQ,GAAG,QAAQ,CAAC,GAAG,CAAC,YAAY,GAAG,YAAY,CAAC,GAAG,YAAY,CAAC;YAC5G,OAAO,MAAM,CAAC,YAAY,CAAC,SAAS,CAAC,CAAC;QACxC,CAAC,CAAC,CAAC;IACL,CAAC;IAED,IAAI,QAAQ;QACV,OAAO,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,MAAM,CAAC,MAAM,CAAC;IAChD,CAAC;IAED,IAAI,SAAS;QACX,OAAO,IAAI,CAAC,SAAS,KAAK,IAAI,CAAC;IACjC,CAAC;IAED,IAAI,OAAO;QACT,OAAO,CACL,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,iBAAiB,KAAK,CAAC;YAC7C,CAAC,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,iBAAiB,KAAK,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CACpE,CAAC;IACJ,CAAC;IAED,IAAI,cAAc;QAChB,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,OAAO,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;SACvD;QACD,MAAM,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9D,OAAO,IAAI,CAAC,iBAAiB,GAAG,MAAM,CAAC;IACzC,CAAC;IAEO,MAAM,CAAC,YAAY,CAAC,SAAiB;QAC3C,OAAO,IAAI,CAAC,IAAI,CAAC,SAAS,GAAG,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,CAAC;IAC9C,CAAC;IAEO,MAAM,CAAC,YAAY,CAAC,SAAiB;QAC3C,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,SAAS,GAAG,EAAE,CAAC,GAAG,EAAE,CAAC,GAAG,GAAG,CAAC;IAClD,CAAC;IAEK,MAAM,CAAC,QAAiB;;YAC5B,IAAI,+CAAe,EAAE,CAAC,KAAK,KAAK,WAAW,EAAE;gBAC3C,MAAM,0CAAU,EAAE,CAAC;aACpB;YACD,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE;gBACnB,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;gBACzB,IAAI,CAAC,YAAY,EAAE,CAAC;aACrB;QACH,CAAC;KAAA;IAED,KAAK;QACH,IAAI,IAAI,CAAC,SAAS,KAAK,IAAI,EAAE;YAC3B,MAAM,CAAC,aAAa,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;YACrC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC;SACvB;IACH,CAAC;IAED,MAAM,CAAC,UAAkB,EAAE,SAAS,GAAG,KAAK;;QAC1C,IAAI,CAAC,iBAAiB,GAAG,UAAU,CAAC;QACpC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,OAAO,IAAI,SAAS,CAAC;QAC3C,UAAI,CAAC,MAAM,+CAAX,IAAI,EAAU,IAAI,CAAC,iBAAiB,EAAE;IACxC,CAAC;IAED,OAAO;QACL,IAAI,CAAC,KAAK,EAAE,CAAC;QACb,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE,CAAC;IACvB,CAAC;IAEO,YAAY;QAClB,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QACjC,MAAM,SAAS,GAAG,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;QAC3D,IAAI,CAAC,KAAK,CAAC,oBAAoB,CAAC,SAAS,EAAE,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,CAAC;QACrE,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE;YACjB,IAAI,CAAC,SAAS,GAAG,MAAM,CAAC,UAAU,CAAC,GAAG,EAAE;gBACtC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC;gBACtB,IAAI,CAAC,YAAY,EAAE,CAAC;YACtB,CAAC,EAAE,IAAI,CAAC,YAAY,CAAC,CAAC;SACvB;IACH,CAAC;IAEO,iBAAiB,CAAC,KAAa;QACrC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,KAAK,CAAC;IAC1C,CAAC;CACF;;;;;;;;;;;;;ACvGD;AAAA;AAAA;AAAA;AAAA;AAAO,SAAS,eAAe,CAAC,CAAS,EAAE,CAAS;IAClD,OAAO,CAAC,GAAG,CAAC,CAAC;AACf,CAAC;AAEM,SAAS,gBAAgB,CAAC,CAAS,EAAE,CAAS;IACnD,OAAO,CAAC,eAAe,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;AAChC,CAAC;AAEM,SAAS,aAAa,CAAC,CAAO,EAAE,CAAO;IAC5C,OAAO,eAAe,CAAC,CAAC,CAAC,OAAO,EAAE,EAAE,CAAC,CAAC,OAAO,EAAE,CAAC,CAAC;AACnD,CAAC;AAEM,SAAS,cAAc,CAAC,CAAO,EAAE,CAAO;IAC7C,OAAO,CAAC,aAAa,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;AAC9B,CAAC","file":"components-line-chart-audification-line-chart-audification-module-es2015.js","sourcesContent":["function _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n\n  return arr2;\n}\n\nmodule.exports = _arrayLikeToArray;","function _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}\n\nmodule.exports = _arrayWithHoles;","function _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\n\nmodule.exports = _classCallCheck;","function _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  return Constructor;\n}\n\nmodule.exports = _createClass;","function _iterableToArrayLimit(arr, i) {\n  if (typeof Symbol === \"undefined\" || !(Symbol.iterator in Object(arr))) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n  var _e = undefined;\n\n  try {\n    for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n\n  return _arr;\n}\n\nmodule.exports = _iterableToArrayLimit;","function _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nmodule.exports = _nonIterableRest;","var arrayWithHoles = require(\"./arrayWithHoles\");\n\nvar iterableToArrayLimit = require(\"./iterableToArrayLimit\");\n\nvar unsupportedIterableToArray = require(\"./unsupportedIterableToArray\");\n\nvar nonIterableRest = require(\"./nonIterableRest\");\n\nfunction _slicedToArray(arr, i) {\n  return arrayWithHoles(arr) || iterableToArrayLimit(arr, i) || unsupportedIterableToArray(arr, i) || nonIterableRest();\n}\n\nmodule.exports = _slicedToArray;","var arrayLikeToArray = require(\"./arrayLikeToArray\");\n\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return arrayLikeToArray(o, minLen);\n}\n\nmodule.exports = _unsupportedIterableToArray;","(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('@babel/runtime/helpers/slicedToArray'), require('@babel/runtime/helpers/classCallCheck'), require('@babel/runtime/helpers/createClass')) :\n    typeof define === 'function' && define.amd ? define(['exports', '@babel/runtime/helpers/slicedToArray', '@babel/runtime/helpers/classCallCheck', '@babel/runtime/helpers/createClass'], factory) :\n    (global = global || self, factory(global.automationEvents = {}, global._slicedToArray, global._classCallCheck, global._createClass));\n}(this, (function (exports, _slicedToArray, _classCallCheck, _createClass) { 'use strict';\n\n    _slicedToArray = _slicedToArray && Object.prototype.hasOwnProperty.call(_slicedToArray, 'default') ? _slicedToArray['default'] : _slicedToArray;\n    _classCallCheck = _classCallCheck && Object.prototype.hasOwnProperty.call(_classCallCheck, 'default') ? _classCallCheck['default'] : _classCallCheck;\n    _createClass = _createClass && Object.prototype.hasOwnProperty.call(_createClass, 'default') ? _createClass['default'] : _createClass;\n\n    var createExtendedExponentialRampToValueAutomationEvent = function createExtendedExponentialRampToValueAutomationEvent(value, endTime, insertTime) {\n      return {\n        endTime: endTime,\n        insertTime: insertTime,\n        type: 'exponentialRampToValue',\n        value: value\n      };\n    };\n\n    var createExtendedLinearRampToValueAutomationEvent = function createExtendedLinearRampToValueAutomationEvent(value, endTime, insertTime) {\n      return {\n        endTime: endTime,\n        insertTime: insertTime,\n        type: 'linearRampToValue',\n        value: value\n      };\n    };\n\n    var createSetValueAutomationEvent = function createSetValueAutomationEvent(value, startTime) {\n      return {\n        startTime: startTime,\n        type: 'setValue',\n        value: value\n      };\n    };\n\n    var createSetValueCurveAutomationEvent = function createSetValueCurveAutomationEvent(values, startTime, duration) {\n      return {\n        duration: duration,\n        startTime: startTime,\n        type: 'setValueCurve',\n        values: values\n      };\n    };\n\n    var getTargetValueAtTime = function getTargetValueAtTime(time, valueAtStartTime, _ref) {\n      var startTime = _ref.startTime,\n          target = _ref.target,\n          timeConstant = _ref.timeConstant;\n      return target + (valueAtStartTime - target) * Math.exp((startTime - time) / timeConstant);\n    };\n\n    var isExponentialRampToValueAutomationEvent = function isExponentialRampToValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'exponentialRampToValue';\n    };\n\n    var isLinearRampToValueAutomationEvent = function isLinearRampToValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'linearRampToValue';\n    };\n\n    var isAnyRampToValueAutomationEvent = function isAnyRampToValueAutomationEvent(automationEvent) {\n      return isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent);\n    };\n\n    var isSetValueAutomationEvent = function isSetValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setValue';\n    };\n\n    var isSetValueCurveAutomationEvent = function isSetValueCurveAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setValueCurve';\n    };\n\n    var getValueOfAutomationEventAtIndexAtTime = function getValueOfAutomationEventAtIndexAtTime(automationEvents, index, time, defaultValue) {\n      var automationEvent = automationEvents[index];\n      return automationEvent === undefined ? defaultValue : isAnyRampToValueAutomationEvent(automationEvent) || isSetValueAutomationEvent(automationEvent) ? automationEvent.value : isSetValueCurveAutomationEvent(automationEvent) ? automationEvent.values[automationEvent.values.length - 1] : getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, automationEvent.startTime, defaultValue), automationEvent);\n    };\n\n    var getEndTimeAndValueOfPreviousAutomationEvent = function getEndTimeAndValueOfPreviousAutomationEvent(automationEvents, index, currentAutomationEvent, nextAutomationEvent, defaultValue) {\n      return currentAutomationEvent === undefined ? [nextAutomationEvent.insertTime, defaultValue] : isAnyRampToValueAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.endTime, currentAutomationEvent.value] : isSetValueAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.startTime, currentAutomationEvent.value] : isSetValueCurveAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.startTime + currentAutomationEvent.duration, currentAutomationEvent.values[currentAutomationEvent.values.length - 1]] : [currentAutomationEvent.startTime, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, currentAutomationEvent.startTime, defaultValue)];\n    };\n\n    var isCancelAndHoldAutomationEvent = function isCancelAndHoldAutomationEvent(automationEvent) {\n      return automationEvent.type === 'cancelAndHold';\n    };\n\n    var isCancelScheduledValuesAutomationEvent = function isCancelScheduledValuesAutomationEvent(automationEvent) {\n      return automationEvent.type === 'cancelScheduledValues';\n    };\n\n    var getEventTime = function getEventTime(automationEvent) {\n      if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {\n        return automationEvent.cancelTime;\n      }\n\n      if (isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent)) {\n        return automationEvent.endTime;\n      }\n\n      return automationEvent.startTime;\n    };\n\n    var getExponentialRampValueAtTime = function getExponentialRampValueAtTime(time, startTime, valueAtStartTime, _ref) {\n      var endTime = _ref.endTime,\n          value = _ref.value;\n\n      if (valueAtStartTime === value) {\n        return value;\n      }\n\n      if (0 < valueAtStartTime && 0 < value || valueAtStartTime < 0 && value < 0) {\n        return valueAtStartTime * Math.pow(value / valueAtStartTime, (time - startTime) / (endTime - startTime));\n      }\n\n      return 0;\n    };\n\n    var getLinearRampValueAtTime = function getLinearRampValueAtTime(time, startTime, valueAtStartTime, _ref) {\n      var endTime = _ref.endTime,\n          value = _ref.value;\n      return valueAtStartTime + (time - startTime) / (endTime - startTime) * (value - valueAtStartTime);\n    };\n\n    var interpolateValue = function interpolateValue(values, theoreticIndex) {\n      var lowerIndex = Math.floor(theoreticIndex);\n      var upperIndex = Math.ceil(theoreticIndex);\n\n      if (lowerIndex === upperIndex) {\n        return values[lowerIndex];\n      }\n\n      return (1 - (theoreticIndex - lowerIndex)) * values[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * values[upperIndex];\n    };\n\n    var getValueCurveValueAtTime = function getValueCurveValueAtTime(time, _ref) {\n      var duration = _ref.duration,\n          startTime = _ref.startTime,\n          values = _ref.values;\n      var theoreticIndex = (time - startTime) / duration * (values.length - 1);\n      return interpolateValue(values, theoreticIndex);\n    };\n\n    var isSetTargetAutomationEvent = function isSetTargetAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setTarget';\n    };\n\n    var AutomationEventList = /*#__PURE__*/function () {\n      function AutomationEventList(defaultValue) {\n        _classCallCheck(this, AutomationEventList);\n\n        this._automationEvents = [];\n        this._currenTime = 0;\n        this._defaultValue = defaultValue;\n      }\n\n      _createClass(AutomationEventList, [{\n        key: Symbol.iterator,\n        value: function value() {\n          return this._automationEvents[Symbol.iterator]();\n        }\n      }, {\n        key: \"add\",\n        value: function add(automationEvent) {\n          var eventTime = getEventTime(automationEvent);\n\n          if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {\n            var index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n              return getEventTime(currentAutomationEvent) >= eventTime;\n            });\n\n            var removedAutomationEvent = this._automationEvents[index];\n\n            if (index !== -1) {\n              this._automationEvents = this._automationEvents.slice(0, index);\n            }\n\n            if (isCancelAndHoldAutomationEvent(automationEvent)) {\n              var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];\n\n              if (removedAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(removedAutomationEvent)) {\n                if (isSetTargetAutomationEvent(lastAutomationEvent)) {\n                  throw new Error('The internal list is malformed.');\n                }\n\n                var startTime = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.startTime + lastAutomationEvent.duration : getEventTime(lastAutomationEvent);\n                var startValue = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.values[lastAutomationEvent.values.length - 1] : lastAutomationEvent.value;\n                var value = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? getExponentialRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent) : getLinearRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent);\n                var truncatedAutomationEvent = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? createExtendedExponentialRampToValueAutomationEvent(value, eventTime, this._currenTime) : createExtendedLinearRampToValueAutomationEvent(value, eventTime, this._currenTime);\n\n                this._automationEvents.push(truncatedAutomationEvent);\n              }\n\n              if (lastAutomationEvent !== undefined && isSetTargetAutomationEvent(lastAutomationEvent)) {\n                this._automationEvents.push(createSetValueAutomationEvent(this.getValue(eventTime), eventTime));\n              }\n\n              if (lastAutomationEvent !== undefined && isSetValueCurveAutomationEvent(lastAutomationEvent) && lastAutomationEvent.startTime + lastAutomationEvent.duration > eventTime) {\n                this._automationEvents[this._automationEvents.length - 1] = createSetValueCurveAutomationEvent(new Float32Array([6, 7]), lastAutomationEvent.startTime, eventTime - lastAutomationEvent.startTime);\n              }\n            }\n          } else {\n            var _index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n              return getEventTime(currentAutomationEvent) > eventTime;\n            });\n\n            var previousAutomationEvent = _index === -1 ? this._automationEvents[this._automationEvents.length - 1] : this._automationEvents[_index - 1];\n\n            if (previousAutomationEvent !== undefined && isSetValueCurveAutomationEvent(previousAutomationEvent) && getEventTime(previousAutomationEvent) + previousAutomationEvent.duration > eventTime) {\n              return false;\n            }\n\n            var persistentAutomationEvent = isExponentialRampToValueAutomationEvent(automationEvent) ? createExtendedExponentialRampToValueAutomationEvent(automationEvent.value, automationEvent.endTime, this._currenTime) : isLinearRampToValueAutomationEvent(automationEvent) ? createExtendedLinearRampToValueAutomationEvent(automationEvent.value, eventTime, this._currenTime) : automationEvent;\n\n            if (_index === -1) {\n              this._automationEvents.push(persistentAutomationEvent);\n            } else {\n              if (isSetValueCurveAutomationEvent(automationEvent) && eventTime + automationEvent.duration > getEventTime(this._automationEvents[_index])) {\n                return false;\n              }\n\n              this._automationEvents.splice(_index, 0, persistentAutomationEvent);\n            }\n          }\n\n          return true;\n        }\n      }, {\n        key: \"flush\",\n        value: function flush(time) {\n          var index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n            return getEventTime(currentAutomationEvent) > time;\n          });\n\n          if (index > 1) {\n            var remainingAutomationEvents = this._automationEvents.slice(index - 1);\n\n            var firstRemainingAutomationEvent = remainingAutomationEvents[0];\n\n            if (isSetTargetAutomationEvent(firstRemainingAutomationEvent)) {\n              remainingAutomationEvents.unshift(createSetValueAutomationEvent(getValueOfAutomationEventAtIndexAtTime(this._automationEvents, index - 2, firstRemainingAutomationEvent.startTime, this._defaultValue), firstRemainingAutomationEvent.startTime));\n            }\n\n            this._automationEvents = remainingAutomationEvents;\n          }\n        }\n      }, {\n        key: \"getValue\",\n        value: function getValue(time) {\n          if (this._automationEvents.length === 0) {\n            return this._defaultValue;\n          }\n\n          var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];\n\n          var index = this._automationEvents.findIndex(function (automationEvent) {\n            return getEventTime(automationEvent) > time;\n          });\n\n          var nextAutomationEvent = this._automationEvents[index];\n          var currentAutomationEvent = getEventTime(lastAutomationEvent) <= time ? lastAutomationEvent : this._automationEvents[index - 1];\n\n          if (currentAutomationEvent !== undefined && isSetTargetAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || nextAutomationEvent.insertTime > time)) {\n            return getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(this._automationEvents, index - 2, currentAutomationEvent.startTime, this._defaultValue), currentAutomationEvent);\n          }\n\n          if (currentAutomationEvent !== undefined && isSetValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) {\n            return currentAutomationEvent.value;\n          }\n\n          if (currentAutomationEvent !== undefined && isSetValueCurveAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || currentAutomationEvent.startTime + currentAutomationEvent.duration > time)) {\n            if (time < currentAutomationEvent.startTime + currentAutomationEvent.duration) {\n              return getValueCurveValueAtTime(time, currentAutomationEvent);\n            }\n\n            return currentAutomationEvent.values[currentAutomationEvent.values.length - 1];\n          }\n\n          if (currentAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) {\n            return currentAutomationEvent.value;\n          }\n\n          if (nextAutomationEvent !== undefined && isExponentialRampToValueAutomationEvent(nextAutomationEvent)) {\n            var _getEndTimeAndValueOf = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, index - 1, currentAutomationEvent, nextAutomationEvent, this._defaultValue),\n                _getEndTimeAndValueOf2 = _slicedToArray(_getEndTimeAndValueOf, 2),\n                startTime = _getEndTimeAndValueOf2[0],\n                value = _getEndTimeAndValueOf2[1];\n\n            return getExponentialRampValueAtTime(time, startTime, value, nextAutomationEvent);\n          }\n\n          if (nextAutomationEvent !== undefined && isLinearRampToValueAutomationEvent(nextAutomationEvent)) {\n            var _getEndTimeAndValueOf3 = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, index - 1, currentAutomationEvent, nextAutomationEvent, this._defaultValue),\n                _getEndTimeAndValueOf4 = _slicedToArray(_getEndTimeAndValueOf3, 2),\n                _startTime = _getEndTimeAndValueOf4[0],\n                _value = _getEndTimeAndValueOf4[1];\n\n            return getLinearRampValueAtTime(time, _startTime, _value, nextAutomationEvent);\n          }\n\n          return this._defaultValue;\n        }\n      }]);\n\n      return AutomationEventList;\n    }();\n\n    var createCancelAndHoldAutomationEvent = function createCancelAndHoldAutomationEvent(cancelTime) {\n      return {\n        cancelTime: cancelTime,\n        type: 'cancelAndHold'\n      };\n    };\n\n    var createCancelScheduledValuesAutomationEvent = function createCancelScheduledValuesAutomationEvent(cancelTime) {\n      return {\n        cancelTime: cancelTime,\n        type: 'cancelScheduledValues'\n      };\n    };\n\n    var createExponentialRampToValueAutomationEvent = function createExponentialRampToValueAutomationEvent(value, endTime) {\n      return {\n        endTime: endTime,\n        type: 'exponentialRampToValue',\n        value: value\n      };\n    };\n\n    var createLinearRampToValueAutomationEvent = function createLinearRampToValueAutomationEvent(value, endTime) {\n      return {\n        endTime: endTime,\n        type: 'linearRampToValue',\n        value: value\n      };\n    };\n\n    var createSetTargetAutomationEvent = function createSetTargetAutomationEvent(target, startTime, timeConstant) {\n      return {\n        startTime: startTime,\n        target: target,\n        timeConstant: timeConstant,\n        type: 'setTarget'\n      };\n    };\n\n    exports.AutomationEventList = AutomationEventList;\n    exports.createCancelAndHoldAutomationEvent = createCancelAndHoldAutomationEvent;\n    exports.createCancelScheduledValuesAutomationEvent = createCancelScheduledValuesAutomationEvent;\n    exports.createExponentialRampToValueAutomationEvent = createExponentialRampToValueAutomationEvent;\n    exports.createLinearRampToValueAutomationEvent = createLinearRampToValueAutomationEvent;\n    exports.createSetTargetAutomationEvent = createSetTargetAutomationEvent;\n    exports.createSetValueAutomationEvent = createSetValueAutomationEvent;\n    exports.createSetValueCurveAutomationEvent = createSetValueCurveAutomationEvent;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n","export const MOST_NEGATIVE_SINGLE_FLOAT = -3.4028234663852886e38;\nexport const MOST_POSITIVE_SINGLE_FLOAT = -MOST_NEGATIVE_SINGLE_FLOAT;\n//# sourceMappingURL=/build/es2019/constants.js.map","export const createAbortError = () => {\n    try {\n        return new DOMException('', 'AbortError');\n    }\n    catch (err) {\n        // Bug #122: Edge is the only browser that does not yet allow to construct a DOMException.\n        err.code = 20;\n        err.name = 'AbortError';\n        return err;\n    }\n};\n//# sourceMappingURL=/build/es2019/factories/abort-error.js.map","export const createAddAudioNodeConnections = (audioNodeConnectionsStore) => {\n    return (audioNode, audioNodeRenderer, nativeAudioNode) => {\n        const activeInputs = [];\n        for (let i = 0; i < nativeAudioNode.numberOfInputs; i += 1) {\n            activeInputs.push(new Set());\n        }\n        audioNodeConnectionsStore.set(audioNode, {\n            activeInputs,\n            outputs: new Set(),\n            passiveInputs: new WeakMap(),\n            renderer: audioNodeRenderer\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/add-audio-node-connections.js.map","export const createAddAudioParamConnections = (audioParamConnectionsStore) => {\n    return (audioParam, audioParamRenderer) => {\n        audioParamConnectionsStore.set(audioParam, { activeInputs: new Set(), passiveInputs: new WeakMap(), renderer: audioParamRenderer });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/add-audio-param-connections.js.map","import { NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS } from '../globals';\nimport { isConstructible } from '../helpers/is-constructible';\nimport { splitImportStatements } from '../helpers/split-import-statements';\nconst verifyParameterDescriptors = (parameterDescriptors) => {\n    if (parameterDescriptors !== undefined && !Array.isArray(parameterDescriptors)) {\n        throw new TypeError('The parameterDescriptors property of given value for processorCtor is not an array.');\n    }\n};\nconst verifyProcessorCtor = (processorCtor) => {\n    if (!isConstructible(processorCtor)) {\n        throw new TypeError('The given value for processorCtor should be a constructor.');\n    }\n    if (processorCtor.prototype === null || typeof processorCtor.prototype !== 'object') {\n        throw new TypeError('The given value for processorCtor should have a prototype.');\n    }\n};\nexport const createAddAudioWorkletModule = (createNotSupportedError, evaluateSource, exposeCurrentFrameAndCurrentTime, fetchSource, getBackupNativeContext, getNativeContext, ongoingRequests, resolvedRequests, window) => {\n    return (context, moduleURL, options = { credentials: 'omit' }) => {\n        const nativeContext = getNativeContext(context);\n        const absoluteUrl = (new URL(moduleURL, window.location.href)).toString();\n        // Bug #59: Only Chrome & Opera do implement the audioWorklet property.\n        if (nativeContext.audioWorklet !== undefined) {\n            return fetchSource(moduleURL)\n                .then((source) => {\n                const [importStatements, sourceWithoutImportStatements] = splitImportStatements(source, absoluteUrl);\n                /*\n                 * Bug #170: Chrome and Opera do call process() with an array with empty channelData for each input if no input is\n                 * connected.\n                 *\n                 * This is the unminified version of the code used below:\n                 *\n                 * ```js\n                 * `${ importStatements };\n                 * ((registerProcessor) => {${ sourceWithoutImportStatements }\n                 * })((name, processorCtor) => registerProcessor(name, class extends processorCtor {\n                 *\n                 *     process (inputs, outputs, parameters) {\n                 *         return super.process(\n                 *             (inputs.map((input) => input.some((channelData) => channelData.length === 0)) ? [ ] : input),\n                 *             outputs,\n                 *             parameters\n                 *         );\n                 *     }\n                 *\n                 * }))`\n                 * ```\n                 */\n                const wrappedSource = `${importStatements};(registerProcessor=>{${sourceWithoutImportStatements}\n})((n,p)=>registerProcessor(n,class extends p{process(i,o,p){return super.process(i.map(j=>j.some(k=>k.length===0)?[]:j),o,p)}}))`; // tslint:disable-line:max-line-length\n                const blob = new Blob([wrappedSource], { type: 'application/javascript; charset=utf-8' });\n                const url = URL.createObjectURL(blob);\n                const backupNativeContext = getBackupNativeContext(nativeContext);\n                const nativeContextOrBackupNativeContext = (backupNativeContext !== null) ? backupNativeContext : nativeContext;\n                return nativeContextOrBackupNativeContext.audioWorklet\n                    .addModule(url, options)\n                    .then(() => URL.revokeObjectURL(url))\n                    // @todo This could be written more elegantly when Promise.finally() becomes avalaible.\n                    .catch((err) => {\n                    URL.revokeObjectURL(url);\n                    if (err.code === undefined || err.name === 'SyntaxError') {\n                        err.code = 12;\n                    }\n                    throw err;\n                });\n            });\n        }\n        const resolvedRequestsOfContext = resolvedRequests.get(context);\n        if (resolvedRequestsOfContext !== undefined && resolvedRequestsOfContext.has(moduleURL)) {\n            return Promise.resolve();\n        }\n        const ongoingRequestsOfContext = ongoingRequests.get(context);\n        if (ongoingRequestsOfContext !== undefined) {\n            const promiseOfOngoingRequest = ongoingRequestsOfContext.get(moduleURL);\n            if (promiseOfOngoingRequest !== undefined) {\n                return promiseOfOngoingRequest;\n            }\n        }\n        const promise = fetchSource(moduleURL)\n            .then((source) => {\n            const [importStatements, sourceWithoutImportStatements] = splitImportStatements(source, absoluteUrl);\n            /*\n             * This is the unminified version of the code used below:\n             *\n             * ```js\n             * ${ importStatements };\n             * ((a, b) => {\n             *     (a[b] = a[b] || [ ]).push(\n             *         (AudioWorkletProcessor, global, registerProcessor, sampleRate, self, window) => {\n             *             ${ sourceWithoutImportStatements }\n             *         }\n             *     );\n             * })(window, '_AWGS');\n             * ```\n             */\n            // tslint:disable-next-line:max-line-length\n            const wrappedSource = `${importStatements};((a,b)=>{(a[b]=a[b]||[]).push((AudioWorkletProcessor,global,registerProcessor,sampleRate,self,window)=>{${sourceWithoutImportStatements}\n})})(window,'_AWGS')`;\n            // @todo Evaluating the given source code is a possible security problem.\n            return evaluateSource(wrappedSource);\n        })\n            .then(() => {\n            const evaluateAudioWorkletGlobalScope = window._AWGS.pop();\n            if (evaluateAudioWorkletGlobalScope === undefined) {\n                throw new SyntaxError();\n            }\n            exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, () => evaluateAudioWorkletGlobalScope(class AudioWorkletProcessor {\n            }, undefined, (name, processorCtor) => {\n                if (name.trim() === '') {\n                    throw createNotSupportedError();\n                }\n                const nodeNameToProcessorConstructorMap = NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);\n                if (nodeNameToProcessorConstructorMap !== undefined) {\n                    if (nodeNameToProcessorConstructorMap.has(name)) {\n                        throw createNotSupportedError();\n                    }\n                    verifyProcessorCtor(processorCtor);\n                    verifyParameterDescriptors(processorCtor.parameterDescriptors);\n                    nodeNameToProcessorConstructorMap.set(name, processorCtor);\n                }\n                else {\n                    verifyProcessorCtor(processorCtor);\n                    verifyParameterDescriptors(processorCtor.parameterDescriptors);\n                    NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.set(nativeContext, new Map([[name, processorCtor]]));\n                }\n            }, nativeContext.sampleRate, undefined, undefined));\n        })\n            .catch((err) => {\n            if (err.code === undefined || err.name === 'SyntaxError') {\n                err.code = 12;\n            }\n            throw err;\n        });\n        if (ongoingRequestsOfContext === undefined) {\n            ongoingRequests.set(context, new Map([[moduleURL, promise]]));\n        }\n        else {\n            ongoingRequestsOfContext.set(moduleURL, promise);\n        }\n        promise\n            .then(() => {\n            const rslvdRqstsFCntxt = resolvedRequests.get(context);\n            if (rslvdRqstsFCntxt === undefined) {\n                resolvedRequests.set(context, new Set([moduleURL]));\n            }\n            else {\n                rslvdRqstsFCntxt.add(moduleURL);\n            }\n        })\n            .catch(() => { }) // tslint:disable-line:no-empty\n            // @todo Use finally when it becomes available in all supported browsers.\n            .then(() => {\n            const ngngRqstsFCntxt = ongoingRequests.get(context);\n            if (ngngRqstsFCntxt !== undefined) {\n                ngngRqstsFCntxt.delete(moduleURL);\n            }\n        });\n        return promise;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/add-audio-worklet-module.js.map","export const createAddSilentConnection = (createNativeGainNode) => {\n    return (nativeContext, nativeAudioScheduledSourceNode) => {\n        const nativeGainNode = createNativeGainNode(nativeContext, { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'discrete', gain: 0 });\n        nativeAudioScheduledSourceNode\n            .connect(nativeGainNode)\n            /*\n             * Bug #50: Edge does not yet allow to create AudioNodes on a closed AudioContext. Therefore the context property is\n             * used here to make sure to connect the right destination.\n             */\n            .connect(nativeGainNode.context.destination);\n        const disconnect = () => {\n            nativeAudioScheduledSourceNode.removeEventListener('ended', disconnect);\n            nativeAudioScheduledSourceNode.disconnect(nativeGainNode);\n            nativeGainNode.disconnect();\n        };\n        nativeAudioScheduledSourceNode.addEventListener('ended', disconnect);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/add-silent-connection.js.map","export const createAddUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes) => {\n    return (nativeContext, audioWorkletNode) => {\n        getUnrenderedAudioWorkletNodes(nativeContext)\n            .add(audioWorkletNode);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/add-unrendered-audio-worklet-node.js.map","const DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    fftSize: 2048,\n    maxDecibels: -30,\n    minDecibels: -100,\n    smoothingTimeConstant: 0.8\n};\nexport const createAnalyserNodeConstructor = (audionNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class AnalyserNode extends audionNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeAnalyserNode = createNativeAnalyserNode(nativeContext, mergedOptions);\n            const analyserNodeRenderer = ((isNativeOfflineAudioContext(nativeContext))\n                ? createAnalyserNodeRenderer()\n                : null);\n            super(context, false, nativeAnalyserNode, analyserNodeRenderer);\n            this._nativeAnalyserNode = nativeAnalyserNode;\n        }\n        get fftSize() {\n            return this._nativeAnalyserNode.fftSize;\n        }\n        set fftSize(value) {\n            this._nativeAnalyserNode.fftSize = value;\n        }\n        get frequencyBinCount() {\n            return this._nativeAnalyserNode.frequencyBinCount;\n        }\n        get maxDecibels() {\n            return this._nativeAnalyserNode.maxDecibels;\n        }\n        set maxDecibels(value) {\n            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n            const maxDecibels = this._nativeAnalyserNode.maxDecibels;\n            this._nativeAnalyserNode.maxDecibels = value;\n            if (!(value > this._nativeAnalyserNode.minDecibels)) {\n                this._nativeAnalyserNode.maxDecibels = maxDecibels;\n                throw createIndexSizeError();\n            }\n        }\n        get minDecibels() {\n            return this._nativeAnalyserNode.minDecibels;\n        }\n        set minDecibels(value) {\n            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n            const minDecibels = this._nativeAnalyserNode.minDecibels;\n            this._nativeAnalyserNode.minDecibels = value;\n            if (!(this._nativeAnalyserNode.maxDecibels > value)) {\n                this._nativeAnalyserNode.minDecibels = minDecibels;\n                throw createIndexSizeError();\n            }\n        }\n        get smoothingTimeConstant() {\n            return this._nativeAnalyserNode.smoothingTimeConstant;\n        }\n        set smoothingTimeConstant(value) {\n            this._nativeAnalyserNode.smoothingTimeConstant = value;\n        }\n        getByteFrequencyData(array) {\n            this._nativeAnalyserNode.getByteFrequencyData(array);\n        }\n        getByteTimeDomainData(array) {\n            this._nativeAnalyserNode.getByteTimeDomainData(array);\n        }\n        getFloatFrequencyData(array) {\n            this._nativeAnalyserNode.getFloatFrequencyData(array);\n        }\n        getFloatTimeDomainData(array) {\n            this._nativeAnalyserNode.getFloatTimeDomainData(array);\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/analyser-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createAnalyserNodeRendererFactory = (createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAnalyserNodes = new WeakMap();\n        const createAnalyserNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeAnalyserNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAnalyserNodeIsOwnedByContext = isOwnedByContext(nativeAnalyserNode, nativeOfflineAudioContext);\n            if (!nativeAnalyserNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAnalyserNode.channelCount,\n                    channelCountMode: nativeAnalyserNode.channelCountMode,\n                    channelInterpretation: nativeAnalyserNode.channelInterpretation,\n                    fftSize: nativeAnalyserNode.fftSize,\n                    maxDecibels: nativeAnalyserNode.maxDecibels,\n                    minDecibels: nativeAnalyserNode.minDecibels,\n                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant\n                };\n                nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode, trace);\n            return nativeAnalyserNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAnalyserNode !== undefined) {\n                    return Promise.resolve(renderedNativeAnalyserNode);\n                }\n                return createAnalyserNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/analyser-node-renderer-factory.js.map","import { testAudioBufferCopyChannelMethodsOutOfBoundsSupport } from '../helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support';\nimport { wrapAudioBufferGetChannelDataMethod } from '../helpers/wrap-audio-buffer-get-channel-data-method';\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nexport const createAudioBufferConstructor = (audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, testNativeAudioBufferConstructorSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    let nativeOfflineAudioContext = null;\n    return class AudioBuffer {\n        constructor(options) {\n            if (nativeOfflineAudioContextConstructor === null) {\n                throw new Error('Missing the native OfflineAudioContext constructor.');\n            }\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            if (nativeOfflineAudioContext === null) {\n                nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n            }\n            /*\n             * Bug #99: Firefox does not throw a NotSupportedError when the numberOfChannels is zero. But it only does it when using the\n             * factory function. But since Firefox also supports the constructor everything should be fine.\n             */\n            const audioBuffer = (nativeAudioBufferConstructor !== null &&\n                cacheTestResult(testNativeAudioBufferConstructorSupport, testNativeAudioBufferConstructorSupport)) ?\n                new nativeAudioBufferConstructor({ length, numberOfChannels, sampleRate }) :\n                nativeOfflineAudioContext.createBuffer(numberOfChannels, length, sampleRate);\n            // Bug #99: Safari does not throw an error when the numberOfChannels is zero.\n            if (audioBuffer.numberOfChannels === 0) {\n                throw createNotSupportedError();\n            }\n            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n            if (typeof audioBuffer.copyFromChannel !== 'function') {\n                wrapAudioBufferCopyChannelMethods(audioBuffer);\n                wrapAudioBufferGetChannelDataMethod(audioBuffer);\n                // Bug #157: Only Chrome & Opera do allow the bufferOffset to be out-of-bounds.\n            }\n            else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {\n                wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n            }\n            audioBufferStore.add(audioBuffer);\n            /*\n             * This does violate all good pratices but it is necessary to allow this AudioBuffer to be used with native\n             * (Offline)AudioContexts.\n             */\n            return audioBuffer;\n        }\n        static [Symbol.hasInstance](instance) {\n            return (instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === AudioBuffer.prototype)\n                || (audioBufferStore.has(instance));\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-buffer-constructor.js.map","import { MOST_NEGATIVE_SINGLE_FLOAT, MOST_POSITIVE_SINGLE_FLOAT } from '../constants';\nimport { setInternalStateToActive } from '../helpers/set-internal-state-to-active';\nimport { setInternalStateToPassive } from '../helpers/set-internal-state-to-passive';\nconst DEFAULT_OPTIONS = {\n    buffer: null,\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    // Bug #149: Safari does not yet support the detune AudioParam.\n    loop: false,\n    loopEnd: 0,\n    loopStart: 0,\n    playbackRate: 1\n};\nexport const createAudioBufferSourceNodeConstructor = (audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class AudioBufferSourceNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const audioBufferSourceNodeRenderer = ((isOffline)\n                ? createAudioBufferSourceNodeRenderer()\n                : null);\n            super(context, false, nativeAudioBufferSourceNode, audioBufferSourceNodeRenderer);\n            this._audioBufferSourceNodeRenderer = audioBufferSourceNodeRenderer;\n            this._isBufferNullified = false;\n            this._isBufferSet = (options.buffer !== null && options.buffer !== undefined);\n            this._nativeAudioBufferSourceNode = nativeAudioBufferSourceNode;\n            this._onended = null;\n            // Bug #73: Edge & Safari do not export the correct values for maxValue and minValue.\n            this._playbackRate = createAudioParam(this, isOffline, nativeAudioBufferSourceNode.playbackRate, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n        }\n        get buffer() {\n            if (this._isBufferNullified) {\n                return null;\n            }\n            return this._nativeAudioBufferSourceNode.buffer;\n        }\n        set buffer(value) {\n            // Bug #71: Edge does not allow to set the buffer to null.\n            try {\n                this._nativeAudioBufferSourceNode.buffer = value;\n            }\n            catch (err) {\n                if (value !== null || err.code !== 17) {\n                    throw err;\n                }\n                // This will modify the buffer in place. Luckily that works in Edge and has the same effect as setting the buffer to null.\n                if (this._nativeAudioBufferSourceNode.buffer !== null) {\n                    const buffer = this._nativeAudioBufferSourceNode.buffer;\n                    const numberOfChannels = buffer.numberOfChannels;\n                    for (let i = 0; i < numberOfChannels; i += 1) {\n                        buffer\n                            .getChannelData(i)\n                            .fill(0);\n                    }\n                    this._isBufferNullified = true;\n                }\n            }\n            // Bug #72: Only Chrome, Edge & Opera do not allow to reassign the buffer yet.\n            if (value !== null) {\n                if (this._isBufferSet) {\n                    throw createInvalidStateError();\n                }\n                this._isBufferSet = true;\n            }\n        }\n        get loop() {\n            return this._nativeAudioBufferSourceNode.loop;\n        }\n        set loop(value) {\n            this._nativeAudioBufferSourceNode.loop = value;\n        }\n        get loopEnd() {\n            return this._nativeAudioBufferSourceNode.loopEnd;\n        }\n        set loopEnd(value) {\n            this._nativeAudioBufferSourceNode.loopEnd = value;\n        }\n        get loopStart() {\n            return this._nativeAudioBufferSourceNode.loopStart;\n        }\n        set loopStart(value) {\n            this._nativeAudioBufferSourceNode.loopStart = value;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = (typeof value === 'function') ? wrapEventListener(this, value) : null;\n            this._nativeAudioBufferSourceNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeAudioBufferSourceNode.onended;\n            this._onended = (nativeOnEnded !== null && nativeOnEnded === wrappedListener)\n                ? value\n                : nativeOnEnded;\n        }\n        get playbackRate() {\n            return this._playbackRate;\n        }\n        start(when = 0, offset = 0, duration) {\n            this._nativeAudioBufferSourceNode.start(when, offset, duration);\n            if (this._audioBufferSourceNodeRenderer !== null) {\n                this._audioBufferSourceNodeRenderer.start = (duration === undefined) ? [when, offset] : [when, offset, duration];\n            }\n            else {\n                setInternalStateToActive(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeAudioBufferSourceNode.removeEventListener('ended', resetInternalStateToPassive);\n                    // @todo Determine a meaningful delay instead of just using one second.\n                    setTimeout(() => setInternalStateToPassive(this), 1000);\n                };\n                this._nativeAudioBufferSourceNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeAudioBufferSourceNode.stop(when);\n            if (this._audioBufferSourceNodeRenderer !== null) {\n                this._audioBufferSourceNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-buffer-source-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createAudioBufferSourceNodeRendererFactory = (connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioBufferSourceNodes = new WeakMap();\n        let start = null;\n        let stop = null;\n        const createAudioBufferSourceNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeAudioBufferSourceNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeAudioBufferSourceNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeAudioBufferSourceNodeIsOwnedByContext = isOwnedByContext(nativeAudioBufferSourceNode, nativeOfflineAudioContext);\n            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {\n                const options = {\n                    buffer: nativeAudioBufferSourceNode.buffer,\n                    channelCount: nativeAudioBufferSourceNode.channelCount,\n                    channelCountMode: nativeAudioBufferSourceNode.channelCountMode,\n                    channelInterpretation: nativeAudioBufferSourceNode.channelInterpretation,\n                    // Bug #149: Safari does not yet support the detune AudioParam.\n                    loop: nativeAudioBufferSourceNode.loop,\n                    loopEnd: nativeAudioBufferSourceNode.loopEnd,\n                    loopStart: nativeAudioBufferSourceNode.loopStart,\n                    playbackRate: nativeAudioBufferSourceNode.playbackRate.value\n                };\n                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeAudioBufferSourceNode.start(...start);\n                }\n                if (stop !== null) {\n                    nativeAudioBufferSourceNode.stop(stop);\n                }\n            }\n            renderedNativeAudioBufferSourceNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode);\n            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {\n                // Bug #149: Safari does not yet support the detune AudioParam.\n                await renderAutomation(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate, trace);\n            }\n            else {\n                // Bug #149: Safari does not yet support the detune AudioParam.\n                await connectAudioParam(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate, trace);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioBufferSourceNode, trace);\n            return nativeAudioBufferSourceNode;\n        };\n        return {\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeAudioBufferSourceNode = renderedNativeAudioBufferSourceNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioBufferSourceNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioBufferSourceNode);\n                }\n                return createAudioBufferSourceNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-buffer-source-node-renderer-factory.js.map","import { isValidLatencyHint } from '../helpers/is-valid-latency-hint';\nexport const createAudioContextConstructor = (baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor) => {\n    return class AudioContext extends baseAudioContextConstructor {\n        constructor(options = {}) {\n            if (nativeAudioContextConstructor === null) {\n                throw new Error('Missing the native AudioContext constructor.');\n            }\n            const nativeAudioContext = new nativeAudioContextConstructor(options);\n            // Bug #131 Safari returns null when there are four other AudioContexts running already.\n            if (nativeAudioContext === null) {\n                throw createUnknownError();\n            }\n            // Bug #51 Only Chrome and Opera throw an error if the given latencyHint is invalid.\n            if (!isValidLatencyHint(options.latencyHint)) {\n                throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);\n            }\n            // Bug #150 Only Chrome, Firefox and Opera support setting the sampleRate.\n            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) {\n                throw createNotSupportedError();\n            }\n            super(nativeAudioContext, 2);\n            const { latencyHint } = options;\n            const { sampleRate } = nativeAudioContext;\n            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.\n            this._baseLatency = (typeof nativeAudioContext.baseLatency === 'number')\n                ? nativeAudioContext.baseLatency\n                : (latencyHint === 'balanced')\n                    ? (512 / sampleRate)\n                    : (latencyHint === 'interactive' || latencyHint === undefined)\n                        ? (256 / sampleRate)\n                        : (latencyHint === 'playback')\n                            ? (1024 / sampleRate)\n                            /*\n                             * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a\n                             * ScriptProcessorNode.\n                             */\n                            : ((Math.max(2, Math.min(128, Math.round((latencyHint * sampleRate) / 128))) * 128) / sampleRate);\n            this._nativeAudioContext = nativeAudioContext;\n            this._state = null;\n            /*\n             * Bug #34: Chrome and Opera pretend to be running right away, but fire an onstatechange event when the state actually changes\n             * to 'running'.\n             */\n            if (nativeAudioContext.state === 'running') {\n                this._state = 'suspended';\n                const revokeState = () => {\n                    if (this._state === 'suspended') {\n                        this._state = null;\n                    }\n                    nativeAudioContext.removeEventListener('statechange', revokeState);\n                };\n                nativeAudioContext.addEventListener('statechange', revokeState);\n            }\n        }\n        get baseLatency() {\n            return this._baseLatency;\n        }\n        get state() {\n            return (this._state !== null) ? this._state : this._nativeAudioContext.state;\n        }\n        close() {\n            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.\n            if (this.state === 'closed') {\n                return this._nativeAudioContext\n                    .close()\n                    .then(() => {\n                    throw createInvalidStateError();\n                });\n            }\n            // Bug #34: If the state was set to suspended before it should be revoked now.\n            if (this._state === 'suspended') {\n                this._state = null;\n            }\n            return this._nativeAudioContext.close();\n            /*\n             * Bug #50: Deleting the AudioGraph is currently not possible anymore.\n             * ...then(() => deleteAudioGraph(this, this._nativeAudioContext));\n             */\n        }\n        createMediaElementSource(mediaElement) {\n            return new mediaElementAudioSourceNodeConstructor(this, { mediaElement });\n        }\n        createMediaStreamDestination() {\n            return new mediaStreamAudioDestinationNodeConstructor(this);\n        }\n        createMediaStreamSource(mediaStream) {\n            return new mediaStreamAudioSourceNodeConstructor(this, { mediaStream });\n        }\n        createMediaStreamTrackSource(mediaStreamTrack) {\n            return new mediaStreamTrackAudioSourceNodeConstructor(this, { mediaStreamTrack });\n        }\n        resume() {\n            if (this._state === 'suspended') {\n                return new Promise((resolve, reject) => {\n                    const resolvePromise = () => {\n                        this._nativeAudioContext.removeEventListener('statechange', resolvePromise);\n                        if (this._nativeAudioContext.state === 'running') {\n                            resolve();\n                        }\n                        else {\n                            this\n                                .resume()\n                                .then(resolve, reject);\n                        }\n                    };\n                    this._nativeAudioContext.addEventListener('statechange', resolvePromise);\n                });\n            }\n            return this._nativeAudioContext\n                .resume()\n                .catch((err) => {\n                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined || err.code === 15) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n        suspend() {\n            return this._nativeAudioContext\n                .suspend()\n                .catch((err) => {\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-context-constructor.js.map","export const createAudioDestinationNodeConstructor = (audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode) => {\n    return class AudioDestinationNode extends audioNodeConstructor {\n        constructor(context, channelCount) {\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const nativeAudioDestinationNode = createNativeAudioDestinationNode(nativeContext, channelCount, isOffline);\n            const audioDestinationNodeRenderer = ((isOffline)\n                ? createAudioDestinationNodeRenderer(renderInputsOfAudioNode)\n                : null);\n            super(context, false, nativeAudioDestinationNode, audioDestinationNodeRenderer);\n            this._isNodeOfNativeOfflineAudioContext = isOffline;\n            this._nativeAudioDestinationNode = nativeAudioDestinationNode;\n        }\n        get channelCount() {\n            return this._nativeAudioDestinationNode.channelCount;\n        }\n        set channelCount(value) {\n            // Bug #52: Chrome, Edge, Opera & Safari do not throw an exception at all.\n            // Bug #54: Firefox does throw an IndexSizeError.\n            if (this._isNodeOfNativeOfflineAudioContext) {\n                throw createInvalidStateError();\n            }\n            // Bug #47: The AudioDestinationNode in Edge and Safari do not initialize the maxChannelCount property correctly.\n            if (value > this._nativeAudioDestinationNode.maxChannelCount) {\n                throw createIndexSizeError();\n            }\n            this._nativeAudioDestinationNode.channelCount = value;\n        }\n        get channelCountMode() {\n            return this._nativeAudioDestinationNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            // Bug #53: No browser does throw an exception yet.\n            if (this._isNodeOfNativeOfflineAudioContext) {\n                throw createInvalidStateError();\n            }\n            this._nativeAudioDestinationNode.channelCountMode = value;\n        }\n        get maxChannelCount() {\n            return this._nativeAudioDestinationNode.maxChannelCount;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-destination-node-constructor.js.map","export const createAudioDestinationNodeRenderer = (renderInputsOfAudioNode) => {\n    let nativeAudioDestinationNodePromise = null;\n    const createAudioDestinationNode = async (proxy, nativeOfflineAudioContext, trace) => {\n        const nativeAudioDestinationNode = nativeOfflineAudioContext.destination;\n        await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioDestinationNode, trace);\n        return nativeAudioDestinationNode;\n    };\n    return {\n        render(proxy, nativeOfflineAudioContext, trace) {\n            if (nativeAudioDestinationNodePromise === null) {\n                nativeAudioDestinationNodePromise = createAudioDestinationNode(proxy, nativeOfflineAudioContext, trace);\n            }\n            return nativeAudioDestinationNodePromise;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-destination-node-renderer-factory.js.map","import { MOST_NEGATIVE_SINGLE_FLOAT, MOST_POSITIVE_SINGLE_FLOAT } from '../constants';\nexport const createAudioListenerFactory = (createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, isNativeOfflineAudioContext) => {\n    return (context, nativeContext) => {\n        const nativeListener = nativeContext.listener;\n        // Bug #117: Only Chrome & Opera support the new interface already.\n        const createFakeAudioParams = () => {\n            const channelMergerNode = createNativeChannelMergerNode(nativeContext, { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'speakers', numberOfInputs: 9 });\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 9, 0);\n            const createFakeAudioParam = (input, value) => {\n                const constantSourceNode = createNativeConstantSourceNode(nativeContext, { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'discrete', offset: value });\n                constantSourceNode.connect(channelMergerNode, 0, input);\n                // @todo This should be stopped when the context is closed.\n                constantSourceNode.start();\n                Object.defineProperty(constantSourceNode.offset, 'defaultValue', {\n                    get() {\n                        return value;\n                    }\n                });\n                /*\n                 * Bug #62 & #74: Edge & Safari do not support ConstantSourceNodes and do not export the correct values for maxValue and\n                 * minValue for GainNodes.\n                 */\n                return createAudioParam({ context }, isOffline, constantSourceNode.offset, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n            };\n            let lastOrientation = [0, 0, -1, 0, 1, 0];\n            let lastPosition = [0, 0, 0];\n            scriptProcessorNode.onaudioprocess = ({ inputBuffer }) => {\n                const orientation = [\n                    inputBuffer.getChannelData(0)[0],\n                    inputBuffer.getChannelData(1)[0],\n                    inputBuffer.getChannelData(2)[0],\n                    inputBuffer.getChannelData(3)[0],\n                    inputBuffer.getChannelData(4)[0],\n                    inputBuffer.getChannelData(5)[0]\n                ];\n                if (orientation.some((value, index) => (value !== lastOrientation[index]))) {\n                    nativeListener.setOrientation(...orientation); // tslint:disable-line:deprecation\n                    lastOrientation = orientation;\n                }\n                const positon = [\n                    inputBuffer.getChannelData(6)[0],\n                    inputBuffer.getChannelData(7)[0],\n                    inputBuffer.getChannelData(8)[0]\n                ];\n                if (positon.some((value, index) => (value !== lastPosition[index]))) {\n                    nativeListener.setPosition(...positon); // tslint:disable-line:deprecation\n                    lastPosition = positon;\n                }\n            };\n            channelMergerNode.connect(scriptProcessorNode);\n            return {\n                forwardX: createFakeAudioParam(0, 0),\n                forwardY: createFakeAudioParam(1, 0),\n                forwardZ: createFakeAudioParam(2, -1),\n                positionX: createFakeAudioParam(6, 0),\n                positionY: createFakeAudioParam(7, 0),\n                positionZ: createFakeAudioParam(8, 0),\n                upX: createFakeAudioParam(3, 0),\n                upY: createFakeAudioParam(4, 1),\n                upZ: createFakeAudioParam(5, 0)\n            };\n        };\n        const { forwardX, forwardY, forwardZ, positionX, positionY, positionZ, upX, upY, upZ } = (nativeListener.forwardX === undefined)\n            ? createFakeAudioParams()\n            : nativeListener;\n        return {\n            get forwardX() {\n                return forwardX;\n            },\n            get forwardY() {\n                return forwardY;\n            },\n            get forwardZ() {\n                return forwardZ;\n            },\n            get positionX() {\n                return positionX;\n            },\n            get positionY() {\n                return positionY;\n            },\n            get positionZ() {\n                return positionZ;\n            },\n            get upX() {\n                return upX;\n            },\n            get upY() {\n                return upY;\n            },\n            get upZ() {\n                return upZ;\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-listener-factory.js.map","import { AUDIO_NODE_STORE, EVENT_LISTENERS } from '../globals';\nimport { isAudioNode } from '../guards/audio-node';\nimport { isAudioNodeOutputConnection } from '../guards/audio-node-output-connection';\nimport { isAudioWorkletNode } from '../guards/audio-worklet-node';\nimport { connectNativeAudioNodeToNativeAudioNode } from '../helpers/connect-native-audio-node-to-native-audio-node';\nimport { deleteEventListenerOfAudioNode } from '../helpers/delete-event-listeners-of-audio-node';\nimport { disconnectNativeAudioNodeFromNativeAudioNode } from '../helpers/disconnect-native-audio-node-from-native-audio-node';\nimport { getAudioNodeConnections } from '../helpers/get-audio-node-connections';\nimport { getAudioParamConnections } from '../helpers/get-audio-param-connections';\nimport { getEventListenersOfAudioNode } from '../helpers/get-event-listeners-of-audio-node';\nimport { getNativeAudioNode } from '../helpers/get-native-audio-node';\nimport { getNativeAudioParam } from '../helpers/get-native-audio-param';\nimport { getValueForKey } from '../helpers/get-value-for-key';\nimport { insertElementInSet } from '../helpers/insert-element-in-set';\nimport { isActiveAudioNode } from '../helpers/is-active-audio-node';\nimport { isPartOfACycle } from '../helpers/is-part-of-a-cycle';\nimport { isPassiveAudioNode } from '../helpers/is-passive-audio-node';\nimport { pickElementFromSet } from '../helpers/pick-element-from-set';\nimport { setInternalStateToActive } from '../helpers/set-internal-state-to-active';\nimport { setInternalStateToPassiveWhenNecessary } from '../helpers/set-internal-state-to-passive-when-necessary';\nimport { testAudioNodeDisconnectMethodSupport } from '../helpers/test-audio-node-disconnect-method-support';\nimport { visitEachAudioNodeOnce } from '../helpers/visit-each-audio-node-once';\nimport { wrapAudioNodeDisconnectMethod } from '../helpers/wrap-audio-node-disconnect-method';\nconst addActiveInputConnectionToAudioNode = (activeInputs, source, [output, input, eventListener], ignoreDuplicates) => {\n    insertElementInSet(activeInputs[input], [source, output, eventListener], (activeInputConnection) => (activeInputConnection[0] === source && activeInputConnection[1] === output), ignoreDuplicates);\n};\nconst addActiveInputConnectionToAudioParam = (activeInputs, source, [output, eventListener], ignoreDuplicates) => {\n    insertElementInSet(activeInputs, [source, output, eventListener], (activeInputConnection) => (activeInputConnection[0] === source && activeInputConnection[1] === output), ignoreDuplicates);\n};\nconst deleteActiveInputConnectionToAudioNode = (activeInputs, source, output, input) => {\n    return pickElementFromSet(activeInputs[input], (activeInputConnection) => (activeInputConnection[0] === source && activeInputConnection[1] === output));\n};\nconst deleteActiveInputConnectionToAudioParam = (activeInputs, source, output) => {\n    return pickElementFromSet(activeInputs, (activeInputConnection) => (activeInputConnection[0] === source && activeInputConnection[1] === output));\n};\nconst addPassiveInputConnectionToAudioNode = (passiveInputs, input, [source, output, eventListener], ignoreDuplicates) => {\n    const passiveInputConnections = passiveInputs.get(source);\n    if (passiveInputConnections === undefined) {\n        passiveInputs.set(source, new Set([[output, input, eventListener]]));\n    }\n    else {\n        insertElementInSet(passiveInputConnections, [output, input, eventListener], (passiveInputConnection) => (passiveInputConnection[0] === output && passiveInputConnection[1] === input), ignoreDuplicates);\n    }\n};\nconst addPassiveInputConnectionToAudioParam = (passiveInputs, [source, output, eventListener], ignoreDuplicates) => {\n    const passiveInputConnections = passiveInputs.get(source);\n    if (passiveInputConnections === undefined) {\n        passiveInputs.set(source, new Set([[output, eventListener]]));\n    }\n    else {\n        insertElementInSet(passiveInputConnections, [output, eventListener], (passiveInputConnection) => (passiveInputConnection[0] === output), ignoreDuplicates);\n    }\n};\nconst deletePassiveInputConnectionToAudioNode = (passiveInputs, source, output, input) => {\n    const passiveInputConnections = getValueForKey(passiveInputs, source);\n    const matchingConnection = pickElementFromSet(passiveInputConnections, (passiveInputConnection) => (passiveInputConnection[0] === output && passiveInputConnection[1] === input));\n    if (passiveInputConnections.size === 0) {\n        passiveInputs.delete(source);\n    }\n    return matchingConnection;\n};\nconst deletePassiveInputConnectionToAudioParam = (passiveInputs, source, output) => {\n    const passiveInputConnections = getValueForKey(passiveInputs, source);\n    const matchingConnection = pickElementFromSet(passiveInputConnections, (passiveInputConnection) => (passiveInputConnection[0] === output));\n    if (passiveInputConnections.size === 0) {\n        passiveInputs.delete(source);\n    }\n    return matchingConnection;\n};\nconst addConnectionToAudioNodeOfAudioContext = (source, destination, output, input) => {\n    const { activeInputs, passiveInputs } = getAudioNodeConnections(destination);\n    const { outputs } = getAudioNodeConnections(source);\n    const eventListeners = getEventListenersOfAudioNode(source);\n    const eventListener = ((isActive) => {\n        const nativeDestinationAudioNode = getNativeAudioNode(destination);\n        const nativeSourceAudioNode = getNativeAudioNode(source);\n        if (isActive) {\n            const partialConnection = deletePassiveInputConnectionToAudioNode(passiveInputs, source, output, input);\n            addActiveInputConnectionToAudioNode(activeInputs, source, partialConnection, false);\n            if (!isPartOfACycle(source)) {\n                connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);\n            }\n            if (isPassiveAudioNode(destination)) {\n                setInternalStateToActive(destination);\n            }\n        }\n        else {\n            const partialConnection = deleteActiveInputConnectionToAudioNode(activeInputs, source, output, input);\n            addPassiveInputConnectionToAudioNode(passiveInputs, input, partialConnection, false);\n            if (!isPartOfACycle(source)) {\n                disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);\n            }\n            if (isActiveAudioNode(destination)) {\n                setInternalStateToPassiveWhenNecessary(destination, activeInputs);\n            }\n        }\n    });\n    if (insertElementInSet(outputs, [destination, output, input], (outputConnection) => (outputConnection[0] === destination && outputConnection[1] === output && outputConnection[2] === input), true)) {\n        eventListeners.add(eventListener);\n        if (isActiveAudioNode(source)) {\n            addActiveInputConnectionToAudioNode(activeInputs, source, [output, input, eventListener], true);\n        }\n        else {\n            addPassiveInputConnectionToAudioNode(passiveInputs, input, [source, output, eventListener], true);\n        }\n        return true;\n    }\n    return false;\n};\nconst addConnectionToAudioNodeOfOfflineAudioContext = (source, destination, output, input) => {\n    const { outputs } = getAudioNodeConnections(source);\n    if (insertElementInSet(outputs, [destination, output, input], (outputConnection) => (outputConnection[0] === destination && outputConnection[1] === output && outputConnection[2] === input), true)) {\n        const { activeInputs } = getAudioNodeConnections(destination);\n        addActiveInputConnectionToAudioNode(activeInputs, source, [output, input, null], true);\n        return true;\n    }\n    return false;\n};\nconst addConnectionToAudioParamOfAudioContext = (source, destination, output) => {\n    const { activeInputs, passiveInputs } = getAudioParamConnections(destination);\n    const { outputs } = getAudioNodeConnections(source);\n    const eventListeners = getEventListenersOfAudioNode(source);\n    const eventListener = ((isActive) => {\n        const nativeAudioNode = getNativeAudioNode(source);\n        const nativeAudioParam = getNativeAudioParam(destination);\n        if (isActive) {\n            const partialConnection = deletePassiveInputConnectionToAudioParam(passiveInputs, source, output);\n            addActiveInputConnectionToAudioParam(activeInputs, source, partialConnection, false);\n            if (!isPartOfACycle(source)) {\n                nativeAudioNode.connect(nativeAudioParam, output);\n            }\n        }\n        else {\n            const partialConnection = deleteActiveInputConnectionToAudioParam(activeInputs, source, output);\n            addPassiveInputConnectionToAudioParam(passiveInputs, partialConnection, false);\n            if (!isPartOfACycle(source)) {\n                nativeAudioNode.disconnect(nativeAudioParam, output);\n            }\n        }\n    });\n    if (insertElementInSet(outputs, [destination, output], (outputConnection) => (outputConnection[0] === destination && outputConnection[1] === output), true)) {\n        eventListeners.add(eventListener);\n        if (isActiveAudioNode(source)) {\n            addActiveInputConnectionToAudioParam(activeInputs, source, [output, eventListener], true);\n        }\n        else {\n            addPassiveInputConnectionToAudioParam(passiveInputs, [source, output, eventListener], true);\n        }\n        return true;\n    }\n    return false;\n};\nconst addConnectionToAudioParamOfOfflineAudioContext = (source, destination, output) => {\n    const { outputs } = getAudioNodeConnections(source);\n    if (insertElementInSet(outputs, [destination, output], (outputConnection) => (outputConnection[0] === destination && outputConnection[1] === output), true)) {\n        const { activeInputs } = getAudioParamConnections(destination);\n        addActiveInputConnectionToAudioParam(activeInputs, source, [output, null], true);\n        return true;\n    }\n    return false;\n};\nconst deleteActiveInputConnection = (activeInputConnections, source, output) => {\n    for (const activeInputConnection of activeInputConnections) {\n        if (activeInputConnection[0] === source && activeInputConnection[1] === output) {\n            activeInputConnections.delete(activeInputConnection);\n            return activeInputConnection;\n        }\n    }\n    return null;\n};\nconst deleteInputConnectionOfAudioNode = (source, destination, output, input) => {\n    const { activeInputs, passiveInputs } = getAudioNodeConnections(destination);\n    const activeInputConnection = deleteActiveInputConnection(activeInputs[input], source, output);\n    if (activeInputConnection === null) {\n        const passiveInputConnection = deletePassiveInputConnectionToAudioNode(passiveInputs, source, output, input);\n        return [passiveInputConnection[2], false];\n    }\n    return [activeInputConnection[2], true];\n};\nconst deleteInputConnectionOfAudioParam = (source, destination, output) => {\n    const { activeInputs, passiveInputs } = getAudioParamConnections(destination);\n    const activeInputConnection = deleteActiveInputConnection(activeInputs, source, output);\n    if (activeInputConnection === null) {\n        const passiveInputConnection = deletePassiveInputConnectionToAudioParam(passiveInputs, source, output);\n        return [passiveInputConnection[1], false];\n    }\n    return [activeInputConnection[2], true];\n};\nconst deleteInputsOfAudioNode = (source, destination, output, input) => {\n    const [listener, isActive] = deleteInputConnectionOfAudioNode(source, destination, output, input);\n    if (listener !== null) {\n        deleteEventListenerOfAudioNode(source, listener);\n        if (isActive && !isPartOfACycle(source)) {\n            disconnectNativeAudioNodeFromNativeAudioNode(getNativeAudioNode(source), getNativeAudioNode(destination), output, input);\n        }\n    }\n    if (isActiveAudioNode(destination)) {\n        const { activeInputs } = getAudioNodeConnections(destination);\n        setInternalStateToPassiveWhenNecessary(destination, activeInputs);\n    }\n};\nconst deleteInputsOfAudioParam = (source, destination, output) => {\n    const [listener, isActive] = deleteInputConnectionOfAudioParam(source, destination, output);\n    if (listener !== null) {\n        deleteEventListenerOfAudioNode(source, listener);\n        if (isActive && !isPartOfACycle(source)) {\n            getNativeAudioNode(source)\n                .disconnect(getNativeAudioParam(destination), output);\n        }\n    }\n};\nconst deleteAnyConnection = (source) => {\n    const audioNodeConnectionsOfSource = getAudioNodeConnections(source);\n    const destinations = [];\n    for (const outputConnection of audioNodeConnectionsOfSource.outputs) {\n        if (isAudioNodeOutputConnection(outputConnection)) {\n            deleteInputsOfAudioNode(source, ...outputConnection);\n        }\n        else {\n            deleteInputsOfAudioParam(source, ...outputConnection);\n        }\n        destinations.push(outputConnection[0]);\n    }\n    audioNodeConnectionsOfSource.outputs.clear();\n    return destinations;\n};\nconst deleteConnectionAtOutput = (source, output) => {\n    const audioNodeConnectionsOfSource = getAudioNodeConnections(source);\n    const destinations = [];\n    for (const outputConnection of audioNodeConnectionsOfSource.outputs) {\n        if (outputConnection[1] === output) {\n            if (isAudioNodeOutputConnection(outputConnection)) {\n                deleteInputsOfAudioNode(source, ...outputConnection);\n            }\n            else {\n                deleteInputsOfAudioParam(source, ...outputConnection);\n            }\n            destinations.push(outputConnection[0]);\n            audioNodeConnectionsOfSource.outputs.delete(outputConnection);\n        }\n    }\n    return destinations;\n};\nconst deleteConnectionToDestination = (source, destination, output, input) => {\n    const audioNodeConnectionsOfSource = getAudioNodeConnections(source);\n    return Array\n        .from(audioNodeConnectionsOfSource.outputs)\n        .filter((outputConnection) => (outputConnection[0] === destination\n        && (output === undefined || outputConnection[1] === output)\n        && (input === undefined || outputConnection[2] === input)))\n        .map((outputConnection) => {\n        if (isAudioNodeOutputConnection(outputConnection)) {\n            deleteInputsOfAudioNode(source, ...outputConnection);\n        }\n        else {\n            deleteInputsOfAudioParam(source, ...outputConnection);\n        }\n        audioNodeConnectionsOfSource.outputs.delete(outputConnection);\n        return outputConnection[0];\n    });\n};\nexport const createAudioNodeConstructor = (addAudioNodeConnections, auxiliaryGainNodeStore, cacheTestResult, createIncrementCycleCounter, createIndexSizeError, createInvalidAccessError, createNotSupportedError, decrementCycleCounter, detectCycles, eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext) => {\n    return class AudioNode extends eventTargetConstructor {\n        constructor(context, isActive, nativeAudioNode, audioNodeRenderer) {\n            super(nativeAudioNode);\n            this._context = context;\n            this._nativeAudioNode = nativeAudioNode;\n            const nativeContext = getNativeContext(context);\n            // Bug #12: Safari does not support to disconnect a specific destination.\n            if (isNativeAudioContext(nativeContext) && true !== cacheTestResult(testAudioNodeDisconnectMethodSupport, () => {\n                return testAudioNodeDisconnectMethodSupport(nativeContext);\n            })) {\n                wrapAudioNodeDisconnectMethod(nativeAudioNode);\n            }\n            AUDIO_NODE_STORE.set(this, nativeAudioNode);\n            EVENT_LISTENERS.set(this, new Set());\n            if (isActive) {\n                setInternalStateToActive(this);\n            }\n            addAudioNodeConnections(this, audioNodeRenderer, nativeAudioNode);\n        }\n        get channelCount() {\n            return this._nativeAudioNode.channelCount;\n        }\n        set channelCount(value) {\n            this._nativeAudioNode.channelCount = value;\n        }\n        get channelCountMode() {\n            return this._nativeAudioNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            this._nativeAudioNode.channelCountMode = value;\n        }\n        get channelInterpretation() {\n            return this._nativeAudioNode.channelInterpretation;\n        }\n        set channelInterpretation(value) {\n            this._nativeAudioNode.channelInterpretation = value;\n        }\n        get context() {\n            return this._context;\n        }\n        get numberOfInputs() {\n            return this._nativeAudioNode.numberOfInputs;\n        }\n        get numberOfOutputs() {\n            return this._nativeAudioNode.numberOfOutputs;\n        }\n        connect(destination, output = 0, input = 0) {\n            // Bug #174: Safari does expose a wrong numberOfOutputs for MediaStreamAudioDestinationNodes.\n            if (output < 0 || output >= this._nativeAudioNode.numberOfOutputs) {\n                throw createIndexSizeError();\n            }\n            const nativeContext = getNativeContext(this._context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            if (isNativeAudioNode(destination) || isNativeAudioParam(destination)) {\n                throw createInvalidAccessError();\n            }\n            if (isAudioNode(destination)) {\n                const nativeDestinationAudioNode = getNativeAudioNode(destination);\n                try {\n                    const connection = connectNativeAudioNodeToNativeAudioNode(this._nativeAudioNode, nativeDestinationAudioNode, output, input);\n                    if (isOffline || isPassiveAudioNode(this)) {\n                        this._nativeAudioNode.disconnect(...connection);\n                    }\n                    else if (isPassiveAudioNode(destination)) {\n                        setInternalStateToActive(destination);\n                    }\n                    // An AudioWorklet needs a connection because it otherwise may truncate the input array.\n                    // @todo Count the number of connections which depend on this auxiliary GainNode to know when it can be removed again.\n                    if (isAudioWorkletNode(destination)) {\n                        const auxiliaryGainNodes = auxiliaryGainNodeStore.get(nativeDestinationAudioNode);\n                        if (auxiliaryGainNodes === undefined) {\n                            const nativeGainNode = nativeContext.createGain();\n                            nativeGainNode.connect(connection[0], 0, connection[2]);\n                            auxiliaryGainNodeStore.set(nativeDestinationAudioNode, new Map([[input, nativeGainNode]]));\n                        }\n                        else if (auxiliaryGainNodes.get(input) === undefined) {\n                            const nativeGainNode = nativeContext.createGain();\n                            nativeGainNode.connect(connection[0], 0, connection[2]);\n                            auxiliaryGainNodes.set(input, nativeGainNode);\n                        }\n                    }\n                }\n                catch (err) {\n                    // Bug #41: Only Chrome, Firefox and Opera throw the correct exception by now.\n                    if (err.code === 12) {\n                        throw createInvalidAccessError();\n                    }\n                    throw err;\n                }\n                const isNewConnectionToAudioNode = isOffline\n                    ? addConnectionToAudioNodeOfOfflineAudioContext(this, destination, output, input)\n                    : addConnectionToAudioNodeOfAudioContext(this, destination, output, input);\n                // Bug #164: Only Firefox detects cycles so far.\n                if (isNewConnectionToAudioNode) {\n                    const cycles = detectCycles([this], destination);\n                    visitEachAudioNodeOnce(cycles, createIncrementCycleCounter(isOffline));\n                }\n                return destination;\n            }\n            const nativeAudioParam = getNativeAudioParam(destination);\n            /*\n             * Bug #147 & #153: Safari does not support to connect an input signal to the playbackRate AudioParam of an\n             * AudioBufferSourceNode. This can't be easily detected and that's why the outdated name property is used here to identify\n             * Safari.\n             */\n            if (nativeAudioParam.name === 'playbackRate') {\n                throw createNotSupportedError();\n            }\n            try {\n                this._nativeAudioNode.connect(nativeAudioParam, output);\n                if (isOffline || isPassiveAudioNode(this)) {\n                    this._nativeAudioNode.disconnect(nativeAudioParam, output);\n                }\n            }\n            catch (err) {\n                // Bug #58: Only Firefox does throw an InvalidStateError yet.\n                if (err.code === 12) {\n                    throw createInvalidAccessError();\n                }\n                throw err;\n            }\n            const isNewConnectionToAudioParam = isOffline\n                ? addConnectionToAudioParamOfOfflineAudioContext(this, destination, output)\n                : addConnectionToAudioParamOfAudioContext(this, destination, output);\n            // Bug #164: Only Firefox detects cycles so far.\n            if (isNewConnectionToAudioParam) {\n                const cycles = detectCycles([this], destination);\n                visitEachAudioNodeOnce(cycles, createIncrementCycleCounter(isOffline));\n            }\n        }\n        disconnect(destinationOrOutput, output, input) {\n            let destinations;\n            if (destinationOrOutput === undefined) {\n                destinations = deleteAnyConnection(this);\n            }\n            else if (typeof destinationOrOutput === 'number') {\n                if (destinationOrOutput < 0 || destinationOrOutput >= this.numberOfOutputs) {\n                    throw createIndexSizeError();\n                }\n                destinations = deleteConnectionAtOutput(this, destinationOrOutput);\n            }\n            else {\n                if (output !== undefined && (output < 0 || output >= this.numberOfOutputs)) {\n                    throw createIndexSizeError();\n                }\n                if (isAudioNode(destinationOrOutput)\n                    && input !== undefined\n                    && (input < 0 || input >= destinationOrOutput.numberOfInputs)) {\n                    throw createIndexSizeError();\n                }\n                destinations = deleteConnectionToDestination(this, destinationOrOutput, output, input);\n                if (destinations.length === 0) {\n                    throw createInvalidAccessError();\n                }\n            }\n            // Bug #164: Only Firefox detects cycles so far.\n            for (const destination of destinations) {\n                const cycles = detectCycles([this], destination);\n                visitEachAudioNodeOnce(cycles, decrementCycleCounter);\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-node-constructor.js.map","import { AutomationEventList } from 'automation-events';\nexport const createAudioParamFactory = (addAudioParamConnections, audioParamAudioNodeStore, audioParamStore, createAudioParamRenderer, createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent, nativeAudioContextConstructor) => {\n    return (audioNode, isAudioParamOfOfflineAudioContext, nativeAudioParam, maxValue = null, minValue = null) => {\n        const automationEventList = new AutomationEventList(nativeAudioParam.defaultValue);\n        const audioParamRenderer = (isAudioParamOfOfflineAudioContext) ? createAudioParamRenderer(automationEventList) : null;\n        const audioParam = {\n            get defaultValue() {\n                return nativeAudioParam.defaultValue;\n            },\n            get maxValue() {\n                return (maxValue === null) ? nativeAudioParam.maxValue : maxValue;\n            },\n            get minValue() {\n                return (minValue === null) ? nativeAudioParam.minValue : minValue;\n            },\n            get value() {\n                return nativeAudioParam.value;\n            },\n            set value(value) {\n                nativeAudioParam.value = value;\n                // Bug #98: Edge, Firefox & Safari do not yet treat the value setter like a call to setValueAtTime().\n                audioParam.setValueAtTime(value, audioNode.context.currentTime);\n            },\n            cancelAndHoldAtTime(cancelTime) {\n                // Bug #28: Edge, Firefox & Safari do not yet implement cancelAndHoldAtTime().\n                if (typeof nativeAudioParam.cancelAndHoldAtTime === 'function') {\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));\n                    nativeAudioParam.cancelAndHoldAtTime(cancelTime);\n                }\n                else {\n                    const previousLastEvent = Array\n                        .from(automationEventList)\n                        .pop();\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));\n                    const currentLastEvent = Array\n                        .from(automationEventList)\n                        .pop();\n                    nativeAudioParam.cancelScheduledValues(cancelTime);\n                    if (previousLastEvent !== currentLastEvent && currentLastEvent !== undefined) {\n                        if (currentLastEvent.type === 'exponentialRampToValue') {\n                            nativeAudioParam.exponentialRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);\n                        }\n                        else if (currentLastEvent.type === 'linearRampToValue') {\n                            nativeAudioParam.linearRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);\n                        }\n                        else if (currentLastEvent.type === 'setValue') {\n                            nativeAudioParam.setValueAtTime(currentLastEvent.value, currentLastEvent.startTime);\n                        }\n                        else if (currentLastEvent.type === 'setValueCurve') {\n                            nativeAudioParam.setValueCurveAtTime(currentLastEvent.values, currentLastEvent.startTime, currentLastEvent.duration);\n                        }\n                    }\n                }\n                return audioParam;\n            },\n            cancelScheduledValues(cancelTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createCancelScheduledValuesAutomationEvent(cancelTime));\n                nativeAudioParam.cancelScheduledValues(cancelTime);\n                return audioParam;\n            },\n            exponentialRampToValueAtTime(value, endTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createExponentialRampToValueAutomationEvent(value, endTime));\n                nativeAudioParam.exponentialRampToValueAtTime(value, endTime);\n                return audioParam;\n            },\n            linearRampToValueAtTime(value, endTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createLinearRampToValueAutomationEvent(value, endTime));\n                nativeAudioParam.linearRampToValueAtTime(value, endTime);\n                return audioParam;\n            },\n            setTargetAtTime(target, startTime, timeConstant) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createSetTargetAutomationEvent(target, startTime, timeConstant));\n                nativeAudioParam.setTargetAtTime(target, startTime, timeConstant);\n                return audioParam;\n            },\n            setValueAtTime(value, startTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createSetValueAutomationEvent(value, startTime));\n                nativeAudioParam.setValueAtTime(value, startTime);\n                return audioParam;\n            },\n            setValueCurveAtTime(values, startTime, duration) {\n                /*\n                 * Bug #152: Safari does not correctly interpolate the values of the curve.\n                 * @todo Unfortunately there is no way to test for this behavior in synchronous fashion which is why testing for the\n                 * existence of the webkitAudioContext is used as a workaround here.\n                 */\n                if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {\n                    const endTime = startTime + duration;\n                    const sampleRate = audioNode.context.sampleRate;\n                    const firstSample = Math.ceil(startTime * sampleRate);\n                    const lastSample = Math.floor((endTime) * sampleRate);\n                    const numberOfInterpolatedValues = lastSample - firstSample;\n                    const interpolatedValues = new Float32Array(numberOfInterpolatedValues);\n                    for (let i = 0; i < numberOfInterpolatedValues; i += 1) {\n                        const theoreticIndex = ((values.length - 1) / duration) * (((firstSample + i) / sampleRate) - startTime);\n                        const lowerIndex = Math.floor(theoreticIndex);\n                        const upperIndex = Math.ceil(theoreticIndex);\n                        interpolatedValues[i] = (lowerIndex === upperIndex)\n                            ? values[lowerIndex]\n                            : ((1 - (theoreticIndex - lowerIndex)) * values[lowerIndex])\n                                + ((1 - (upperIndex - theoreticIndex)) * values[upperIndex]);\n                    }\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createSetValueCurveAutomationEvent(interpolatedValues, startTime, duration));\n                    nativeAudioParam.setValueCurveAtTime(interpolatedValues, startTime, duration);\n                    const timeOfLastSample = lastSample / sampleRate;\n                    if (timeOfLastSample < endTime) {\n                        audioParam.setValueAtTime(interpolatedValues[interpolatedValues.length - 1], timeOfLastSample);\n                    }\n                    audioParam.setValueAtTime(values[values.length - 1], endTime);\n                }\n                else {\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createSetValueCurveAutomationEvent(values, startTime, duration));\n                    nativeAudioParam.setValueCurveAtTime(values, startTime, duration);\n                }\n                return audioParam;\n            }\n        };\n        audioParamStore.set(audioParam, nativeAudioParam);\n        audioParamAudioNodeStore.set(audioParam, audioNode);\n        addAudioParamConnections(audioParam, audioParamRenderer);\n        return audioParam;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-param-factory.js.map","export const createAudioParamRenderer = (automationEventList) => {\n    return {\n        replay(audioParam) {\n            for (const automationEvent of automationEventList) {\n                if (automationEvent.type === 'exponentialRampToValue') {\n                    const { endTime, value } = automationEvent;\n                    audioParam.exponentialRampToValueAtTime(value, endTime);\n                }\n                else if (automationEvent.type === 'linearRampToValue') {\n                    const { endTime, value } = automationEvent;\n                    audioParam.linearRampToValueAtTime(value, endTime);\n                }\n                else if (automationEvent.type === 'setTarget') {\n                    const { startTime, target, timeConstant } = automationEvent;\n                    audioParam.setTargetAtTime(target, startTime, timeConstant);\n                }\n                else if (automationEvent.type === 'setValue') {\n                    const { startTime, value } = automationEvent;\n                    audioParam.setValueAtTime(value, startTime);\n                }\n                else if (automationEvent.type === 'setValueCurve') {\n                    const { duration, startTime, values } = automationEvent;\n                    audioParam.setValueCurveAtTime(values, startTime, duration);\n                }\n                else {\n                    throw new Error(\"Can't apply an unknown automation.\");\n                }\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-param-renderer.js.map","import { NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS } from '../globals';\nimport { ReadOnlyMap } from '../read-only-map';\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    // Bug #61: The channelCountMode should be 'max' according to the spec but is set to 'explicit' to achieve consistent behavior.\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    numberOfInputs: 1,\n    numberOfOutputs: 1,\n    outputChannelCount: undefined,\n    parameterData: {},\n    processorOptions: {}\n};\nconst createChannelCount = (length) => {\n    const channelCount = [];\n    for (let i = 0; i < length; i += 1) {\n        channelCount.push(1);\n    }\n    return channelCount;\n};\nconst sanitizedOptions = (options) => {\n    return {\n        ...options,\n        outputChannelCount: (options.outputChannelCount !== undefined) ?\n            options.outputChannelCount :\n            (options.numberOfInputs === 1 && options.numberOfOutputs === 1) ?\n                /*\n                 * Bug #61: This should be the computedNumberOfChannels, but unfortunately that is almost impossible to fake. That's why\n                 * the channelCountMode is required to be 'explicit' as long as there is not a native implementation in every browser. That\n                 * makes sure the computedNumberOfChannels is equivilant to the channelCount which makes it much easier to compute.\n                 */\n                [options.channelCount] :\n                createChannelCount(options.numberOfOutputs)\n    };\n};\nexport const createAudioWorkletNodeConstructor = (addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, wrapEventListener) => {\n    return class AudioWorkletNode extends audioNodeConstructor {\n        constructor(context, name, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const mergedOptions = sanitizedOptions({ ...DEFAULT_OPTIONS, ...options });\n            const nodeNameToProcessorConstructorMap = NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);\n            const processorConstructor = (nodeNameToProcessorConstructorMap === undefined) ?\n                undefined :\n                nodeNameToProcessorConstructorMap.get(name);\n            const nativeAudioWorkletNode = createNativeAudioWorkletNode(nativeContext, isOffline ? null : context.baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, mergedOptions);\n            const audioWorkletNodeRenderer = ((isOffline)\n                ? createAudioWorkletNodeRenderer(name, mergedOptions, processorConstructor)\n                : null);\n            /*\n             * @todo Add a mechanism to switch an AudioWorkletNode to passive once the process() function of the AudioWorkletProcessor\n             * returns false.\n             */\n            super(context, true, nativeAudioWorkletNode, audioWorkletNodeRenderer);\n            const parameters = [];\n            nativeAudioWorkletNode.parameters.forEach((nativeAudioParam, nm) => {\n                const audioParam = createAudioParam(this, isOffline, nativeAudioParam);\n                parameters.push([nm, audioParam]);\n            });\n            this._nativeAudioWorkletNode = nativeAudioWorkletNode;\n            this._onprocessorerror = null;\n            this._parameters = new ReadOnlyMap(parameters);\n            /*\n             * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to\n             * the destination.\n             */\n            if (isOffline) {\n                addUnrenderedAudioWorkletNode(nativeContext, this);\n            }\n        }\n        get onprocessorerror() {\n            return this._onprocessorerror;\n        }\n        set onprocessorerror(value) {\n            const wrappedListener = (typeof value === 'function')\n                ? wrapEventListener(this, value)\n                : null;\n            this._nativeAudioWorkletNode.onprocessorerror = wrappedListener;\n            const nativeOnProcessorError = this._nativeAudioWorkletNode.onprocessorerror;\n            this._onprocessorerror = (nativeOnProcessorError !== null && nativeOnProcessorError === wrappedListener)\n                ? value\n                : nativeOnProcessorError;\n        }\n        get parameters() {\n            if (this._parameters === null) {\n                // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                return this._nativeAudioWorkletNode.parameters;\n            }\n            return this._parameters;\n        }\n        get port() {\n            return this._nativeAudioWorkletNode.port;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-worklet-node-constructor.js.map","import { copyFromChannel } from '../helpers/copy-from-channel';\nimport { copyToChannel } from '../helpers/copy-to-channel';\nimport { createNestedArrays } from '../helpers/create-nested-arrays';\nimport { getAudioNodeConnections } from '../helpers/get-audio-node-connections';\nimport { getAudioWorkletProcessor } from '../helpers/get-audio-worklet-processor';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nconst processBuffer = async (proxy, renderedBuffer, nativeOfflineAudioContext, options, processorConstructor, exposeCurrentFrameAndCurrentTime) => {\n    // Ceil the length to the next full render quantum.\n    // Bug #17: Safari does not yet expose the length.\n    const length = (renderedBuffer === null) ? (Math.ceil(proxy.context.length / 128) * 128) : renderedBuffer.length;\n    const numberOfInputChannels = options.channelCount * options.numberOfInputs;\n    const numberOfOutputChannels = options.outputChannelCount.reduce((sum, value) => sum + value, 0);\n    const processedBuffer = (numberOfOutputChannels === 0) ? null : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);\n    if (processorConstructor === undefined) {\n        throw new Error('Missing the processor constructor.');\n    }\n    const audioNodeConnections = getAudioNodeConnections(proxy);\n    const audioWorkletProcessor = await getAudioWorkletProcessor(nativeOfflineAudioContext, proxy);\n    const inputs = createNestedArrays(options.numberOfInputs, options.channelCount);\n    const outputs = createNestedArrays(options.numberOfOutputs, options.outputChannelCount);\n    const parameters = Array\n        .from(proxy.parameters.keys())\n        .reduce((prmtrs, name) => ({ ...prmtrs, [name]: new Float32Array(128) }), {});\n    for (let i = 0; i < length; i += 128) {\n        if (options.numberOfInputs > 0 && renderedBuffer !== null) {\n            for (let j = 0; j < options.numberOfInputs; j += 1) {\n                for (let k = 0; k < options.channelCount; k += 1) {\n                    copyFromChannel(renderedBuffer, inputs[j], k, k, i);\n                }\n            }\n        }\n        if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) {\n            processorConstructor.parameterDescriptors.forEach(({ name }, index) => {\n                copyFromChannel(renderedBuffer, parameters, name, numberOfInputChannels + index, i);\n            });\n        }\n        for (let j = 0; j < options.numberOfInputs; j += 1) {\n            for (let k = 0; k < options.outputChannelCount[j]; k += 1) {\n                // The byteLength will be 0 when the ArrayBuffer was transferred.\n                if (outputs[j][k].byteLength === 0) {\n                    outputs[j][k] = new Float32Array(128);\n                }\n            }\n        }\n        try {\n            const potentiallyEmptyInputs = inputs\n                .map((input, index) => {\n                if (audioNodeConnections.activeInputs[index].size === 0) {\n                    return [];\n                }\n                return input;\n            });\n            const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));\n            if (processedBuffer !== null) {\n                for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {\n                    for (let k = 0; k < options.outputChannelCount[j]; k += 1) {\n                        copyToChannel(processedBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);\n                    }\n                    outputChannelSplitterNodeOutput += options.outputChannelCount[j];\n                }\n            }\n            if (!activeSourceFlag) {\n                break;\n            }\n        }\n        catch (error) {\n            proxy.dispatchEvent(new ErrorEvent('processorerror', { error }));\n            break;\n        }\n    }\n    return processedBuffer;\n};\nexport const createAudioWorkletNodeRendererFactory = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return (name, options, processorConstructor) => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let processedBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeAudioWorkletNode = getNativeAudioNode(proxy);\n            let nativeOutputNodes = null;\n            const nativeAudioWorkletNodeIsOwnedByContext = isOwnedByContext(nativeAudioWorkletNode, nativeOfflineAudioContext);\n            // Bug #61: Only Chrome & Opera have an implementation of the AudioWorkletNode yet.\n            if (nativeAudioWorkletNodeConstructor === null) {\n                const numberOfOutputChannels = options.outputChannelCount.reduce((sum, value) => sum + value, 0);\n                const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {\n                    channelCount: Math.max(1, numberOfOutputChannels),\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    numberOfOutputs: Math.max(1, numberOfOutputChannels)\n                });\n                const outputChannelMergerNodes = [];\n                for (let i = 0; i < proxy.numberOfOutputs; i += 1) {\n                    outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {\n                        channelCount: 1,\n                        channelCountMode: 'explicit',\n                        channelInterpretation: 'speakers',\n                        numberOfInputs: options.outputChannelCount[i]\n                    }));\n                }\n                const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {\n                    channelCount: options.channelCount,\n                    channelCountMode: options.channelCountMode,\n                    channelInterpretation: options.channelInterpretation,\n                    gain: 1\n                });\n                outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);\n                outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);\n                nativeOutputNodes = [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode];\n            }\n            else if (!nativeAudioWorkletNodeIsOwnedByContext) {\n                nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, (nativeOutputNodes === null) ? nativeAudioWorkletNode : nativeOutputNodes[2]);\n            if (nativeOutputNodes !== null) {\n                if (processedBufferPromise === null) {\n                    if (processorConstructor === undefined) {\n                        throw new Error('Missing the processor constructor.');\n                    }\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    // Bug #47: The AudioDestinationNode in Edge and Safari gets not initialized correctly.\n                    const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;\n                    const numberOfParameters = (processorConstructor.parameterDescriptors === undefined)\n                        ? 0\n                        : processorConstructor.parameterDescriptors.length;\n                    const numberOfChannels = numberOfInputChannels + numberOfParameters;\n                    const renderBuffer = async () => {\n                        const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, \n                        // Ceil the length to the next full render quantum.\n                        // Bug #17: Safari does not yet expose the length.\n                        Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);\n                        const gainNodes = [];\n                        const inputChannelSplitterNodes = [];\n                        for (let i = 0; i < options.numberOfInputs; i += 1) {\n                            gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {\n                                channelCount: options.channelCount,\n                                channelCountMode: options.channelCountMode,\n                                channelInterpretation: options.channelInterpretation,\n                                gain: 1\n                            }));\n                            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {\n                                channelCount: options.channelCount,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                numberOfOutputs: options.channelCount\n                            }));\n                        }\n                        const constantSourceNodes = await Promise\n                            .all(Array\n                            .from(proxy.parameters.values())\n                            .map(async (audioParam) => {\n                            const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                                channelCount: 1,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                offset: audioParam.value\n                            });\n                            await renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset, trace);\n                            return constantSourceNode;\n                        }));\n                        const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n                            channelCount: 1,\n                            channelCountMode: 'explicit',\n                            channelInterpretation: 'speakers',\n                            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)\n                        });\n                        for (let i = 0; i < options.numberOfInputs; i += 1) {\n                            gainNodes[i].connect(inputChannelSplitterNodes[i]);\n                            for (let j = 0; j < options.channelCount; j += 1) {\n                                inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, (i * options.channelCount) + j);\n                            }\n                        }\n                        for (const [index, constantSourceNode] of constantSourceNodes.entries()) {\n                            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);\n                            constantSourceNode.start(0);\n                        }\n                        inputChannelMergerNode.connect(partialOfflineAudioContext.destination);\n                        await Promise\n                            .all(gainNodes\n                            .map((gainNode) => renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode, trace)));\n                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                    };\n                    processedBufferPromise = processBuffer(proxy, (numberOfChannels === 0) ? null : await renderBuffer(), nativeOfflineAudioContext, options, processorConstructor, exposeCurrentFrameAndCurrentTime);\n                }\n                const processedBuffer = await processedBufferPromise;\n                const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {\n                    buffer: null,\n                    channelCount: 2,\n                    channelCountMode: 'max',\n                    channelInterpretation: 'speakers',\n                    loop: false,\n                    loopEnd: 0,\n                    loopStart: 0,\n                    playbackRate: 1\n                });\n                const [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode] = nativeOutputNodes;\n                if (processedBuffer !== null) {\n                    audioBufferSourceNode.buffer = processedBuffer;\n                    audioBufferSourceNode.start(0);\n                }\n                audioBufferSourceNode.connect(outputChannelSplitterNode);\n                for (let i = 0, outputChannelSplitterNodeOutput = 0; i < proxy.numberOfOutputs; i += 1) {\n                    const outputChannelMergerNode = outputChannelMergerNodes[i];\n                    for (let j = 0; j < options.outputChannelCount[i]; j += 1) {\n                        outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                    }\n                    outputChannelSplitterNodeOutput += options.outputChannelCount[i];\n                }\n                return outputGainNode;\n            }\n            if (!nativeAudioWorkletNodeIsOwnedByContext) {\n                for (const [nm, audioParam] of proxy.parameters.entries()) {\n                    await renderAutomation(nativeOfflineAudioContext, audioParam, \n                    // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                    nativeAudioWorkletNode.parameters.get(nm), trace);\n                }\n            }\n            else {\n                for (const [nm, audioParam] of proxy.parameters.entries()) {\n                    await connectAudioParam(nativeOfflineAudioContext, audioParam, \n                    // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                    nativeAudioWorkletNode.parameters.get(nm), trace);\n                }\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode, trace);\n            return nativeAudioWorkletNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);\n                const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/audio-worklet-node-renderer-factory.js.map","export const createBaseAudioContextConstructor = (addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor) => {\n    return class BaseAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(_nativeContext, numberOfChannels) {\n            super(_nativeContext, numberOfChannels);\n            this._nativeContext = _nativeContext;\n            this._audioWorklet = (addAudioWorkletModule === undefined) ?\n                undefined :\n                {\n                    addModule: (moduleURL, options) => {\n                        return addAudioWorkletModule(this, moduleURL, options);\n                    }\n                };\n        }\n        get audioWorklet() {\n            return this._audioWorklet;\n        }\n        createAnalyser() {\n            return new analyserNodeConstructor(this);\n        }\n        createBiquadFilter() {\n            return new biquadFilterNodeConstructor(this);\n        }\n        createBuffer(numberOfChannels, length, sampleRate) {\n            return new audioBufferConstructor({ length, numberOfChannels, sampleRate });\n        }\n        createBufferSource() {\n            return new audioBufferSourceNodeConstructor(this);\n        }\n        createChannelMerger(numberOfInputs = 6) {\n            return new channelMergerNodeConstructor(this, { numberOfInputs });\n        }\n        createChannelSplitter(numberOfOutputs = 6) {\n            return new channelSplitterNodeConstructor(this, { numberOfOutputs });\n        }\n        createConstantSource() {\n            return new constantSourceNodeConstructor(this);\n        }\n        createConvolver() {\n            return new convolverNodeConstructor(this);\n        }\n        createDelay(maxDelayTime = 1) {\n            return new delayNodeConstructor(this, { maxDelayTime });\n        }\n        createDynamicsCompressor() {\n            return new dynamicsCompressorNodeConstructor(this);\n        }\n        createGain() {\n            return new gainNodeConstructor(this);\n        }\n        createIIRFilter(feedforward, feedback) {\n            return new iIRFilterNodeConstructor(this, { feedback, feedforward });\n        }\n        createOscillator() {\n            return new oscillatorNodeConstructor(this);\n        }\n        createPanner() {\n            return new pannerNodeConstructor(this);\n        }\n        createPeriodicWave(real, imag, constraints = { disableNormalization: false }) {\n            return new periodicWaveConstructor(this, { ...constraints, imag, real });\n        }\n        createStereoPanner() {\n            return new stereoPannerNodeConstructor(this);\n        }\n        createWaveShaper() {\n            return new waveShaperNodeConstructor(this);\n        }\n        decodeAudioData(audioData, successCallback, errorCallback) {\n            return decodeAudioData(this._nativeContext, audioData)\n                .then((audioBuffer) => {\n                if (typeof successCallback === 'function') {\n                    successCallback(audioBuffer);\n                }\n                return audioBuffer;\n            })\n                .catch((err) => {\n                if (typeof errorCallback === 'function') {\n                    errorCallback(err);\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/base-audio-context-constructor.js.map","import { MOST_NEGATIVE_SINGLE_FLOAT, MOST_POSITIVE_SINGLE_FLOAT } from '../constants';\nconst DEFAULT_OPTIONS = {\n    Q: 1,\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    detune: 0,\n    frequency: 350,\n    gain: 0,\n    type: 'lowpass'\n};\nexport const createBiquadFilterNodeConstructor = (audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class BiquadFilterNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const biquadFilterNodeRenderer = ((isOffline) ? createBiquadFilterNodeRenderer() : null);\n            super(context, false, nativeBiquadFilterNode, biquadFilterNodeRenderer);\n            // Bug #80: Edge & Safari do not export the correct values for maxValue and minValue.\n            this._Q = createAudioParam(this, isOffline, nativeBiquadFilterNode.Q, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n            // Bug #78: Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._detune = createAudioParam(this, isOffline, nativeBiquadFilterNode.detune, 1200 * Math.log2(MOST_POSITIVE_SINGLE_FLOAT), -1200 * Math.log2(MOST_POSITIVE_SINGLE_FLOAT));\n            /*\n             * Bug #77: Edge does not export the correct values for maxValue and minValue. Firefox & Safari do not export the correct value\n             * for minValue.\n             */\n            this._frequency = createAudioParam(this, isOffline, nativeBiquadFilterNode.frequency, context.sampleRate / 2, 0);\n            // Bug #79: Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._gain = createAudioParam(this, isOffline, nativeBiquadFilterNode.gain, 40 * Math.log10(MOST_POSITIVE_SINGLE_FLOAT), MOST_NEGATIVE_SINGLE_FLOAT);\n            this._nativeBiquadFilterNode = nativeBiquadFilterNode;\n        }\n        get detune() {\n            return this._detune;\n        }\n        get frequency() {\n            return this._frequency;\n        }\n        get gain() {\n            return this._gain;\n        }\n        get Q() {\n            return this._Q;\n        }\n        get type() {\n            return this._nativeBiquadFilterNode.type;\n        }\n        set type(value) {\n            this._nativeBiquadFilterNode.type = value;\n        }\n        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n            this._nativeBiquadFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);\n            // Bug #68: Only Chrome, Firefox & Opera do throw an error if the parameters differ in their length.\n            if ((frequencyHz.length !== magResponse.length) || (magResponse.length !== phaseResponse.length)) {\n                throw createInvalidAccessError();\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/biquad-filter-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createBiquadFilterNodeRendererFactory = (connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeBiquadFilterNodes = new WeakMap();\n        const createBiquadFilterNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeBiquadFilterNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeBiquadFilterNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeBiquadFilterNodeIsOwnedByContext = isOwnedByContext(nativeBiquadFilterNode, nativeOfflineAudioContext);\n            if (!nativeBiquadFilterNodeIsOwnedByContext) {\n                const options = {\n                    Q: nativeBiquadFilterNode.Q.value,\n                    channelCount: nativeBiquadFilterNode.channelCount,\n                    channelCountMode: nativeBiquadFilterNode.channelCountMode,\n                    channelInterpretation: nativeBiquadFilterNode.channelInterpretation,\n                    detune: nativeBiquadFilterNode.detune.value,\n                    frequency: nativeBiquadFilterNode.frequency.value,\n                    gain: nativeBiquadFilterNode.gain.value,\n                    type: nativeBiquadFilterNode.type\n                };\n                nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeBiquadFilterNodes.set(nativeOfflineAudioContext, nativeBiquadFilterNode);\n            if (!nativeBiquadFilterNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain, trace);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain, trace);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeBiquadFilterNode, trace);\n            return nativeBiquadFilterNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeBiquadFilterNode = renderedNativeBiquadFilterNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeBiquadFilterNode !== undefined) {\n                    return Promise.resolve(renderedNativeBiquadFilterNode);\n                }\n                return createBiquadFilterNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/biquad-filter-node-renderer-factory.js.map","export const createCacheTestResult = (ongoingTests, testResults) => {\n    return (tester, test) => {\n        const cachedTestResult = testResults.get(tester);\n        if (cachedTestResult !== undefined) {\n            return cachedTestResult;\n        }\n        const ongoingTest = ongoingTests.get(tester);\n        if (ongoingTest !== undefined) {\n            return ongoingTest;\n        }\n        try {\n            const synchronousTestResult = test();\n            if (synchronousTestResult instanceof Promise) {\n                ongoingTests.set(tester, synchronousTestResult);\n                return synchronousTestResult\n                    .catch(() => false)\n                    .then((finalTestResult) => {\n                    ongoingTests.delete(tester);\n                    testResults.set(tester, finalTestResult);\n                    return finalTestResult;\n                });\n            }\n            testResults.set(tester, synchronousTestResult);\n            return synchronousTestResult;\n        }\n        catch {\n            testResults.set(tester, false);\n            return false;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/cache-test-result.js.map","const DEFAULT_OPTIONS = {\n    channelCount: 1,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    numberOfInputs: 6\n};\nexport const createChannelMergerNodeConstructor = (audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class ChannelMergerNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeChannelMergerNode = createNativeChannelMergerNode(nativeContext, mergedOptions);\n            const channelMergerNodeRenderer = ((isNativeOfflineAudioContext(nativeContext))\n                ? createChannelMergerNodeRenderer()\n                : null);\n            super(context, false, nativeChannelMergerNode, channelMergerNodeRenderer);\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/channel-merger-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createChannelMergerNodeRendererFactory = (createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeAudioNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAudioNodeIsOwnedByContext = isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext);\n            if (!nativeAudioNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAudioNode.channelCount,\n                    channelCountMode: nativeAudioNode.channelCountMode,\n                    channelInterpretation: nativeAudioNode.channelInterpretation,\n                    numberOfInputs: nativeAudioNode.numberOfInputs\n                };\n                nativeAudioNode = createNativeChannelMergerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode, trace);\n            return nativeAudioNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/channel-merger-node-renderer-factory.js.map","const DEFAULT_OPTIONS = {\n    channelCount: 6,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'discrete',\n    numberOfOutputs: 6\n};\nconst sanitizedOptions = (options) => {\n    return { ...options, channelCount: options.numberOfOutputs };\n};\nexport const createChannelSplitterNodeConstructor = (audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class ChannelSplitterNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = sanitizedOptions({ ...DEFAULT_OPTIONS, ...options });\n            const nativeChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, mergedOptions);\n            const channelSplitterNodeRenderer = ((isNativeOfflineAudioContext(nativeContext))\n                ? createChannelSplitterNodeRenderer()\n                : null);\n            super(context, false, nativeChannelSplitterNode, channelSplitterNodeRenderer);\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/channel-splitter-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createChannelSplitterNodeRendererFactory = (createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeAudioNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAudioNodeIsOwnedByContext = isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext);\n            if (!nativeAudioNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAudioNode.channelCount,\n                    channelCountMode: nativeAudioNode.channelCountMode,\n                    channelInterpretation: nativeAudioNode.channelInterpretation,\n                    numberOfOutputs: nativeAudioNode.numberOfOutputs\n                };\n                nativeAudioNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode, trace);\n            return nativeAudioNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/channel-splitter-node-renderer-factory.js.map","export const createConnectAudioParam = (renderInputsOfAudioParam) => {\n    return (nativeOfflineAudioContext, audioParam, nativeAudioParam, trace) => {\n        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam, trace);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/connect-audio-param.js.map","import { isNativeAudioNode } from '../guards/native-audio-node';\nexport const createConnectMultipleOutputs = (createIndexSizeError) => {\n    return (outputAudioNodes, destination, output = 0, input = 0) => {\n        const outputAudioNode = outputAudioNodes[output];\n        if (outputAudioNode === undefined) {\n            throw createIndexSizeError();\n        }\n        if (isNativeAudioNode(destination)) {\n            return outputAudioNode.connect(destination, 0, input);\n        }\n        return outputAudioNode.connect(destination, 0);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/connect-multiple-outputs.js.map","export const createConnectedNativeAudioBufferSourceNodeFactory = (createNativeAudioBufferSourceNode) => {\n    return (nativeContext, nativeAudioNode) => {\n        const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {\n            buffer: null,\n            channelCount: 2,\n            channelCountMode: 'max',\n            channelInterpretation: 'speakers',\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            playbackRate: 1\n        });\n        const nativeAudioBuffer = nativeContext.createBuffer(1, 2, nativeContext.sampleRate);\n        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n        nativeAudioBufferSourceNode.loop = true;\n        nativeAudioBufferSourceNode.connect(nativeAudioNode);\n        nativeAudioBufferSourceNode.start();\n        return () => {\n            nativeAudioBufferSourceNode.stop();\n            nativeAudioBufferSourceNode.disconnect(nativeAudioNode);\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js.map","import { MOST_NEGATIVE_SINGLE_FLOAT, MOST_POSITIVE_SINGLE_FLOAT } from '../constants';\nimport { setInternalStateToActive } from '../helpers/set-internal-state-to-active';\nimport { setInternalStateToPassive } from '../helpers/set-internal-state-to-passive';\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    offset: 1\n};\nexport const createConstantSourceNodeConstructor = (audioNodeConstructor, createAudioParam, createConstantSourceNodeRendererFactory, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class ConstantSourceNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeConstantSourceNode = createNativeConstantSourceNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const constantSourceNodeRenderer = ((isOffline)\n                ? createConstantSourceNodeRendererFactory()\n                : null);\n            super(context, false, nativeConstantSourceNode, constantSourceNodeRenderer);\n            this._constantSourceNodeRenderer = constantSourceNodeRenderer;\n            this._nativeConstantSourceNode = nativeConstantSourceNode;\n            /*\n             * Bug #62 & #74: Edge & Safari do not support ConstantSourceNodes and do not export the correct values for maxValue and\n             * minValue for GainNodes.\n             */\n            this._offset = createAudioParam(this, isOffline, nativeConstantSourceNode.offset, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n            this._onended = null;\n        }\n        get offset() {\n            return this._offset;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = (typeof value === 'function') ? wrapEventListener(this, value) : null;\n            this._nativeConstantSourceNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeConstantSourceNode.onended;\n            this._onended = (nativeOnEnded !== null && nativeOnEnded === wrappedListener)\n                ? value\n                : nativeOnEnded;\n        }\n        start(when = 0) {\n            this._nativeConstantSourceNode.start(when);\n            if (this._constantSourceNodeRenderer !== null) {\n                this._constantSourceNodeRenderer.start = when;\n            }\n            else {\n                setInternalStateToActive(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeConstantSourceNode.removeEventListener('ended', resetInternalStateToPassive);\n                    // @todo Determine a meaningful delay instead of just using one second.\n                    setTimeout(() => setInternalStateToPassive(this), 1000);\n                };\n                this._nativeConstantSourceNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeConstantSourceNode.stop(when);\n            if (this._constantSourceNodeRenderer !== null) {\n                this._constantSourceNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/constant-source-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createConstantSourceNodeRendererFactory = (connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeConstantSourceNodes = new WeakMap();\n        let start = null;\n        let stop = null;\n        const createConstantSourceNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeConstantSourceNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeConstantSourceNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeConstantSourceNodeIsOwnedByContext = isOwnedByContext(nativeConstantSourceNode, nativeOfflineAudioContext);\n            if (!nativeConstantSourceNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeConstantSourceNode.channelCount,\n                    channelCountMode: nativeConstantSourceNode.channelCountMode,\n                    channelInterpretation: nativeConstantSourceNode.channelInterpretation,\n                    offset: nativeConstantSourceNode.offset.value\n                };\n                nativeConstantSourceNode = createNativeConstantSourceNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeConstantSourceNode.start(start);\n                }\n                if (stop !== null) {\n                    nativeConstantSourceNode.stop(stop);\n                }\n            }\n            renderedNativeConstantSourceNodes.set(nativeOfflineAudioContext, nativeConstantSourceNode);\n            if (!nativeConstantSourceNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset, trace);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset, trace);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConstantSourceNode, trace);\n            return nativeConstantSourceNode;\n        };\n        return {\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeConstantSourceNode = renderedNativeConstantSourceNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeConstantSourceNode !== undefined) {\n                    return Promise.resolve(renderedNativeConstantSourceNode);\n                }\n                return createConstantSourceNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/constant-source-node-renderer-factory.js.map","export const createConvertNumberToUnsignedLong = (unit32Array) => {\n    return (value) => {\n        unit32Array[0] = value;\n        return unit32Array[0];\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/convert-number-to-unsigned-long.js.map","const DEFAULT_OPTIONS = {\n    buffer: null,\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    disableNormalization: false\n};\nexport const createConvolverNodeConstructor = (audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class ConvolverNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeConvolverNode = createNativeConvolverNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const convolverNodeRenderer = ((isOffline) ? createConvolverNodeRenderer() : null);\n            super(context, false, nativeConvolverNode, convolverNodeRenderer);\n            this._isBufferNullified = false;\n            this._nativeConvolverNode = nativeConvolverNode;\n        }\n        get buffer() {\n            if (this._isBufferNullified) {\n                return null;\n            }\n            return this._nativeConvolverNode.buffer;\n        }\n        set buffer(value) {\n            this._nativeConvolverNode.buffer = value;\n            // Bug #115: Safari does not allow to set the buffer to null.\n            if (value === null && this._nativeConvolverNode.buffer !== null) {\n                const nativeContext = this._nativeConvolverNode.context;\n                this._nativeConvolverNode.buffer = nativeContext.createBuffer(1, 1, nativeContext.sampleRate);\n                this._isBufferNullified = true;\n            }\n            else {\n                this._isBufferNullified = false;\n            }\n        }\n        get normalize() {\n            return this._nativeConvolverNode.normalize;\n        }\n        set normalize(value) {\n            this._nativeConvolverNode.normalize = value;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/convolver-node-constructor.js.map","import { isNativeAudioNodeFaker } from '../guards/native-audio-node-faker';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createConvolverNodeRendererFactory = (createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeConvolverNodes = new WeakMap();\n        const createConvolverNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeConvolverNode = getNativeAudioNode(proxy);\n            // If the initially used nativeConvolverNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeConvolverNodeIsOwnedByContext = isOwnedByContext(nativeConvolverNode, nativeOfflineAudioContext);\n            if (!nativeConvolverNodeIsOwnedByContext) {\n                const options = {\n                    buffer: nativeConvolverNode.buffer,\n                    channelCount: nativeConvolverNode.channelCount,\n                    channelCountMode: nativeConvolverNode.channelCountMode,\n                    channelInterpretation: nativeConvolverNode.channelInterpretation,\n                    disableNormalization: !nativeConvolverNode.normalize\n                };\n                nativeConvolverNode = createNativeConvolverNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeConvolverNodes.set(nativeOfflineAudioContext, nativeConvolverNode);\n            if (isNativeAudioNodeFaker(nativeConvolverNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode.inputs[0], trace);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode, trace);\n            }\n            return nativeConvolverNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeConvolverNode = renderedNativeConvolverNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeConvolverNode !== undefined) {\n                    return Promise.resolve(renderedNativeConvolverNode);\n                }\n                return createConvolverNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/convolver-node-renderer-factory.js.map","export const createCreateNativeOfflineAudioContext = (createNotSupportedError, nativeOfflineAudioContextConstructor) => {\n    return (numberOfChannels, length, sampleRate) => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            throw new Error('Missing the native OfflineAudioContext constructor.');\n        }\n        try {\n            return new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);\n        }\n        catch (err) {\n            // Bug #143, #144 & #146: Safari throws a SyntaxError when numberOfChannels, length or sampleRate are invalid.\n            // Bug #143: Edge throws a SyntaxError when numberOfChannels or length are invalid.\n            // Bug #145: Edge throws an IndexSizeError when sampleRate is zero.\n            if (err.name === 'IndexSizeError' || err.name === 'SyntaxError') {\n                throw createNotSupportedError();\n            }\n            throw err;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/create-native-offline-audio-context.js.map","export const createDataCloneError = () => {\n    try {\n        return new DOMException('', 'DataCloneError');\n    }\n    catch (err) {\n        // Bug #122: Edge is the only browser that does not yet allow to construct a DOMException.\n        err.code = 25;\n        err.name = 'DataCloneError';\n        return err;\n    }\n};\n//# sourceMappingURL=/build/es2019/factories/data-clone-error.js.map","import { detachArrayBuffer } from '../helpers/detach-array-buffer';\nimport { wrapAudioBufferGetChannelDataMethod } from '../helpers/wrap-audio-buffer-get-channel-data-method';\nexport const createDecodeAudioData = (audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, detachedArrayBuffers, getNativeContext, isNativeContext, isNativeOfflineAudioContext, nativeOfflineAudioContextConstructor, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    return (anyContext, audioData) => {\n        const nativeContext = isNativeContext(anyContext) ? anyContext : getNativeContext(anyContext);\n        // Bug #43: Only Chrome and Opera do throw a DataCloneError.\n        if (detachedArrayBuffers.has(audioData)) {\n            const err = createDataCloneError();\n            return Promise.reject(err);\n        }\n        // The audioData parameter maybe of a type which can't be added to a WeakSet.\n        try {\n            detachedArrayBuffers.add(audioData);\n        }\n        catch {\n            // Ignore errors.\n        }\n        // Bug #21: Safari does not support promises yet.\n        if (cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeContext))) {\n            // Bug #101: Edge does not decode something on a closed OfflineAudioContext.\n            const nativeContextOrBackupNativeContext = (nativeContext.state === 'closed' &&\n                nativeOfflineAudioContextConstructor !== null &&\n                isNativeOfflineAudioContext(nativeContext)) ?\n                new nativeOfflineAudioContextConstructor(1, 1, nativeContext.sampleRate) :\n                nativeContext;\n            const promise = nativeContextOrBackupNativeContext\n                .decodeAudioData(audioData)\n                .catch((err) => {\n                // Bug #27: Edge is rejecting invalid arrayBuffers with a DOMException.\n                if (err instanceof DOMException && err.name === 'NotSupportedError') {\n                    throw new TypeError();\n                }\n                throw err;\n            });\n            return promise\n                .then((audioBuffer) => {\n                // Bug #157: Only Chrome & Opera do allow the bufferOffset to be out-of-bounds.\n                if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {\n                    wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n                }\n                audioBufferStore.add(audioBuffer);\n                return audioBuffer;\n            });\n        }\n        // Bug #21: Safari does not return a Promise yet.\n        return new Promise((resolve, reject) => {\n            const complete = () => {\n                // Bug #133: Safari does neuter the ArrayBuffer.\n                try {\n                    detachArrayBuffer(audioData);\n                }\n                catch { /* Ignore errors. */ }\n            };\n            const fail = (err) => {\n                reject(err);\n                complete();\n            };\n            // Bug #26: Safari throws a synchronous error.\n            try {\n                // Bug #1: Safari requires a successCallback.\n                nativeContext.decodeAudioData(audioData, (audioBuffer) => {\n                    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n                    // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n                    if (typeof audioBuffer.copyFromChannel !== 'function') {\n                        wrapAudioBufferCopyChannelMethods(audioBuffer);\n                        wrapAudioBufferGetChannelDataMethod(audioBuffer);\n                    }\n                    audioBufferStore.add(audioBuffer);\n                    complete();\n                    resolve(audioBuffer);\n                }, (err) => {\n                    // Bug #4: Safari returns null instead of an error.\n                    if (err === null) {\n                        fail(createEncodingError());\n                    }\n                    else {\n                        fail(err);\n                    }\n                });\n            }\n            catch (err) {\n                fail(err);\n            }\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/decode-audio-data.js.map","import { isAudioNodeOutputConnection } from '../guards/audio-node-output-connection';\nexport const createDecrementCycleCounter = (connectNativeAudioNodeToNativeAudioNode, cycleCounters, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext) => {\n    return (audioNode, count) => {\n        const cycleCounter = cycleCounters.get(audioNode);\n        if (cycleCounter === undefined) {\n            throw new Error('Missing the expected cycle count.');\n        }\n        const nativeContext = getNativeContext(audioNode.context);\n        const isOffline = isNativeOfflineAudioContext(nativeContext);\n        if (cycleCounter === count) {\n            cycleCounters.delete(audioNode);\n            if (!isOffline && isActiveAudioNode(audioNode)) {\n                const nativeSourceAudioNode = getNativeAudioNode(audioNode);\n                const { outputs } = getAudioNodeConnections(audioNode);\n                for (const output of outputs) {\n                    if (isAudioNodeOutputConnection(output)) {\n                        const nativeDestinationAudioNode = getNativeAudioNode(output[0]);\n                        connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);\n                    }\n                    else {\n                        const nativeDestinationAudioParam = getNativeAudioParam(output[0]);\n                        nativeSourceAudioNode.connect(nativeDestinationAudioParam, output[1]);\n                    }\n                }\n            }\n        }\n        else {\n            cycleCounters.set(audioNode, cycleCounter - count);\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/decrement-cycle-counter.js.map","const DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    delayTime: 0,\n    maxDelayTime: 1\n};\nexport const createDelayNodeConstructor = (audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class DelayNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeDelayNode = createNativeDelayNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const delayNodeRenderer = ((isOffline)\n                ? createDelayNodeRenderer(mergedOptions.maxDelayTime)\n                : null);\n            super(context, false, nativeDelayNode, delayNodeRenderer);\n            // Bug #161: Edge does not export the correct values for maxValue and minValue.\n            this._delayTime = createAudioParam(this, isOffline, nativeDelayNode.delayTime, mergedOptions.maxDelayTime, 0);\n        }\n        get delayTime() {\n            return this._delayTime;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/delay-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createDelayNodeRendererFactory = (connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return (maxDelayTime) => {\n        const renderedNativeDelayNodes = new WeakMap();\n        const createDelayNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeDelayNode = getNativeAudioNode(proxy);\n            // If the initially used nativeDelayNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeDelayNodeIsOwnedByContext = isOwnedByContext(nativeDelayNode, nativeOfflineAudioContext);\n            if (!nativeDelayNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeDelayNode.channelCount,\n                    channelCountMode: nativeDelayNode.channelCountMode,\n                    channelInterpretation: nativeDelayNode.channelInterpretation,\n                    delayTime: nativeDelayNode.delayTime.value,\n                    maxDelayTime\n                };\n                nativeDelayNode = createNativeDelayNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeDelayNodes.set(nativeOfflineAudioContext, nativeDelayNode);\n            if (!nativeDelayNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime, trace);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime, trace);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDelayNode, trace);\n            return nativeDelayNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeDelayNode = renderedNativeDelayNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeDelayNode !== undefined) {\n                    return Promise.resolve(renderedNativeDelayNode);\n                }\n                return createDelayNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/delay-node-renderer-factory.js.map","export const createDeleteUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes) => {\n    return (nativeContext, audioWorkletNode) => {\n        getUnrenderedAudioWorkletNodes(nativeContext)\n            .delete(audioWorkletNode);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/delete-unrendered-audio-worklet-node.js.map","import { isAudioNode } from '../guards/audio-node';\nimport { isDelayNode } from '../guards/delay-node';\nexport const createDetectCycles = (audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey) => {\n    return function detectCycles(chain, nextLink) {\n        const audioNode = (isAudioNode(nextLink))\n            ? nextLink\n            : getValueForKey(audioParamAudioNodeStore, nextLink);\n        if (isDelayNode(audioNode)) {\n            return [];\n        }\n        if (chain[0] === audioNode) {\n            return [chain];\n        }\n        if (chain.includes(audioNode)) {\n            return [];\n        }\n        const { outputs } = getAudioNodeConnections(audioNode);\n        return Array\n            .from(outputs)\n            .map((outputConnection) => detectCycles([...chain, audioNode], outputConnection[0]))\n            .reduce((mergedCycles, nestedCycles) => mergedCycles.concat(nestedCycles), []);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/detect-cycles.js.map","import { isNativeAudioNode } from '../guards/native-audio-node';\nconst getOutputAudioNodeAtIndex = (createIndexSizeError, outputAudioNodes, output) => {\n    const outputAudioNode = outputAudioNodes[output];\n    if (outputAudioNode === undefined) {\n        throw createIndexSizeError();\n    }\n    return outputAudioNode;\n};\nexport const createDisconnectMultipleOutputs = (createIndexSizeError) => {\n    return (outputAudioNodes, destinationOrOutput = undefined, output = undefined, input = 0) => {\n        if (destinationOrOutput === undefined) {\n            return outputAudioNodes\n                .forEach((outputAudioNode) => outputAudioNode.disconnect());\n        }\n        if (typeof destinationOrOutput === 'number') {\n            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, destinationOrOutput)\n                .disconnect();\n        }\n        if (isNativeAudioNode(destinationOrOutput)) {\n            if (output === undefined) {\n                return outputAudioNodes\n                    .forEach((outputAudioNode) => outputAudioNode.disconnect(destinationOrOutput));\n            }\n            if (input === undefined) {\n                return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output)\n                    .disconnect(destinationOrOutput, 0);\n            }\n            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output)\n                .disconnect(destinationOrOutput, 0, input);\n        }\n        if (output === undefined) {\n            return outputAudioNodes\n                .forEach((outputAudioNode) => outputAudioNode.disconnect(destinationOrOutput));\n        }\n        return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output)\n            .disconnect(destinationOrOutput, 0);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/disconnect-multiple-outputs.js.map","const DEFAULT_OPTIONS = {\n    attack: 0.003,\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    knee: 30,\n    ratio: 12,\n    release: 0.25,\n    threshold: -24\n};\nexport const createDynamicsCompressorNodeConstructor = (audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext) => {\n    return class DynamicsCompressorNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const dynamicsCompressorNodeRenderer = ((isOffline)\n                ? createDynamicsCompressorNodeRenderer()\n                : null);\n            super(context, false, nativeDynamicsCompressorNode, dynamicsCompressorNodeRenderer);\n            // Bug #110: Edge does not export the correct values for maxValue and minValue.\n            this._attack = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.attack, 1, 0);\n            this._knee = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.knee, 40, 0);\n            this._nativeDynamicsCompressorNode = nativeDynamicsCompressorNode;\n            this._ratio = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.ratio, 20, 1);\n            this._release = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.release, 1, 0);\n            this._threshold = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.threshold, 0, -100);\n        }\n        get attack() {\n            return this._attack;\n        }\n        /*\n         * Bug #108: Only Chrome, Firefox and Opera disallow a channelCount of three and above yet which is why the getter and setter needs\n         * to be overwritten here.\n         */\n        get channelCount() {\n            return this._nativeDynamicsCompressorNode.channelCount;\n        }\n        set channelCount(value) {\n            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCount;\n            this._nativeDynamicsCompressorNode.channelCount = value;\n            if (value > 2) {\n                this._nativeDynamicsCompressorNode.channelCount = previousChannelCount;\n                throw createNotSupportedError();\n            }\n        }\n        /*\n         * Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max' yet which is why the getter and setter needs to be\n         * overwritten here.\n         */\n        get channelCountMode() {\n            return this._nativeDynamicsCompressorNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCountMode;\n            this._nativeDynamicsCompressorNode.channelCountMode = value;\n            if (value === 'max') {\n                this._nativeDynamicsCompressorNode.channelCountMode = previousChannelCount;\n                throw createNotSupportedError();\n            }\n        }\n        get knee() {\n            return this._knee;\n        }\n        get ratio() {\n            return this._ratio;\n        }\n        get reduction() {\n            // Bug #111: Safari returns an AudioParam instead of a number.\n            if (typeof this._nativeDynamicsCompressorNode.reduction.value === 'number') {\n                return this._nativeDynamicsCompressorNode.reduction.value;\n            }\n            return this._nativeDynamicsCompressorNode.reduction;\n        }\n        get release() {\n            return this._release;\n        }\n        get threshold() {\n            return this._threshold;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/dynamics-compressor-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createDynamicsCompressorNodeRendererFactory = (connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeDynamicsCompressorNodes = new WeakMap();\n        const createDynamicsCompressorNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeDynamicsCompressorNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeDynamicsCompressorNode was not constructed on the same OfflineAudioContext it needs to be\n             * created again.\n             */\n            const nativeDynamicsCompressorNodeIsOwnedByContext = isOwnedByContext(nativeDynamicsCompressorNode, nativeOfflineAudioContext);\n            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {\n                const options = {\n                    attack: nativeDynamicsCompressorNode.attack.value,\n                    channelCount: nativeDynamicsCompressorNode.channelCount,\n                    channelCountMode: nativeDynamicsCompressorNode.channelCountMode,\n                    channelInterpretation: nativeDynamicsCompressorNode.channelInterpretation,\n                    knee: nativeDynamicsCompressorNode.knee.value,\n                    ratio: nativeDynamicsCompressorNode.ratio.value,\n                    release: nativeDynamicsCompressorNode.release.value,\n                    threshold: nativeDynamicsCompressorNode.threshold.value\n                };\n                nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeDynamicsCompressorNodes.set(nativeOfflineAudioContext, nativeDynamicsCompressorNode);\n            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold, trace);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold, trace);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDynamicsCompressorNode, trace);\n            return nativeDynamicsCompressorNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeDynamicsCompressorNode = renderedNativeDynamicsCompressorNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeDynamicsCompressorNode !== undefined) {\n                    return Promise.resolve(renderedNativeDynamicsCompressorNode);\n                }\n                return createDynamicsCompressorNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/dynamics-compressor-node-renderer-factory.js.map","export const createEncodingError = () => {\n    try {\n        return new DOMException('', 'EncodingError');\n    }\n    catch (err) {\n        // Bug #122: Edge is the only browser that does not yet allow to construct a DOMException.\n        err.code = 0;\n        err.name = 'EncodingError';\n        return err;\n    }\n};\n//# sourceMappingURL=/build/es2019/factories/encoding-error.js.map","export const createEvaluateSource = (window) => {\n    return (source) => new Promise((resolve, reject) => {\n        if (window === null) {\n            reject(new SyntaxError());\n            return;\n        }\n        const head = window.document.head;\n        if (head === null) {\n            reject(new SyntaxError());\n        }\n        else {\n            const script = window.document.createElement('script');\n            // @todo Safari doesn't like URLs with a type of 'application/javascript; charset=utf-8'.\n            const blob = new Blob([source], { type: 'application/javascript' });\n            const url = URL.createObjectURL(blob);\n            const originalOnErrorHandler = window.onerror;\n            const removeErrorEventListenerAndRevokeUrl = () => {\n                window.onerror = originalOnErrorHandler;\n                URL.revokeObjectURL(url);\n            };\n            window.onerror = (message, src, lineno, colno, error) => {\n                // @todo Edge thinks the source is the one of the html document.\n                if (src === url || (src === window.location.href && lineno === 1 && colno === 1)) {\n                    removeErrorEventListenerAndRevokeUrl();\n                    reject(error);\n                    return false;\n                }\n                if (originalOnErrorHandler !== null) {\n                    return originalOnErrorHandler(message, src, lineno, colno, error);\n                }\n            };\n            script.onerror = () => {\n                removeErrorEventListenerAndRevokeUrl();\n                reject(new SyntaxError());\n            };\n            script.onload = () => {\n                removeErrorEventListenerAndRevokeUrl();\n                resolve();\n            };\n            script.src = url;\n            script.type = 'module';\n            head.appendChild(script);\n        }\n    });\n};\n//# sourceMappingURL=/build/es2019/factories/evaluate-source.js.map","export const createEventTargetConstructor = (wrapEventListener) => {\n    return class EventTarget {\n        constructor(_nativeEventTarget) {\n            this._nativeEventTarget = _nativeEventTarget;\n            this._listeners = new WeakMap();\n        }\n        addEventListener(type, listener, options) {\n            if (listener !== null) {\n                let wrappedEventListener = this._listeners.get(listener);\n                if (wrappedEventListener === undefined) {\n                    wrappedEventListener = wrapEventListener(this, listener);\n                    if (typeof listener === 'function') {\n                        this._listeners.set(listener, wrappedEventListener);\n                    }\n                }\n                this._nativeEventTarget.addEventListener(type, wrappedEventListener, options);\n            }\n        }\n        dispatchEvent(event) {\n            return this._nativeEventTarget.dispatchEvent(event);\n        }\n        removeEventListener(type, listener, options) {\n            const wrappedEventListener = (listener === null) ? undefined : this._listeners.get(listener);\n            this._nativeEventTarget.removeEventListener(type, (wrappedEventListener === undefined) ? null : wrappedEventListener, options);\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/event-target-constructor.js.map","export const createExposeCurrentFrameAndCurrentTime = (window) => {\n    return (currentTime, sampleRate, fn) => {\n        Object.defineProperties(window, {\n            currentFrame: {\n                configurable: true,\n                get() {\n                    return Math.round(currentTime * sampleRate);\n                }\n            },\n            currentTime: {\n                configurable: true,\n                get() {\n                    return currentTime;\n                }\n            }\n        });\n        try {\n            return fn();\n        }\n        finally {\n            if (window !== null) {\n                delete window.currentFrame;\n                delete window.currentTime;\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/expose-current-frame-and-current-time.js.map","export const createFetchSource = (createAbortError) => {\n    return async (url) => {\n        try {\n            const response = await fetch(url);\n            if (response.ok) {\n                return response.text();\n            }\n        }\n        catch { /* Ignore errors. */ } // tslint:disable-line:no-empty\n        throw createAbortError();\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/fetch-source.js.map","import { MOST_NEGATIVE_SINGLE_FLOAT, MOST_POSITIVE_SINGLE_FLOAT } from '../constants';\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    gain: 1\n};\nexport const createGainNodeConstructor = (audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class GainNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeGainNode = createNativeGainNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const gainNodeRenderer = ((isOffline) ? createGainNodeRenderer() : null);\n            super(context, false, nativeGainNode, gainNodeRenderer);\n            // Bug #74: Edge & Safari do not export the correct values for maxValue and minValue.\n            this._gain = createAudioParam(this, isOffline, nativeGainNode.gain, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n        }\n        get gain() {\n            return this._gain;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/gain-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createGainNodeRendererFactory = (connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeGainNodes = new WeakMap();\n        const createGainNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeGainNode = getNativeAudioNode(proxy);\n            // If the initially used nativeGainNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeGainNodeIsOwnedByContext = isOwnedByContext(nativeGainNode, nativeOfflineAudioContext);\n            if (!nativeGainNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeGainNode.channelCount,\n                    channelCountMode: nativeGainNode.channelCountMode,\n                    channelInterpretation: nativeGainNode.channelInterpretation,\n                    gain: nativeGainNode.gain.value\n                };\n                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeGainNodes.set(nativeOfflineAudioContext, nativeGainNode);\n            if (!nativeGainNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain, trace);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain, trace);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeGainNode, trace);\n            return nativeGainNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeGainNode = renderedNativeGainNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeGainNode !== undefined) {\n                    return Promise.resolve(renderedNativeGainNode);\n                }\n                return createGainNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/gain-node-renderer-factory.js.map","export const createGetAudioNodeRenderer = (getAudioNodeConnections) => {\n    return (audioNode) => {\n        const audioNodeConnections = getAudioNodeConnections(audioNode);\n        if (audioNodeConnections.renderer === null) {\n            throw new Error('Missing the renderer of the given AudioNode in the audio graph.');\n        }\n        return audioNodeConnections.renderer;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/get-audio-node-renderer.js.map","export const createGetAudioParamRenderer = (getAudioParamConnections) => {\n    return (audioParam) => {\n        const audioParamConnections = getAudioParamConnections(audioParam);\n        if (audioParamConnections.renderer === null) {\n            throw new Error('Missing the renderer of the given AudioParam in the audio graph.');\n        }\n        return audioParamConnections.renderer;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/get-audio-param-renderer.js.map","import { BACKUP_NATIVE_CONTEXT_STORE } from '../globals';\nexport const createGetBackupNativeContext = (isNativeOfflineAudioContext, nativeAudioContextConstructor, nativeOfflineAudioContextConstructor) => {\n    return (nativeContext) => {\n        /*\n         * Bug #50: Only Edge does currently not allow to create AudioNodes on a closed context yet which is why there needs to be no\n         * backupNativeContext in that case.\n         */\n        if (nativeContext.state === 'closed'\n            && nativeAudioContextConstructor !== null\n            && nativeAudioContextConstructor.name !== 'webkitAudioContext') {\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                const backupNativeContext = BACKUP_NATIVE_CONTEXT_STORE.get(nativeContext);\n                if (backupNativeContext !== undefined) {\n                    return backupNativeContext;\n                }\n                if (nativeOfflineAudioContextConstructor !== null) {\n                    // @todo Copy the attached AudioWorkletProcessors and other settings.\n                    const bckpNtveCntxt = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n                    BACKUP_NATIVE_CONTEXT_STORE.set(nativeContext, bckpNtveCntxt);\n                    return bckpNtveCntxt;\n                }\n            }\n            else {\n                const backupNativeContext = BACKUP_NATIVE_CONTEXT_STORE.get(nativeContext);\n                if (backupNativeContext !== undefined) {\n                    return backupNativeContext;\n                }\n                // @todo Copy the attached AudioWorkletProcessors and other settings.\n                const bckpNtveCntxt = new nativeAudioContextConstructor();\n                BACKUP_NATIVE_CONTEXT_STORE.set(nativeContext, bckpNtveCntxt);\n                return bckpNtveCntxt;\n            }\n        }\n        return null;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/get-backup-native-context.js.map","import { createInvalidStateError } from './invalid-state-error';\nexport const createGetNativeContext = (contextStore) => {\n    return (context) => {\n        const nativeContext = contextStore.get(context);\n        if (nativeContext === undefined) {\n            throw createInvalidStateError();\n        }\n        return nativeContext;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/get-native-context.js.map","export const createGetUnrenderedAudioWorkletNodes = (unrenderedAudioWorkletNodeStore) => {\n    return (nativeContext) => {\n        const unrenderedAudioWorkletNodes = unrenderedAudioWorkletNodeStore.get(nativeContext);\n        if (unrenderedAudioWorkletNodes === undefined) {\n            throw new Error('The context has no set of AudioWorkletNodes.');\n        }\n        return unrenderedAudioWorkletNodes;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/get-unrendered-audio-worklet-nodes.js.map","import { wrapIIRFilterNodeGetFrequencyResponseMethod } from '../helpers/wrap-iir-filter-node-get-frequency-response-method';\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers'\n};\nexport const createIIRFilterNodeConstructor = (audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext) => {\n    return class IIRFilterNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeIIRFilterNode = createNativeIIRFilterNode(nativeContext, isOffline ? null : context.baseLatency, mergedOptions);\n            const iirFilterNodeRenderer = ((isOffline)\n                ? createIIRFilterNodeRenderer(mergedOptions.feedback, mergedOptions.feedforward)\n                : null);\n            super(context, false, nativeIIRFilterNode, iirFilterNodeRenderer);\n            // Bug #23 & #24: FirefoxDeveloper does not throw an InvalidAccessError.\n            // @todo Write a test which allows other browsers to remain unpatched.\n            wrapIIRFilterNodeGetFrequencyResponseMethod(nativeIIRFilterNode);\n            this._nativeIIRFilterNode = nativeIIRFilterNode;\n        }\n        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n            return this._nativeIIRFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/iir-filter-node-constructor.js.map","import { filterBuffer } from '../helpers/filter-buffer';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nconst filterFullBuffer = (renderedBuffer, nativeOfflineAudioContext, feedback, feedforward) => {\n    const feedbackLength = feedback.length;\n    const feedforwardLength = feedforward.length;\n    const minLength = Math.min(feedbackLength, feedforwardLength);\n    if (feedback[0] !== 1) {\n        for (let i = 0; i < feedbackLength; i += 1) {\n            feedforward[i] /= feedback[0];\n        }\n        for (let i = 1; i < feedforwardLength; i += 1) {\n            feedback[i] /= feedback[0];\n        }\n    }\n    const bufferLength = 32;\n    const xBuffer = new Float32Array(bufferLength);\n    const yBuffer = new Float32Array(bufferLength);\n    const filteredBuffer = nativeOfflineAudioContext.createBuffer(renderedBuffer.numberOfChannels, renderedBuffer.length, renderedBuffer.sampleRate);\n    const numberOfChannels = renderedBuffer.numberOfChannels;\n    for (let i = 0; i < numberOfChannels; i += 1) {\n        const input = renderedBuffer.getChannelData(i);\n        const output = filteredBuffer.getChannelData(i);\n        xBuffer.fill(0);\n        yBuffer.fill(0);\n        filterBuffer(feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, 0, bufferLength, input, output);\n    }\n    return filteredBuffer;\n};\nexport const createIIRFilterNodeRendererFactory = (createNativeAudioBufferSourceNode, createNativeAudioNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return (feedback, feedforward) => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let filteredBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeAudioBufferSourceNode = null;\n            let nativeIIRFilterNode = getNativeAudioNode(proxy);\n            // If the initially used nativeIIRFilterNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeIIRFilterNodeIsOwnedByContext = isOwnedByContext(nativeIIRFilterNode, nativeOfflineAudioContext);\n            // Bug #9: Safari does not support IIRFilterNodes.\n            if (nativeOfflineAudioContext.createIIRFilter === undefined) {\n                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {\n                    buffer: null,\n                    channelCount: 2,\n                    channelCountMode: 'max',\n                    channelInterpretation: 'speakers',\n                    loop: false,\n                    loopEnd: 0,\n                    loopStart: 0,\n                    playbackRate: 1\n                });\n            }\n            else if (!nativeIIRFilterNodeIsOwnedByContext) {\n                nativeIIRFilterNode = createNativeAudioNode(nativeOfflineAudioContext, (ntvCntxt) => {\n                    return ntvCntxt.createIIRFilter(feedforward, feedback);\n                });\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, (nativeAudioBufferSourceNode === null) ? nativeIIRFilterNode : nativeAudioBufferSourceNode);\n            if (nativeAudioBufferSourceNode !== null) {\n                if (filteredBufferPromise === null) {\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(\n                    // Bug #47: The AudioDestinationNode in Edge and Safari gets not initialized correctly.\n                    proxy.context.destination.channelCount, \n                    // Bug #17: Safari does not yet expose the length.\n                    proxy.context.length, nativeOfflineAudioContext.sampleRate);\n                    filteredBufferPromise = (async () => {\n                        await renderInputsOfAudioNode(proxy, partialOfflineAudioContext, partialOfflineAudioContext.destination, trace);\n                        const renderedBuffer = await renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                        return filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward);\n                    })();\n                }\n                const filteredBuffer = await filteredBufferPromise;\n                nativeAudioBufferSourceNode.buffer = filteredBuffer;\n                nativeAudioBufferSourceNode.start(0);\n                return nativeAudioBufferSourceNode;\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeIIRFilterNode, trace);\n            return nativeIIRFilterNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/iir-filter-node-renderer-factory.js.map","import { isAudioNodeOutputConnection } from '../guards/audio-node-output-connection';\nexport const createIncrementCycleCounterFactory = (cycleCounters, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode) => {\n    return (isOffline) => {\n        return (audioNode, count) => {\n            const cycleCounter = cycleCounters.get(audioNode);\n            if (cycleCounter === undefined) {\n                if (!isOffline && isActiveAudioNode(audioNode)) {\n                    const nativeSourceAudioNode = getNativeAudioNode(audioNode);\n                    const { outputs } = getAudioNodeConnections(audioNode);\n                    for (const output of outputs) {\n                        if (isAudioNodeOutputConnection(output)) {\n                            const nativeDestinationAudioNode = getNativeAudioNode(output[0]);\n                            disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);\n                        }\n                        else {\n                            const nativeDestinationAudioParam = getNativeAudioParam(output[0]);\n                            nativeSourceAudioNode.disconnect(nativeDestinationAudioParam, output[1]);\n                        }\n                    }\n                }\n                cycleCounters.set(audioNode, count);\n            }\n            else {\n                cycleCounters.set(audioNode, cycleCounter + count);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/increment-cycle-counter-factory.js.map","export const createIndexSizeError = () => {\n    try {\n        return new DOMException('', 'IndexSizeError');\n    }\n    catch (err) {\n        // Bug #122: Edge is the only browser that does not yet allow to construct a DOMException.\n        err.code = 1;\n        err.name = 'IndexSizeError';\n        return err;\n    }\n};\n//# sourceMappingURL=/build/es2019/factories/index-size-error.js.map","export const createInvalidAccessError = () => {\n    try {\n        return new DOMException('', 'InvalidAccessError');\n    }\n    catch (err) {\n        // Bug #122: Edge is the only browser that does not yet allow to construct a DOMException.\n        err.code = 15;\n        err.name = 'InvalidAccessError';\n        return err;\n    }\n};\n//# sourceMappingURL=/build/es2019/factories/invalid-access-error.js.map","export const createInvalidStateError = () => {\n    try {\n        return new DOMException('', 'InvalidStateError');\n    }\n    catch (err) {\n        // Bug #122: Edge is the only browser that does not yet allow to construct a DOMException.\n        err.code = 11;\n        err.name = 'InvalidStateError';\n        return err;\n    }\n};\n//# sourceMappingURL=/build/es2019/factories/invalid-state-error.js.map","export const createIsAnyAudioContext = (contextStore, isNativeAudioContext) => {\n    return (anything) => {\n        const nativeContext = contextStore.get(anything);\n        return isNativeAudioContext(nativeContext) || isNativeAudioContext(anything);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/is-any-audio-context.js.map","export const createIsAnyAudioNode = (audioNodeStore, isNativeAudioNode) => {\n    return (anything) => audioNodeStore.has(anything) || isNativeAudioNode(anything);\n};\n//# sourceMappingURL=/build/es2019/factories/is-any-audio-node.js.map","export const createIsAnyAudioParam = (audioParamStore, isNativeAudioParam) => {\n    return (anything) => audioParamStore.has(anything) || isNativeAudioParam(anything);\n};\n//# sourceMappingURL=/build/es2019/factories/is-any-audio-param.js.map","export const createIsAnyOfflineAudioContext = (contextStore, isNativeOfflineAudioContext) => {\n    return (anything) => {\n        const nativeContext = contextStore.get(anything);\n        return isNativeOfflineAudioContext(nativeContext) || isNativeOfflineAudioContext(anything);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/is-any-offline-audio-context.js.map","export const createIsNativeAudioContext = (nativeAudioContextConstructor) => {\n    return (anything) => {\n        return (nativeAudioContextConstructor !== null && anything instanceof nativeAudioContextConstructor);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/is-native-audio-context.js.map","export const createIsNativeAudioNode = (window) => {\n    return (anything) => {\n        return (window !== null && typeof window.AudioNode === 'function' && anything instanceof window.AudioNode);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/is-native-audio-node.js.map","export const createIsNativeAudioParam = (window) => {\n    return (anything) => {\n        return (window !== null && typeof window.AudioParam === 'function' && anything instanceof window.AudioParam);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/is-native-audio-param.js.map","export const createIsNativeContext = (isNativeAudioContext, isNativeOfflineAudioContext) => {\n    return (anything) => {\n        return (isNativeAudioContext(anything) || isNativeOfflineAudioContext(anything));\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/is-native-context.js.map","export const createIsNativeOfflineAudioContext = (nativeOfflineAudioContextConstructor) => {\n    return (anything) => {\n        return (nativeOfflineAudioContextConstructor !== null && anything instanceof nativeOfflineAudioContextConstructor);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/is-native-offline-audio-context.js.map","export const createIsSecureContext = (window) => (window !== null && window.isSecureContext);\n//# sourceMappingURL=/build/es2019/factories/is-secure-context.js.map","export const createIsSupportedPromise = async (cacheTestResult, testAudioBufferCopyChannelMethodsSubarraySupport, testAudioContextCloseMethodSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextOptionsSupport, testAudioNodeConnectMethodSupport, testAudioWorkletProcessorNoOutputsSupport, testChannelMergerNodeChannelCountSupport, testConstantSourceNodeAccurateSchedulingSupport, testConvolverNodeBufferReassignabilitySupport, testIsSecureContextSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testStereoPannerNodeDefaultValueSupport, testTransferablesSupport) => {\n    if (cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, testAudioBufferCopyChannelMethodsSubarraySupport)\n        && cacheTestResult(testAudioContextCloseMethodSupport, testAudioContextCloseMethodSupport)\n        && cacheTestResult(testAudioContextOptionsSupport, testAudioContextOptionsSupport)\n        && cacheTestResult(testAudioNodeConnectMethodSupport, testAudioNodeConnectMethodSupport)\n        && cacheTestResult(testChannelMergerNodeChannelCountSupport, testChannelMergerNodeChannelCountSupport)\n        && cacheTestResult(testConstantSourceNodeAccurateSchedulingSupport, testConstantSourceNodeAccurateSchedulingSupport)\n        && cacheTestResult(testConvolverNodeBufferReassignabilitySupport, testConvolverNodeBufferReassignabilitySupport)\n        && cacheTestResult(testIsSecureContextSupport, testIsSecureContextSupport)\n        && cacheTestResult(testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)) {\n        const results = await Promise\n            .all([\n            cacheTestResult(testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport),\n            cacheTestResult(testAudioWorkletProcessorNoOutputsSupport, testAudioWorkletProcessorNoOutputsSupport),\n            cacheTestResult(testStereoPannerNodeDefaultValueSupport, testStereoPannerNodeDefaultValueSupport),\n            cacheTestResult(testTransferablesSupport, testTransferablesSupport)\n        ]);\n        return results.every((result) => result);\n    }\n    return false;\n};\n//# sourceMappingURL=/build/es2019/factories/is-supported-promise.js.map","export const createMediaElementAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaElementAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaElementAudioSourceNode = createNativeMediaElementAudioSourceNode(nativeContext, options);\n            // Bug #171: Safari allows to create a MediaElementAudioSourceNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw TypeError();\n            }\n            super(context, true, nativeMediaElementAudioSourceNode, null);\n            // Bug #63: Edge does not expose the mediaElement yet.\n            this._mediaElement = options.mediaElement;\n            this._nativeMediaElementAudioSourceNode = nativeMediaElementAudioSourceNode;\n        }\n        get mediaElement() {\n            return (this._nativeMediaElementAudioSourceNode.mediaElement === undefined) ?\n                this._mediaElement :\n                this._nativeMediaElementAudioSourceNode.mediaElement;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/media-element-audio-source-node-constructor.js.map","const DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers'\n};\nexport const createMediaStreamAudioDestinationNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaStreamAudioDestinationNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            // Bug #173: Safari allows to create a MediaStreamAudioDestinationNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw new TypeError();\n            }\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeMediaStreamAudioDestinationNode = createNativeMediaStreamAudioDestinationNode(nativeContext, mergedOptions);\n            super(context, false, nativeMediaStreamAudioDestinationNode, null);\n            this._nativeMediaStreamAudioDestinationNode = nativeMediaStreamAudioDestinationNode;\n        }\n        get stream() {\n            return this._nativeMediaStreamAudioDestinationNode.stream;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/media-stream-audio-destination-node-constructor.js.map","export const createMediaStreamAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaStreamAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaStreamAudioSourceNode = createNativeMediaStreamAudioSourceNode(nativeContext, options);\n            // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw new TypeError();\n            }\n            super(context, true, nativeMediaStreamAudioSourceNode, null);\n            this._nativeMediaStreamAudioSourceNode = nativeMediaStreamAudioSourceNode;\n        }\n        get mediaStream() {\n            return this._nativeMediaStreamAudioSourceNode.mediaStream;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/media-stream-audio-source-node-constructor.js.map","export const createMediaStreamTrackAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext) => {\n    return class MediaStreamTrackAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNode(nativeContext, options);\n            super(context, true, nativeMediaStreamTrackAudioSourceNode, null);\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/media-stream-track-audio-source-node-constructor.js.map","import { isValidLatencyHint } from '../helpers/is-valid-latency-hint';\nexport const createMinimalAudioContextConstructor = (createInvalidStateError, createNotSupportedError, createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor) => {\n    return class MinimalAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(options = {}) {\n            if (nativeAudioContextConstructor === null) {\n                throw new Error('Missing the native AudioContext constructor.');\n            }\n            const nativeAudioContext = new nativeAudioContextConstructor(options);\n            // Bug #131 Safari returns null when there are four other AudioContexts running already.\n            if (nativeAudioContext === null) {\n                throw createUnknownError();\n            }\n            // Bug #51 Only Chrome and Opera throw an error if the given latencyHint is invalid.\n            if (!isValidLatencyHint(options.latencyHint)) {\n                throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);\n            }\n            // Bug #150 Only Chrome, Firefox and Opera support setting the sampleRate.\n            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) {\n                throw createNotSupportedError();\n            }\n            super(nativeAudioContext, 2);\n            const { latencyHint } = options;\n            const { sampleRate } = nativeAudioContext;\n            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.\n            this._baseLatency = (typeof nativeAudioContext.baseLatency === 'number')\n                ? nativeAudioContext.baseLatency\n                : (latencyHint === 'balanced')\n                    ? (512 / sampleRate)\n                    : (latencyHint === 'interactive' || latencyHint === undefined)\n                        ? (256 / sampleRate)\n                        : (latencyHint === 'playback')\n                            ? (1024 / sampleRate)\n                            /*\n                             * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a\n                             * ScriptProcessorNode.\n                             */\n                            : ((Math.max(2, Math.min(128, Math.round((latencyHint * sampleRate) / 128))) * 128) / sampleRate);\n            this._nativeAudioContext = nativeAudioContext;\n            this._state = null;\n            /*\n             * Bug #34: Chrome and Opera pretend to be running right away, but fire an onstatechange event when the state actually\n             * changes to 'running'.\n             */\n            if (nativeAudioContext.state === 'running') {\n                this._state = 'suspended';\n                const revokeState = () => {\n                    if (this._state === 'suspended') {\n                        this._state = null;\n                    }\n                    nativeAudioContext.removeEventListener('statechange', revokeState);\n                };\n                nativeAudioContext.addEventListener('statechange', revokeState);\n            }\n        }\n        get baseLatency() {\n            return this._baseLatency;\n        }\n        get state() {\n            return (this._state !== null) ? this._state : this._nativeAudioContext.state;\n        }\n        close() {\n            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.\n            if (this.state === 'closed') {\n                return this._nativeAudioContext\n                    .close()\n                    .then(() => {\n                    throw createInvalidStateError();\n                });\n            }\n            // Bug #34: If the state was set to suspended before it should be revoked now.\n            if (this._state === 'suspended') {\n                this._state = null;\n            }\n            return this._nativeAudioContext.close();\n            /*\n             * Bug #50: Deleting the AudioGraph is currently not possible anymore.\n             * ...then(() => deleteAudioGraph(this, this._nativeAudioContext));\n             */\n        }\n        resume() {\n            if (this._state === 'suspended') {\n                return new Promise((resolve, reject) => {\n                    const resolvePromise = () => {\n                        this._nativeAudioContext.removeEventListener('statechange', resolvePromise);\n                        if (this._nativeAudioContext.state === 'running') {\n                            resolve();\n                        }\n                        else {\n                            this\n                                .resume()\n                                .then(resolve, reject);\n                        }\n                    };\n                    this._nativeAudioContext.addEventListener('statechange', resolvePromise);\n                });\n            }\n            return this._nativeAudioContext\n                .resume()\n                .catch((err) => {\n                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined || err.code === 15) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n        suspend() {\n            return this._nativeAudioContext\n                .suspend()\n                .catch((err) => {\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/minimal-audio-context-constructor.js.map","import { CONTEXT_STORE } from '../globals';\nexport const createMinimalBaseAudioContextConstructor = (audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener) => {\n    return class MinimalBaseAudioContext extends eventTargetConstructor {\n        constructor(_nativeContext, numberOfChannels) {\n            super(_nativeContext);\n            this._nativeContext = _nativeContext;\n            CONTEXT_STORE.set(this, _nativeContext);\n            // Bug #93: Edge will set the sampleRate of an AudioContext to zero when it is closed.\n            const sampleRate = _nativeContext.sampleRate;\n            Object.defineProperty(_nativeContext, 'sampleRate', {\n                get: () => sampleRate\n            });\n            if (isNativeOfflineAudioContext(_nativeContext)) {\n                unrenderedAudioWorkletNodeStore.set(_nativeContext, new Set());\n            }\n            this._destination = new audioDestinationNodeConstructor(this, numberOfChannels);\n            this._listener = createAudioListener(this, _nativeContext);\n            this._onstatechange = null;\n        }\n        get currentTime() {\n            return this._nativeContext.currentTime;\n        }\n        get destination() {\n            return this._destination;\n        }\n        get listener() {\n            return this._listener;\n        }\n        get onstatechange() {\n            return this._onstatechange;\n        }\n        set onstatechange(value) {\n            const wrappedListener = (typeof value === 'function') ? wrapEventListener(this, value) : null;\n            this._nativeContext.onstatechange = wrappedListener;\n            const nativeOnStateChange = this._nativeContext.onstatechange;\n            this._onstatechange = (nativeOnStateChange !== null && nativeOnStateChange === wrappedListener)\n                ? value\n                : nativeOnStateChange;\n        }\n        get sampleRate() {\n            return this._nativeContext.sampleRate;\n        }\n        get state() {\n            return this._nativeContext.state;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/minimal-base-audio-context-constructor.js.map","import { testPromiseSupport } from '../helpers/test-promise-support';\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nexport const createMinimalOfflineAudioContextConstructor = (cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering) => {\n    return class MinimalOfflineAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(options) {\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);\n            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.\n            if (!cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeOfflineAudioContext))) {\n                nativeOfflineAudioContext.addEventListener('statechange', (() => {\n                    let i = 0;\n                    const delayStateChangeEvent = (event) => {\n                        if (this._state === 'running') {\n                            if (i > 0) {\n                                nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);\n                                event.stopImmediatePropagation();\n                                this._waitForThePromiseToSettle(event);\n                            }\n                            else {\n                                i += 1;\n                            }\n                        }\n                    };\n                    return delayStateChangeEvent;\n                })());\n            }\n            super(nativeOfflineAudioContext, numberOfChannels);\n            this._length = length;\n            this._nativeOfflineAudioContext = nativeOfflineAudioContext;\n            this._state = null;\n        }\n        get length() {\n            // Bug #17: Safari does not yet expose the length.\n            if (this._nativeOfflineAudioContext.length === undefined) {\n                return this._length;\n            }\n            return this._nativeOfflineAudioContext.length;\n        }\n        get state() {\n            return (this._state === null) ? this._nativeOfflineAudioContext.state : this._state;\n        }\n        startRendering() {\n            /*\n             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore\n             * the state of the nativeOfflineAudioContext might no transition to running immediately.\n             */\n            if (this._state === 'running') {\n                return Promise.reject(createInvalidStateError());\n            }\n            this._state = 'running';\n            return startRendering(this.destination, this._nativeOfflineAudioContext)\n                .then((audioBuffer) => {\n                this._state = null;\n                /*\n                 * Bug #50: Deleting the AudioGraph is currently not possible anymore.\n                 * deleteAudioGraph(this, this._nativeOfflineAudioContext);\n                 */\n                return audioBuffer;\n            })\n                // @todo This could be written more elegantly when Promise.finally() becomes avalaible.\n                .catch((err) => {\n                this._state = null;\n                /*\n                 * Bug #50: Deleting the AudioGraph is currently not possible anymore.\n                 * deleteAudioGraph(this, this._nativeOfflineAudioContext);\n                 */\n                throw err;\n            });\n        }\n        _waitForThePromiseToSettle(event) {\n            if (this._state === null) {\n                this._nativeOfflineAudioContext.dispatchEvent(event);\n            }\n            else {\n                setTimeout(() => this._waitForThePromiseToSettle(event));\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/minimal-offline-audio-context-constructor.js.map","export const createMonitorConnections = (insertElementInSet, isNativeAudioNode) => {\n    return (nativeAudioNode, whenConnected, whenDisconnected) => {\n        const connections = new Set();\n        nativeAudioNode.connect = ((connect) => {\n            return (destination, output = 0, input = 0) => {\n                const wasDisconnected = connections.size === 0;\n                if (isNativeAudioNode(destination)) {\n                    // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n                    connect.call(nativeAudioNode, destination, output, input);\n                    insertElementInSet(connections, [destination, output, input], (connection) => (connection[0] === destination && connection[1] === output && connection[2] === input), true);\n                    if (wasDisconnected) {\n                        whenConnected();\n                    }\n                    return destination;\n                }\n                connect.call(nativeAudioNode, destination, output);\n                insertElementInSet(connections, [destination, output], (connection) => (connection[0] === destination && connection[1] === output), true);\n                if (wasDisconnected) {\n                    whenConnected();\n                }\n                return;\n            };\n        })(nativeAudioNode.connect);\n        nativeAudioNode.disconnect = ((disconnect) => {\n            return (destinationOrOutput, output, input) => {\n                const wasConnected = connections.size > 0;\n                if (destinationOrOutput === undefined) {\n                    disconnect.apply(nativeAudioNode);\n                    connections.clear();\n                }\n                else if (typeof destinationOrOutput === 'number') {\n                    // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.\n                    disconnect.call(nativeAudioNode, destinationOrOutput);\n                    for (const connection of connections) {\n                        if (connection[1] === destinationOrOutput) {\n                            connections.delete(connection);\n                        }\n                    }\n                }\n                else {\n                    if (isNativeAudioNode(destinationOrOutput)) {\n                        // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n                        disconnect.call(nativeAudioNode, destinationOrOutput, output, input);\n                    }\n                    else {\n                        // @todo TypeScript cannot infer the overloaded signature with 2 arguments yet.\n                        disconnect.call(nativeAudioNode, destinationOrOutput, output);\n                    }\n                    for (const connection of connections) {\n                        if (connection[0] === destinationOrOutput\n                            && (output === undefined || connection[1] === output)\n                            && (input === undefined || connection[2] === input)) {\n                            connections.delete(connection);\n                        }\n                    }\n                }\n                const isDisconnected = connections.size === 0;\n                if (wasConnected && isDisconnected) {\n                    whenDisconnected();\n                }\n            };\n        })(nativeAudioNode.disconnect);\n        return nativeAudioNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/monitor-connections.js.map","import { assignNativeAudioNodeOption } from '../helpers/assign-native-audio-node-option';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nimport { testAnalyserNodeGetFloatTimeDomainDataMethodSupport } from '../helpers/test-analyser-node-get-float-time-domain-data-method-support';\nimport { wrapAnalyserNodeGetFloatTimeDomainDataMethod } from '../helpers/wrap-analyser-node-get-float-time-domain-data-method';\nexport const createNativeAnalyserNodeFactory = (cacheTestResult, createIndexSizeError, createNativeAudioNode) => {\n    return (nativeContext, options) => {\n        const nativeAnalyserNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createAnalyser());\n        // Bug #37: Firefox does not create an AnalyserNode with the default properties.\n        assignNativeAudioNodeOptions(nativeAnalyserNode, options);\n        // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n        if (!(options.maxDecibels > options.minDecibels)) {\n            throw createIndexSizeError();\n        }\n        assignNativeAudioNodeOption(nativeAnalyserNode, options, 'fftSize');\n        assignNativeAudioNodeOption(nativeAnalyserNode, options, 'maxDecibels');\n        assignNativeAudioNodeOption(nativeAnalyserNode, options, 'minDecibels');\n        assignNativeAudioNodeOption(nativeAnalyserNode, options, 'smoothingTimeConstant');\n        // Bug #36: Safari does not support getFloatTimeDomainData() yet.\n        if (!cacheTestResult(testAnalyserNodeGetFloatTimeDomainDataMethodSupport, () => testAnalyserNodeGetFloatTimeDomainDataMethodSupport(nativeAnalyserNode))) {\n            wrapAnalyserNodeGetFloatTimeDomainDataMethod(nativeAnalyserNode);\n        }\n        return nativeAnalyserNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-analyser-node-factory.js.map","export const createNativeAudioBufferConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('AudioBuffer')) {\n        return window.AudioBuffer;\n    }\n    return null;\n};\n//# sourceMappingURL=/build/es2019/factories/native-audio-buffer-constructor.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOption } from '../helpers/assign-native-audio-node-option';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nimport { wrapAudioBufferSourceNodeStartMethodConsecutiveCalls } from '../helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls';\nimport { wrapAudioBufferSourceNodeStartMethodDurationParameter } from '../helpers/wrap-audio-buffer-source-node-start-method-duration-parameter';\nimport { wrapAudioScheduledSourceNodeStartMethodNegativeParameters } from '../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters';\nimport { wrapAudioScheduledSourceNodeStopMethodNegativeParameters } from '../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters';\nexport const createNativeAudioBufferSourceNodeFactory = (addSilentConnection, cacheTestResult, createNativeAudioNode, testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, testAudioBufferSourceNodeStartMethodDurationParameterSupport, testAudioBufferSourceNodeStartMethodOffsetClampingSupport, testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClampling, wrapAudioBufferSourceNodeStopMethodNullifiedBuffer, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls) => {\n    return (nativeContext, options) => {\n        const nativeAudioBufferSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createBufferSource());\n        assignNativeAudioNodeOptions(nativeAudioBufferSourceNode, options);\n        assignNativeAudioNodeAudioParamValue(nativeAudioBufferSourceNode, options, 'playbackRate');\n        // Bug #71: Edge does not allow to set the buffer to null.\n        assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'buffer');\n        // Bug #149: Safari does not yet support the detune AudioParam.\n        assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loop');\n        assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loopEnd');\n        assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loopStart');\n        // Bug #69: Safari does allow calls to start() of an already scheduled AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, () => testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext))) {\n            wrapAudioBufferSourceNodeStartMethodConsecutiveCalls(nativeAudioBufferSourceNode);\n        }\n        // Bug #92: Chrome & Edge do not respect the duration parameter yet.\n        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodDurationParameterSupport, testAudioBufferSourceNodeStartMethodDurationParameterSupport)) {\n            wrapAudioBufferSourceNodeStartMethodDurationParameter(nativeAudioBufferSourceNode, nativeContext);\n        }\n        // Bug #154 & #155: Safari does not handle offsets which are equal to or greater than the duration of the buffer.\n        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodOffsetClampingSupport, () => testAudioBufferSourceNodeStartMethodOffsetClampingSupport(nativeContext))) {\n            wrapAudioBufferSourceNodeStartMethodOffsetClampling(nativeAudioBufferSourceNode);\n        }\n        // Bug #162: Safari does throw an error when stop() is called on an AudioBufferSourceNode which has no buffer assigned to it.\n        if (!cacheTestResult(testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, () => testAudioBufferSourceNodeStopMethodNullifiedBufferSupport(nativeContext))) {\n            wrapAudioBufferSourceNodeStopMethodNullifiedBuffer(nativeAudioBufferSourceNode, nativeContext);\n        }\n        // Bug #44: Only Chrome, Firefox & Opera throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeAudioBufferSourceNode);\n        }\n        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, () => testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioBufferSourceNode, nativeContext);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeAudioBufferSourceNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.\n        addSilentConnection(nativeContext, nativeAudioBufferSourceNode);\n        return nativeAudioBufferSourceNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-audio-buffer-source-node-factory.js.map","export const createNativeAudioContextConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('AudioContext')) {\n        return window.AudioContext;\n    }\n    return (window.hasOwnProperty('webkitAudioContext')) ? window.webkitAudioContext : null;\n};\n//# sourceMappingURL=/build/es2019/factories/native-audio-context-constructor.js.map","export const createNativeAudioDestinationNodeFactory = (createNativeGainNode, overwriteAccessors) => {\n    return (nativeContext, channelCount, isNodeOfNativeOfflineAudioContext) => {\n        const nativeAudioDestinationNode = nativeContext.destination;\n        // Bug #132: Edge & Safari do not have the correct channelCount.\n        if (nativeAudioDestinationNode.channelCount !== channelCount) {\n            try {\n                nativeAudioDestinationNode.channelCount = channelCount;\n            }\n            catch {\n                // Bug #169: Safari throws an error on each attempt to change the channelCount.\n            }\n        }\n        // Bug #83: Edge & Safari do not have the correct channelCountMode.\n        if (isNodeOfNativeOfflineAudioContext && nativeAudioDestinationNode.channelCountMode !== 'explicit') {\n            nativeAudioDestinationNode.channelCountMode = 'explicit';\n        }\n        // Bug #47: The AudioDestinationNode in Edge and Safari does not initialize the maxChannelCount property correctly.\n        if (nativeAudioDestinationNode.maxChannelCount === 0) {\n            Object.defineProperty(nativeAudioDestinationNode, 'maxChannelCount', {\n                value: channelCount\n            });\n        }\n        // Bug #168: No browser does yet have an AudioDestinationNode with an output.\n        const gainNode = createNativeGainNode(nativeContext, {\n            channelCount,\n            channelCountMode: nativeAudioDestinationNode.channelCountMode,\n            channelInterpretation: nativeAudioDestinationNode.channelInterpretation,\n            gain: 1\n        });\n        overwriteAccessors(gainNode, 'channelCount', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            try {\n                nativeAudioDestinationNode.channelCount = value;\n            }\n            catch (err) {\n                // Bug #169: Safari throws an error on each attempt to change the channelCount.\n                if (value > nativeAudioDestinationNode.maxChannelCount) {\n                    throw err;\n                }\n            }\n        });\n        overwriteAccessors(gainNode, 'channelCountMode', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            nativeAudioDestinationNode.channelCountMode = value;\n        });\n        overwriteAccessors(gainNode, 'channelInterpretation', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            nativeAudioDestinationNode.channelInterpretation = value;\n        });\n        Object.defineProperty(gainNode, 'maxChannelCount', {\n            get: () => nativeAudioDestinationNode.maxChannelCount\n        });\n        // @todo This should be disconnected when the context is closed.\n        gainNode.connect(nativeAudioDestinationNode);\n        return gainNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-audio-destination-node.js.map","export const createNativeAudioNodeFactory = (getBackupNativeContext) => {\n    return (nativeContext, factoryFunction) => {\n        // Bug #50: Only Edge does currently not allow to create AudioNodes on a closed context yet.\n        const backupNativeContext = getBackupNativeContext(nativeContext);\n        if (backupNativeContext !== null) {\n            return factoryFunction(backupNativeContext);\n        }\n        return factoryFunction(nativeContext);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-audio-node-factory.js.map","export const createNativeAudioWorkletNodeConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    return (window.hasOwnProperty('AudioWorkletNode')) ? window.AudioWorkletNode : null;\n};\n//# sourceMappingURL=/build/es2019/factories/native-audio-worklet-node-constructor.js.map","import { testClonabilityOfAudioWorkletNodeOptions } from '../helpers/test-clonability-of-audio-worklet-node-options';\nexport const createNativeAudioWorkletNodeFactory = (createInvalidStateError, createNativeAudioNode, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections) => {\n    return (nativeContext, baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, options) => {\n        if (nativeAudioWorkletNodeConstructor !== null) {\n            try {\n                const nativeAudioWorkletNode = createNativeAudioNode(nativeContext, (ntvCntxt) => {\n                    return new nativeAudioWorkletNodeConstructor(ntvCntxt, name, options);\n                });\n                const patchedEventListeners = new Map(); // tslint:disable-line:max-line-length\n                let onprocessorerror = null;\n                Object.defineProperties(nativeAudioWorkletNode, {\n                    /*\n                     * Bug #61: Overwriting the property accessors for channelCount and channelCountMode is necessary as long as some\n                     * browsers have no native implementation to achieve a consistent behavior.\n                     */\n                    channelCount: {\n                        get: () => options.channelCount,\n                        set: () => {\n                            throw createInvalidStateError();\n                        }\n                    },\n                    channelCountMode: {\n                        get: () => 'explicit',\n                        set: () => {\n                            throw createInvalidStateError();\n                        }\n                    },\n                    // Bug #156: Chrome & Opera do not yet fire an ErrorEvent.\n                    onprocessorerror: {\n                        get: () => onprocessorerror,\n                        set: (value) => {\n                            if (typeof onprocessorerror === 'function') {\n                                nativeAudioWorkletNode.removeEventListener('processorerror', onprocessorerror);\n                            }\n                            onprocessorerror = (typeof value === 'function') ? value : null;\n                            if (typeof onprocessorerror === 'function') {\n                                nativeAudioWorkletNode.addEventListener('processorerror', onprocessorerror);\n                            }\n                        }\n                    }\n                });\n                nativeAudioWorkletNode.addEventListener = ((addEventListener) => {\n                    return (...args) => {\n                        if (args[0] === 'processorerror') {\n                            const unpatchedEventListener = (typeof args[1] === 'function')\n                                ? args[1]\n                                : (typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function')\n                                    ? args[1].handleEvent\n                                    : null;\n                            if (unpatchedEventListener !== null) {\n                                const patchedEventListener = patchedEventListeners.get(args[1]);\n                                if (patchedEventListener !== undefined) {\n                                    args[1] = patchedEventListener;\n                                }\n                                else {\n                                    args[1] = (event) => {\n                                        unpatchedEventListener(new ErrorEvent(args[0], { ...event, error: new Error( /* @todo */) }));\n                                    };\n                                    patchedEventListeners.set(unpatchedEventListener, args[1]);\n                                }\n                            }\n                        }\n                        return addEventListener.call(nativeAudioWorkletNode, args[0], args[1], args[2]);\n                    };\n                })(nativeAudioWorkletNode.addEventListener);\n                nativeAudioWorkletNode.removeEventListener = ((removeEventListener) => {\n                    return (...args) => {\n                        if (args[0] === 'processorerror') {\n                            const patchedEventListener = patchedEventListeners.get(args[1]);\n                            if (patchedEventListener !== undefined) {\n                                patchedEventListeners.delete(args[1]);\n                                args[1] = patchedEventListener;\n                            }\n                        }\n                        return removeEventListener.call(nativeAudioWorkletNode, args[0], args[1], args[2]);\n                    };\n                })(nativeAudioWorkletNode.removeEventListener);\n                /*\n                 * Bug #86: Chrome & Opera do not invoke the process() function if the corresponding AudioWorkletNode is unconnected but has\n                 * an output.\n                 */\n                if (options.numberOfOutputs !== 0) {\n                    const nativeGainNode = createNativeGainNode(nativeContext, { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'discrete', gain: 0 });\n                    nativeAudioWorkletNode\n                        .connect(nativeGainNode)\n                        /*\n                         * Bug #50: Edge does not yet allow to create AudioNodes on a closed AudioContext. Therefore the context property is\n                         * used here to make sure to connect the right destination.\n                         */\n                        .connect(nativeGainNode.context.destination);\n                    const whenConnected = () => nativeGainNode.disconnect();\n                    /*\n                     * Bug #50: Edge does not yet allow to create AudioNodes on a closed AudioContext. Therefore the context property is\n                     * used here to make sure to connect the right destination.\n                     */\n                    const whenDisconnected = () => nativeGainNode.connect(nativeGainNode.context.destination);\n                    // @todo Disconnect the connection when the process() function of the AudioWorkletNode returns false.\n                    return monitorConnections(nativeAudioWorkletNode, whenConnected, whenDisconnected);\n                }\n                return nativeAudioWorkletNode;\n            }\n            catch (err) {\n                // Bug #60: Chrome & Opera throw an InvalidStateError instead of a NotSupportedError.\n                if (err.code === 11) {\n                    throw createNotSupportedError();\n                }\n                throw err;\n            }\n        }\n        // Bug #61: Only Chrome & Opera have an implementation of the AudioWorkletNode yet.\n        if (processorConstructor === undefined) {\n            throw createNotSupportedError();\n        }\n        testClonabilityOfAudioWorkletNodeOptions(options);\n        return createNativeAudioWorkletNodeFaker(nativeContext, baseLatency, processorConstructor, options);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-audio-worklet-node-factory.js.map","import { MOST_NEGATIVE_SINGLE_FLOAT, MOST_POSITIVE_SINGLE_FLOAT } from '../constants';\nimport { computeBufferSize } from '../helpers/compute-buffer-size';\nimport { copyFromChannel } from '../helpers/copy-from-channel';\nimport { copyToChannel } from '../helpers/copy-to-channel';\nimport { createAudioWorkletProcessor } from '../helpers/create-audio-worklet-processor';\nimport { createNestedArrays } from '../helpers/create-nested-arrays';\nimport { ReadOnlyMap } from '../read-only-map';\nexport const createNativeAudioWorkletNodeFakerFactory = (auxiliaryGainNodeStore, connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, monitorConnections) => {\n    return (nativeContext, baseLatency, processorConstructor, options) => {\n        if (options.numberOfInputs === 0 && options.numberOfOutputs === 0) {\n            throw createNotSupportedError();\n        }\n        if (options.outputChannelCount !== undefined) {\n            // @todo Check if any of the channelCount values is greater than the implementation's maximum number of channels.\n            if (options.outputChannelCount.some((channelCount) => (channelCount < 1))) {\n                throw createNotSupportedError();\n            }\n            if (options.outputChannelCount.length !== options.numberOfOutputs) {\n                throw createIndexSizeError();\n            }\n        }\n        // Bug #61: This is not part of the standard but required for the faker to work.\n        if (options.channelCountMode !== 'explicit') {\n            throw createNotSupportedError();\n        }\n        const numberOfInputChannels = options.channelCount * options.numberOfInputs;\n        const numberOfOutputChannels = options.outputChannelCount.reduce((sum, value) => sum + value, 0);\n        const numberOfParameters = (processorConstructor.parameterDescriptors === undefined)\n            ? 0\n            : processorConstructor.parameterDescriptors.length;\n        // Bug #61: This is not part of the standard but required for the faker to work.\n        if (numberOfInputChannels + numberOfParameters > 6 || numberOfOutputChannels > 6) {\n            throw createNotSupportedError();\n        }\n        const messageChannel = new MessageChannel();\n        const gainNodes = [];\n        const inputChannelSplitterNodes = [];\n        for (let i = 0; i < options.numberOfInputs; i += 1) {\n            gainNodes.push(createNativeGainNode(nativeContext, {\n                channelCount: options.channelCount,\n                channelCountMode: options.channelCountMode,\n                channelInterpretation: options.channelInterpretation,\n                gain: 1\n            }));\n            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(nativeContext, {\n                channelCount: options.channelCount,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'discrete',\n                numberOfOutputs: options.channelCount\n            }));\n        }\n        const constantSourceNodes = [];\n        if (processorConstructor.parameterDescriptors !== undefined) {\n            for (const { defaultValue, maxValue, minValue, name } of processorConstructor.parameterDescriptors) {\n                const constantSourceNode = createNativeConstantSourceNode(nativeContext, {\n                    channelCount: 1,\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    offset: (options.parameterData[name] !== undefined)\n                        ? options.parameterData[name]\n                        : (defaultValue === undefined)\n                            ? 0\n                            : defaultValue\n                });\n                Object.defineProperties(constantSourceNode.offset, {\n                    defaultValue: {\n                        get: () => (defaultValue === undefined) ? 0 : defaultValue\n                    },\n                    maxValue: {\n                        get: () => (maxValue === undefined) ? MOST_POSITIVE_SINGLE_FLOAT : maxValue\n                    },\n                    minValue: {\n                        get: () => (minValue === undefined) ? MOST_NEGATIVE_SINGLE_FLOAT : minValue\n                    }\n                });\n                constantSourceNodes.push(constantSourceNode);\n            }\n        }\n        const inputChannelMergerNode = createNativeChannelMergerNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'speakers',\n            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)\n        });\n        const bufferSize = computeBufferSize(baseLatency, nativeContext.sampleRate);\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, numberOfInputChannels + numberOfParameters, \n        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.\n        Math.max(1, numberOfOutputChannels));\n        const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, {\n            channelCount: Math.max(1, numberOfOutputChannels),\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            numberOfOutputs: Math.max(1, numberOfOutputChannels)\n        });\n        const outputChannelMergerNodes = [];\n        for (let i = 0; i < options.numberOfOutputs; i += 1) {\n            outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'speakers',\n                numberOfInputs: options.outputChannelCount[i]\n            }));\n        }\n        for (let i = 0; i < options.numberOfInputs; i += 1) {\n            gainNodes[i].connect(inputChannelSplitterNodes[i]);\n            for (let j = 0; j < options.channelCount; j += 1) {\n                inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, (i * options.channelCount) + j);\n            }\n        }\n        const parameterMap = new ReadOnlyMap((processorConstructor.parameterDescriptors === undefined)\n            ? []\n            : processorConstructor.parameterDescriptors\n                .map(({ name }, index) => {\n                const constantSourceNode = constantSourceNodes[index];\n                constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);\n                constantSourceNode.start(0);\n                return [name, constantSourceNode.offset];\n            }));\n        inputChannelMergerNode.connect(scriptProcessorNode);\n        let channelInterpretation = options.channelInterpretation;\n        let onprocessorerror = null;\n        // Bug #87: Expose at least one output to make this node connectable.\n        const outputAudioNodes = (options.numberOfOutputs === 0) ? [scriptProcessorNode] : outputChannelMergerNodes;\n        const nativeAudioWorkletNodeFaker = {\n            get bufferSize() {\n                return bufferSize;\n            },\n            get channelCount() {\n                return options.channelCount;\n            },\n            set channelCount(_) {\n                // Bug #61: This is not part of the standard but required for the faker to work.\n                throw createInvalidStateError();\n            },\n            get channelCountMode() {\n                return options.channelCountMode;\n            },\n            set channelCountMode(_) {\n                // Bug #61: This is not part of the standard but required for the faker to work.\n                throw createInvalidStateError();\n            },\n            get channelInterpretation() {\n                return channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                for (const gainNode of gainNodes) {\n                    gainNode.channelInterpretation = value;\n                }\n                channelInterpretation = value;\n            },\n            get context() {\n                return scriptProcessorNode.context;\n            },\n            get inputs() {\n                return gainNodes;\n            },\n            get numberOfInputs() {\n                return options.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return options.numberOfOutputs;\n            },\n            get onprocessorerror() {\n                return onprocessorerror;\n            },\n            set onprocessorerror(value) {\n                if (typeof onprocessorerror === 'function') {\n                    nativeAudioWorkletNodeFaker.removeEventListener('processorerror', onprocessorerror);\n                }\n                onprocessorerror = (typeof value === 'function') ? value : null;\n                if (typeof onprocessorerror === 'function') {\n                    nativeAudioWorkletNodeFaker.addEventListener('processorerror', onprocessorerror);\n                }\n            },\n            get parameters() {\n                return parameterMap;\n            },\n            get port() {\n                return messageChannel.port2;\n            },\n            addEventListener(...args) {\n                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);\n            },\n            connect: connectMultipleOutputs.bind(null, outputAudioNodes),\n            disconnect: disconnectMultipleOutputs.bind(null, outputAudioNodes),\n            dispatchEvent(...args) {\n                return scriptProcessorNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        const patchedEventListeners = new Map(); // tslint:disable-line:max-line-length\n        messageChannel.port1.addEventListener = ((addEventListener) => {\n            return (...args) => {\n                if (args[0] === 'message') {\n                    const unpatchedEventListener = (typeof args[1] === 'function')\n                        ? args[1]\n                        : (typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function')\n                            ? args[1].handleEvent\n                            : null;\n                    if (unpatchedEventListener !== null) {\n                        const patchedEventListener = patchedEventListeners.get(args[1]);\n                        if (patchedEventListener !== undefined) {\n                            args[1] = patchedEventListener;\n                        }\n                        else {\n                            args[1] = (event) => {\n                                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, () => unpatchedEventListener(event));\n                            };\n                            patchedEventListeners.set(unpatchedEventListener, args[1]);\n                        }\n                    }\n                }\n                return addEventListener.call(messageChannel.port1, args[0], args[1], args[2]);\n            };\n        })(messageChannel.port1.addEventListener);\n        messageChannel.port1.removeEventListener = ((removeEventListener) => {\n            return (...args) => {\n                if (args[0] === 'message') {\n                    const patchedEventListener = patchedEventListeners.get(args[1]);\n                    if (patchedEventListener !== undefined) {\n                        patchedEventListeners.delete(args[1]);\n                        args[1] = patchedEventListener;\n                    }\n                }\n                return removeEventListener.call(messageChannel.port1, args[0], args[1], args[2]);\n            };\n        })(messageChannel.port1.removeEventListener);\n        let onmessage = null;\n        Object.defineProperty(messageChannel.port1, 'onmessage', {\n            get: () => onmessage,\n            set: (value) => {\n                if (typeof onmessage === 'function') {\n                    messageChannel.port1.removeEventListener('message', onmessage);\n                }\n                onmessage = (typeof value === 'function') ? value : null;\n                if (typeof onmessage === 'function') {\n                    messageChannel.port1.addEventListener('message', onmessage);\n                    messageChannel.port1.start();\n                }\n            }\n        });\n        processorConstructor.prototype.port = messageChannel.port1;\n        let audioWorkletProcessor = null;\n        const audioWorkletProcessorPromise = createAudioWorkletProcessor(nativeContext, nativeAudioWorkletNodeFaker, processorConstructor, options);\n        audioWorkletProcessorPromise\n            .then((dWrkltPrcssr) => audioWorkletProcessor = dWrkltPrcssr);\n        const inputs = createNestedArrays(options.numberOfInputs, options.channelCount);\n        const outputs = createNestedArrays(options.numberOfOutputs, options.outputChannelCount);\n        const parameters = (processorConstructor.parameterDescriptors === undefined) ?\n            [] :\n            processorConstructor.parameterDescriptors\n                .reduce((prmtrs, { name }) => ({ ...prmtrs, [name]: new Float32Array(128) }), {});\n        let isActive = true;\n        const disconnectOutputsGraph = () => {\n            if (options.numberOfOutputs > 0) {\n                scriptProcessorNode.disconnect(outputChannelSplitterNode);\n            }\n            for (let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1) {\n                const outputChannelMergerNode = outputChannelMergerNodes[i];\n                for (let j = 0; j < options.outputChannelCount[i]; j += 1) {\n                    outputChannelSplitterNode.disconnect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                }\n                outputChannelSplitterNodeOutput += options.outputChannelCount[i];\n            }\n        };\n        scriptProcessorNode.onaudioprocess = ({ inputBuffer, outputBuffer }) => {\n            if (audioWorkletProcessor !== null) {\n                for (let i = 0; i < bufferSize; i += 128) {\n                    for (let j = 0; j < options.numberOfInputs; j += 1) {\n                        for (let k = 0; k < options.channelCount; k += 1) {\n                            copyFromChannel(inputBuffer, inputs[j], k, k, i);\n                        }\n                    }\n                    if (processorConstructor.parameterDescriptors !== undefined) {\n                        processorConstructor.parameterDescriptors.forEach(({ name }, index) => {\n                            copyFromChannel(inputBuffer, parameters, name, numberOfInputChannels + index, i);\n                        });\n                    }\n                    for (let j = 0; j < options.numberOfInputs; j += 1) {\n                        for (let k = 0; k < options.outputChannelCount[j]; k += 1) {\n                            // The byteLength will be 0 when the ArrayBuffer was transferred.\n                            if (outputs[j][k].byteLength === 0) {\n                                outputs[j][k] = new Float32Array(128);\n                            }\n                        }\n                    }\n                    try {\n                        const potentiallyEmptyInputs = inputs\n                            .map((input, index) => {\n                            const auxiliaryGainNodes = auxiliaryGainNodeStore.get(nativeAudioWorkletNodeFaker);\n                            if (auxiliaryGainNodes === undefined || auxiliaryGainNodes.get(index) === undefined) {\n                                return [];\n                            }\n                            return input;\n                        });\n                        const activeSourceFlag = exposeCurrentFrameAndCurrentTime(nativeContext.currentTime + (i / nativeContext.sampleRate), nativeContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));\n                        isActive = activeSourceFlag;\n                        for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {\n                            for (let k = 0; k < options.outputChannelCount[j]; k += 1) {\n                                copyToChannel(outputBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);\n                            }\n                            outputChannelSplitterNodeOutput += options.outputChannelCount[j];\n                        }\n                    }\n                    catch (error) {\n                        isActive = false;\n                        nativeAudioWorkletNodeFaker.dispatchEvent(new ErrorEvent('processorerror', { error }));\n                    }\n                    if (!isActive) {\n                        for (let j = 0; j < options.numberOfInputs; j += 1) {\n                            gainNodes[j].disconnect(inputChannelSplitterNodes[j]);\n                            for (let k = 0; k < options.channelCount; k += 1) {\n                                inputChannelSplitterNodes[i].disconnect(inputChannelMergerNode, k, (j * options.channelCount) + k);\n                            }\n                        }\n                        if (processorConstructor.parameterDescriptors !== undefined) {\n                            const length = processorConstructor.parameterDescriptors.length;\n                            for (let j = 0; j < length; j += 1) {\n                                const constantSourceNode = constantSourceNodes[j];\n                                constantSourceNode.disconnect(inputChannelMergerNode, 0, numberOfInputChannels + j);\n                                constantSourceNode.stop();\n                            }\n                        }\n                        inputChannelMergerNode.disconnect(scriptProcessorNode);\n                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation\n                        if (isConnected) {\n                            disconnectOutputsGraph();\n                        }\n                        else {\n                            disconnectFakeGraph();\n                        }\n                        break;\n                    }\n                }\n            }\n        };\n        let isConnected = false;\n        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.\n        const nativeGainNode = createNativeGainNode(nativeContext, { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'discrete', gain: 0 });\n        const connectFakeGraph = () => scriptProcessorNode\n            .connect(nativeGainNode)\n            /*\n             * Bug #50: Edge does not yet allow to create AudioNodes on a closed AudioContext. Therefore the context property is used here\n             * to make sure to connect the right destination.\n             */\n            .connect(nativeGainNode.context.destination);\n        const disconnectFakeGraph = () => {\n            scriptProcessorNode.disconnect(nativeGainNode);\n            nativeGainNode.disconnect();\n        };\n        const whenConnected = () => {\n            if (isActive) {\n                disconnectFakeGraph();\n                if (options.numberOfOutputs > 0) {\n                    scriptProcessorNode.connect(outputChannelSplitterNode);\n                }\n                for (let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1) {\n                    const outputChannelMergerNode = outputChannelMergerNodes[i];\n                    for (let j = 0; j < options.outputChannelCount[i]; j += 1) {\n                        outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                    }\n                    outputChannelSplitterNodeOutput += options.outputChannelCount[i];\n                }\n            }\n            isConnected = true;\n        };\n        const whenDisconnected = () => {\n            if (isActive) {\n                connectFakeGraph();\n                disconnectOutputsGraph();\n            }\n            isConnected = false;\n        };\n        connectFakeGraph();\n        return monitorConnections(nativeAudioWorkletNodeFaker, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-audio-worklet-node-faker-factory.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOption } from '../helpers/assign-native-audio-node-option';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeBiquadFilterNodeFactory = (createNativeAudioNode) => {\n    return (nativeContext, options) => {\n        const nativeBiquadFilterNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createBiquadFilter());\n        assignNativeAudioNodeOptions(nativeBiquadFilterNode, options);\n        assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'Q');\n        assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'detune');\n        assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'frequency');\n        assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'gain');\n        assignNativeAudioNodeOption(nativeBiquadFilterNode, options, 'type');\n        return nativeBiquadFilterNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-biquad-filter-node-factory.js.map","import { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeChannelMergerNodeFactory = (createNativeAudioNode, wrapChannelMergerNode) => {\n    return (nativeContext, options) => {\n        const nativeChannelMergerNode = createNativeAudioNode(nativeContext, (ntvCntxt) => {\n            return ntvCntxt.createChannelMerger(options.numberOfInputs);\n        });\n        // Bug #15: Safari does not return the default properties.\n        // Bug #16: Safari does not throw an error when setting a different channelCount or channelCountMode.\n        if (nativeChannelMergerNode.channelCount !== 1 &&\n            nativeChannelMergerNode.channelCountMode !== 'explicit') {\n            wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);\n        }\n        assignNativeAudioNodeOptions(nativeChannelMergerNode, options);\n        return nativeChannelMergerNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-channel-merger-node-factory.js.map","import { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nimport { wrapChannelSplitterNode } from '../helpers/wrap-channel-splitter-node';\nexport const createNativeChannelSplitterNodeFactory = (createNativeAudioNode) => {\n    return (nativeContext, options) => {\n        const nativeChannelSplitterNode = createNativeAudioNode(nativeContext, (ntvCntxt) => {\n            return ntvCntxt.createChannelSplitter(options.numberOfOutputs);\n        });\n        // Bug #96: Safari does not have the correct channelCount.\n        // Bug #29: Edge & Safari do not have the correct channelCountMode.\n        // Bug #31: Edge & Safari do not have the correct channelInterpretation.\n        assignNativeAudioNodeOptions(nativeChannelSplitterNode, options);\n        // Bug #29, #30, #31, #32, #96 & #97: Only Chrome, Firefox & Opera partially support the spec yet.\n        wrapChannelSplitterNode(nativeChannelSplitterNode);\n        return nativeChannelSplitterNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-channel-splitter-node-factory.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nimport { wrapAudioScheduledSourceNodeStartMethodNegativeParameters } from '../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters';\nimport { wrapAudioScheduledSourceNodeStopMethodNegativeParameters } from '../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters';\nexport const createNativeConstantSourceNodeFactory = (addSilentConnection, cacheTestResult, createNativeAudioNode, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport) => {\n    return (nativeContext, options) => {\n        // Bug #62: Edge & Safari do not support ConstantSourceNodes.\n        if (nativeContext.createConstantSource === undefined) {\n            return createNativeConstantSourceNodeFaker(nativeContext, options);\n        }\n        const nativeConstantSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => {\n            return ntvCntxt.createConstantSource();\n        });\n        assignNativeAudioNodeOptions(nativeConstantSourceNode, options);\n        assignNativeAudioNodeAudioParamValue(nativeConstantSourceNode, options, 'offset');\n        // Bug #44: Only Chrome, Firefox & Opera throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeConstantSourceNode);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeConstantSourceNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the ConstantSourceNode is unconnected.\n        addSilentConnection(nativeContext, nativeConstantSourceNode);\n        return nativeConstantSourceNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-constant-source-node-factory.js.map","import { interceptConnections } from '../helpers/intercept-connections';\nexport const createNativeConstantSourceNodeFakerFactory = (addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections) => {\n    return (nativeContext, { offset, ...audioNodeOptions }) => {\n        const audioBuffer = nativeContext.createBuffer(1, 2, nativeContext.sampleRate);\n        const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {\n            buffer: null,\n            channelCount: 2,\n            channelCountMode: 'max',\n            channelInterpretation: 'speakers',\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            playbackRate: 1\n        });\n        const gainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: offset });\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        const channelData = audioBuffer.getChannelData(0);\n        // Bug #95: Safari does not play or loop one sample buffers.\n        channelData[0] = 1;\n        channelData[1] = 1;\n        audioBufferSourceNode.buffer = audioBuffer;\n        audioBufferSourceNode.loop = true;\n        const nativeConstantSourceNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return gainNode.channelCount;\n            },\n            set channelCount(value) {\n                gainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return gainNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                gainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return gainNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                gainNode.channelInterpretation = value;\n            },\n            get context() {\n                return gainNode.context;\n            },\n            get inputs() {\n                return [];\n            },\n            get numberOfInputs() {\n                return audioBufferSourceNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return gainNode.numberOfOutputs;\n            },\n            get offset() {\n                return gainNode.gain;\n            },\n            get onended() {\n                return audioBufferSourceNode.onended;\n            },\n            set onended(value) {\n                audioBufferSourceNode.onended = value;\n            },\n            addEventListener(...args) {\n                return audioBufferSourceNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return audioBufferSourceNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return audioBufferSourceNode.removeEventListener(args[0], args[1], args[2]);\n            },\n            start(when = 0) {\n                audioBufferSourceNode.start.call(audioBufferSourceNode, when);\n            },\n            stop(when = 0) {\n                audioBufferSourceNode.stop.call(audioBufferSourceNode, when);\n            }\n        };\n        const whenConnected = () => audioBufferSourceNode.connect(gainNode);\n        const whenDisconnected = () => audioBufferSourceNode.disconnect(gainNode);\n        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.\n        addSilentConnection(nativeContext, audioBufferSourceNode);\n        return monitorConnections(interceptConnections(nativeConstantSourceNodeFaker, gainNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-constant-source-node-faker-factory.js.map","import { assignNativeAudioNodeOption } from '../helpers/assign-native-audio-node-option';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeConvolverNodeFactory = (createNativeAudioNode, createNativeConvolverNodeFaker, createNotSupportedError, overwriteAccessors) => {\n    return (nativeContext, options) => {\n        const nativeConvolverNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createConvolver());\n        try {\n            // Bug #166: Opera does not allow yet to set the channelCount to 1.\n            nativeConvolverNode.channelCount = 1;\n        }\n        catch (err) {\n            return createNativeConvolverNodeFaker(nativeContext, options);\n        }\n        assignNativeAudioNodeOptions(nativeConvolverNode, options);\n        // The normalize property needs to be set before setting the buffer.\n        if (options.disableNormalization === nativeConvolverNode.normalize) {\n            nativeConvolverNode.normalize = !options.disableNormalization;\n        }\n        assignNativeAudioNodeOption(nativeConvolverNode, options, 'buffer');\n        // Bug #113: Edge & Safari allow to set the channelCount to a value larger than 2.\n        if (options.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        overwriteAccessors(nativeConvolverNode, 'channelCount', (get) => () => get.call(nativeConvolverNode), (set) => (value) => {\n            if (value > 2) {\n                throw createNotSupportedError();\n            }\n            return set.call(nativeConvolverNode, value);\n        });\n        // Bug #114: Edge & Safari allow to set the channelCountMode to 'max'.\n        if (options.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        overwriteAccessors(nativeConvolverNode, 'channelCountMode', (get) => () => get.call(nativeConvolverNode), (set) => (value) => {\n            if (value === 'max') {\n                throw createNotSupportedError();\n            }\n            return set.call(nativeConvolverNode, value);\n        });\n        return nativeConvolverNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-convolver-node-factory.js.map","import { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nimport { interceptConnections } from '../helpers/intercept-connections';\nexport const createNativeConvolverNodeFakerFactory = (createNativeAudioNode, createNativeGainNode, monitorConnections) => {\n    return (nativeContext, { buffer, channelCount, channelCountMode, channelInterpretation, disableNormalization }) => {\n        const convolverNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createConvolver());\n        assignNativeAudioNodeOptions(convolverNode, {\n            // Bug #166: Opera does not allow yet to set the channelCount to 1.\n            channelCount: Math.max(channelCount, 2),\n            // Bug #167: Opera does not allow yet to set the channelCountMode to 'explicit'.\n            channelCountMode: (channelCountMode === 'max') ? channelCountMode : 'clamped-max',\n            channelInterpretation\n        });\n        const gainNode = createNativeGainNode(nativeContext, { channelCount, channelCountMode, channelInterpretation, gain: 1 });\n        const nativeConvolverNodeFaker = {\n            get buffer() {\n                return convolverNode.buffer;\n            },\n            set buffer(value) {\n                convolverNode.buffer = value;\n            },\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return gainNode.channelCount;\n            },\n            set channelCount(value) {\n                // Bug #166: Opera does not allow yet to set the channelCount to 1.\n                if (value > 2) {\n                    convolverNode.channelCount = value;\n                }\n                gainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return gainNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                // Bug #167: Opera does not allow yet to set the channelCountMode to 'explicit'.\n                if (value === 'max') {\n                    convolverNode.channelCountMode = value;\n                }\n                gainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return convolverNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                convolverNode.channelInterpretation = value;\n                gainNode.channelInterpretation = value;\n            },\n            get context() {\n                return convolverNode.context;\n            },\n            get inputs() {\n                return [convolverNode];\n            },\n            get numberOfInputs() {\n                return convolverNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return convolverNode.numberOfOutputs;\n            },\n            get normalize() {\n                return convolverNode.normalize;\n            },\n            set normalize(value) {\n                convolverNode.normalize = value;\n            },\n            addEventListener(...args) {\n                return convolverNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return convolverNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return convolverNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        // The normalize property needs to be set before setting the buffer.\n        if (disableNormalization === nativeConvolverNodeFaker.normalize) {\n            nativeConvolverNodeFaker.normalize = !disableNormalization;\n        }\n        if (buffer !== nativeConvolverNodeFaker.buffer) {\n            nativeConvolverNodeFaker.buffer = buffer;\n        }\n        const whenConnected = () => convolverNode.connect(gainNode);\n        const whenDisconnected = () => convolverNode.disconnect(gainNode);\n        return monitorConnections(interceptConnections(nativeConvolverNodeFaker, gainNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-convolver-node-faker-factory.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeDelayNodeFactory = (createNativeAudioNode) => {\n    return (nativeContext, options) => {\n        const nativeDelayNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createDelay(options.maxDelayTime));\n        assignNativeAudioNodeOptions(nativeDelayNode, options);\n        assignNativeAudioNodeAudioParamValue(nativeDelayNode, options, 'delayTime');\n        return nativeDelayNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-delay-node-factory.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeDynamicsCompressorNodeFactory = (createNativeAudioNode, createNotSupportedError) => {\n    return (nativeContext, options) => {\n        const nativeDynamicsCompressorNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createDynamicsCompressor());\n        assignNativeAudioNodeOptions(nativeDynamicsCompressorNode, options);\n        // Bug #108: Only Chrome, Firefox and Opera disallow a channelCount of three and above yet.\n        if (options.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        // Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max'.\n        if (options.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'attack');\n        assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'knee');\n        assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'ratio');\n        assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'release');\n        assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'threshold');\n        return nativeDynamicsCompressorNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-dynamics-compressor-node-factory.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeGainNodeFactory = (createNativeAudioNode) => {\n    return (nativeContext, options) => {\n        const nativeGainNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createGain());\n        assignNativeAudioNodeOptions(nativeGainNode, options);\n        assignNativeAudioNodeAudioParamValue(nativeGainNode, options, 'gain');\n        return nativeGainNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-gain-node-factory.js.map","import { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeIIRFilterNodeFactory = (createNativeAudioNode, createNativeIIRFilterNodeFaker) => {\n    return (nativeContext, baseLatency, options) => {\n        // Bug #9: Safari does not support IIRFilterNodes.\n        if (nativeContext.createIIRFilter === undefined) {\n            return createNativeIIRFilterNodeFaker(nativeContext, baseLatency, options);\n        }\n        const nativeIIRFilterNode = createNativeAudioNode(nativeContext, (ntvCntxt) => {\n            return ntvCntxt.createIIRFilter(options.feedforward, options.feedback);\n        });\n        assignNativeAudioNodeOptions(nativeIIRFilterNode, options);\n        return nativeIIRFilterNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-iir-filter-node-factory.js.map","import { computeBufferSize } from '../helpers/compute-buffer-size';\nimport { filterBuffer } from '../helpers/filter-buffer';\nimport { interceptConnections } from '../helpers/intercept-connections';\nfunction divide(a, b) {\n    const denominator = (b[0] * b[0]) + (b[1] * b[1]);\n    return [(((a[0] * b[0]) + (a[1] * b[1])) / denominator), (((a[1] * b[0]) - (a[0] * b[1])) / denominator)];\n}\nfunction multiply(a, b) {\n    return [((a[0] * b[0]) - (a[1] * b[1])), ((a[0] * b[1]) + (a[1] * b[0]))];\n}\nfunction evaluatePolynomial(coefficient, z) {\n    let result = [0, 0];\n    for (let i = coefficient.length - 1; i >= 0; i -= 1) {\n        result = multiply(result, z);\n        result[0] += coefficient[i];\n    }\n    return result;\n}\nexport const createNativeIIRFilterNodeFakerFactory = (createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError) => {\n    return (nativeContext, baseLatency, { channelCount, channelCountMode, channelInterpretation, feedback, feedforward }) => {\n        const bufferSize = computeBufferSize(baseLatency, nativeContext.sampleRate);\n        const feedbackLength = feedback.length;\n        const feedforwardLength = feedforward.length;\n        const minLength = Math.min(feedbackLength, feedforwardLength);\n        if (feedback.length === 0 || feedback.length > 20) {\n            throw createNotSupportedError();\n        }\n        if (feedback[0] === 0) {\n            throw createInvalidStateError();\n        }\n        if (feedforward.length === 0 || feedforward.length > 20) {\n            throw createNotSupportedError();\n        }\n        if (feedforward[0] === 0) {\n            throw createInvalidStateError();\n        }\n        if (feedback[0] !== 1) {\n            for (let i = 0; i < feedforwardLength; i += 1) {\n                feedforward[i] /= feedback[0];\n            }\n            for (let i = 1; i < feedbackLength; i += 1) {\n                feedback[i] /= feedback[0];\n            }\n        }\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, channelCount, channelCount);\n        scriptProcessorNode.channelCount = channelCount;\n        scriptProcessorNode.channelCountMode = channelCountMode;\n        scriptProcessorNode.channelInterpretation = channelInterpretation;\n        const bufferLength = 32;\n        const bufferIndexes = [];\n        const xBuffers = [];\n        const yBuffers = [];\n        for (let i = 0; i < channelCount; i += 1) {\n            bufferIndexes.push(0);\n            const xBuffer = new Float32Array(bufferLength);\n            const yBuffer = new Float32Array(bufferLength);\n            xBuffer.fill(0);\n            yBuffer.fill(0);\n            xBuffers.push(xBuffer);\n            yBuffers.push(yBuffer);\n        }\n        scriptProcessorNode.onaudioprocess = (event) => {\n            const inputBuffer = event.inputBuffer;\n            const outputBuffer = event.outputBuffer;\n            const numberOfChannels = inputBuffer.numberOfChannels;\n            for (let i = 0; i < numberOfChannels; i += 1) {\n                const input = inputBuffer.getChannelData(i);\n                const output = outputBuffer.getChannelData(i);\n                bufferIndexes[i] = filterBuffer(feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffers[i], yBuffers[i], bufferIndexes[i], bufferLength, input, output);\n            }\n        };\n        const nyquist = nativeContext.sampleRate / 2;\n        const nativeIIRFilterNodeFaker = {\n            get bufferSize() {\n                return bufferSize;\n            },\n            get channelCount() {\n                return scriptProcessorNode.channelCount;\n            },\n            set channelCount(value) {\n                scriptProcessorNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return scriptProcessorNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                scriptProcessorNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return scriptProcessorNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                scriptProcessorNode.channelInterpretation = value;\n            },\n            get context() {\n                return scriptProcessorNode.context;\n            },\n            get inputs() {\n                return [scriptProcessorNode];\n            },\n            get numberOfInputs() {\n                return scriptProcessorNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return scriptProcessorNode.numberOfOutputs;\n            },\n            addEventListener(...args) {\n                // @todo Dissallow adding an audioprocess listener.\n                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return scriptProcessorNode.dispatchEvent(args[0]);\n            },\n            getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n                if ((frequencyHz.length !== magResponse.length) || (magResponse.length !== phaseResponse.length)) {\n                    throw createInvalidAccessError();\n                }\n                const length = frequencyHz.length;\n                for (let i = 0; i < length; i += 1) {\n                    const omega = -Math.PI * (frequencyHz[i] / nyquist);\n                    const z = [Math.cos(omega), Math.sin(omega)];\n                    const numerator = evaluatePolynomial(feedforward, z);\n                    const denominator = evaluatePolynomial(feedback, z);\n                    const response = divide(numerator, denominator);\n                    magResponse[i] = Math.sqrt((response[0] * response[0]) + (response[1] * response[1]));\n                    phaseResponse[i] = Math.atan2(response[1], response[0]);\n                }\n            },\n            removeEventListener(...args) {\n                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        return interceptConnections(nativeIIRFilterNodeFaker, scriptProcessorNode);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-iir-filter-node-faker-factory.js.map","export const createNativeMediaElementAudioSourceNodeFactory = (createNativeAudioNode) => {\n    return (nativeAudioContext, options) => createNativeAudioNode(nativeAudioContext, (ntvDCntxt) => {\n        return ntvDCntxt.createMediaElementSource(options.mediaElement);\n    });\n};\n//# sourceMappingURL=/build/es2019/factories/native-media-element-audio-source-node-factory.js.map","import { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeMediaStreamAudioDestinationNodeFactory = (createNativeAudioNode, createNotSupportedError) => {\n    return (nativeAudioContext, options) => {\n        // Bug #64: Edge does not support MediaStreamAudioDestinationNodes.\n        if (nativeAudioContext.createMediaStreamDestination === undefined) {\n            throw createNotSupportedError();\n        }\n        const nativeMediaStreamAudioDestinationNode = createNativeAudioNode(nativeAudioContext, (ntvDCntxt) => {\n            return ntvDCntxt.createMediaStreamDestination();\n        });\n        assignNativeAudioNodeOptions(nativeMediaStreamAudioDestinationNode, options);\n        // Bug #174: Safari does expose a wrong numberOfOutputs.\n        if (nativeMediaStreamAudioDestinationNode.numberOfOutputs === 1) {\n            Object.defineProperty(nativeMediaStreamAudioDestinationNode, 'numberOfOutputs', { get: () => 0 });\n        }\n        return nativeMediaStreamAudioDestinationNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-media-stream-audio-destination-node-factory.js.map","export const createNativeMediaStreamAudioSourceNodeFactory = (createNativeAudioNode) => {\n    return (nativeAudioContext, { mediaStream }) => {\n        const audioStreamTracks = mediaStream.getAudioTracks();\n        const nativeMediaStreamAudioSourceNode = createNativeAudioNode(nativeAudioContext, (ntvDCntxt) => {\n            /*\n             * Bug #151: Safari does not use the audio track as input anymore if it gets removed from the mediaStream after construction.\n             * Bug #159: Safari picks the first audio track if the MediaStream has more than one audio track.\n             */\n            const filteredAudioStreamTracks = audioStreamTracks\n                .sort((a, b) => ((a.id < b.id) ? -1 : (a.id > b.id) ? 1 : 0))\n                .slice(0, 1);\n            return ntvDCntxt.createMediaStreamSource(new MediaStream(filteredAudioStreamTracks));\n        });\n        // Bug #63: Edge does not expose the mediaStream yet.\n        Object.defineProperty(nativeMediaStreamAudioSourceNode, 'mediaStream', { value: mediaStream });\n        return nativeMediaStreamAudioSourceNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-media-stream-audio-source-node-factory.js.map","export const createNativeMediaStreamTrackAudioSourceNodeFactory = (createInvalidStateError, createNativeAudioNode, isNativeOfflineAudioContext) => {\n    return (nativeAudioContext, { mediaStreamTrack }) => {\n        if (typeof nativeAudioContext.createMediaStreamTrackSource === 'function') {\n            return createNativeAudioNode(nativeAudioContext, (ntvDCntxt) => ntvDCntxt.createMediaStreamTrackSource(mediaStreamTrack));\n        }\n        // Bug #121: Only Firefox does yet support the MediaStreamTrackAudioSourceNode.\n        return createNativeAudioNode(nativeAudioContext, (ntvDCntxt) => {\n            const mediaStream = new MediaStream([mediaStreamTrack]);\n            const nativeMediaStreamAudioSourceNode = ntvDCntxt.createMediaStreamSource(mediaStream);\n            // Bug #120: Firefox does not throw an error if the mediaStream has no audio track.\n            if (mediaStreamTrack.kind !== 'audio') {\n                throw createInvalidStateError();\n            }\n            // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(ntvDCntxt)) {\n                throw new TypeError();\n            }\n            return nativeMediaStreamAudioSourceNode;\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js.map","export const createNativeOfflineAudioContextConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('OfflineAudioContext')) {\n        return window.OfflineAudioContext;\n    }\n    return (window.hasOwnProperty('webkitOfflineAudioContext')) ? window.webkitOfflineAudioContext : null;\n};\n//# sourceMappingURL=/build/es2019/factories/native-offline-audio-context-constructor.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOption } from '../helpers/assign-native-audio-node-option';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nimport { wrapAudioScheduledSourceNodeStartMethodNegativeParameters } from '../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters';\nimport { wrapAudioScheduledSourceNodeStopMethodNegativeParameters } from '../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters';\nexport const createNativeOscillatorNodeFactory = (addSilentConnection, cacheTestResult, createNativeAudioNode, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls) => {\n    return (nativeContext, options) => {\n        const nativeOscillatorNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createOscillator());\n        assignNativeAudioNodeOptions(nativeOscillatorNode, options);\n        assignNativeAudioNodeAudioParamValue(nativeOscillatorNode, options, 'detune');\n        assignNativeAudioNodeAudioParamValue(nativeOscillatorNode, options, 'frequency');\n        if (options.periodicWave !== undefined) {\n            nativeOscillatorNode.setPeriodicWave(options.periodicWave);\n        }\n        else {\n            assignNativeAudioNodeOption(nativeOscillatorNode, options, 'type');\n        }\n        // Bug #44: Only Chrome & Opera throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeOscillatorNode);\n        }\n        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, () => testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeOscillatorNode, nativeContext);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeOscillatorNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the OscillatorNode is unconnected.\n        addSilentConnection(nativeContext, nativeOscillatorNode);\n        return nativeOscillatorNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-oscillator-node-factory.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOption } from '../helpers/assign-native-audio-node-option';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativePannerNodeFactory = (createNativeAudioNode, createNativePannerNodeFaker) => {\n    return (nativeContext, options) => {\n        const nativePannerNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createPanner());\n        // Bug #124: Edge & Safari do not support modifying the orientation and the position with AudioParams.\n        if (nativePannerNode.orientationX === undefined) {\n            return createNativePannerNodeFaker(nativeContext, options);\n        }\n        assignNativeAudioNodeOptions(nativePannerNode, options);\n        assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationX');\n        assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationY');\n        assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationZ');\n        assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionX');\n        assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionY');\n        assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionZ');\n        assignNativeAudioNodeOption(nativePannerNode, options, 'coneInnerAngle');\n        assignNativeAudioNodeOption(nativePannerNode, options, 'coneOuterAngle');\n        assignNativeAudioNodeOption(nativePannerNode, options, 'coneOuterGain');\n        assignNativeAudioNodeOption(nativePannerNode, options, 'distanceModel');\n        assignNativeAudioNodeOption(nativePannerNode, options, 'maxDistance');\n        assignNativeAudioNodeOption(nativePannerNode, options, 'panningModel');\n        assignNativeAudioNodeOption(nativePannerNode, options, 'refDistance');\n        assignNativeAudioNodeOption(nativePannerNode, options, 'rolloffFactor');\n        return nativePannerNode;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-panner-node-factory.js.map","import { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nimport { interceptConnections } from '../helpers/intercept-connections';\nexport const createNativePannerNodeFakerFactory = (connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeAudioNode, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, monitorConnections) => {\n    return (nativeContext, { coneInnerAngle, coneOuterAngle, coneOuterGain, distanceModel, maxDistance, orientationX, orientationY, orientationZ, panningModel, positionX, positionY, positionZ, refDistance, rolloffFactor, ...audioNodeOptions }) => {\n        const pannerNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createPanner());\n        // Bug #125: Safari does not throw an error yet.\n        if (audioNodeOptions.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        // Bug #126: Safari does not throw an error yet.\n        if (audioNodeOptions.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        assignNativeAudioNodeOptions(pannerNode, audioNodeOptions);\n        const SINGLE_CHANNEL_OPTIONS = {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete'\n        };\n        const channelMergerNode = createNativeChannelMergerNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, channelInterpretation: 'speakers', numberOfInputs: 6 });\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const orientationXGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 1 });\n        const orientationYGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const orientationZGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionXGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionYGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionZGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 6, 1);\n        const waveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, curve: new Float32Array([1, 1]), oversample: 'none' });\n        let lastOrientation = [orientationX, orientationY, orientationZ];\n        let lastPosition = [positionX, positionY, positionZ];\n        scriptProcessorNode.onaudioprocess = ({ inputBuffer }) => {\n            const orientation = [\n                inputBuffer.getChannelData(0)[0],\n                inputBuffer.getChannelData(1)[0],\n                inputBuffer.getChannelData(2)[0]\n            ];\n            if (orientation.some((value, index) => (value !== lastOrientation[index]))) {\n                pannerNode.setOrientation(...orientation); // tslint:disable-line:deprecation\n                lastOrientation = orientation;\n            }\n            const positon = [\n                inputBuffer.getChannelData(3)[0],\n                inputBuffer.getChannelData(4)[0],\n                inputBuffer.getChannelData(5)[0]\n            ];\n            if (positon.some((value, index) => (value !== lastPosition[index]))) {\n                pannerNode.setPosition(...positon); // tslint:disable-line:deprecation\n                lastPosition = positon;\n            }\n        };\n        Object.defineProperty(orientationYGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(orientationZGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionXGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionYGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionZGainNode.gain, 'defaultValue', { get: () => 0 });\n        const nativePannerNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return pannerNode.channelCount;\n            },\n            set channelCount(value) {\n                // Bug #125: Safari does not throw an error yet.\n                if (value > 2) {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCount = value;\n                pannerNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return pannerNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                // Bug #126: Safari does not throw an error yet.\n                if (value === 'max') {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCountMode = value;\n                pannerNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return pannerNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n                pannerNode.channelInterpretation = value;\n            },\n            get coneInnerAngle() {\n                return pannerNode.coneInnerAngle;\n            },\n            set coneInnerAngle(value) {\n                pannerNode.coneInnerAngle = value;\n            },\n            get coneOuterAngle() {\n                return pannerNode.coneOuterAngle;\n            },\n            set coneOuterAngle(value) {\n                pannerNode.coneOuterAngle = value;\n            },\n            get coneOuterGain() {\n                return pannerNode.coneOuterGain;\n            },\n            set coneOuterGain(value) {\n                // Bug #127: Edge & Safari do not throw an InvalidStateError yet.\n                if (value < 0 || value > 1) {\n                    throw createInvalidStateError();\n                }\n                pannerNode.coneOuterGain = value;\n            },\n            get context() {\n                return pannerNode.context;\n            },\n            get distanceModel() {\n                return pannerNode.distanceModel;\n            },\n            set distanceModel(value) {\n                pannerNode.distanceModel = value;\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get maxDistance() {\n                return pannerNode.maxDistance;\n            },\n            set maxDistance(value) {\n                // Bug #128: Edge & Safari do not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.maxDistance = value;\n            },\n            get numberOfInputs() {\n                return pannerNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return pannerNode.numberOfOutputs;\n            },\n            get orientationX() {\n                return orientationXGainNode.gain;\n            },\n            get orientationY() {\n                return orientationYGainNode.gain;\n            },\n            get orientationZ() {\n                return orientationZGainNode.gain;\n            },\n            get panningModel() {\n                return pannerNode.panningModel;\n            },\n            set panningModel(value) {\n                pannerNode.panningModel = value;\n                // Bug #123: Edge does not support HRTF as panningModel.\n                if (pannerNode.panningModel !== value && value === 'HRTF') {\n                    throw createNotSupportedError();\n                }\n            },\n            get positionX() {\n                return positionXGainNode.gain;\n            },\n            get positionY() {\n                return positionYGainNode.gain;\n            },\n            get positionZ() {\n                return positionZGainNode.gain;\n            },\n            get refDistance() {\n                return pannerNode.refDistance;\n            },\n            set refDistance(value) {\n                // Bug #129: Edge & Safari do not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.refDistance = value;\n            },\n            get rolloffFactor() {\n                return pannerNode.rolloffFactor;\n            },\n            set rolloffFactor(value) {\n                // Bug #130: Edge & Safari do not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.rolloffFactor = value;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        if (coneInnerAngle !== nativePannerNodeFaker.coneInnerAngle) {\n            nativePannerNodeFaker.coneInnerAngle = coneInnerAngle;\n        }\n        if (coneOuterAngle !== nativePannerNodeFaker.coneOuterAngle) {\n            nativePannerNodeFaker.coneOuterAngle = coneOuterAngle;\n        }\n        if (coneOuterGain !== nativePannerNodeFaker.coneOuterGain) {\n            nativePannerNodeFaker.coneOuterGain = coneOuterGain;\n        }\n        if (distanceModel !== nativePannerNodeFaker.distanceModel) {\n            nativePannerNodeFaker.distanceModel = distanceModel;\n        }\n        if (maxDistance !== nativePannerNodeFaker.maxDistance) {\n            nativePannerNodeFaker.maxDistance = maxDistance;\n        }\n        if (orientationX !== nativePannerNodeFaker.orientationX.value) {\n            nativePannerNodeFaker.orientationX.value = orientationX;\n        }\n        if (orientationY !== nativePannerNodeFaker.orientationY.value) {\n            nativePannerNodeFaker.orientationY.value = orientationY;\n        }\n        if (orientationZ !== nativePannerNodeFaker.orientationZ.value) {\n            nativePannerNodeFaker.orientationZ.value = orientationZ;\n        }\n        if (panningModel !== nativePannerNodeFaker.panningModel) {\n            nativePannerNodeFaker.panningModel = panningModel;\n        }\n        if (positionX !== nativePannerNodeFaker.positionX.value) {\n            nativePannerNodeFaker.positionX.value = positionX;\n        }\n        if (positionY !== nativePannerNodeFaker.positionY.value) {\n            nativePannerNodeFaker.positionY.value = positionY;\n        }\n        if (positionZ !== nativePannerNodeFaker.positionZ.value) {\n            nativePannerNodeFaker.positionZ.value = positionZ;\n        }\n        if (refDistance !== nativePannerNodeFaker.refDistance) {\n            nativePannerNodeFaker.refDistance = refDistance;\n        }\n        if (rolloffFactor !== nativePannerNodeFaker.rolloffFactor) {\n            nativePannerNodeFaker.rolloffFactor = rolloffFactor;\n        }\n        if (lastOrientation[0] !== 1 || lastOrientation[1] !== 0 || lastOrientation[2] !== 0) {\n            pannerNode.setOrientation(...lastOrientation); // tslint:disable-line:deprecation\n        }\n        if (lastPosition[0] !== 0 || lastPosition[1] !== 0 || lastPosition[2] !== 0) {\n            pannerNode.setPosition(...lastPosition); // tslint:disable-line:deprecation\n        }\n        const whenConnected = () => {\n            inputGainNode.connect(pannerNode);\n            // Bug #119: Safari does not fully support the WaveShaperNode.\n            connectNativeAudioNodeToNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);\n            waveShaperNode\n                .connect(orientationXGainNode)\n                .connect(channelMergerNode, 0, 0);\n            waveShaperNode\n                .connect(orientationYGainNode)\n                .connect(channelMergerNode, 0, 1);\n            waveShaperNode\n                .connect(orientationZGainNode)\n                .connect(channelMergerNode, 0, 2);\n            waveShaperNode\n                .connect(positionXGainNode)\n                .connect(channelMergerNode, 0, 3);\n            waveShaperNode\n                .connect(positionYGainNode)\n                .connect(channelMergerNode, 0, 4);\n            waveShaperNode\n                .connect(positionZGainNode)\n                .connect(channelMergerNode, 0, 5);\n            channelMergerNode\n                .connect(scriptProcessorNode)\n                .connect(nativeContext.destination);\n        };\n        const whenDisconnected = () => {\n            inputGainNode.disconnect(pannerNode);\n            // Bug #119: Safari does not fully support the WaveShaperNode.\n            disconnectNativeAudioNodeFromNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);\n            waveShaperNode.disconnect(orientationXGainNode);\n            orientationXGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(orientationYGainNode);\n            orientationYGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(orientationZGainNode);\n            orientationZGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionXGainNode);\n            positionXGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionYGainNode);\n            positionYGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionZGainNode);\n            positionZGainNode.disconnect(channelMergerNode);\n            channelMergerNode.disconnect(scriptProcessorNode);\n            scriptProcessorNode.disconnect(nativeContext.destination);\n        };\n        return monitorConnections(interceptConnections(nativePannerNodeFaker, pannerNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-panner-node-faker-factory.js.map","export const createNativePeriodicWaveFactory = (getBackupNativeContext) => {\n    return (nativeContext, { disableNormalization, imag, real }) => {\n        // Bug #50: Only Edge does currently not allow to create AudioNodes (and other objects) on a closed context yet.\n        const backupNativeContext = getBackupNativeContext(nativeContext);\n        // @todo Edge, Firefox & Safari do only accept Float32Arrays.\n        const wrappedImag = new Float32Array(imag);\n        const wrappedReal = new Float32Array(real);\n        if (backupNativeContext !== null) {\n            return backupNativeContext.createPeriodicWave(wrappedReal, wrappedImag, { disableNormalization });\n        }\n        return nativeContext.createPeriodicWave(wrappedReal, wrappedImag, { disableNormalization });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-periodic-wave-factory.js.map","export const createNativeScriptProcessorNodeFactory = (createNativeAudioNode) => {\n    return (nativeContext, bufferSize, numberOfInputChannels, numberOfOutputChannels) => {\n        return createNativeAudioNode(nativeContext, (ntvCntxt) => {\n            return ntvCntxt.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels);\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-script-processor-node-factory.js.map","import { assignNativeAudioNodeAudioParamValue } from '../helpers/assign-native-audio-node-audio-param-value';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeStereoPannerNodeFactory = (createNativeAudioNode, createNativeStereoPannerNodeFaker, createNotSupportedError) => {\n    return (nativeContext, options) => createNativeAudioNode(nativeContext, (ntvCntxt) => {\n        const channelCountMode = options.channelCountMode;\n        /*\n         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari\n         * which supports it and therefore it can't be supported at all.\n         */\n        if (channelCountMode === 'clamped-max') {\n            throw createNotSupportedError();\n        }\n        // Bug #105: Safari does not support the StereoPannerNode.\n        if (nativeContext.createStereoPanner === undefined) {\n            return createNativeStereoPannerNodeFaker(nativeContext, options);\n        }\n        const nativeStereoPannerNode = ntvCntxt.createStereoPanner();\n        assignNativeAudioNodeOptions(nativeStereoPannerNode, options);\n        assignNativeAudioNodeAudioParamValue(nativeStereoPannerNode, options, 'pan');\n        /*\n         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari\n         * which supports it and therefore it can't be supported at all.\n         */\n        Object.defineProperty(nativeStereoPannerNode, 'channelCountMode', {\n            get: () => channelCountMode,\n            set: (value) => {\n                if (value !== channelCountMode) {\n                    throw createNotSupportedError();\n                }\n            }\n        });\n        return nativeStereoPannerNode;\n    });\n};\n//# sourceMappingURL=/build/es2019/factories/native-stereo-panner-node-factory.js.map","import { interceptConnections } from '../helpers/intercept-connections';\nexport const createNativeStereoPannerNodeFakerFactory = (createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections) => {\n    // The curve has a size of 14bit plus 1 value to have an exact representation for zero. This value has been determined experimentally.\n    const CURVE_SIZE = 16385;\n    const DC_CURVE = new Float32Array([1, 1]);\n    const HALF_PI = Math.PI / 2;\n    const SINGLE_CHANNEL_OPTIONS = { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'discrete' };\n    const SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS = { ...SINGLE_CHANNEL_OPTIONS, oversample: 'none' };\n    const buildInternalGraphForMono = (nativeContext, inputGainNode, panGainNode, channelMergerNode) => {\n        const leftWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        for (let i = 0; i < CURVE_SIZE; i += 1) {\n            const x = (i / (CURVE_SIZE - 1)) * HALF_PI;\n            leftWaveShaperCurve[i] = Math.cos(x);\n            rightWaveShaperCurve[i] = Math.sin(x);\n        }\n        const leftGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftWaveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: leftWaveShaperCurve });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const panWaveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: DC_CURVE });\n        const rightGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightWaveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: rightWaveShaperCurve });\n        return {\n            connectGraph() {\n                inputGainNode.connect(leftGainNode);\n                inputGainNode.connect(panWaveShaperNode.inputs[0]);\n                inputGainNode.connect(rightGainNode);\n                panWaveShaperNode.connect(panGainNode);\n                panGainNode.connect(leftWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightWaveShaperNode.inputs[0]);\n                leftWaveShaperNode.connect(leftGainNode.gain);\n                rightWaveShaperNode.connect(rightGainNode.gain);\n                leftGainNode.connect(channelMergerNode, 0, 0);\n                rightGainNode.connect(channelMergerNode, 0, 1);\n            },\n            disconnectGraph() {\n                inputGainNode.disconnect(leftGainNode);\n                inputGainNode.disconnect(panWaveShaperNode.inputs[0]);\n                inputGainNode.disconnect(rightGainNode);\n                panWaveShaperNode.disconnect(panGainNode);\n                panGainNode.disconnect(leftWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightWaveShaperNode.inputs[0]);\n                leftWaveShaperNode.disconnect(leftGainNode.gain);\n                rightWaveShaperNode.disconnect(rightGainNode.gain);\n                leftGainNode.disconnect(channelMergerNode, 0, 0);\n                rightGainNode.disconnect(channelMergerNode, 0, 1);\n            }\n        };\n    };\n    const buildInternalGraphForStereo = (nativeContext, inputGainNode, panGainNode, channelMergerNode) => {\n        const leftInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const leftInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const centerIndex = Math.floor(CURVE_SIZE / 2);\n        for (let i = 0; i < CURVE_SIZE; i += 1) {\n            if (i > centerIndex) {\n                const x = ((i - centerIndex) / (CURVE_SIZE - 1 - centerIndex)) * HALF_PI;\n                leftInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);\n                leftInputForRightOutputWaveShaperCurve[i] = Math.sin(x);\n                rightInputForLeftOutputWaveShaperCurve[i] = 0;\n                rightInputForRightOutputWaveShaperCurve[i] = 1;\n            }\n            else {\n                const x = (i / (CURVE_SIZE - 1 - centerIndex)) * HALF_PI;\n                leftInputForLeftOutputWaveShaperCurve[i] = 1;\n                leftInputForRightOutputWaveShaperCurve[i] = 0;\n                rightInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);\n                rightInputForRightOutputWaveShaperCurve[i] = Math.sin(x);\n            }\n        }\n        const channelSplitterNode = createNativeChannelSplitterNode(nativeContext, {\n            channelCount: 2,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            numberOfOutputs: 2\n        });\n        const leftInputForLeftOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: leftInputForLeftOutputWaveShaperCurve });\n        const leftInputForRightOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: leftInputForRightOutputWaveShaperCurve });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const panWaveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: DC_CURVE });\n        const rightInputForLeftOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: rightInputForLeftOutputWaveShaperCurve });\n        const rightInputForRightOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: rightInputForRightOutputWaveShaperCurve });\n        return {\n            connectGraph() {\n                inputGainNode.connect(channelSplitterNode);\n                inputGainNode.connect(panWaveShaperNode.inputs[0]);\n                channelSplitterNode.connect(leftInputForLeftOutputGainNode, 1);\n                channelSplitterNode.connect(leftInputForRightOutputGainNode, 1);\n                channelSplitterNode.connect(rightInputForLeftOutputGainNode, 1);\n                channelSplitterNode.connect(rightInputForRightOutputGainNode, 1);\n                panWaveShaperNode.connect(panGainNode);\n                panGainNode.connect(leftInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(leftInputForRightOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightInputForRightOutputWaveShaperNode.inputs[0]);\n                leftInputForLeftOutputWaveShaperNode.connect(leftInputForLeftOutputGainNode.gain);\n                leftInputForRightOutputWaveShaperNode.connect(leftInputForRightOutputGainNode.gain);\n                rightInputForLeftOutputWaveShaperNode.connect(rightInputForLeftOutputGainNode.gain);\n                rightInputForRightOutputWaveShaperNode.connect(rightInputForRightOutputGainNode.gain);\n                leftInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);\n                rightInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);\n                leftInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);\n                rightInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);\n            },\n            disconnectGraph() {\n                inputGainNode.disconnect(channelSplitterNode);\n                inputGainNode.disconnect(panWaveShaperNode.inputs[0]);\n                channelSplitterNode.disconnect(leftInputForLeftOutputGainNode, 1);\n                channelSplitterNode.disconnect(leftInputForRightOutputGainNode, 1);\n                channelSplitterNode.disconnect(rightInputForLeftOutputGainNode, 1);\n                channelSplitterNode.disconnect(rightInputForRightOutputGainNode, 1);\n                panWaveShaperNode.disconnect(panGainNode);\n                panGainNode.disconnect(leftInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(leftInputForRightOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightInputForRightOutputWaveShaperNode.inputs[0]);\n                leftInputForLeftOutputWaveShaperNode.disconnect(leftInputForLeftOutputGainNode.gain);\n                leftInputForRightOutputWaveShaperNode.disconnect(leftInputForRightOutputGainNode.gain);\n                rightInputForLeftOutputWaveShaperNode.disconnect(rightInputForLeftOutputGainNode.gain);\n                rightInputForRightOutputWaveShaperNode.disconnect(rightInputForRightOutputGainNode.gain);\n                leftInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);\n                rightInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);\n                leftInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);\n                rightInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);\n            }\n        };\n    };\n    const buildInternalGraph = (nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode) => {\n        if (channelCount === 1) {\n            return buildInternalGraphForMono(nativeContext, inputGainNode, panGainNode, channelMergerNode);\n        }\n        if (channelCount === 2) {\n            return buildInternalGraphForStereo(nativeContext, inputGainNode, panGainNode, channelMergerNode);\n        }\n        throw createNotSupportedError();\n    };\n    return (nativeContext, { channelCount, channelCountMode, pan, ...audioNodeOptions }) => {\n        if (channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {\n            ...audioNodeOptions,\n            channelCount: 1,\n            channelCountMode,\n            numberOfInputs: 2\n        });\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, channelCount, channelCountMode, gain: 1 });\n        const panGainNode = createNativeGainNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: pan\n        });\n        let { connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode);\n        Object.defineProperty(panGainNode.gain, 'defaultValue', { get: () => 0 });\n        const nativeStereoPannerNodeFakerFactory = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return inputGainNode.channelCount;\n            },\n            set channelCount(value) {\n                if (inputGainNode.channelCount !== value) {\n                    if (isConnected) {\n                        disconnectGraph();\n                    }\n                    ({ connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, value, inputGainNode, panGainNode, channelMergerNode));\n                    if (isConnected) {\n                        connectGraph();\n                    }\n                }\n                inputGainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return inputGainNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                if (value === 'clamped-max' || value === 'max') {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return inputGainNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n            },\n            get context() {\n                return inputGainNode.context;\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get numberOfInputs() {\n                return inputGainNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return inputGainNode.numberOfOutputs;\n            },\n            get pan() {\n                return panGainNode.gain;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        let isConnected = false;\n        const whenConnected = () => {\n            connectGraph();\n            isConnected = true;\n        };\n        const whenDisconnected = () => {\n            disconnectGraph();\n            isConnected = false;\n        };\n        return monitorConnections(interceptConnections(nativeStereoPannerNodeFakerFactory, channelMergerNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-stereo-panner-node-faker-factory.js.map","import { assignNativeAudioNodeOption } from '../helpers/assign-native-audio-node-option';\nimport { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nexport const createNativeWaveShaperNodeFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeAudioNode, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, overwriteAccessors) => {\n    return (nativeContext, options) => {\n        const nativeWaveShaperNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createWaveShaper());\n        try {\n            // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.\n            // Bug #119: Safari does not correctly map the values. Bug #102 is only used to detect Safari in this case.\n            nativeWaveShaperNode.curve = new Float32Array([1]);\n            return createNativeWaveShaperNodeFaker(nativeContext, options);\n        }\n        catch { /* Ignore errors. */ }\n        assignNativeAudioNodeOptions(nativeWaveShaperNode, options);\n        const curve = options.curve;\n        // Bug #104: Chrome will throw an InvalidAccessError when the curve has less than two samples.\n        if (curve !== null && curve.length < 2) {\n            throw createInvalidStateError();\n        }\n        assignNativeAudioNodeOption(nativeWaveShaperNode, options, 'curve');\n        assignNativeAudioNodeOption(nativeWaveShaperNode, options, 'oversample');\n        let disconnectNativeAudioBufferSourceNode = null;\n        let isConnected = false;\n        overwriteAccessors(nativeWaveShaperNode, 'curve', (get) => () => get.call(nativeWaveShaperNode), (set) => (value) => {\n            set.call(nativeWaveShaperNode, value);\n            if (isConnected) {\n                if (isDCCurve(value) && disconnectNativeAudioBufferSourceNode === null) {\n                    disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);\n                }\n                else if (!isDCCurve(value) && disconnectNativeAudioBufferSourceNode !== null) {\n                    disconnectNativeAudioBufferSourceNode();\n                    disconnectNativeAudioBufferSourceNode = null;\n                }\n            }\n            return value;\n        });\n        const whenConnected = () => {\n            isConnected = true;\n            if (isDCCurve(nativeWaveShaperNode.curve)) {\n                disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);\n            }\n        };\n        const whenDisconnected = () => {\n            isConnected = false;\n            if (disconnectNativeAudioBufferSourceNode !== null) {\n                disconnectNativeAudioBufferSourceNode();\n                disconnectNativeAudioBufferSourceNode = null;\n            }\n        };\n        return monitorConnections(nativeWaveShaperNode, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-wave-shaper-node-factory.js.map","import { assignNativeAudioNodeOptions } from '../helpers/assign-native-audio-node-options';\nimport { interceptConnections } from '../helpers/intercept-connections';\nexport const createNativeWaveShaperNodeFakerFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeAudioNode, createNativeGainNode, isDCCurve, monitorConnections) => {\n    return (nativeContext, { curve, oversample, ...audioNodeOptions }) => {\n        const negativeWaveShaperNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createWaveShaper());\n        const positiveWaveShaperNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createWaveShaper());\n        assignNativeAudioNodeOptions(negativeWaveShaperNode, audioNodeOptions);\n        assignNativeAudioNodeOptions(positiveWaveShaperNode, audioNodeOptions);\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const invertGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: -1 });\n        const outputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const revertGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: -1 });\n        let disconnectNativeAudioBufferSourceNode = null;\n        let isConnected = false;\n        let unmodifiedCurve = null;\n        const nativeWaveShaperNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return negativeWaveShaperNode.channelCount;\n            },\n            set channelCount(value) {\n                inputGainNode.channelCount = value;\n                invertGainNode.channelCount = value;\n                negativeWaveShaperNode.channelCount = value;\n                outputGainNode.channelCount = value;\n                positiveWaveShaperNode.channelCount = value;\n                revertGainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return negativeWaveShaperNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                inputGainNode.channelCountMode = value;\n                invertGainNode.channelCountMode = value;\n                negativeWaveShaperNode.channelCountMode = value;\n                outputGainNode.channelCountMode = value;\n                positiveWaveShaperNode.channelCountMode = value;\n                revertGainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return negativeWaveShaperNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n                invertGainNode.channelInterpretation = value;\n                negativeWaveShaperNode.channelInterpretation = value;\n                outputGainNode.channelInterpretation = value;\n                positiveWaveShaperNode.channelInterpretation = value;\n                revertGainNode.channelInterpretation = value;\n            },\n            get context() {\n                return negativeWaveShaperNode.context;\n            },\n            get curve() {\n                return unmodifiedCurve;\n            },\n            set curve(value) {\n                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.\n                if (curve !== null && curve.length < 2) {\n                    throw createInvalidStateError();\n                }\n                if (value === null) {\n                    negativeWaveShaperNode.curve = value;\n                    positiveWaveShaperNode.curve = value;\n                }\n                else {\n                    const curveLength = value.length;\n                    const negativeCurve = new Float32Array(curveLength + 2 - (curveLength % 2));\n                    const positiveCurve = new Float32Array(curveLength + 2 - (curveLength % 2));\n                    negativeCurve[0] = value[0];\n                    positiveCurve[0] = -value[curveLength - 1];\n                    const length = Math.ceil((curveLength + 1) / 2);\n                    const centerIndex = ((curveLength + 1) / 2) - 1;\n                    for (let i = 1; i < length; i += 1) {\n                        const theoreticIndex = (i / length) * centerIndex;\n                        const lowerIndex = Math.floor(theoreticIndex);\n                        const upperIndex = Math.ceil(theoreticIndex);\n                        negativeCurve[i] = (lowerIndex === upperIndex)\n                            ? value[lowerIndex]\n                            : ((1 - (theoreticIndex - lowerIndex)) * value[lowerIndex])\n                                + ((1 - (upperIndex - theoreticIndex)) * value[upperIndex]);\n                        positiveCurve[i] = (lowerIndex === upperIndex)\n                            ? -value[curveLength - 1 - lowerIndex]\n                            : -((1 - (theoreticIndex - lowerIndex)) * value[curveLength - 1 - lowerIndex])\n                                - ((1 - (upperIndex - theoreticIndex)) * value[curveLength - 1 - upperIndex]);\n                    }\n                    negativeCurve[length] = (curveLength % 2 === 1) ? value[length - 1] : (value[length - 2] + value[length - 1]) / 2;\n                    negativeWaveShaperNode.curve = negativeCurve;\n                    positiveWaveShaperNode.curve = positiveCurve;\n                }\n                unmodifiedCurve = value;\n                if (isConnected) {\n                    if (isDCCurve(unmodifiedCurve) && disconnectNativeAudioBufferSourceNode === null) {\n                        disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);\n                    }\n                    else if (disconnectNativeAudioBufferSourceNode !== null) {\n                        disconnectNativeAudioBufferSourceNode();\n                        disconnectNativeAudioBufferSourceNode = null;\n                    }\n                }\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get numberOfInputs() {\n                return negativeWaveShaperNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return negativeWaveShaperNode.numberOfOutputs;\n            },\n            get oversample() {\n                return negativeWaveShaperNode.oversample;\n            },\n            set oversample(value) {\n                negativeWaveShaperNode.oversample = value;\n                positiveWaveShaperNode.oversample = value;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        if (curve !== nativeWaveShaperNodeFaker.curve) {\n            nativeWaveShaperNodeFaker.curve = curve;\n        }\n        if (oversample !== nativeWaveShaperNodeFaker.oversample) {\n            nativeWaveShaperNodeFaker.oversample = oversample;\n        }\n        const whenConnected = () => {\n            inputGainNode\n                .connect(negativeWaveShaperNode)\n                .connect(outputGainNode);\n            inputGainNode\n                .connect(invertGainNode)\n                .connect(positiveWaveShaperNode)\n                .connect(revertGainNode)\n                .connect(outputGainNode);\n            isConnected = true;\n            if (isDCCurve(unmodifiedCurve)) {\n                disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);\n            }\n        };\n        const whenDisconnected = () => {\n            inputGainNode.disconnect(negativeWaveShaperNode);\n            negativeWaveShaperNode.disconnect(outputGainNode);\n            inputGainNode.disconnect(invertGainNode);\n            invertGainNode.disconnect(positiveWaveShaperNode);\n            positiveWaveShaperNode.disconnect(revertGainNode);\n            revertGainNode.disconnect(outputGainNode);\n            isConnected = false;\n            if (disconnectNativeAudioBufferSourceNode !== null) {\n                disconnectNativeAudioBufferSourceNode();\n                disconnectNativeAudioBufferSourceNode = null;\n            }\n        };\n        return monitorConnections(interceptConnections(nativeWaveShaperNodeFaker, outputGainNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/native-wave-shaper-node-faker-factory.js.map","export const createNotSupportedError = () => {\n    try {\n        return new DOMException('', 'NotSupportedError');\n    }\n    catch (err) {\n        // Bug #122: Edge is the only browser that does not yet allow to construct a DOMException.\n        err.code = 9;\n        err.name = 'NotSupportedError';\n        return err;\n    }\n};\n//# sourceMappingURL=/build/es2019/factories/not-supported-error.js.map","import { testPromiseSupport } from '../helpers/test-promise-support';\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nexport const createOfflineAudioContextConstructor = (baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering) => {\n    return class OfflineAudioContext extends baseAudioContextConstructor {\n        constructor(a, b, c) {\n            let options;\n            if (typeof a === 'number' && b !== undefined && c !== undefined) {\n                options = { length: b, numberOfChannels: a, sampleRate: c };\n            }\n            else if (typeof a === 'object') {\n                options = a;\n            }\n            else {\n                throw new Error('The given parameters are not valid.');\n            }\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);\n            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.\n            if (!cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeOfflineAudioContext))) {\n                nativeOfflineAudioContext.addEventListener('statechange', (() => {\n                    let i = 0;\n                    const delayStateChangeEvent = (event) => {\n                        if (this._state === 'running') {\n                            if (i > 0) {\n                                nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);\n                                event.stopImmediatePropagation();\n                                this._waitForThePromiseToSettle(event);\n                            }\n                            else {\n                                i += 1;\n                            }\n                        }\n                    };\n                    return delayStateChangeEvent;\n                })());\n            }\n            super(nativeOfflineAudioContext, numberOfChannels);\n            this._length = length;\n            this._nativeOfflineAudioContext = nativeOfflineAudioContext;\n            this._state = null;\n        }\n        get length() {\n            // Bug #17: Safari does not yet expose the length.\n            if (this._nativeOfflineAudioContext.length === undefined) {\n                return this._length;\n            }\n            return this._nativeOfflineAudioContext.length;\n        }\n        get state() {\n            return (this._state === null) ? this._nativeOfflineAudioContext.state : this._state;\n        }\n        startRendering() {\n            /*\n             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore\n             * the state of the nativeOfflineAudioContext might no transition to running immediately.\n             */\n            if (this._state === 'running') {\n                return Promise.reject(createInvalidStateError());\n            }\n            this._state = 'running';\n            return startRendering(this.destination, this._nativeOfflineAudioContext)\n                .then((audioBuffer) => {\n                this._state = null;\n                /*\n                 * Bug #50: Deleting the AudioGraph is currently not possible anymore.\n                 * deleteAudioGraph(this, this._nativeOfflineAudioContext);\n                 */\n                return audioBuffer;\n            })\n                // @todo This could be written more elegantly when Promise.finally() becomes avalaible.\n                .catch((err) => {\n                this._state = null;\n                /*\n                 * Bug #50: Deleting the AudioGraph is currently not possible anymore.\n                 * deleteAudioGraph(this, this._nativeOfflineAudioContext);\n                 */\n                throw err;\n            });\n        }\n        _waitForThePromiseToSettle(event) {\n            if (this._state === null) {\n                this._nativeOfflineAudioContext.dispatchEvent(event);\n            }\n            else {\n                setTimeout(() => this._waitForThePromiseToSettle(event));\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/offline-audio-context-constructor.js.map","import { setInternalStateToActive } from '../helpers/set-internal-state-to-active';\nimport { setInternalStateToPassive } from '../helpers/set-internal-state-to-passive';\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    detune: 0,\n    frequency: 440,\n    type: 'sine'\n};\nexport const createOscillatorNodeConstructor = (audioNodeConstructor, createAudioParam, createInvalidStateError, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class OscillatorNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOscillatorNode = createNativeOscillatorNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const oscillatorNodeRenderer = ((isOffline) ? createOscillatorNodeRenderer() : null);\n            const nyquist = context.sampleRate / 2;\n            super(context, false, nativeOscillatorNode, oscillatorNodeRenderer);\n            // Bug #81: Edge, Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._detune = createAudioParam(this, isOffline, nativeOscillatorNode.detune, 153600, -153600);\n            // Bug #76: Edge & Safari do not export the correct values for maxValue and minValue.\n            this._frequency = createAudioParam(this, isOffline, nativeOscillatorNode.frequency, nyquist, -nyquist);\n            this._nativeOscillatorNode = nativeOscillatorNode;\n            this._onended = null;\n            this._oscillatorNodeRenderer = oscillatorNodeRenderer;\n            if (this._oscillatorNodeRenderer !== null && mergedOptions.periodicWave !== undefined) {\n                this._oscillatorNodeRenderer.periodicWave =\n                    mergedOptions.periodicWave;\n            }\n        }\n        get detune() {\n            return this._detune;\n        }\n        get frequency() {\n            return this._frequency;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = (typeof value === 'function') ? wrapEventListener(this, value) : null;\n            this._nativeOscillatorNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeOscillatorNode.onended;\n            this._onended = (nativeOnEnded !== null && nativeOnEnded === wrappedListener)\n                ? value\n                : nativeOnEnded;\n        }\n        get type() {\n            return this._nativeOscillatorNode.type;\n        }\n        set type(value) {\n            this._nativeOscillatorNode.type = value;\n            // Bug #57: Edge will not throw an error when assigning the type to 'custom'. But it still will change the value.\n            if (value === 'custom') {\n                throw createInvalidStateError();\n            }\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.periodicWave = null;\n            }\n        }\n        setPeriodicWave(periodicWave) {\n            this._nativeOscillatorNode.setPeriodicWave(periodicWave);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.periodicWave = periodicWave;\n            }\n        }\n        start(when = 0) {\n            this._nativeOscillatorNode.start(when);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.start = when;\n            }\n            else {\n                setInternalStateToActive(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeOscillatorNode.removeEventListener('ended', resetInternalStateToPassive);\n                    // @todo Determine a meaningful delay instead of just using one second.\n                    setTimeout(() => setInternalStateToPassive(this), 1000);\n                };\n                this._nativeOscillatorNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeOscillatorNode.stop(when);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/oscillator-node-constructor.js.map","import { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createOscillatorNodeRendererFactory = (connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeOscillatorNodes = new WeakMap();\n        let periodicWave = null;\n        let start = null;\n        let stop = null;\n        const createOscillatorNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeOscillatorNode = getNativeAudioNode(proxy);\n            // If the initially used nativeOscillatorNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeOscillatorNodeIsOwnedByContext = isOwnedByContext(nativeOscillatorNode, nativeOfflineAudioContext);\n            if (!nativeOscillatorNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeOscillatorNode.channelCount,\n                    channelCountMode: nativeOscillatorNode.channelCountMode,\n                    channelInterpretation: nativeOscillatorNode.channelInterpretation,\n                    detune: nativeOscillatorNode.detune.value,\n                    frequency: nativeOscillatorNode.frequency.value,\n                    periodicWave: (periodicWave === null) ? undefined : periodicWave,\n                    type: nativeOscillatorNode.type\n                };\n                nativeOscillatorNode = createNativeOscillatorNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeOscillatorNode.start(start);\n                }\n                if (stop !== null) {\n                    nativeOscillatorNode.stop(stop);\n                }\n            }\n            renderedNativeOscillatorNodes.set(nativeOfflineAudioContext, nativeOscillatorNode);\n            if (!nativeOscillatorNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency, trace);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency, trace);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeOscillatorNode, trace);\n            return nativeOscillatorNode;\n        };\n        return {\n            set periodicWave(value) {\n                periodicWave = value;\n            },\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeOscillatorNode = renderedNativeOscillatorNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeOscillatorNode !== undefined) {\n                    return Promise.resolve(renderedNativeOscillatorNode);\n                }\n                return createOscillatorNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/oscillator-node-renderer-factory.js.map","import { MOST_NEGATIVE_SINGLE_FLOAT, MOST_POSITIVE_SINGLE_FLOAT } from '../constants';\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    coneInnerAngle: 360,\n    coneOuterAngle: 360,\n    coneOuterGain: 0,\n    distanceModel: 'inverse',\n    maxDistance: 10000,\n    orientationX: 1,\n    orientationY: 0,\n    orientationZ: 0,\n    panningModel: 'equalpower',\n    positionX: 0,\n    positionY: 0,\n    positionZ: 0,\n    refDistance: 1,\n    rolloffFactor: 1\n};\nexport const createPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext) => {\n    return class PannerNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativePannerNode = createNativePannerNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const pannerNodeRenderer = ((isOffline) ? createPannerNodeRenderer() : null);\n            super(context, false, nativePannerNode, pannerNodeRenderer);\n            this._nativePannerNode = nativePannerNode;\n            // Bug #74: Edge & Safari do not export the correct values for maxValue and minValue for GainNodes.\n            this._orientationX = createAudioParam(this, isOffline, nativePannerNode.orientationX, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n            this._orientationY = createAudioParam(this, isOffline, nativePannerNode.orientationY, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n            this._orientationZ = createAudioParam(this, isOffline, nativePannerNode.orientationZ, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionX = createAudioParam(this, isOffline, nativePannerNode.positionX, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionY = createAudioParam(this, isOffline, nativePannerNode.positionY, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionZ = createAudioParam(this, isOffline, nativePannerNode.positionZ, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);\n        }\n        get coneInnerAngle() {\n            return this._nativePannerNode.coneInnerAngle;\n        }\n        set coneInnerAngle(value) {\n            this._nativePannerNode.coneInnerAngle = value;\n        }\n        get coneOuterAngle() {\n            return this._nativePannerNode.coneOuterAngle;\n        }\n        set coneOuterAngle(value) {\n            this._nativePannerNode.coneOuterAngle = value;\n        }\n        get coneOuterGain() {\n            return this._nativePannerNode.coneOuterGain;\n        }\n        set coneOuterGain(value) {\n            this._nativePannerNode.coneOuterGain = value;\n        }\n        get distanceModel() {\n            return this._nativePannerNode.distanceModel;\n        }\n        set distanceModel(value) {\n            this._nativePannerNode.distanceModel = value;\n        }\n        get maxDistance() {\n            return this._nativePannerNode.maxDistance;\n        }\n        set maxDistance(value) {\n            this._nativePannerNode.maxDistance = value;\n        }\n        get orientationX() {\n            return this._orientationX;\n        }\n        get orientationY() {\n            return this._orientationY;\n        }\n        get orientationZ() {\n            return this._orientationZ;\n        }\n        get panningModel() {\n            return this._nativePannerNode.panningModel;\n        }\n        set panningModel(value) {\n            this._nativePannerNode.panningModel = value;\n        }\n        get positionX() {\n            return this._positionX;\n        }\n        get positionY() {\n            return this._positionY;\n        }\n        get positionZ() {\n            return this._positionZ;\n        }\n        get refDistance() {\n            return this._nativePannerNode.refDistance;\n        }\n        set refDistance(value) {\n            this._nativePannerNode.refDistance = value;\n        }\n        get rolloffFactor() {\n            return this._nativePannerNode.rolloffFactor;\n        }\n        set rolloffFactor(value) {\n            this._nativePannerNode.rolloffFactor = value;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/panner-node-constructor.js.map","import { isNativeAudioNodeFaker } from '../guards/native-audio-node-faker';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createPannerNodeRendererFactory = (connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let renderedBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeGainNode = null;\n            let nativePannerNode = getNativeAudioNode(proxy);\n            const commonAudioNodeOptions = {\n                channelCount: nativePannerNode.channelCount,\n                channelCountMode: nativePannerNode.channelCountMode,\n                channelInterpretation: nativePannerNode.channelInterpretation\n            };\n            const commonNativePannerNodeOptions = {\n                ...commonAudioNodeOptions,\n                coneInnerAngle: nativePannerNode.coneInnerAngle,\n                coneOuterAngle: nativePannerNode.coneOuterAngle,\n                coneOuterGain: nativePannerNode.coneOuterGain,\n                distanceModel: nativePannerNode.distanceModel,\n                maxDistance: nativePannerNode.maxDistance,\n                panningModel: nativePannerNode.panningModel,\n                refDistance: nativePannerNode.refDistance,\n                rolloffFactor: nativePannerNode.rolloffFactor\n            };\n            // If the initially used nativePannerNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativePannerNodeIsOwnedByContext = isOwnedByContext(nativePannerNode, nativeOfflineAudioContext);\n            // Bug #124: Edge & Safari do not support modifying the orientation and the position with AudioParams.\n            if ('bufferSize' in nativePannerNode) {\n                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n            }\n            else if (!nativePannerNodeIsOwnedByContext) {\n                const options = {\n                    ...commonNativePannerNodeOptions,\n                    orientationX: nativePannerNode.orientationX.value,\n                    orientationY: nativePannerNode.orientationY.value,\n                    orientationZ: nativePannerNode.orientationZ.value,\n                    positionX: nativePannerNode.positionX.value,\n                    positionY: nativePannerNode.positionY.value,\n                    positionZ: nativePannerNode.positionZ.value\n                };\n                nativePannerNode = createNativePannerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, (nativeGainNode === null) ? nativePannerNode : nativeGainNode);\n            if (nativeGainNode !== null) {\n                if (renderedBufferPromise === null) {\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(6, \n                    // Bug #17: Safari does not yet expose the length.\n                    proxy.context.length, nativeOfflineAudioContext.sampleRate);\n                    const nativeChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n                        channelCount: 1,\n                        channelCountMode: 'explicit',\n                        channelInterpretation: 'speakers',\n                        numberOfInputs: 6\n                    });\n                    nativeChannelMergerNode.connect(partialOfflineAudioContext.destination);\n                    renderedBufferPromise = (async () => {\n                        const nativeConstantSourceNodes = await Promise\n                            .all([\n                            proxy.orientationX,\n                            proxy.orientationY,\n                            proxy.orientationZ,\n                            proxy.positionX,\n                            proxy.positionY,\n                            proxy.positionZ\n                        ]\n                            .map(async (audioParam, index) => {\n                            const nativeConstantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                                channelCount: 1,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                offset: (index === 0) ? 1 : 0\n                            });\n                            await renderAutomation(partialOfflineAudioContext, audioParam, nativeConstantSourceNode.offset, trace);\n                            return nativeConstantSourceNode;\n                        }));\n                        for (let i = 0; i < 6; i += 1) {\n                            nativeConstantSourceNodes[i].connect(nativeChannelMergerNode, 0, i);\n                            nativeConstantSourceNodes[i].start(0);\n                        }\n                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                    })();\n                }\n                const renderedBuffer = await renderedBufferPromise;\n                const inputGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, inputGainNode, trace);\n                const channelDatas = [];\n                for (let i = 0; i < renderedBuffer.numberOfChannels; i += 1) {\n                    channelDatas.push(renderedBuffer.getChannelData(i));\n                }\n                let lastOrientation = [channelDatas[0][0], channelDatas[1][0], channelDatas[2][0]];\n                let lastPosition = [channelDatas[3][0], channelDatas[4][0], channelDatas[5][0]];\n                let gateGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n                let partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {\n                    ...commonNativePannerNodeOptions,\n                    orientationX: lastOrientation[0],\n                    orientationY: lastOrientation[1],\n                    orientationZ: lastOrientation[2],\n                    positionX: lastPosition[0],\n                    positionY: lastPosition[1],\n                    positionZ: lastPosition[2]\n                });\n                inputGainNode\n                    .connect(gateGainNode)\n                    .connect(partialPannerNode.inputs[0]);\n                partialPannerNode.connect(nativeGainNode);\n                for (let i = 128; i < renderedBuffer.length; i += 128) {\n                    const orientation = [channelDatas[0][i], channelDatas[1][i], channelDatas[2][i]];\n                    const positon = [channelDatas[3][i], channelDatas[4][i], channelDatas[5][i]];\n                    if (orientation.some((value, index) => (value !== lastOrientation[index]))\n                        || positon.some((value, index) => (value !== lastPosition[index]))) {\n                        lastOrientation = orientation;\n                        lastPosition = positon;\n                        const currentTime = i / nativeOfflineAudioContext.sampleRate;\n                        gateGainNode.gain.setValueAtTime(0, currentTime);\n                        gateGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 0 });\n                        partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {\n                            ...commonNativePannerNodeOptions,\n                            orientationX: lastOrientation[0],\n                            orientationY: lastOrientation[1],\n                            orientationZ: lastOrientation[2],\n                            positionX: lastPosition[0],\n                            positionY: lastPosition[1],\n                            positionZ: lastPosition[2]\n                        });\n                        gateGainNode.gain.setValueAtTime(1, currentTime);\n                        inputGainNode\n                            .connect(gateGainNode)\n                            .connect(partialPannerNode.inputs[0]);\n                        partialPannerNode.connect(nativeGainNode);\n                    }\n                }\n                return nativeGainNode;\n            }\n            if (!nativePannerNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY, trace);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ, trace);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY, trace);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ, trace);\n            }\n            if (isNativeAudioNodeFaker(nativePannerNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode.inputs[0], trace);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode, trace);\n            }\n            return nativePannerNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeGainNodeOrNativePannerNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeGainNodeOrNativePannerNode !== undefined) {\n                    return Promise.resolve(renderedNativeGainNodeOrNativePannerNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/panner-node-renderer-factory.js.map","const DEFAULT_OPTIONS = {\n    disableNormalization: false\n};\nexport const createPeriodicWaveConstructor = (createNativePeriodicWave, getNativeContext, periodicWaveStore) => {\n    return class PeriodicWave {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const periodicWave = createNativePeriodicWave(nativeContext, mergedOptions);\n            periodicWaveStore.add(periodicWave);\n            // This does violate all good pratices but it is used here to simplify the handling of periodic waves.\n            return periodicWave;\n        }\n        static [Symbol.hasInstance](instance) {\n            return (instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === PeriodicWave.prototype)\n                || (periodicWaveStore.has(instance));\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/periodic-wave-constructor.js.map","export const createRenderAutomation = (getAudioParamRenderer, renderInputsOfAudioParam) => {\n    return (nativeOfflineAudioContext, audioParam, nativeAudioParam, trace) => {\n        const audioParamRenderer = getAudioParamRenderer(audioParam);\n        audioParamRenderer.replay(nativeAudioParam);\n        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam, trace);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/render-automation.js.map","export const createRenderInputsOfAudioNode = (getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle) => {\n    return async (audioNode, nativeOfflineAudioContext, nativeAudioNode, trace) => {\n        const audioNodeConnections = getAudioNodeConnections(audioNode);\n        const nextTrace = [...trace, audioNode];\n        await Promise\n            .all(audioNodeConnections.activeInputs\n            .map((connections, input) => Array\n            .from(connections)\n            .filter(([source]) => !nextTrace.includes(source))\n            .map(async ([source, output]) => {\n            const audioNodeRenderer = getAudioNodeRenderer(source);\n            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext, nextTrace);\n            const destination = audioNode.context.destination;\n            if (!isPartOfACycle(source) && ((audioNode !== destination) || !isPartOfACycle(audioNode))) {\n                renderedNativeAudioNode.connect(nativeAudioNode, output, input);\n            }\n        }))\n            .reduce((allRenderingPromises, renderingPromises) => [...allRenderingPromises, ...renderingPromises], []));\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/render-inputs-of-audio-node.js.map","export const createRenderInputsOfAudioParam = (getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle) => {\n    return async (audioParam, nativeOfflineAudioContext, nativeAudioParam, trace) => {\n        const audioParamConnections = getAudioParamConnections(audioParam);\n        await Promise\n            .all(Array\n            .from(audioParamConnections.activeInputs)\n            .map(async ([source, output]) => {\n            const audioNodeRenderer = getAudioNodeRenderer(source);\n            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext, trace);\n            if (!isPartOfACycle(source)) {\n                renderedNativeAudioNode.connect(nativeAudioParam, output);\n            }\n        }));\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/render-inputs-of-audio-param.js.map","import { testPromiseSupport } from '../helpers/test-promise-support';\nexport const createRenderNativeOfflineAudioContext = (cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, testOfflineAudioContextCurrentTimeSupport) => {\n    return (nativeOfflineAudioContext) => {\n        // Bug #21: Safari does not support promises yet.\n        if (cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeOfflineAudioContext))) {\n            // Bug #158: Edge does not advance currentTime if it is not accessed while rendering the audio.\n            return Promise\n                .resolve(cacheTestResult(testOfflineAudioContextCurrentTimeSupport, testOfflineAudioContextCurrentTimeSupport))\n                .then((isOfflineAudioContextCurrentTimeSupported) => {\n                if (!isOfflineAudioContextCurrentTimeSupported) {\n                    const scriptProcessorNode = createNativeScriptProcessorNode(nativeOfflineAudioContext, 512, 0, 1);\n                    nativeOfflineAudioContext.oncomplete = () => {\n                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation\n                        scriptProcessorNode.disconnect();\n                    };\n                    scriptProcessorNode.onaudioprocess = () => nativeOfflineAudioContext.currentTime; // tslint:disable-line:deprecation\n                    scriptProcessorNode.connect(nativeOfflineAudioContext.destination);\n                }\n                return nativeOfflineAudioContext.startRendering();\n            });\n        }\n        return new Promise((resolve) => {\n            // Bug #48: Safari does not render an OfflineAudioContext without any connected node.\n            const gainNode = createNativeGainNode(nativeOfflineAudioContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'discrete',\n                gain: 0\n            });\n            nativeOfflineAudioContext.oncomplete = (event) => {\n                gainNode.disconnect();\n                resolve(event.renderedBuffer);\n            };\n            gainNode.connect(nativeOfflineAudioContext.destination);\n            nativeOfflineAudioContext.startRendering();\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/render-native-offline-audio-context.js.map","import { wrapAudioBufferGetChannelDataMethod } from '../helpers/wrap-audio-buffer-get-channel-data-method';\nexport const createStartRendering = (audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    const trace = [];\n    return (destination, nativeOfflineAudioContext) => getAudioNodeRenderer(destination)\n        .render(destination, nativeOfflineAudioContext, trace)\n        /*\n         * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to the\n         * destination.\n         */\n        .then(() => Promise\n        .all(Array\n        .from(getUnrenderedAudioWorkletNodes(nativeOfflineAudioContext))\n        .map((audioWorkletNode) => getAudioNodeRenderer(audioWorkletNode)\n        .render(audioWorkletNode, nativeOfflineAudioContext, trace))))\n        .then(() => renderNativeOfflineAudioContext(nativeOfflineAudioContext))\n        .then((audioBuffer) => {\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n        if (typeof audioBuffer.copyFromChannel !== 'function') {\n            wrapAudioBufferCopyChannelMethods(audioBuffer);\n            wrapAudioBufferGetChannelDataMethod(audioBuffer);\n            // Bug #157: Only Chrome & Opera do allow the bufferOffset to be out-of-bounds.\n        }\n        else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {\n            wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n        }\n        audioBufferStore.add(audioBuffer);\n        return audioBuffer;\n    });\n};\n//# sourceMappingURL=/build/es2019/factories/start-rendering.js.map","const DEFAULT_OPTIONS = {\n    channelCount: 2,\n    /*\n     * Bug #105: The channelCountMode should be 'clamped-max' according to the spec but is set to 'explicit' to achieve consistent\n     * behavior.\n     */\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    pan: 0\n};\nexport const createStereoPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext) => {\n    return class StereoPannerNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeStereoPannerNode = createNativeStereoPannerNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const stereoPannerNodeRenderer = ((isOffline) ? createStereoPannerNodeRenderer() : null);\n            super(context, false, nativeStereoPannerNode, stereoPannerNodeRenderer);\n            // Bug #106: Edge does not export a maxValue and minValue property.\n            this._pan = createAudioParam(this, isOffline, nativeStereoPannerNode.pan, 1, -1);\n        }\n        get pan() {\n            return this._pan;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/stereo-panner-node-constructor.js.map","import { isNativeAudioNodeFaker } from '../guards/native-audio-node-faker';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createStereoPannerNodeRendererFactory = (connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeStereoPannerNodes = new WeakMap();\n        const createStereoPannerNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeStereoPannerNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeStereoPannerNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeStereoPannerNodeIsOwnedByContext = isOwnedByContext(nativeStereoPannerNode, nativeOfflineAudioContext);\n            if (!nativeStereoPannerNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeStereoPannerNode.channelCount,\n                    channelCountMode: nativeStereoPannerNode.channelCountMode,\n                    channelInterpretation: nativeStereoPannerNode.channelInterpretation,\n                    pan: nativeStereoPannerNode.pan.value\n                };\n                nativeStereoPannerNode = createNativeStereoPannerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeStereoPannerNodes.set(nativeOfflineAudioContext, nativeStereoPannerNode);\n            if (!nativeStereoPannerNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan, trace);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan, trace);\n            }\n            if (isNativeAudioNodeFaker(nativeStereoPannerNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode.inputs[0], trace);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode, trace);\n            }\n            return nativeStereoPannerNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeStereoPannerNode = renderedNativeStereoPannerNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeStereoPannerNode !== undefined) {\n                    return Promise.resolve(renderedNativeStereoPannerNode);\n                }\n                return createStereoPannerNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/stereo-panner-node-renderer-factory.js.map","// Bug #33: Edge & Safari expose an AudioBuffer but it can't be used as a constructor.\nexport const createTestAudioBufferConstructorSupport = (nativeAudioBufferConstructor) => {\n    return () => {\n        if (nativeAudioBufferConstructor === null) {\n            return false;\n        }\n        try {\n            new nativeAudioBufferConstructor({ length: 1, sampleRate: 44100 }); // tslint:disable-line:no-unused-expression\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-buffer-constructor-support.js.map","/*\n * Firefox up to version 67 didn't fully support the copyFromChannel() and copyToChannel() methods. Therefore testing one of those methods\n * is enough to know if the other one is supported as well.\n */\nexport const createTestAudioBufferCopyChannelMethodsSubarraySupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeAudioBuffer = nativeOfflineAudioContext.createBuffer(1, 1, 44100);\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        if (nativeAudioBuffer.copyToChannel === undefined) {\n            return true;\n        }\n        const source = new Float32Array(2);\n        try {\n            nativeAudioBuffer.copyFromChannel(source, 0, 0);\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js.map","export const createTestAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = (createNativeAudioNode) => {\n    return (nativeContext) => {\n        const nativeAudioBufferSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createBufferSource());\n        nativeAudioBufferSourceNode.start();\n        try {\n            nativeAudioBufferSourceNode.start();\n        }\n        catch {\n            return true;\n        }\n        return false;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-buffer-source-node-start-method-consecutive-calls-support.js.map","// Bug #92: Edge does not respect the duration parameter yet.\nexport const createTestAudioBufferSourceNodeStartMethodDurationParameterSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const audioBuffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);\n        const audioBufferSourceNode = offlineAudioContext.createBufferSource();\n        audioBuffer.getChannelData(0)[0] = 1;\n        audioBufferSourceNode.buffer = audioBuffer;\n        audioBufferSourceNode.start(0, 0, 0);\n        audioBufferSourceNode.connect(offlineAudioContext.destination);\n        // Bug #21: Safari does not support promises yet.\n        return new Promise((resolve) => {\n            offlineAudioContext.oncomplete = ({ renderedBuffer }) => {\n                // Bug #5: Safari does not support copyFromChannel().\n                resolve(renderedBuffer.getChannelData(0)[0] === 0);\n            };\n            offlineAudioContext.startRendering();\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-buffer-source-node-start-method-duration-parameter-support.js.map","export const createTestAudioBufferSourceNodeStartMethodOffsetClampingSupport = (createNativeAudioNode) => {\n    return (nativeContext) => {\n        const nativeAudioBufferSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createBufferSource());\n        const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);\n        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n        try {\n            nativeAudioBufferSourceNode.start(0, 1);\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-buffer-source-node-start-method-offset-clamping-support.js.map","export const createTestAudioBufferSourceNodeStopMethodNullifiedBufferSupport = (createNativeAudioNode) => {\n    return (nativeContext) => {\n        const nativeAudioBufferSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createBufferSource());\n        nativeAudioBufferSourceNode.start();\n        try {\n            nativeAudioBufferSourceNode.stop();\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js.map","export const createTestAudioContextCloseMethodSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        // Try to check the prototype before constructing the AudioContext.\n        if (nativeAudioContextConstructor.prototype !== undefined &&\n            nativeAudioContextConstructor.prototype.close !== undefined) {\n            return true;\n        }\n        const audioContext = new nativeAudioContextConstructor();\n        const isAudioContextClosable = (audioContext.close !== undefined);\n        try {\n            audioContext.close();\n        }\n        catch {\n            // Ignore errors.\n        }\n        return isAudioContextClosable;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-context-close-method-support.js.map","/**\n * Edge up to version 14, Firefox up to version 52, Safari up to version 9 and maybe other browsers\n * did not refuse to decode invalid parameters with a TypeError.\n */\nexport const createTestAudioContextDecodeAudioDataMethodTypeErrorSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #21: Safari does not support promises yet.\n        return new Promise((resolve) => {\n            let isPending = true;\n            const resolvePromise = (err) => {\n                if (isPending) {\n                    isPending = false;\n                    offlineAudioContext.startRendering();\n                    resolve(err instanceof TypeError);\n                }\n            };\n            let promise;\n            // Bug #26: Safari throws a synchronous error.\n            try {\n                promise = offlineAudioContext\n                    // Bug #1: Safari requires a successCallback.\n                    .decodeAudioData(null, () => {\n                    // Ignore the success callback.\n                }, resolvePromise);\n            }\n            catch (err) {\n                resolvePromise(err);\n            }\n            // Bug #21: Safari does not support promises yet.\n            if (promise !== undefined) {\n                // Bug #6 Chrome does not call the errorCallback\n                promise.catch(resolvePromise);\n            }\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js.map","export const createTestAudioContextOptionsSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        let audioContext;\n        try {\n            audioContext = new nativeAudioContextConstructor({ latencyHint: 'balanced' });\n        }\n        catch {\n            return false;\n        }\n        audioContext.close();\n        return true;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-context-options-support.js.map","// Safari up to version 12.0 (but not v12.1) didn't return the destination in case it was an AudioNode.\nexport const createTestAudioNodeConnectMethodSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeGainNode = nativeOfflineAudioContext.createGain();\n        const isSupported = (nativeGainNode.connect(nativeGainNode) === nativeGainNode);\n        nativeGainNode.disconnect(nativeGainNode);\n        return isSupported;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-node-connect-method-support.js.map","export const createTestAudioScheduledSourceNodeStartMethodNegativeParametersSupport = (createNativeAudioNode) => {\n    return (nativeContext) => {\n        const nativeAudioBufferSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createOscillator());\n        try {\n            nativeAudioBufferSourceNode.start(-1);\n        }\n        catch (err) {\n            return (err instanceof RangeError);\n        }\n        return false;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-scheduled-source-node-start-method-negative-parameters-support.js.map","export const createTestAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = (createNativeAudioNode) => {\n    return (nativeContext) => {\n        const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);\n        const nativeAudioBufferSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createBufferSource());\n        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n        nativeAudioBufferSourceNode.start();\n        nativeAudioBufferSourceNode.stop();\n        try {\n            nativeAudioBufferSourceNode.stop();\n            return true;\n        }\n        catch {\n            return false;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js.map","export const createTestAudioScheduledSourceNodeStopMethodNegativeParametersSupport = (createNativeAudioNode) => {\n    return (nativeContext) => {\n        const nativeAudioBufferSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createOscillator());\n        try {\n            nativeAudioBufferSourceNode.stop(-1);\n        }\n        catch (err) {\n            return (err instanceof RangeError);\n        }\n        return false;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js.map","/**\n * Chrome version 66 and 67 did not call the process() function of an AudioWorkletProcessor if it had no outputs. AudioWorklet support was\n * enabled by default in version 66.\n */\nexport const createTestAudioWorkletProcessorNoOutputsSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor) => {\n    return async () => {\n        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.\n        if (nativeAudioWorkletNodeConstructor === null) {\n            return true;\n        }\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const blob = new Blob(['class A extends AudioWorkletProcessor{process(){this.port.postMessage(0)}}registerProcessor(\"a\",A)'], { type: 'application/javascript; charset=utf-8' });\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 3200);\n        const url = URL.createObjectURL(blob);\n        let isCallingProcess = false;\n        try {\n            await offlineAudioContext.audioWorklet.addModule(url);\n            const gainNode = offlineAudioContext.createGain();\n            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', { numberOfOutputs: 0 });\n            audioWorkletNode.port.onmessage = () => isCallingProcess = true;\n            gainNode.connect(audioWorkletNode);\n            await offlineAudioContext.startRendering();\n        }\n        catch {\n            // Ignore errors.\n        }\n        finally {\n            URL.revokeObjectURL(url);\n        }\n        return isCallingProcess;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js.map","/**\n * Firefox up to version 69 did not throw an error when setting a different channelCount or channelCountMode.\n */\nexport const createTestChannelMergerNodeChannelCountSupport = (createNativeAudioNode, nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeChannelMergerNode = createNativeAudioNode(offlineAudioContext, (ntvCntxt) => ntvCntxt.createChannelMerger());\n        /**\n         * Bug #15: Safari does not return the default properties. It still needs to be patched. This test is supposed to test the support\n         * in other browsers.\n         */\n        if (nativeChannelMergerNode.channelCountMode === 'max') {\n            return true;\n        }\n        try {\n            nativeChannelMergerNode.channelCount = 2;\n        }\n        catch {\n            return true;\n        }\n        return false;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-channel-merger-node-channel-count-support.js.map","export const createTestConstantSourceNodeAccurateSchedulingSupport = (createNativeAudioNode, nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #62: Edge & Safari do not support ConstantSourceNodes.\n        if (nativeOfflineAudioContext.createConstantSource === undefined) {\n            return true;\n        }\n        const nativeConstantSourceNode = createNativeAudioNode(nativeOfflineAudioContext, (ntvCntxt) => ntvCntxt.createConstantSource());\n        /*\n         * @todo This is using bug #75 to detect bug #70. That works because both bugs were unique to\n         * the implementation of Firefox right now, but it could probably be done in a better way.\n         */\n        return (nativeConstantSourceNode.offset.maxValue !== Number.POSITIVE_INFINITY);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js.map","// Opera up to version 57 did not allow to reassign the buffer of a ConvolverNode.\nexport const createTestConvolverNodeBufferReassignabilitySupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeConvolverNode = offlineAudioContext.createConvolver();\n        nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);\n        try {\n            nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js.map","export const createTestIsSecureContextSupport = (window) => {\n    return () => (window !== null && window.hasOwnProperty('isSecureContext'));\n};\n//# sourceMappingURL=/build/es2019/factories/test-is-secure-context-support.js.map","// Firefox up to version 68 did not throw an error when creating a MediaStreamAudioSourceNode with a mediaStream that had no audio track.\nexport const createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        const audioContext = new nativeAudioContextConstructor();\n        try {\n            audioContext.createMediaStreamSource(new MediaStream());\n            return false;\n        }\n        catch (err) {\n            return true;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js.map","export const createTestOfflineAudioContextCurrentTimeSupport = (createNativeGainNode, nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #48: Safari does not render an OfflineAudioContext without any connected node.\n        const gainNode = createNativeGainNode(nativeOfflineAudioContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: 0\n        });\n        // Bug #21: Safari does not support promises yet.\n        return new Promise((resolve) => {\n            nativeOfflineAudioContext.oncomplete = () => {\n                gainNode.disconnect();\n                resolve(nativeOfflineAudioContext.currentTime !== 0);\n            };\n            nativeOfflineAudioContext.startRendering();\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-offline-audio-context-current-time-support.js.map","/**\n * Firefox up to version 62 did not kick off the processing of the StereoPannerNode if the value of pan was zero.\n */\nexport const createTestStereoPannerNodeDefaultValueSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        /*\n         * Bug #105: Safari does not support the StereoPannerNode. Therefore the returned value should normally be false but the faker does\n         * support the tested behaviour.\n         */\n        if (nativeOfflineAudioContext.createStereoPanner === undefined) {\n            return Promise.resolve(true);\n        }\n        // Bug #62: Edge & Safari do not support ConstantSourceNodes.\n        if (nativeOfflineAudioContext.createConstantSource === undefined) {\n            return Promise.resolve(true);\n        }\n        const constantSourceNode = nativeOfflineAudioContext.createConstantSource();\n        const stereoPanner = nativeOfflineAudioContext.createStereoPanner();\n        constantSourceNode.channelCount = 1;\n        constantSourceNode.offset.value = 1;\n        stereoPanner.channelCount = 1;\n        constantSourceNode.start();\n        constantSourceNode\n            .connect(stereoPanner)\n            .connect(nativeOfflineAudioContext.destination);\n        return nativeOfflineAudioContext\n            .startRendering()\n            .then((buffer) => buffer.getChannelData(0)[0] !== 1);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/test-stereo-panner-node-default-value-support.js.map","export const createUnknownError = () => {\n    try {\n        return new DOMException('', 'UnknownError');\n    }\n    catch (err) {\n        // Bug #122: Edge is the only browser that does not yet allow to construct a DOMException.\n        err.name = 'UnknownError';\n        return err;\n    }\n};\n//# sourceMappingURL=/build/es2019/factories/unknown-error.js.map","const DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    curve: null,\n    oversample: 'none'\n};\nexport const createWaveShaperNodeConstructor = (audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext) => {\n    return class WaveShaperNode extends audioNodeConstructor {\n        constructor(context, options = DEFAULT_OPTIONS) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeWaveShaperNode = createNativeWaveShaperNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const waveShaperNodeRenderer = ((isOffline) ? createWaveShaperNodeRenderer() : null);\n            // @todo Add a mechanism to only switch a WaveShaperNode to active while it is connected.\n            super(context, true, nativeWaveShaperNode, waveShaperNodeRenderer);\n            this._isCurveNullified = false;\n            this._nativeWaveShaperNode = nativeWaveShaperNode;\n        }\n        get curve() {\n            if (this._isCurveNullified) {\n                return null;\n            }\n            return this._nativeWaveShaperNode.curve;\n        }\n        set curve(value) {\n            // Bug #103: Safari does not allow to set the curve to null.\n            if (value === null) {\n                this._isCurveNullified = true;\n                this._nativeWaveShaperNode.curve = new Float32Array([0, 0]);\n            }\n            else {\n                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.\n                // Bug #104: Chrome will throw an InvalidAccessError when the curve has less than two samples.\n                if (value.length < 2) {\n                    throw createInvalidStateError();\n                }\n                this._isCurveNullified = false;\n                this._nativeWaveShaperNode.curve = value;\n            }\n        }\n        get oversample() {\n            return this._nativeWaveShaperNode.oversample;\n        }\n        set oversample(value) {\n            this._nativeWaveShaperNode.oversample = value;\n        }\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/wave-shaper-node-constructor.js.map","import { isNativeAudioNodeFaker } from '../guards/native-audio-node-faker';\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport const createWaveShaperNodeRendererFactory = (createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeWaveShaperNodes = new WeakMap();\n        const createWaveShaperNode = async (proxy, nativeOfflineAudioContext, trace) => {\n            let nativeWaveShaperNode = getNativeAudioNode(proxy);\n            // If the initially used nativeWaveShaperNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeWaveShaperNodeIsOwnedByContext = isOwnedByContext(nativeWaveShaperNode, nativeOfflineAudioContext);\n            if (!nativeWaveShaperNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeWaveShaperNode.channelCount,\n                    channelCountMode: nativeWaveShaperNode.channelCountMode,\n                    channelInterpretation: nativeWaveShaperNode.channelInterpretation,\n                    curve: nativeWaveShaperNode.curve,\n                    oversample: nativeWaveShaperNode.oversample\n                };\n                nativeWaveShaperNode = createNativeWaveShaperNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeWaveShaperNodes.set(nativeOfflineAudioContext, nativeWaveShaperNode);\n            if (isNativeAudioNodeFaker(nativeWaveShaperNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode.inputs[0], trace);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode, trace);\n            }\n            return nativeWaveShaperNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext, trace) {\n                const renderedNativeWaveShaperNode = renderedNativeWaveShaperNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeWaveShaperNode !== undefined) {\n                    return Promise.resolve(renderedNativeWaveShaperNode);\n                }\n                return createWaveShaperNode(proxy, nativeOfflineAudioContext, trace);\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/wave-shaper-node-renderer-factory.js.map","export const createWindow = () => (typeof window === 'undefined') ? null : window;\n//# sourceMappingURL=/build/es2019/factories/window.js.map","export const createWrapAudioBufferCopyChannelMethodsOutOfBounds = (convertNumberToUnsignedLong) => {\n    return (audioBuffer) => {\n        audioBuffer.copyFromChannel = ((copyFromChannel) => {\n            return (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n                if (bufferOffset < audioBuffer.length) {\n                    return copyFromChannel.call(audioBuffer, destination, channelNumber, bufferOffset);\n                }\n            };\n        })(audioBuffer.copyFromChannel);\n        audioBuffer.copyToChannel = ((copyToChannel) => {\n            return (source, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n                if (bufferOffset < audioBuffer.length) {\n                    return copyToChannel.call(audioBuffer, source, channelNumber, bufferOffset);\n                }\n            };\n        })(audioBuffer.copyToChannel);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js.map","export const createWrapAudioBufferCopyChannelMethods = (convertNumberToUnsignedLong, createIndexSizeError) => {\n    return (audioBuffer) => {\n        audioBuffer.copyFromChannel = (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n            if (channelNumber >= audioBuffer.numberOfChannels) {\n                throw createIndexSizeError();\n            }\n            const audioBufferLength = audioBuffer.length;\n            const channelData = audioBuffer.getChannelData(channelNumber);\n            const destinationLength = destination.length;\n            for (let i = (bufferOffset < 0) ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < destinationLength; i += 1) {\n                destination[i] = channelData[i + bufferOffset];\n            }\n        };\n        audioBuffer.copyToChannel = (source, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n            if (channelNumber >= audioBuffer.numberOfChannels) {\n                throw createIndexSizeError();\n            }\n            const audioBufferLength = audioBuffer.length;\n            const channelData = audioBuffer.getChannelData(channelNumber);\n            const sourceLength = source.length;\n            for (let i = (bufferOffset < 0) ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < sourceLength; i += 1) {\n                channelData[i + bufferOffset] = source[i];\n            }\n        };\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js.map","export const createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer = (overwriteAccessors) => {\n    return (nativeAudioBufferSourceNode, nativeContext) => {\n        const nullifiedBuffer = nativeContext.createBuffer(1, 1, nativeContext.sampleRate);\n        if (nativeAudioBufferSourceNode.buffer === null) {\n            nativeAudioBufferSourceNode.buffer = nullifiedBuffer;\n        }\n        overwriteAccessors(nativeAudioBufferSourceNode, 'buffer', (get) => () => {\n            const value = get.call(nativeAudioBufferSourceNode);\n            return (value === nullifiedBuffer) ? null : value;\n        }, (set) => (value) => {\n            return set.call(nativeAudioBufferSourceNode, (value === null) ? nullifiedBuffer : value);\n        });\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js.map","import { interceptConnections } from '../helpers/intercept-connections';\nexport const createWrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = (createNativeAudioNode) => {\n    return (nativeAudioScheduledSourceNode, nativeContext) => {\n        const nativeGainNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createGain());\n        nativeAudioScheduledSourceNode.connect(nativeGainNode);\n        const disconnectGainNode = ((disconnect) => {\n            return () => {\n                // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.\n                disconnect.call(nativeAudioScheduledSourceNode, nativeGainNode);\n                nativeAudioScheduledSourceNode.removeEventListener('ended', disconnectGainNode);\n            };\n        })(nativeAudioScheduledSourceNode.disconnect);\n        nativeAudioScheduledSourceNode.addEventListener('ended', disconnectGainNode);\n        interceptConnections(nativeAudioScheduledSourceNode, nativeGainNode);\n        nativeAudioScheduledSourceNode.stop = ((stop) => {\n            let isStopped = false;\n            return (when = 0) => {\n                if (isStopped) {\n                    try {\n                        stop.call(nativeAudioScheduledSourceNode, when);\n                    }\n                    catch {\n                        nativeGainNode.gain.setValueAtTime(0, when);\n                    }\n                }\n                else {\n                    stop.call(nativeAudioScheduledSourceNode, when);\n                    isStopped = true;\n                }\n            };\n        })(nativeAudioScheduledSourceNode.stop);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js.map","export const createWrapChannelMergerNode = (createInvalidStateError, createNativeAudioNode, monitorConnectionsFunction) => {\n    return (nativeContext, channelMergerNode) => {\n        channelMergerNode.channelCount = 1;\n        channelMergerNode.channelCountMode = 'explicit';\n        Object.defineProperty(channelMergerNode, 'channelCount', {\n            get: () => 1,\n            set: () => {\n                throw createInvalidStateError();\n            }\n        });\n        Object.defineProperty(channelMergerNode, 'channelCountMode', {\n            get: () => 'explicit',\n            set: () => {\n                throw createInvalidStateError();\n            }\n        });\n        // Bug #20: Safari requires a connection of any kind to treat the input signal correctly.\n        const audioBufferSourceNode = createNativeAudioNode(nativeContext, (ntvCntxt) => ntvCntxt.createBufferSource());\n        const whenConnected = () => {\n            const length = channelMergerNode.numberOfInputs;\n            for (let i = 0; i < length; i += 1) {\n                audioBufferSourceNode.connect(channelMergerNode, 0, i);\n            }\n        };\n        const whenDisconnected = () => audioBufferSourceNode.disconnect(channelMergerNode);\n        monitorConnectionsFunction(channelMergerNode, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=/build/es2019/factories/wrap-channel-merger-node.js.map","export const ACTIVE_AUDIO_NODE_STORE = new WeakSet();\nexport const AUDIO_NODE_CONNECTIONS_STORE = new WeakMap();\nexport const AUDIO_NODE_STORE = new WeakMap();\nexport const AUDIO_PARAM_CONNECTIONS_STORE = new WeakMap();\nexport const AUDIO_PARAM_STORE = new WeakMap();\nexport const BACKUP_NATIVE_CONTEXT_STORE = new WeakMap();\nexport const CONTEXT_STORE = new WeakMap();\nexport const EVENT_LISTENERS = new WeakMap();\nexport const CYCLE_COUNTERS = new WeakMap();\n// This clunky name is borrowed from the spec. :-)\nexport const NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS = new WeakMap();\nexport const NODE_TO_PROCESSOR_MAPS = new WeakMap();\n//# sourceMappingURL=/build/es2019/globals.js.map","import { isAudioNode } from './audio-node';\nexport const isAudioNodeOutputConnection = (outputConnection) => {\n    return isAudioNode(outputConnection[0]);\n};\n//# sourceMappingURL=/build/es2019/guards/audio-node-output-connection.js.map","export const isAudioNode = (audioNodeOrAudioParam) => {\n    return 'context' in audioNodeOrAudioParam;\n};\n//# sourceMappingURL=/build/es2019/guards/audio-node.js.map","export const isAudioWorkletNode = (audioNode) => {\n    return 'port' in audioNode;\n};\n//# sourceMappingURL=/build/es2019/guards/audio-worklet-node.js.map","export const isDelayNode = (audioNode) => {\n    return 'delayTime' in audioNode;\n};\n//# sourceMappingURL=/build/es2019/guards/delay-node.js.map","export const isNativeAudioNodeFaker = (nativeAudioNodeOrNativeAudioNodeFaker) => {\n    return 'inputs' in nativeAudioNodeOrNativeAudioNodeFaker;\n};\n//# sourceMappingURL=/build/es2019/guards/native-audio-node-faker.js.map","export const isNativeAudioNode = (nativeAudioNodeOrAudioParam) => {\n    return 'context' in nativeAudioNodeOrAudioParam;\n};\n//# sourceMappingURL=/build/es2019/guards/native-audio-node.js.map","export const assignNativeAudioNodeAudioParamValue = (nativeAudioNode, options, audioParam) => {\n    const value = options[audioParam];\n    if (value !== undefined && value !== nativeAudioNode[audioParam].value) {\n        nativeAudioNode[audioParam].value = value;\n    }\n};\n//# sourceMappingURL=/build/es2019/helpers/assign-native-audio-node-audio-param-value.js.map","export const assignNativeAudioNodeOption = (nativeAudioNode, options, option) => {\n    const value = options[option];\n    if (value !== undefined && value !== nativeAudioNode[option]) {\n        nativeAudioNode[option] = value;\n    }\n};\n//# sourceMappingURL=/build/es2019/helpers/assign-native-audio-node-option.js.map","import { assignNativeAudioNodeOption } from './assign-native-audio-node-option';\nexport const assignNativeAudioNodeOptions = (nativeAudioNode, options) => {\n    assignNativeAudioNodeOption(nativeAudioNode, options, 'channelCount');\n    assignNativeAudioNodeOption(nativeAudioNode, options, 'channelCountMode');\n    assignNativeAudioNodeOption(nativeAudioNode, options, 'channelInterpretation');\n};\n//# sourceMappingURL=/build/es2019/helpers/assign-native-audio-node-options.js.map","export const cloneAudioWorkletNodeOptions = (audioWorkletNodeOptions) => {\n    return new Promise((resolve, reject) => {\n        const { port1, port2 } = new MessageChannel();\n        port1.onmessage = ({ data }) => {\n            port1.close();\n            port2.close();\n            resolve(data);\n        };\n        port1.onmessageerror = ({ data }) => {\n            port1.close();\n            port2.close();\n            reject(data);\n        };\n        // This will throw an error if the audioWorkletNodeOptions are not clonable.\n        port2.postMessage(audioWorkletNodeOptions);\n    });\n};\n//# sourceMappingURL=/build/es2019/helpers/clone-audio-worklet-node-options.js.map","export const computeBufferSize = (baseLatency, sampleRate) => {\n    if (baseLatency === null) {\n        return 512;\n    }\n    return Math.max(512, Math.min(16384, Math.pow(2, Math.round(Math.log2(baseLatency * sampleRate)))));\n};\n//# sourceMappingURL=/build/es2019/helpers/compute-buffer-size.js.map","import { isNativeAudioNodeFaker } from '../guards/native-audio-node-faker';\nexport const connectNativeAudioNodeToNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input) => {\n    if (isNativeAudioNodeFaker(nativeDestinationAudioNode)) {\n        const fakeNativeDestinationAudioNode = nativeDestinationAudioNode.inputs[input];\n        nativeSourceAudioNode.connect(fakeNativeDestinationAudioNode, output, 0);\n        return [fakeNativeDestinationAudioNode, output, 0];\n    }\n    nativeSourceAudioNode.connect(nativeDestinationAudioNode, output, input);\n    return [nativeDestinationAudioNode, output, input];\n};\n//# sourceMappingURL=/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js.map","export function copyFromChannel(audioBuffer, \n// @todo There is currently no way to define something like { [ key: number | string ]: Float32Array }\nparent, key, channelNumber, bufferOffset) {\n    if (typeof audioBuffer.copyFromChannel === 'function') {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength === 0) {\n            parent[key] = new Float32Array(128);\n        }\n        audioBuffer.copyFromChannel(parent[key], channelNumber, bufferOffset);\n        // Bug #5: Safari does not support copyFromChannel().\n    }\n    else {\n        const channelData = audioBuffer.getChannelData(channelNumber);\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength === 0) {\n            parent[key] = channelData.slice(bufferOffset, bufferOffset + 128);\n        }\n        else {\n            const slicedInput = new Float32Array(channelData.buffer, bufferOffset * Float32Array.BYTES_PER_ELEMENT, 128);\n            parent[key].set(slicedInput);\n        }\n    }\n}\n//# sourceMappingURL=/build/es2019/helpers/copy-from-channel.js.map","export const copyToChannel = (audioBuffer, parent, key, channelNumber, bufferOffset) => {\n    if (typeof audioBuffer.copyToChannel === 'function') {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength !== 0) {\n            audioBuffer.copyToChannel(parent[key], channelNumber, bufferOffset);\n        }\n        // Bug #5: Safari does not support copyToChannel().\n    }\n    else {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength !== 0) {\n            audioBuffer\n                .getChannelData(channelNumber)\n                .set(parent[key], bufferOffset);\n        }\n    }\n};\n//# sourceMappingURL=/build/es2019/helpers/copy-to-channel.js.map","import { cloneAudioWorkletNodeOptions } from './clone-audio-worklet-node-options';\nexport const createAudioWorkletProcessorPromise = async (processorConstructor, audioWorkletNodeOptions) => {\n    const clonedAudioWorkletNodeOptions = await cloneAudioWorkletNodeOptions(audioWorkletNodeOptions);\n    return new processorConstructor(clonedAudioWorkletNodeOptions);\n};\n//# sourceMappingURL=/build/es2019/helpers/create-audio-worklet-processor-promise.js.map","import { NODE_TO_PROCESSOR_MAPS } from '../globals';\nimport { createAudioWorkletProcessorPromise } from './create-audio-worklet-processor-promise';\nexport const createAudioWorkletProcessor = (nativeContext, nativeAudioWorkletNode, processorConstructor, audioWorkletNodeOptions) => {\n    let nodeToProcessorMap = NODE_TO_PROCESSOR_MAPS.get(nativeContext);\n    if (nodeToProcessorMap === undefined) {\n        nodeToProcessorMap = new WeakMap();\n        NODE_TO_PROCESSOR_MAPS.set(nativeContext, nodeToProcessorMap);\n    }\n    const audioWorkletProcessorPromise = createAudioWorkletProcessorPromise(processorConstructor, audioWorkletNodeOptions);\n    nodeToProcessorMap.set(nativeAudioWorkletNode, audioWorkletProcessorPromise);\n    return audioWorkletProcessorPromise;\n};\n//# sourceMappingURL=/build/es2019/helpers/create-audio-worklet-processor.js.map","export const createNestedArrays = (x, y) => {\n    const arrays = [];\n    for (let i = 0; i < x; i += 1) {\n        const array = [];\n        const length = (typeof y === 'number') ? y : y[i];\n        for (let j = 0; j < length; j += 1) {\n            array.push(new Float32Array(128));\n        }\n        arrays.push(array);\n    }\n    return arrays;\n};\n//# sourceMappingURL=/build/es2019/helpers/create-nested-arrays.js.map","import { getEventListenersOfAudioNode } from './get-event-listeners-of-audio-node';\nexport const deleteEventListenerOfAudioNode = (audioNode, eventListener) => {\n    const eventListeners = getEventListenersOfAudioNode(audioNode);\n    if (!eventListeners.delete(eventListener)) {\n        throw new Error('Missing the expected event listener.');\n    }\n};\n//# sourceMappingURL=/build/es2019/helpers/delete-event-listeners-of-audio-node.js.map","export const detachArrayBuffer = (arrayBuffer) => {\n    const { port1 } = new MessageChannel();\n    port1.postMessage(arrayBuffer, [arrayBuffer]);\n};\n//# sourceMappingURL=/build/es2019/helpers/detach-array-buffer.js.map","import { isNativeAudioNodeFaker } from '../guards/native-audio-node-faker';\nexport const disconnectNativeAudioNodeFromNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input) => {\n    if (isNativeAudioNodeFaker(nativeDestinationAudioNode)) {\n        nativeSourceAudioNode.disconnect(nativeDestinationAudioNode.inputs[input], output, 0);\n    }\n    else {\n        nativeSourceAudioNode.disconnect(nativeDestinationAudioNode, output, input);\n    }\n};\n//# sourceMappingURL=/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js.map","// This implementation as shamelessly inspired by source code of\n// tslint:disable-next-line:max-line-length\n// {@link https://chromium.googlesource.com/chromium/src.git/+/master/third_party/WebKit/Source/platform/audio/IIRFilter.cpp|Chromium's IIRFilter}.\nexport const filterBuffer = (feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, bufferIndex, bufferLength, input, output) => {\n    const inputLength = input.length;\n    let i = bufferIndex;\n    for (let j = 0; j < inputLength; j += 1) {\n        let y = feedforward[0] * input[j];\n        for (let k = 1; k < minLength; k += 1) {\n            const x = (i - k) & (bufferLength - 1); // tslint:disable-line:no-bitwise\n            y += feedforward[k] * xBuffer[x];\n            y -= feedback[k] * yBuffer[x];\n        }\n        for (let k = minLength; k < feedforwardLength; k += 1) {\n            y += feedforward[k] * xBuffer[(i - k) & (bufferLength - 1)]; // tslint:disable-line:no-bitwise\n        }\n        for (let k = minLength; k < feedbackLength; k += 1) {\n            y -= feedback[k] * yBuffer[(i - k) & (bufferLength - 1)]; // tslint:disable-line:no-bitwise\n        }\n        xBuffer[i] = input[j];\n        yBuffer[i] = y;\n        i = (i + 1) & (bufferLength - 1); // tslint:disable-line:no-bitwise\n        output[j] = y;\n    }\n    return i;\n};\n//# sourceMappingURL=/build/es2019/helpers/filter-buffer.js.map","import { AUDIO_NODE_CONNECTIONS_STORE } from '../globals';\nimport { getValueForKey } from './get-value-for-key';\nexport const getAudioNodeConnections = (audioNode) => {\n    return getValueForKey(AUDIO_NODE_CONNECTIONS_STORE, audioNode);\n};\n//# sourceMappingURL=/build/es2019/helpers/get-audio-node-connections.js.map","import { AUDIO_PARAM_CONNECTIONS_STORE } from '../globals';\nimport { getValueForKey } from './get-value-for-key';\nexport const getAudioParamConnections = (audioParam) => {\n    return getValueForKey(AUDIO_PARAM_CONNECTIONS_STORE, audioParam);\n};\n//# sourceMappingURL=/build/es2019/helpers/get-audio-param-connections.js.map","import { NODE_TO_PROCESSOR_MAPS } from '../globals';\nimport { getNativeAudioNode } from './get-native-audio-node';\nimport { getValueForKey } from './get-value-for-key';\nexport const getAudioWorkletProcessor = (nativeOfflineAudioContext, proxy) => {\n    const nodeToProcessorMap = getValueForKey(NODE_TO_PROCESSOR_MAPS, nativeOfflineAudioContext);\n    const nativeAudioWorkletNode = getNativeAudioNode(proxy);\n    return getValueForKey(nodeToProcessorMap, nativeAudioWorkletNode);\n};\n//# sourceMappingURL=/build/es2019/helpers/get-audio-worklet-processor.js.map","import { EVENT_LISTENERS } from '../globals';\nimport { getValueForKey } from './get-value-for-key';\nexport const getEventListenersOfAudioNode = (audioNode) => {\n    return getValueForKey(EVENT_LISTENERS, audioNode);\n};\n//# sourceMappingURL=/build/es2019/helpers/get-event-listeners-of-audio-node.js.map","import { AUDIO_NODE_STORE } from '../globals';\nimport { getValueForKey } from './get-value-for-key';\nexport const getNativeAudioNode = (audioNode) => {\n    return getValueForKey(AUDIO_NODE_STORE, audioNode);\n};\n//# sourceMappingURL=/build/es2019/helpers/get-native-audio-node.js.map","import { AUDIO_PARAM_STORE } from '../globals';\nimport { getValueForKey } from './get-value-for-key';\nexport const getNativeAudioParam = (audioParam) => {\n    return getValueForKey(AUDIO_PARAM_STORE, audioParam);\n};\n//# sourceMappingURL=/build/es2019/helpers/get-native-audio-param.js.map","export const getValueForKey = (map, key) => {\n    const value = map.get(key);\n    if (value === undefined) {\n        throw new Error('A value with the given key could not be found.');\n    }\n    return value;\n};\n//# sourceMappingURL=/build/es2019/helpers/get-value-for-key.js.map","export const insertElementInSet = (set, element, predicate, ignoreDuplicates) => {\n    for (const lmnt of set) {\n        if (predicate(lmnt)) {\n            if (ignoreDuplicates) {\n                return false;\n            }\n            throw Error('The set contains at least one similar element.');\n        }\n    }\n    set.add(element);\n    return true;\n};\n//# sourceMappingURL=/build/es2019/helpers/insert-element-in-set.js.map","export const interceptConnections = (original, interceptor) => {\n    original.connect = interceptor.connect.bind(interceptor);\n    original.disconnect = interceptor.disconnect.bind(interceptor);\n    return original;\n};\n//# sourceMappingURL=/build/es2019/helpers/intercept-connections.js.map","import { ACTIVE_AUDIO_NODE_STORE } from '../globals';\nexport const isActiveAudioNode = (audioNode) => ACTIVE_AUDIO_NODE_STORE.has(audioNode);\n//# sourceMappingURL=/build/es2019/helpers/is-active-audio-node.js.map","const handler = {\n    construct() {\n        return handler;\n    }\n};\nexport const isConstructible = (constructible) => {\n    try {\n        const proxy = new Proxy(constructible, handler);\n        new proxy(); // tslint:disable-line:no-unused-expression\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=/build/es2019/helpers/is-constructible.js.map","export const isDCCurve = (curve) => {\n    if (curve === null) {\n        return false;\n    }\n    const length = curve.length;\n    if (length % 2 !== 0) {\n        return (curve[Math.floor(length / 2)] !== 0);\n    }\n    return (curve[(length / 2) - 1] + curve[length / 2] !== 0);\n};\n//# sourceMappingURL=/build/es2019/helpers/is-dc-curve.js.map","export const isOwnedByContext = (nativeAudioNode, nativeContext) => {\n    return nativeAudioNode.context === nativeContext;\n};\n//# sourceMappingURL=/build/es2019/helpers/is-owned-by-context.js.map","import { CYCLE_COUNTERS } from '../globals';\nexport const isPartOfACycle = (audioNode) => {\n    return CYCLE_COUNTERS.has(audioNode);\n};\n//# sourceMappingURL=/build/es2019/helpers/is-part-of-a-cycle.js.map","import { ACTIVE_AUDIO_NODE_STORE } from '../globals';\nexport const isPassiveAudioNode = (audioNode) => {\n    return !ACTIVE_AUDIO_NODE_STORE.has(audioNode);\n};\n//# sourceMappingURL=/build/es2019/helpers/is-passive-audio-node.js.map","export const isValidLatencyHint = (latencyHint) => {\n    return latencyHint === undefined ||\n        typeof latencyHint === 'number' ||\n        (typeof latencyHint === 'string' && (latencyHint === 'balanced' || latencyHint === 'interactive' || latencyHint === 'playback'));\n};\n//# sourceMappingURL=/build/es2019/helpers/is-valid-latency-hint.js.map","export const overwriteAccessors = (object, property, createGetter, createSetter) => {\n    let prototype = Object.getPrototypeOf(object);\n    while (!prototype.hasOwnProperty(property)) {\n        prototype = Object.getPrototypeOf(prototype);\n    }\n    const { get, set } = Object.getOwnPropertyDescriptor(prototype, property);\n    Object.defineProperty(object, property, { get: createGetter(get), set: createSetter(set) });\n};\n//# sourceMappingURL=/build/es2019/helpers/overwrite-accessors.js.map","export const pickElementFromSet = (set, predicate) => {\n    const matchingElements = Array\n        .from(set)\n        .filter(predicate);\n    if (matchingElements.length > 1) {\n        throw Error('More than one element was found.');\n    }\n    if (matchingElements.length === 0) {\n        throw Error('No element was found.');\n    }\n    const [matchingElement] = matchingElements;\n    set.delete(matchingElement);\n    return matchingElement;\n};\n//# sourceMappingURL=/build/es2019/helpers/pick-element-from-set.js.map","import { ACTIVE_AUDIO_NODE_STORE } from '../globals';\nimport { getEventListenersOfAudioNode } from './get-event-listeners-of-audio-node';\nexport const setInternalStateToActive = (audioNode) => {\n    if (ACTIVE_AUDIO_NODE_STORE.has(audioNode)) {\n        throw new Error('The AudioNode is already stored.');\n    }\n    ACTIVE_AUDIO_NODE_STORE.add(audioNode);\n    getEventListenersOfAudioNode(audioNode)\n        .forEach((eventListener) => eventListener(true));\n};\n//# sourceMappingURL=/build/es2019/helpers/set-internal-state-to-active.js.map","import { isAudioWorkletNode } from '../guards/audio-worklet-node';\nimport { setInternalStateToPassive } from './set-internal-state-to-passive';\n// Set the internalState of the audioNode to 'passive' if it is not an AudioWorkletNode and if it has no 'active' input connections.\nexport const setInternalStateToPassiveWhenNecessary = (audioNode, activeInputs) => {\n    if (!isAudioWorkletNode(audioNode) && activeInputs.every((connections) => (connections.size === 0))) {\n        setInternalStateToPassive(audioNode);\n    }\n};\n//# sourceMappingURL=/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js.map","import { ACTIVE_AUDIO_NODE_STORE } from '../globals';\nimport { getEventListenersOfAudioNode } from './get-event-listeners-of-audio-node';\nexport const setInternalStateToPassive = (audioNode) => {\n    if (!ACTIVE_AUDIO_NODE_STORE.has(audioNode)) {\n        throw new Error('The AudioNode is not stored.');\n    }\n    ACTIVE_AUDIO_NODE_STORE.delete(audioNode);\n    getEventListenersOfAudioNode(audioNode)\n        .forEach((eventListener) => eventListener(false));\n};\n//# sourceMappingURL=/build/es2019/helpers/set-internal-state-to-passive.js.map","/*\n * This massive regex tries to cover all the following cases.\n *\n * import './path';\n * import defaultImport from './path';\n * import { namedImport } from './path';\n * import { namedImport as renamendImport } from './path';\n * import * as namespaceImport from './path';\n * import defaultImport, { namedImport } from './path';\n * import defaultImport, { namedImport as renamendImport } from './path';\n * import defaultImport, * as namespaceImport from './path';\n */\nconst IMPORT_STATEMENT_REGEX = /^import(?:(?:[\\s]+[\\w]+|(?:[\\s]+[\\w]+[\\s]*,)?[\\s]*\\{[\\s]*[\\w]+(?:[\\s]+as[\\s]+[\\w]+)?(?:[\\s]*,[\\s]*[\\w]+(?:[\\s]+as[\\s]+[\\w]+)?)*[\\s]*}|(?:[\\s]+[\\w]+[\\s]*,)?[\\s]*\\*[\\s]+as[\\s]+[\\w]+)[\\s]+from)?(?:[\\s]*)(\"([^\"\\\\]|\\\\.)+\"|'([^'\\\\]|\\\\.)+')(?:[\\s]*);?/; // tslint:disable-line:max-line-length\nexport const splitImportStatements = (source, url) => {\n    const importStatements = [];\n    let sourceWithoutImportStatements = source.replace(/^[\\s]+/, '');\n    let result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);\n    while (result !== null) {\n        const unresolvedUrl = result[1].slice(1, -1);\n        const importStatementWithResolvedUrl = result[0]\n            .replace(/([\\s]+)?;?$/, '')\n            .replace(unresolvedUrl, (new URL(unresolvedUrl, url)).toString());\n        importStatements.push(importStatementWithResolvedUrl);\n        sourceWithoutImportStatements = sourceWithoutImportStatements\n            .slice(result[0].length)\n            .replace(/^[\\s]+/, '');\n        result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);\n    }\n    return [importStatements.join(';'), sourceWithoutImportStatements];\n};\n//# sourceMappingURL=/build/es2019/helpers/split-import-statements.js.map","export const testAnalyserNodeGetFloatTimeDomainDataMethodSupport = (nativeAnalyserNode) => {\n    return typeof nativeAnalyserNode.getFloatTimeDomainData === 'function';\n};\n//# sourceMappingURL=/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js.map","export const testAudioBufferCopyChannelMethodsOutOfBoundsSupport = (nativeAudioBuffer) => {\n    try {\n        nativeAudioBuffer.copyToChannel(new Float32Array(1), 0, -1);\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js.map","export const testAudioNodeDisconnectMethodSupport = (nativeAudioContext) => {\n    return new Promise((resolve) => {\n        const analyzer = nativeAudioContext.createScriptProcessor(256, 1, 1);\n        const dummy = nativeAudioContext.createGain();\n        // Bug #95: Safari does not play one sample buffers.\n        const ones = nativeAudioContext.createBuffer(1, 2, 44100);\n        const channelData = ones.getChannelData(0);\n        channelData[0] = 1;\n        channelData[1] = 1;\n        const source = nativeAudioContext.createBufferSource();\n        source.buffer = ones;\n        source.loop = true;\n        source\n            .connect(analyzer)\n            .connect(nativeAudioContext.destination);\n        source.connect(dummy);\n        source.disconnect(dummy);\n        analyzer.onaudioprocess = (event) => {\n            const chnnlDt = event.inputBuffer.getChannelData(0);\n            if (Array.prototype.some.call(chnnlDt, (sample) => sample === 1)) {\n                resolve(true);\n            }\n            else {\n                resolve(false);\n            }\n            source.stop();\n            analyzer.onaudioprocess = null; // tslint:disable-line:deprecation\n            source.disconnect(analyzer);\n            analyzer.disconnect(nativeAudioContext.destination);\n        };\n        source.start();\n    });\n};\n//# sourceMappingURL=/build/es2019/helpers/test-audio-node-disconnect-method-support.js.map","export const testClonabilityOfAudioWorkletNodeOptions = (audioWorkletNodeOptions) => {\n    const { port1 } = new MessageChannel();\n    try {\n        // This will throw an error if the audioWorkletNodeOptions are not clonable.\n        port1.postMessage(audioWorkletNodeOptions);\n    }\n    finally {\n        port1.close();\n    }\n};\n//# sourceMappingURL=/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js.map","export const testPromiseSupport = (nativeContext) => {\n    // This 12 numbers represent the 48 bytes of an empty WAVE file with a single sample.\n    const uint32Array = new Uint32Array([\n        1179011410,\n        40,\n        1163280727,\n        544501094,\n        16,\n        131073,\n        44100,\n        176400,\n        1048580,\n        1635017060,\n        4,\n        0\n    ]);\n    try {\n        // Bug #1: Safari requires a successCallback.\n        const promise = nativeContext.decodeAudioData(uint32Array.buffer, () => {\n            // Ignore the success callback.\n        });\n        if (promise === undefined) {\n            return false;\n        }\n        promise.catch(() => {\n            // Ignore rejected errors.\n        });\n        return true;\n    }\n    catch {\n        // Ignore errors.\n    }\n    return false;\n};\n//# sourceMappingURL=/build/es2019/helpers/test-promise-support.js.map","// Safari at version 11 did not support transferables.\nexport const testTransferablesSupport = () => new Promise((resolve) => {\n    const arrayBuffer = new ArrayBuffer(0);\n    const { port1, port2 } = new MessageChannel();\n    port1.onmessage = ({ data }) => resolve(data !== null);\n    port2.postMessage(arrayBuffer, [arrayBuffer]);\n});\n//# sourceMappingURL=/build/es2019/helpers/test-transferables-support.js.map","export const visitEachAudioNodeOnce = (cycles, visitor) => {\n    const counts = new Map();\n    for (const cycle of cycles) {\n        for (const audioNode of cycle) {\n            const count = counts.get(audioNode);\n            counts.set(audioNode, (count === undefined) ? 1 : count + 1);\n        }\n    }\n    counts.forEach((count, audioNode) => visitor(audioNode, count));\n};\n//# sourceMappingURL=/build/es2019/helpers/visit-each-audio-node-once.js.map","export const wrapAnalyserNodeGetFloatTimeDomainDataMethod = (nativeAnalyserNode) => {\n    nativeAnalyserNode.getFloatTimeDomainData = (array) => {\n        const byteTimeDomainData = new Uint8Array(array.length);\n        nativeAnalyserNode.getByteTimeDomainData(byteTimeDomainData);\n        const length = Math.max(byteTimeDomainData.length, nativeAnalyserNode.fftSize);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = (byteTimeDomainData[i] - 128) * 0.0078125;\n        }\n        return array;\n    };\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js.map","import { createIndexSizeError } from '../factories/index-size-error';\nexport const wrapAudioBufferGetChannelDataMethod = (audioBuffer) => {\n    audioBuffer.getChannelData = ((getChannelData) => {\n        return (channel) => {\n            try {\n                return getChannelData.call(audioBuffer, channel);\n            }\n            catch (err) {\n                if (err.code === 12) {\n                    throw createIndexSizeError();\n                }\n                throw err;\n            }\n        };\n    })(audioBuffer.getChannelData);\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js.map","import { createInvalidStateError } from '../factories/invalid-state-error';\nexport const wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = (nativeAudioBufferSourceNode) => {\n    nativeAudioBufferSourceNode.start = ((start) => {\n        let isScheduled = false;\n        return (when = 0, offset = 0, duration) => {\n            if (isScheduled) {\n                throw createInvalidStateError();\n            }\n            start.call(nativeAudioBufferSourceNode, when, offset, duration);\n            isScheduled = true;\n        };\n    })(nativeAudioBufferSourceNode.start);\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js.map","export const wrapAudioBufferSourceNodeStartMethodDurationParameter = (nativeAudioScheduledSourceNode, nativeContext) => {\n    let endTime = Number.POSITIVE_INFINITY;\n    let stopTime = Number.POSITIVE_INFINITY;\n    nativeAudioScheduledSourceNode.start = ((start, stop) => {\n        return (when = 0, offset = 0, duration = Number.POSITIVE_INFINITY) => {\n            start.call(nativeAudioScheduledSourceNode, when, offset);\n            if (duration >= 0 && duration < Number.POSITIVE_INFINITY) {\n                const actualStartTime = Math.max(when, nativeContext.currentTime);\n                // @todo The playbackRate could of course also have been automated and is not always fixed.\n                const durationInBufferTime = (duration / nativeAudioScheduledSourceNode.playbackRate.value);\n                endTime = actualStartTime + durationInBufferTime;\n                stop.call(nativeAudioScheduledSourceNode, Math.min(endTime, stopTime));\n            }\n        };\n    })(nativeAudioScheduledSourceNode.start, nativeAudioScheduledSourceNode.stop);\n    nativeAudioScheduledSourceNode.stop = ((stop) => {\n        return (when = 0) => {\n            stopTime = Math.max(when, nativeContext.currentTime);\n            stop.call(nativeAudioScheduledSourceNode, Math.min(endTime, stopTime));\n        };\n    })(nativeAudioScheduledSourceNode.stop);\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-duration-parameter.js.map","export const wrapAudioBufferSourceNodeStartMethodOffsetClamping = (nativeAudioBufferSourceNode) => {\n    nativeAudioBufferSourceNode.start = ((start) => {\n        return (when = 0, offset = 0, duration) => {\n            const buffer = nativeAudioBufferSourceNode.buffer;\n            // Bug #154: Safari does not clamp the offset if it is equal to or greater than the duration of the buffer.\n            const clampedOffset = (buffer === null) ? offset : Math.min(buffer.duration, offset);\n            // Bug #155: Safari does not handle the offset correctly if it would cause the buffer to be not be played at all.\n            if (buffer !== null && clampedOffset > buffer.duration - (0.5 / nativeAudioBufferSourceNode.context.sampleRate)) {\n                start.call(nativeAudioBufferSourceNode, when, 0, 0);\n            }\n            else {\n                start.call(nativeAudioBufferSourceNode, when, clampedOffset, duration);\n            }\n        };\n    })(nativeAudioBufferSourceNode.start);\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js.map","import { isNativeAudioNode } from '../guards/native-audio-node';\nexport const wrapAudioNodeDisconnectMethod = (nativeAudioNode) => {\n    const connections = new Map();\n    nativeAudioNode.connect = ((connect) => {\n        return (destination, output = 0, input = 0) => {\n            const returnValue = (isNativeAudioNode(destination))\n                ? connect(destination, output, input)\n                : connect(destination, output);\n            // Save the new connection only if the calls to connect above didn't throw an error.\n            const connectionsToDestination = connections.get(destination);\n            if (connectionsToDestination === undefined) {\n                connections.set(destination, [{ input, output }]);\n            }\n            else {\n                if (connectionsToDestination.every((connection) => (connection.input !== input || connection.output !== output))) {\n                    connectionsToDestination.push({ input, output });\n                }\n            }\n            return returnValue;\n        };\n    })(nativeAudioNode.connect.bind(nativeAudioNode));\n    nativeAudioNode.disconnect = ((disconnect) => {\n        return (destinationOrOutput, output, input) => {\n            disconnect.apply(nativeAudioNode);\n            if (destinationOrOutput === undefined) {\n                connections.clear();\n            }\n            else if (typeof destinationOrOutput === 'number') {\n                for (const [destination, connectionsToDestination] of connections) {\n                    const filteredConnections = connectionsToDestination\n                        .filter((connection) => (connection.output !== destinationOrOutput));\n                    if (filteredConnections.length === 0) {\n                        connections.delete(destination);\n                    }\n                    else {\n                        connections.set(destination, filteredConnections);\n                    }\n                }\n            }\n            else if (connections.has(destinationOrOutput)) {\n                if (output === undefined) {\n                    connections.delete(destinationOrOutput);\n                }\n                else {\n                    const connectionsToDestination = connections.get(destinationOrOutput);\n                    if (connectionsToDestination !== undefined) {\n                        const filteredConnections = connectionsToDestination\n                            .filter((connection) => (connection.output !== output && (connection.input !== input || input === undefined)));\n                        if (filteredConnections.length === 0) {\n                            connections.delete(destinationOrOutput);\n                        }\n                        else {\n                            connections.set(destinationOrOutput, filteredConnections);\n                        }\n                    }\n                }\n            }\n            for (const [destination, connectionsToDestination] of connections) {\n                connectionsToDestination\n                    .forEach((connection) => {\n                    if (isNativeAudioNode(destination)) {\n                        nativeAudioNode.connect(destination, connection.output, connection.input);\n                    }\n                    else {\n                        nativeAudioNode.connect(destination, connection.output);\n                    }\n                });\n            }\n        };\n    })(nativeAudioNode.disconnect);\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-audio-node-disconnect-method.js.map","export const wrapAudioScheduledSourceNodeStartMethodNegativeParameters = (nativeAudioScheduledSourceNode) => {\n    nativeAudioScheduledSourceNode.start = ((start) => {\n        return (when = 0, offset = 0, duration) => {\n            if ((typeof duration === 'number' && duration < 0) || offset < 0 || when < 0) {\n                throw new RangeError(\"The parameters can't be negative.\");\n            }\n            // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n            start.call(nativeAudioScheduledSourceNode, when, offset, duration);\n        };\n    })(nativeAudioScheduledSourceNode.start);\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js.map","export const wrapAudioScheduledSourceNodeStopMethodNegativeParameters = (nativeAudioScheduledSourceNode) => {\n    nativeAudioScheduledSourceNode.stop = ((stop) => {\n        return (when = 0) => {\n            if (when < 0) {\n                throw new RangeError(\"The parameter can't be negative.\");\n            }\n            stop.call(nativeAudioScheduledSourceNode, when);\n        };\n    })(nativeAudioScheduledSourceNode.stop);\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js.map","import { createInvalidStateError } from '../factories/invalid-state-error';\nexport const wrapChannelSplitterNode = (channelSplitterNode) => {\n    const channelCount = channelSplitterNode.numberOfOutputs;\n    // Bug #97: Safari does not throw an error when attempting to change the channelCount to something other than its initial value.\n    Object.defineProperty(channelSplitterNode, 'channelCount', {\n        get: () => channelCount,\n        set: (value) => {\n            if (value !== channelCount) {\n                throw createInvalidStateError();\n            }\n        }\n    });\n    /*\n     * Bug #30: Only Chrome, Firefox & Opera throw an error when attempting to change the channelCountMode to something other than\n     * explicit.\n     */\n    Object.defineProperty(channelSplitterNode, 'channelCountMode', {\n        get: () => 'explicit',\n        set: (value) => {\n            if (value !== 'explicit') {\n                throw createInvalidStateError();\n            }\n        }\n    });\n    /*\n     * Bug #32: Only Chrome, Firefox & Opera throws an error when attempting to change the channelInterpretation to something other than\n     * discrete.\n     */\n    Object.defineProperty(channelSplitterNode, 'channelInterpretation', {\n        get: () => 'discrete',\n        set: (value) => {\n            if (value !== 'discrete') {\n                throw createInvalidStateError();\n            }\n        }\n    });\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-channel-splitter-node.js.map","export const wrapEventListener = (target, eventListener) => {\n    return (event) => {\n        const descriptor = { value: target };\n        Object.defineProperties(event, {\n            currentTarget: descriptor,\n            target: descriptor\n        });\n        if (typeof eventListener === 'function') {\n            return eventListener.call(target, event);\n        }\n        return eventListener.handleEvent.call(target, event);\n    };\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-event-listener.js.map","import { createInvalidAccessError } from '../factories/invalid-access-error';\nexport const wrapIIRFilterNodeGetFrequencyResponseMethod = (nativeIIRFilterNode) => {\n    nativeIIRFilterNode.getFrequencyResponse = ((getFrequencyResponse) => {\n        return (frequencyHz, magResponse, phaseResponse) => {\n            if ((frequencyHz.length !== magResponse.length) || (magResponse.length !== phaseResponse.length)) {\n                throw createInvalidAccessError();\n            }\n            return getFrequencyResponse.call(nativeIIRFilterNode, frequencyHz, magResponse, phaseResponse);\n        };\n    })(nativeIIRFilterNode.getFrequencyResponse);\n};\n//# sourceMappingURL=/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js.map","//# sourceMappingURL=/build/es2019/interfaces/analyser-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/analyser-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-buffer-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-buffer-source-node-renderer.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-buffer-source-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-buffer-source-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-buffer.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-context-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-context.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-destination-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-listener.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-node-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-node-renderer.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-param-descriptor.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-param-renderer.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-param.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-scheduled-source-node-event-map.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-scheduled-source-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-worklet-node-event-map.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-worklet-node-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-worklet-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-worklet-processor-constructor.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-worklet-processor.js.map","//# sourceMappingURL=/build/es2019/interfaces/audio-worklet.js.map","//# sourceMappingURL=/build/es2019/interfaces/automation.js.map","//# sourceMappingURL=/build/es2019/interfaces/base-audio-context.js.map","//# sourceMappingURL=/build/es2019/interfaces/biquad-filter-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/biquad-filter-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/channel-merger-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/channel-splitter-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/common-audio-context.js.map","//# sourceMappingURL=/build/es2019/interfaces/common-offline-audio-context.js.map","//# sourceMappingURL=/build/es2019/interfaces/constant-source-node-renderer.js.map","//# sourceMappingURL=/build/es2019/interfaces/constant-source-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/constant-source-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/convolver-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/convolver-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/delay-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/delay-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/dynamics-compressor-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/dynamics-compressor-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/gain-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/gain-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/iir-filter-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/iir-filter-options.js.map","export * from './analyser-node';\nexport * from './analyser-options';\nexport * from './audio-buffer';\nexport * from './audio-buffer-options';\nexport * from './audio-buffer-source-node';\nexport * from './audio-buffer-source-node-renderer';\nexport * from './audio-buffer-source-options';\nexport * from './audio-context';\nexport * from './audio-context-options';\nexport * from './audio-destination-node';\nexport * from './audio-listener';\nexport * from './audio-node';\nexport * from './audio-node-options';\nexport * from './audio-node-renderer';\nexport * from './audio-param';\nexport * from './audio-param-descriptor';\nexport * from './audio-param-renderer';\nexport * from './audio-scheduled-source-node';\nexport * from './audio-scheduled-source-node-event-map';\nexport * from './audio-worklet';\nexport * from './audio-worklet-node';\nexport * from './audio-worklet-node-event-map';\nexport * from './audio-worklet-node-options';\nexport * from './audio-worklet-processor';\nexport * from './audio-worklet-processor-constructor';\nexport * from './automation';\nexport * from './base-audio-context';\nexport * from './biquad-filter-node';\nexport * from './biquad-filter-options';\nexport * from './channel-merger-options';\nexport * from './channel-splitter-options';\nexport * from './common-audio-context';\nexport * from './common-offline-audio-context';\nexport * from './constant-source-node';\nexport * from './constant-source-node-renderer';\nexport * from './constant-source-options';\nexport * from './convolver-node';\nexport * from './convolver-options';\nexport * from './delay-node';\nexport * from './delay-options';\nexport * from './dynamics-compressor-node';\nexport * from './dynamics-compressor-options';\nexport * from './gain-node';\nexport * from './gain-options';\nexport * from './iir-filter-node';\nexport * from './iir-filter-options';\nexport * from './media-element-audio-source-node';\nexport * from './media-element-audio-source-options';\nexport * from './media-stream-audio-destination-node';\nexport * from './media-stream-audio-source-node';\nexport * from './media-stream-audio-source-options';\nexport * from './media-stream-track-audio-source-node';\nexport * from './media-stream-track-audio-source-options';\nexport * from './minimal-audio-context';\nexport * from './minimal-base-audio-context';\nexport * from './minimal-base-audio-context-event-map';\nexport * from './minimal-offline-audio-context';\nexport * from './native-audio-node-faker';\nexport * from './native-audio-worklet-node-faker';\nexport * from './native-constant-source-node-faker';\nexport * from './native-convolver-node-faker';\nexport * from './native-iir-filter-node-faker';\nexport * from './native-panner-node-faker';\nexport * from './native-stereo-panner-node-faker';\nexport * from './native-wave-shaper-node-faker';\nexport * from './offline-audio-completion-event';\nexport * from './offline-audio-context';\nexport * from './offline-audio-context-constructor';\nexport * from './offline-audio-context-options';\nexport * from './oscillator-node';\nexport * from './oscillator-node-renderer';\nexport * from './oscillator-options';\nexport * from './panner-node';\nexport * from './panner-options';\nexport * from './periodic-wave';\nexport * from './periodic-wave-constraints';\nexport * from './periodic-wave-options';\nexport * from './read-only-map';\nexport * from './stereo-panner-node';\nexport * from './stereo-panner-options';\nexport * from './wave-shaper-node';\nexport * from './wave-shaper-options';\nexport * from './worklet-options';\n//# sourceMappingURL=/build/es2019/interfaces/index.js.map","//# sourceMappingURL=/build/es2019/interfaces/media-element-audio-source-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/media-element-audio-source-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/media-stream-audio-destination-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/media-stream-audio-source-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/media-stream-audio-source-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/media-stream-track-audio-source-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/media-stream-track-audio-source-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/minimal-audio-context.js.map","//# sourceMappingURL=/build/es2019/interfaces/minimal-base-audio-context-event-map.js.map","//# sourceMappingURL=/build/es2019/interfaces/minimal-base-audio-context.js.map","//# sourceMappingURL=/build/es2019/interfaces/minimal-offline-audio-context.js.map","//# sourceMappingURL=/build/es2019/interfaces/native-audio-node-faker.js.map","//# sourceMappingURL=/build/es2019/interfaces/native-audio-worklet-node-faker.js.map","//# sourceMappingURL=/build/es2019/interfaces/native-constant-source-node-faker.js.map","//# sourceMappingURL=/build/es2019/interfaces/native-convolver-node-faker.js.map","//# sourceMappingURL=/build/es2019/interfaces/native-iir-filter-node-faker.js.map","//# sourceMappingURL=/build/es2019/interfaces/native-panner-node-faker.js.map","//# sourceMappingURL=/build/es2019/interfaces/native-stereo-panner-node-faker.js.map","//# sourceMappingURL=/build/es2019/interfaces/native-wave-shaper-node-faker.js.map","//# sourceMappingURL=/build/es2019/interfaces/offline-audio-completion-event.js.map","//# sourceMappingURL=/build/es2019/interfaces/offline-audio-context-constructor.js.map","//# sourceMappingURL=/build/es2019/interfaces/offline-audio-context-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/offline-audio-context.js.map","//# sourceMappingURL=/build/es2019/interfaces/oscillator-node-renderer.js.map","//# sourceMappingURL=/build/es2019/interfaces/oscillator-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/oscillator-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/panner-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/panner-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/periodic-wave-constraints.js.map","//# sourceMappingURL=/build/es2019/interfaces/periodic-wave-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/periodic-wave.js.map","//# sourceMappingURL=/build/es2019/interfaces/read-only-map.js.map","//# sourceMappingURL=/build/es2019/interfaces/stereo-panner-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/stereo-panner-options.js.map","//# sourceMappingURL=/build/es2019/interfaces/wave-shaper-node.js.map","//# sourceMappingURL=/build/es2019/interfaces/wave-shaper-options.js.map","// @todo This is currently named IWorkletOptions and not IAudioWorkletOptions because it defines the options of a generic Worklet.\n//# sourceMappingURL=/build/es2019/interfaces/worklet-options.js.map","import { createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent } from 'automation-events';\nimport { createAbortError } from './factories/abort-error';\nimport { createAddAudioNodeConnections } from './factories/add-audio-node-connections';\nimport { createAddAudioParamConnections } from './factories/add-audio-param-connections';\nimport { createAddAudioWorkletModule } from './factories/add-audio-worklet-module';\nimport { createAddSilentConnection } from './factories/add-silent-connection';\nimport { createAddUnrenderedAudioWorkletNode } from './factories/add-unrendered-audio-worklet-node';\nimport { createAnalyserNodeConstructor } from './factories/analyser-node-constructor';\nimport { createAnalyserNodeRendererFactory } from './factories/analyser-node-renderer-factory';\nimport { createAudioBufferConstructor } from './factories/audio-buffer-constructor';\nimport { createAudioBufferSourceNodeConstructor } from './factories/audio-buffer-source-node-constructor';\nimport { createAudioBufferSourceNodeRendererFactory } from './factories/audio-buffer-source-node-renderer-factory';\nimport { createAudioContextConstructor } from './factories/audio-context-constructor';\nimport { createAudioDestinationNodeConstructor } from './factories/audio-destination-node-constructor';\nimport { createAudioDestinationNodeRenderer } from './factories/audio-destination-node-renderer-factory';\nimport { createAudioListenerFactory } from './factories/audio-listener-factory';\nimport { createAudioNodeConstructor } from './factories/audio-node-constructor';\nimport { createAudioParamFactory } from './factories/audio-param-factory';\nimport { createAudioParamRenderer } from './factories/audio-param-renderer';\nimport { createAudioWorkletNodeConstructor } from './factories/audio-worklet-node-constructor';\nimport { createAudioWorkletNodeRendererFactory } from './factories/audio-worklet-node-renderer-factory';\nimport { createBaseAudioContextConstructor } from './factories/base-audio-context-constructor';\nimport { createBiquadFilterNodeConstructor } from './factories/biquad-filter-node-constructor';\nimport { createBiquadFilterNodeRendererFactory } from './factories/biquad-filter-node-renderer-factory';\nimport { createCacheTestResult } from './factories/cache-test-result';\nimport { createChannelMergerNodeConstructor } from './factories/channel-merger-node-constructor';\nimport { createChannelMergerNodeRendererFactory } from './factories/channel-merger-node-renderer-factory';\nimport { createChannelSplitterNodeConstructor } from './factories/channel-splitter-node-constructor';\nimport { createChannelSplitterNodeRendererFactory } from './factories/channel-splitter-node-renderer-factory';\nimport { createConnectAudioParam } from './factories/connect-audio-param';\nimport { createConnectMultipleOutputs } from './factories/connect-multiple-outputs';\nimport { createConnectedNativeAudioBufferSourceNodeFactory } from './factories/connected-native-audio-buffer-source-node-factory';\nimport { createConstantSourceNodeConstructor } from './factories/constant-source-node-constructor';\nimport { createConstantSourceNodeRendererFactory } from './factories/constant-source-node-renderer-factory';\nimport { createConvertNumberToUnsignedLong } from './factories/convert-number-to-unsigned-long';\nimport { createConvolverNodeConstructor } from './factories/convolver-node-constructor';\nimport { createConvolverNodeRendererFactory } from './factories/convolver-node-renderer-factory';\nimport { createCreateNativeOfflineAudioContext } from './factories/create-native-offline-audio-context';\nimport { createDataCloneError } from './factories/data-clone-error';\nimport { createDecodeAudioData } from './factories/decode-audio-data';\nimport { createDecrementCycleCounter } from './factories/decrement-cycle-counter';\nimport { createDelayNodeConstructor } from './factories/delay-node-constructor';\nimport { createDelayNodeRendererFactory } from './factories/delay-node-renderer-factory';\nimport { createDeleteUnrenderedAudioWorkletNode } from './factories/delete-unrendered-audio-worklet-node';\nimport { createDetectCycles } from './factories/detect-cycles';\nimport { createDisconnectMultipleOutputs } from './factories/disconnect-multiple-outputs';\nimport { createDynamicsCompressorNodeConstructor } from './factories/dynamics-compressor-node-constructor';\nimport { createDynamicsCompressorNodeRendererFactory } from './factories/dynamics-compressor-node-renderer-factory';\nimport { createEncodingError } from './factories/encoding-error';\nimport { createEvaluateSource } from './factories/evaluate-source';\nimport { createEventTargetConstructor } from './factories/event-target-constructor';\nimport { createExposeCurrentFrameAndCurrentTime } from './factories/expose-current-frame-and-current-time';\nimport { createFetchSource } from './factories/fetch-source';\nimport { createGainNodeConstructor } from './factories/gain-node-constructor';\nimport { createGainNodeRendererFactory } from './factories/gain-node-renderer-factory';\nimport { createGetAudioNodeRenderer } from './factories/get-audio-node-renderer';\nimport { createGetAudioParamRenderer } from './factories/get-audio-param-renderer';\nimport { createGetBackupNativeContext } from './factories/get-backup-native-context';\nimport { createGetNativeContext } from './factories/get-native-context';\nimport { createGetUnrenderedAudioWorkletNodes } from './factories/get-unrendered-audio-worklet-nodes';\nimport { createIIRFilterNodeConstructor } from './factories/iir-filter-node-constructor';\nimport { createIIRFilterNodeRendererFactory } from './factories/iir-filter-node-renderer-factory';\nimport { createIncrementCycleCounterFactory } from './factories/increment-cycle-counter-factory';\nimport { createIndexSizeError } from './factories/index-size-error';\nimport { createInvalidAccessError } from './factories/invalid-access-error';\nimport { createInvalidStateError } from './factories/invalid-state-error';\nimport { createIsAnyAudioContext } from './factories/is-any-audio-context';\nimport { createIsAnyAudioNode } from './factories/is-any-audio-node';\nimport { createIsAnyAudioParam } from './factories/is-any-audio-param';\nimport { createIsAnyOfflineAudioContext } from './factories/is-any-offline-audio-context';\nimport { createIsNativeAudioContext } from './factories/is-native-audio-context';\nimport { createIsNativeAudioNode } from './factories/is-native-audio-node';\nimport { createIsNativeAudioParam } from './factories/is-native-audio-param';\nimport { createIsNativeContext } from './factories/is-native-context';\nimport { createIsNativeOfflineAudioContext } from './factories/is-native-offline-audio-context';\nimport { createIsSecureContext } from './factories/is-secure-context';\nimport { createIsSupportedPromise } from './factories/is-supported-promise';\nimport { createMediaElementAudioSourceNodeConstructor } from './factories/media-element-audio-source-node-constructor';\nimport { createMediaStreamAudioDestinationNodeConstructor } from './factories/media-stream-audio-destination-node-constructor';\nimport { createMediaStreamAudioSourceNodeConstructor } from './factories/media-stream-audio-source-node-constructor';\nimport { createMediaStreamTrackAudioSourceNodeConstructor } from './factories/media-stream-track-audio-source-node-constructor';\nimport { createMinimalAudioContextConstructor } from './factories/minimal-audio-context-constructor';\nimport { createMinimalBaseAudioContextConstructor } from './factories/minimal-base-audio-context-constructor';\nimport { createMinimalOfflineAudioContextConstructor } from './factories/minimal-offline-audio-context-constructor';\nimport { createMonitorConnections } from './factories/monitor-connections';\nimport { createNativeAnalyserNodeFactory } from './factories/native-analyser-node-factory';\nimport { createNativeAudioBufferConstructor } from './factories/native-audio-buffer-constructor';\nimport { createNativeAudioBufferSourceNodeFactory } from './factories/native-audio-buffer-source-node-factory';\nimport { createNativeAudioContextConstructor } from './factories/native-audio-context-constructor';\nimport { createNativeAudioDestinationNodeFactory } from './factories/native-audio-destination-node';\nimport { createNativeAudioNodeFactory } from './factories/native-audio-node-factory';\nimport { createNativeAudioWorkletNodeConstructor } from './factories/native-audio-worklet-node-constructor';\nimport { createNativeAudioWorkletNodeFactory } from './factories/native-audio-worklet-node-factory';\nimport { createNativeAudioWorkletNodeFakerFactory } from './factories/native-audio-worklet-node-faker-factory';\nimport { createNativeBiquadFilterNodeFactory } from './factories/native-biquad-filter-node-factory';\nimport { createNativeChannelMergerNodeFactory } from './factories/native-channel-merger-node-factory';\nimport { createNativeChannelSplitterNodeFactory } from './factories/native-channel-splitter-node-factory';\nimport { createNativeConstantSourceNodeFactory } from './factories/native-constant-source-node-factory';\nimport { createNativeConstantSourceNodeFakerFactory } from './factories/native-constant-source-node-faker-factory';\nimport { createNativeConvolverNodeFactory } from './factories/native-convolver-node-factory';\nimport { createNativeConvolverNodeFakerFactory } from './factories/native-convolver-node-faker-factory';\nimport { createNativeDelayNodeFactory } from './factories/native-delay-node-factory';\nimport { createNativeDynamicsCompressorNodeFactory } from './factories/native-dynamics-compressor-node-factory';\nimport { createNativeGainNodeFactory } from './factories/native-gain-node-factory';\nimport { createNativeIIRFilterNodeFactory } from './factories/native-iir-filter-node-factory';\nimport { createNativeIIRFilterNodeFakerFactory } from './factories/native-iir-filter-node-faker-factory';\nimport { createNativeMediaElementAudioSourceNodeFactory } from './factories/native-media-element-audio-source-node-factory';\nimport { createNativeMediaStreamAudioDestinationNodeFactory } from './factories/native-media-stream-audio-destination-node-factory';\nimport { createNativeMediaStreamAudioSourceNodeFactory } from './factories/native-media-stream-audio-source-node-factory';\nimport { createNativeMediaStreamTrackAudioSourceNodeFactory } from './factories/native-media-stream-track-audio-source-node-factory';\nimport { createNativeOfflineAudioContextConstructor } from './factories/native-offline-audio-context-constructor';\nimport { createNativeOscillatorNodeFactory } from './factories/native-oscillator-node-factory';\nimport { createNativePannerNodeFactory } from './factories/native-panner-node-factory';\nimport { createNativePannerNodeFakerFactory } from './factories/native-panner-node-faker-factory';\nimport { createNativePeriodicWaveFactory } from './factories/native-periodic-wave-factory';\nimport { createNativeScriptProcessorNodeFactory } from './factories/native-script-processor-node-factory';\nimport { createNativeStereoPannerNodeFactory } from './factories/native-stereo-panner-node-factory';\nimport { createNativeStereoPannerNodeFakerFactory } from './factories/native-stereo-panner-node-faker-factory';\nimport { createNativeWaveShaperNodeFactory } from './factories/native-wave-shaper-node-factory';\nimport { createNativeWaveShaperNodeFakerFactory } from './factories/native-wave-shaper-node-faker-factory';\nimport { createNotSupportedError } from './factories/not-supported-error';\nimport { createOfflineAudioContextConstructor } from './factories/offline-audio-context-constructor';\nimport { createOscillatorNodeConstructor } from './factories/oscillator-node-constructor';\nimport { createOscillatorNodeRendererFactory } from './factories/oscillator-node-renderer-factory';\nimport { createPannerNodeConstructor } from './factories/panner-node-constructor';\nimport { createPannerNodeRendererFactory } from './factories/panner-node-renderer-factory';\nimport { createPeriodicWaveConstructor } from './factories/periodic-wave-constructor';\nimport { createRenderAutomation } from './factories/render-automation';\nimport { createRenderInputsOfAudioNode } from './factories/render-inputs-of-audio-node';\nimport { createRenderInputsOfAudioParam } from './factories/render-inputs-of-audio-param';\nimport { createRenderNativeOfflineAudioContext } from './factories/render-native-offline-audio-context';\nimport { createStartRendering } from './factories/start-rendering';\nimport { createStereoPannerNodeConstructor } from './factories/stereo-panner-node-constructor';\nimport { createStereoPannerNodeRendererFactory } from './factories/stereo-panner-node-renderer-factory';\nimport { createTestAudioBufferConstructorSupport } from './factories/test-audio-buffer-constructor-support';\nimport { createTestAudioBufferCopyChannelMethodsSubarraySupport } from './factories/test-audio-buffer-copy-channel-methods-subarray-support';\nimport { createTestAudioBufferSourceNodeStartMethodConsecutiveCallsSupport } from './factories/test-audio-buffer-source-node-start-method-consecutive-calls-support';\nimport { createTestAudioBufferSourceNodeStartMethodDurationParameterSupport } from './factories/test-audio-buffer-source-node-start-method-duration-parameter-support';\nimport { createTestAudioBufferSourceNodeStartMethodOffsetClampingSupport } from './factories/test-audio-buffer-source-node-start-method-offset-clamping-support';\nimport { createTestAudioBufferSourceNodeStopMethodNullifiedBufferSupport } from './factories/test-audio-buffer-source-node-stop-method-nullified-buffer-support';\nimport { createTestAudioContextCloseMethodSupport } from './factories/test-audio-context-close-method-support';\nimport { createTestAudioContextDecodeAudioDataMethodTypeErrorSupport } from './factories/test-audio-context-decode-audio-data-method-type-error-support';\nimport { createTestAudioContextOptionsSupport } from './factories/test-audio-context-options-support';\nimport { createTestAudioNodeConnectMethodSupport } from './factories/test-audio-node-connect-method-support';\nimport { createTestAudioScheduledSourceNodeStartMethodNegativeParametersSupport } from './factories/test-audio-scheduled-source-node-start-method-negative-parameters-support';\nimport { createTestAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport } from './factories/test-audio-scheduled-source-node-stop-method-consecutive-calls-support';\nimport { createTestAudioScheduledSourceNodeStopMethodNegativeParametersSupport } from './factories/test-audio-scheduled-source-node-stop-method-negative-parameters-support';\nimport { createTestAudioWorkletProcessorNoOutputsSupport } from './factories/test-audio-worklet-processor-no-outputs-support';\nimport { createTestChannelMergerNodeChannelCountSupport } from './factories/test-channel-merger-node-channel-count-support';\nimport { createTestConstantSourceNodeAccurateSchedulingSupport } from './factories/test-constant-source-node-accurate-scheduling-support';\nimport { createTestConvolverNodeBufferReassignabilitySupport } from './factories/test-convolver-node-buffer-reassignability-support';\nimport { createTestIsSecureContextSupport } from './factories/test-is-secure-context-support';\nimport { createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport } from './factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support';\nimport { createTestOfflineAudioContextCurrentTimeSupport } from './factories/test-offline-audio-context-current-time-support';\nimport { createTestStereoPannerNodeDefaultValueSupport } from './factories/test-stereo-panner-node-default-value-support';\nimport { createUnknownError } from './factories/unknown-error';\nimport { createWaveShaperNodeConstructor } from './factories/wave-shaper-node-constructor';\nimport { createWaveShaperNodeRendererFactory } from './factories/wave-shaper-node-renderer-factory';\nimport { createWindow } from './factories/window';\nimport { createWrapAudioBufferCopyChannelMethods } from './factories/wrap-audio-buffer-copy-channel-methods';\nimport { createWrapAudioBufferCopyChannelMethodsOutOfBounds } from './factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds';\nimport { createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer } from './factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer';\nimport { createWrapAudioScheduledSourceNodeStopMethodConsecutiveCalls } from './factories/wrap-audio-scheduled-source-node-stop-method-consecutive-calls';\nimport { createWrapChannelMergerNode } from './factories/wrap-channel-merger-node';\nimport { AUDIO_NODE_CONNECTIONS_STORE, AUDIO_NODE_STORE, AUDIO_PARAM_CONNECTIONS_STORE, AUDIO_PARAM_STORE, CONTEXT_STORE, CYCLE_COUNTERS } from './globals';\nimport { connectNativeAudioNodeToNativeAudioNode } from './helpers/connect-native-audio-node-to-native-audio-node';\nimport { disconnectNativeAudioNodeFromNativeAudioNode } from './helpers/disconnect-native-audio-node-from-native-audio-node';\nimport { getAudioNodeConnections } from './helpers/get-audio-node-connections';\nimport { getAudioParamConnections } from './helpers/get-audio-param-connections';\nimport { getNativeAudioNode } from './helpers/get-native-audio-node';\nimport { getNativeAudioParam } from './helpers/get-native-audio-param';\nimport { getValueForKey } from './helpers/get-value-for-key';\nimport { insertElementInSet } from './helpers/insert-element-in-set';\nimport { isActiveAudioNode } from './helpers/is-active-audio-node';\nimport { isDCCurve } from './helpers/is-dc-curve';\nimport { isPartOfACycle } from './helpers/is-part-of-a-cycle';\nimport { overwriteAccessors } from './helpers/overwrite-accessors';\nimport { testAudioBufferCopyChannelMethodsOutOfBoundsSupport } from './helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support';\nimport { testPromiseSupport } from './helpers/test-promise-support';\nimport { testTransferablesSupport } from './helpers/test-transferables-support';\nimport { wrapAudioBufferSourceNodeStartMethodOffsetClamping } from './helpers/wrap-audio-buffer-source-node-start-method-offset-clamping';\nimport { wrapEventListener } from './helpers/wrap-event-listener';\n/*\n * @todo Explicitly referencing the barrel file seems to be necessary when enabling the\n * isolatedModules compiler option.\n */\nexport * from './interfaces/index';\nexport * from './types/index';\nconst cacheTestResult = createCacheTestResult(new Map(), new WeakMap());\nconst window = createWindow();\nconst nativeOfflineAudioContextConstructor = createNativeOfflineAudioContextConstructor(window);\nconst isNativeOfflineAudioContext = createIsNativeOfflineAudioContext(nativeOfflineAudioContextConstructor);\nconst nativeAudioContextConstructor = createNativeAudioContextConstructor(window);\nconst getBackupNativeContext = createGetBackupNativeContext(isNativeOfflineAudioContext, nativeAudioContextConstructor, nativeOfflineAudioContextConstructor);\nconst createNativeAudioNode = createNativeAudioNodeFactory(getBackupNativeContext);\nconst createNativeAnalyserNode = createNativeAnalyserNodeFactory(cacheTestResult, createIndexSizeError, createNativeAudioNode);\nconst getAudioNodeRenderer = createGetAudioNodeRenderer(getAudioNodeConnections);\nconst renderInputsOfAudioNode = createRenderInputsOfAudioNode(getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle);\nconst createAnalyserNodeRenderer = createAnalyserNodeRendererFactory(createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode);\nconst auxiliaryGainNodeStore = new WeakMap();\nconst getNativeContext = createGetNativeContext(CONTEXT_STORE);\nconst audioParamAudioNodeStore = new WeakMap();\nconst eventTargetConstructor = createEventTargetConstructor(wrapEventListener);\nconst isNativeAudioContext = createIsNativeAudioContext(nativeAudioContextConstructor);\nconst isNativeAudioNode = createIsNativeAudioNode(window);\nconst isNativeAudioParam = createIsNativeAudioParam(window);\nconst audioNodeConstructor = createAudioNodeConstructor(createAddAudioNodeConnections(AUDIO_NODE_CONNECTIONS_STORE), auxiliaryGainNodeStore, cacheTestResult, createIncrementCycleCounterFactory(CYCLE_COUNTERS, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode), createIndexSizeError, createInvalidAccessError, createNotSupportedError, createDecrementCycleCounter(connectNativeAudioNodeToNativeAudioNode, CYCLE_COUNTERS, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext), createDetectCycles(audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey), eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext);\nconst analyserNodeConstructor = createAnalyserNodeConstructor(audioNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext);\nexport { analyserNodeConstructor as AnalyserNode };\nconst audioBufferStore = new WeakSet();\nconst nativeAudioBufferConstructor = createNativeAudioBufferConstructor(window);\nconst convertNumberToUnsignedLong = createConvertNumberToUnsignedLong(new Uint32Array(1));\nconst wrapAudioBufferCopyChannelMethods = createWrapAudioBufferCopyChannelMethods(convertNumberToUnsignedLong, createIndexSizeError);\nconst wrapAudioBufferCopyChannelMethodsOutOfBounds = createWrapAudioBufferCopyChannelMethodsOutOfBounds(convertNumberToUnsignedLong);\nconst audioBufferConstructor = createAudioBufferConstructor(audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, createTestAudioBufferConstructorSupport(nativeAudioBufferConstructor), wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\nexport { audioBufferConstructor as AudioBuffer };\nconst createNativeGainNode = createNativeGainNodeFactory(createNativeAudioNode);\nconst addSilentConnection = createAddSilentConnection(createNativeGainNode);\nconst testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = createTestAudioScheduledSourceNodeStartMethodNegativeParametersSupport(createNativeAudioNode);\nconst testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = createTestAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(createNativeAudioNode);\nconst testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = createTestAudioScheduledSourceNodeStopMethodNegativeParametersSupport(createNativeAudioNode);\nconst wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = createWrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(createNativeAudioNode);\nconst renderInputsOfAudioParam = createRenderInputsOfAudioParam(getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle);\nconst connectAudioParam = createConnectAudioParam(renderInputsOfAudioParam);\nconst createNativeAudioBufferSourceNode = createNativeAudioBufferSourceNodeFactory(addSilentConnection, cacheTestResult, createNativeAudioNode, createTestAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(createNativeAudioNode), createTestAudioBufferSourceNodeStartMethodDurationParameterSupport(nativeOfflineAudioContextConstructor), createTestAudioBufferSourceNodeStartMethodOffsetClampingSupport(createNativeAudioNode), createTestAudioBufferSourceNodeStopMethodNullifiedBufferSupport(createNativeAudioNode), testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClamping, createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer(overwriteAccessors), wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);\nconst renderAutomation = createRenderAutomation(createGetAudioParamRenderer(getAudioParamConnections), renderInputsOfAudioParam);\nconst createAudioBufferSourceNodeRenderer = createAudioBufferSourceNodeRendererFactory(connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst createAudioParam = createAudioParamFactory(createAddAudioParamConnections(AUDIO_PARAM_CONNECTIONS_STORE), audioParamAudioNodeStore, AUDIO_PARAM_STORE, createAudioParamRenderer, createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent, nativeAudioContextConstructor);\nconst audioBufferSourceNodeConstructor = createAudioBufferSourceNodeConstructor(audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener);\nexport { audioBufferSourceNodeConstructor as AudioBufferSourceNode };\nconst audioDestinationNodeConstructor = createAudioDestinationNodeConstructor(audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNodeFactory(createNativeGainNode, overwriteAccessors), getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode);\nconst createNativeBiquadFilterNode = createNativeBiquadFilterNodeFactory(createNativeAudioNode);\nconst createBiquadFilterNodeRenderer = createBiquadFilterNodeRendererFactory(connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst biquadFilterNodeConstructor = createBiquadFilterNodeConstructor(audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext);\nconst monitorConnections = createMonitorConnections(insertElementInSet, isNativeAudioNode);\nconst wrapChannelMergerNode = createWrapChannelMergerNode(createInvalidStateError, createNativeAudioNode, monitorConnections);\nconst createNativeChannelMergerNode = createNativeChannelMergerNodeFactory(createNativeAudioNode, wrapChannelMergerNode);\nconst createChannelMergerNodeRenderer = createChannelMergerNodeRendererFactory(createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode);\nconst channelMergerNodeConstructor = createChannelMergerNodeConstructor(audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeChannelSplitterNode = createNativeChannelSplitterNodeFactory(createNativeAudioNode);\nconst createChannelSplitterNodeRenderer = createChannelSplitterNodeRendererFactory(createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode);\nconst channelSplitterNodeConstructor = createChannelSplitterNodeConstructor(audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeConstantSourceNodeFaker = createNativeConstantSourceNodeFakerFactory(addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections);\nconst createNativeConstantSourceNode = createNativeConstantSourceNodeFactory(addSilentConnection, cacheTestResult, createNativeAudioNode, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport);\nconst createConstantSourceNodeRenderer = createConstantSourceNodeRendererFactory(connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst constantSourceNodeConstructor = createConstantSourceNodeConstructor(audioNodeConstructor, createAudioParam, createConstantSourceNodeRenderer, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener);\nconst createNativeConvolverNodeFaker = createNativeConvolverNodeFakerFactory(createNativeAudioNode, createNativeGainNode, monitorConnections);\nconst createNativeConvolverNode = createNativeConvolverNodeFactory(createNativeAudioNode, createNativeConvolverNodeFaker, createNotSupportedError, overwriteAccessors);\nconst createConvolverNodeRenderer = createConvolverNodeRendererFactory(createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode);\nconst convolverNodeConstructor = createConvolverNodeConstructor(audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeDelayNode = createNativeDelayNodeFactory(createNativeAudioNode);\nconst createDelayNodeRenderer = createDelayNodeRendererFactory(connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst delayNodeConstructor = createDelayNodeConstructor(audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeDynamicsCompressorNode = createNativeDynamicsCompressorNodeFactory(createNativeAudioNode, createNotSupportedError);\nconst createDynamicsCompressorNodeRenderer = createDynamicsCompressorNodeRendererFactory(connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst dynamicsCompressorNodeConstructor = createDynamicsCompressorNodeConstructor(audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext);\nconst createGainNodeRenderer = createGainNodeRendererFactory(connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst gainNodeConstructor = createGainNodeConstructor(audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeScriptProcessorNode = createNativeScriptProcessorNodeFactory(createNativeAudioNode);\nconst createNativeIIRFilterNodeFaker = createNativeIIRFilterNodeFakerFactory(createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError);\nconst renderNativeOfflineAudioContext = createRenderNativeOfflineAudioContext(cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, createTestOfflineAudioContextCurrentTimeSupport(createNativeGainNode, nativeOfflineAudioContextConstructor));\nconst createIIRFilterNodeRenderer = createIIRFilterNodeRendererFactory(createNativeAudioBufferSourceNode, createNativeAudioNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\nconst createNativeIIRFilterNode = createNativeIIRFilterNodeFactory(createNativeAudioNode, createNativeIIRFilterNodeFaker);\nconst iIRFilterNodeConstructor = createIIRFilterNodeConstructor(audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext);\nconst createAudioListener = createAudioListenerFactory(createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, isNativeOfflineAudioContext);\nconst unrenderedAudioWorkletNodeStore = new WeakMap();\nconst minimalBaseAudioContextConstructor = createMinimalBaseAudioContextConstructor(audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener);\nconst createNativeOscillatorNode = createNativeOscillatorNodeFactory(addSilentConnection, cacheTestResult, createNativeAudioNode, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);\nconst createOscillatorNodeRenderer = createOscillatorNodeRendererFactory(connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst oscillatorNodeConstructor = createOscillatorNodeConstructor(audioNodeConstructor, createAudioParam, createInvalidStateError, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener);\nconst createConnectedNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNodeFactory(createNativeAudioBufferSourceNode);\nconst createNativeWaveShaperNodeFaker = createNativeWaveShaperNodeFakerFactory(createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeAudioNode, createNativeGainNode, isDCCurve, monitorConnections);\nconst createNativeWaveShaperNode = createNativeWaveShaperNodeFactory(createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeAudioNode, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, overwriteAccessors);\nconst createNativePannerNodeFaker = createNativePannerNodeFakerFactory(connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeAudioNode, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, monitorConnections);\nconst createNativePannerNode = createNativePannerNodeFactory(createNativeAudioNode, createNativePannerNodeFaker);\nconst createPannerNodeRenderer = createPannerNodeRendererFactory(connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\nconst pannerNodeConstructor = createPannerNodeConstructor(audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext);\nconst createNativePeriodicWave = createNativePeriodicWaveFactory(getBackupNativeContext);\nconst periodicWaveConstructor = createPeriodicWaveConstructor(createNativePeriodicWave, getNativeContext, new WeakSet());\nconst nativeStereoPannerNodeFakerFactory = createNativeStereoPannerNodeFakerFactory(createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections);\nconst createNativeStereoPannerNode = createNativeStereoPannerNodeFactory(createNativeAudioNode, nativeStereoPannerNodeFakerFactory, createNotSupportedError);\nconst createStereoPannerNodeRenderer = createStereoPannerNodeRendererFactory(connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst stereoPannerNodeConstructor = createStereoPannerNodeConstructor(audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext);\nconst createWaveShaperNodeRenderer = createWaveShaperNodeRendererFactory(createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode);\nconst waveShaperNodeConstructor = createWaveShaperNodeConstructor(audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext);\nconst isSecureContext = createIsSecureContext(window);\nconst exposeCurrentFrameAndCurrentTime = createExposeCurrentFrameAndCurrentTime(window);\n// The addAudioWorkletModule() function is only available in a SecureContext.\nexport const addAudioWorkletModule = (isSecureContext) ?\n    createAddAudioWorkletModule(createNotSupportedError, createEvaluateSource(window), exposeCurrentFrameAndCurrentTime, createFetchSource(createAbortError), getBackupNativeContext, getNativeContext, new WeakMap(), new WeakMap(), \n    // @todo window is guaranteed to be defined because isSecureContext checks that as well.\n    window) :\n    undefined;\nconst isNativeContext = createIsNativeContext(isNativeAudioContext, isNativeOfflineAudioContext);\nexport const decodeAudioData = createDecodeAudioData(audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, new WeakSet(), getNativeContext, isNativeContext, isNativeOfflineAudioContext, nativeOfflineAudioContextConstructor, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\nconst baseAudioContextConstructor = createBaseAudioContextConstructor(addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor);\nconst createNativeMediaElementAudioSourceNode = createNativeMediaElementAudioSourceNodeFactory(createNativeAudioNode);\nconst mediaElementAudioSourceNodeConstructor = createMediaElementAudioSourceNodeConstructor(audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeMediaStreamAudioDestinationNode = createNativeMediaStreamAudioDestinationNodeFactory(createNativeAudioNode, createNotSupportedError);\nconst mediaStreamAudioDestinationNodeConstructor = createMediaStreamAudioDestinationNodeConstructor(audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeMediaStreamAudioSourceNode = createNativeMediaStreamAudioSourceNodeFactory(createNativeAudioNode);\nconst mediaStreamAudioSourceNodeConstructor = createMediaStreamAudioSourceNodeConstructor(audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNodeFactory(createInvalidStateError, createNativeAudioNode, isNativeOfflineAudioContext);\nconst mediaStreamTrackAudioSourceNodeConstructor = createMediaStreamTrackAudioSourceNodeConstructor(audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext);\nconst audioContextConstructor = createAudioContextConstructor(baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor);\nexport { audioContextConstructor as AudioContext };\nconst getUnrenderedAudioWorkletNodes = createGetUnrenderedAudioWorkletNodes(unrenderedAudioWorkletNodeStore);\nconst addUnrenderedAudioWorkletNode = createAddUnrenderedAudioWorkletNode(getUnrenderedAudioWorkletNodes);\nconst connectMultipleOutputs = createConnectMultipleOutputs(createIndexSizeError);\nconst deleteUnrenderedAudioWorkletNode = createDeleteUnrenderedAudioWorkletNode(getUnrenderedAudioWorkletNodes);\nconst disconnectMultipleOutputs = createDisconnectMultipleOutputs(createIndexSizeError);\nconst createNativeAudioWorkletNodeFaker = createNativeAudioWorkletNodeFakerFactory(auxiliaryGainNodeStore, connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, monitorConnections);\nconst createNativeAudioWorkletNode = createNativeAudioWorkletNodeFactory(createInvalidStateError, createNativeAudioNode, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections);\nconst nativeAudioWorkletNodeConstructor = createNativeAudioWorkletNodeConstructor(window);\nconst createAudioWorkletNodeRenderer = createAudioWorkletNodeRendererFactory(connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\n// The AudioWorkletNode constructor is only available in a SecureContext.\nconst audioWorkletNodeConstructor = (isSecureContext) ?\n    createAudioWorkletNodeConstructor(addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, wrapEventListener) :\n    undefined;\nexport { audioWorkletNodeConstructor as AudioWorkletNode };\nexport { biquadFilterNodeConstructor as BiquadFilterNode };\nexport { channelMergerNodeConstructor as ChannelMergerNode };\nexport { channelSplitterNodeConstructor as ChannelSplitterNode };\nexport { convolverNodeConstructor as ConvolverNode };\nexport { constantSourceNodeConstructor as ConstantSourceNode };\nexport { delayNodeConstructor as DelayNode };\nexport { dynamicsCompressorNodeConstructor as DynamicsCompressorNode };\nexport { gainNodeConstructor as GainNode };\nexport { iIRFilterNodeConstructor as IIRFilterNode };\nexport { mediaElementAudioSourceNodeConstructor as MediaElementAudioSourceNode };\nexport { mediaStreamAudioDestinationNodeConstructor as MediaStreamAudioDestinationNode };\nexport { mediaStreamAudioSourceNodeConstructor as MediaStreamAudioSourceNode };\nexport { mediaStreamTrackAudioSourceNodeConstructor as MediaStreamTrackAudioSourceNode };\nconst minimalAudioContextConstructor = createMinimalAudioContextConstructor(createInvalidStateError, createNotSupportedError, createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor);\nexport { minimalAudioContextConstructor as MinimalAudioContext };\nconst createNativeOfflineAudioContext = createCreateNativeOfflineAudioContext(createNotSupportedError, nativeOfflineAudioContextConstructor);\nconst startRendering = createStartRendering(audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\nconst minimalOfflineAudioContextConstructor = createMinimalOfflineAudioContextConstructor(cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering);\nexport { minimalOfflineAudioContextConstructor as MinimalOfflineAudioContext };\nconst offlineAudioContextConstructor = createOfflineAudioContextConstructor(baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering);\nexport { offlineAudioContextConstructor as OfflineAudioContext };\nexport { oscillatorNodeConstructor as OscillatorNode };\nexport { pannerNodeConstructor as PannerNode };\nexport { periodicWaveConstructor as PeriodicWave };\nexport { stereoPannerNodeConstructor as StereoPannerNode };\nexport { waveShaperNodeConstructor as WaveShaperNode };\nexport const isAnyAudioContext = createIsAnyAudioContext(CONTEXT_STORE, isNativeAudioContext);\nexport const isAnyAudioNode = createIsAnyAudioNode(AUDIO_NODE_STORE, isNativeAudioNode);\nexport const isAnyAudioParam = createIsAnyAudioParam(AUDIO_PARAM_STORE, isNativeAudioParam);\nexport const isAnyOfflineAudioContext = createIsAnyOfflineAudioContext(CONTEXT_STORE, isNativeOfflineAudioContext);\nexport const isSupported = () => createIsSupportedPromise(cacheTestResult, createTestAudioBufferCopyChannelMethodsSubarraySupport(nativeOfflineAudioContextConstructor), createTestAudioContextCloseMethodSupport(nativeAudioContextConstructor), createTestAudioContextDecodeAudioDataMethodTypeErrorSupport(nativeOfflineAudioContextConstructor), createTestAudioContextOptionsSupport(nativeAudioContextConstructor), createTestAudioNodeConnectMethodSupport(nativeOfflineAudioContextConstructor), createTestAudioWorkletProcessorNoOutputsSupport(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), createTestChannelMergerNodeChannelCountSupport(createNativeAudioNode, nativeOfflineAudioContextConstructor), createTestConstantSourceNodeAccurateSchedulingSupport(createNativeAudioNode, nativeOfflineAudioContextConstructor), createTestConvolverNodeBufferReassignabilitySupport(nativeOfflineAudioContextConstructor), createTestIsSecureContextSupport(window), createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport(nativeAudioContextConstructor), createTestStereoPannerNodeDefaultValueSupport(nativeOfflineAudioContextConstructor), testTransferablesSupport);\n//# sourceMappingURL=/build/es2019/module.js.map","export class ReadOnlyMap {\n    constructor(parameters) {\n        this._map = new Map(parameters);\n    }\n    get size() {\n        return this._map.size;\n    }\n    entries() {\n        return this._map.entries();\n    }\n    forEach(callback, thisArg = null) {\n        return this._map.forEach((value, key) => callback.call(thisArg, value, key, this));\n    }\n    get(name) {\n        return this._map.get(name);\n    }\n    has(name) {\n        return this._map.has(name);\n    }\n    keys() {\n        return this._map.keys();\n    }\n    values() {\n        return this._map.values();\n    }\n}\n//# sourceMappingURL=/build/es2019/read-only-map.js.map","//# sourceMappingURL=/build/es2019/types/abort-error-factory.js.map","//# sourceMappingURL=/build/es2019/types/active-input-connection.js.map","//# sourceMappingURL=/build/es2019/types/add-audio-node-connections-factory.js.map","//# sourceMappingURL=/build/es2019/types/add-audio-node-connections-function.js.map","//# sourceMappingURL=/build/es2019/types/add-audio-param-connections-factory.js.map","//# sourceMappingURL=/build/es2019/types/add-audio-param-connections-function.js.map","//# sourceMappingURL=/build/es2019/types/add-audio-worklet-module-factory.js.map","//# sourceMappingURL=/build/es2019/types/add-audio-worklet-module-function.js.map","//# sourceMappingURL=/build/es2019/types/add-silent-connection-factory.js.map","//# sourceMappingURL=/build/es2019/types/add-silent-connection-function.js.map","//# sourceMappingURL=/build/es2019/types/add-unrendered-audio-worklet-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/add-unrendered-audio-worklet-node-function.js.map","//# sourceMappingURL=/build/es2019/types/analyser-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/analyser-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/analyser-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/analyser-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/any-audio-buffer.js.map","//# sourceMappingURL=/build/es2019/types/any-context.js.map","//# sourceMappingURL=/build/es2019/types/audio-buffer-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-buffer-constructor.js.map","//# sourceMappingURL=/build/es2019/types/audio-buffer-source-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-buffer-source-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-buffer-source-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-buffer-source-node-renderer.js.map","//# sourceMappingURL=/build/es2019/types/audio-buffer-store.js.map","//# sourceMappingURL=/build/es2019/types/audio-context-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-context-constructor.js.map","//# sourceMappingURL=/build/es2019/types/audio-context-latency-category.js.map","//# sourceMappingURL=/build/es2019/types/audio-context-state.js.map","//# sourceMappingURL=/build/es2019/types/audio-destination-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-destination-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/audio-destination-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-listener-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-listener-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-node-connections-store.js.map","//# sourceMappingURL=/build/es2019/types/audio-node-connections.js.map","//# sourceMappingURL=/build/es2019/types/audio-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/audio-node-output-connection.js.map","//# sourceMappingURL=/build/es2019/types/audio-node-renderer.js.map","//# sourceMappingURL=/build/es2019/types/audio-node-store.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-audio-node-store.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-connections-store.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-connections.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-map.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-output-connection.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-param-store.js.map","//# sourceMappingURL=/build/es2019/types/audio-worklet-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-worklet-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/audio-worklet-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/audio-worklet-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/auxiliary-gain-node-store.js.map","//# sourceMappingURL=/build/es2019/types/base-audio-context-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/base-audio-context-constructor.js.map","//# sourceMappingURL=/build/es2019/types/biquad-filter-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/biquad-filter-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/biquad-filter-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/biquad-filter-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/biquad-filter-type.js.map","//# sourceMappingURL=/build/es2019/types/cache-test-result-factory.js.map","//# sourceMappingURL=/build/es2019/types/cache-test-result-function.js.map","//# sourceMappingURL=/build/es2019/types/channel-count-mode.js.map","//# sourceMappingURL=/build/es2019/types/channel-interpretation.js.map","//# sourceMappingURL=/build/es2019/types/channel-merger-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/channel-merger-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/channel-merger-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/channel-merger-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/channel-splitter-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/channel-splitter-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/channel-splitter-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/channel-splitter-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/connect-audio-param-factory.js.map","//# sourceMappingURL=/build/es2019/types/connect-audio-param-function.js.map","//# sourceMappingURL=/build/es2019/types/connect-multiple-outputs-factory.js.map","//# sourceMappingURL=/build/es2019/types/connect-multiple-outputs-function.js.map","//# sourceMappingURL=/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js.map","//# sourceMappingURL=/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/connected-native-audio-buffer-source-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/constant-source-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/constant-source-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/constant-source-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/constant-source-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/constant-source-node-renderer.js.map","//# sourceMappingURL=/build/es2019/types/constructor.js.map","//# sourceMappingURL=/build/es2019/types/context-store.js.map","//# sourceMappingURL=/build/es2019/types/context.js.map","//# sourceMappingURL=/build/es2019/types/convert-number-to-unsigned-long-factory.js.map","//# sourceMappingURL=/build/es2019/types/convert-number-to-unsigned-long-function.js.map","//# sourceMappingURL=/build/es2019/types/convolver-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/convolver-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/convolver-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/convolver-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/create-native-offline-audio-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/create-native-offline-audio-context-function.js.map","//# sourceMappingURL=/build/es2019/types/cycle-counters.js.map","//# sourceMappingURL=/build/es2019/types/data-clone-error-factory.js.map","//# sourceMappingURL=/build/es2019/types/decode-audio-data-factory.js.map","//# sourceMappingURL=/build/es2019/types/decode-audio-data-function.js.map","//# sourceMappingURL=/build/es2019/types/decode-error-callback.js.map","//# sourceMappingURL=/build/es2019/types/decode-success-callback.js.map","//# sourceMappingURL=/build/es2019/types/decrement-cycle-counter-factory.js.map","//# sourceMappingURL=/build/es2019/types/decrement-cycle-counter-function.js.map","//# sourceMappingURL=/build/es2019/types/delay-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/delay-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/delay-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/delay-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/delete-unrendered-audio-worklet-node-function.js.map","//# sourceMappingURL=/build/es2019/types/detect-cycles-factory.js.map","//# sourceMappingURL=/build/es2019/types/detect-cycles-function.js.map","//# sourceMappingURL=/build/es2019/types/disconnect-multiple-outputs-factory.js.map","//# sourceMappingURL=/build/es2019/types/disconnect-multiple-outputs-function.js.map","//# sourceMappingURL=/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js.map","//# sourceMappingURL=/build/es2019/types/distance-model-type.js.map","//# sourceMappingURL=/build/es2019/types/dynamics-compressor-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/dynamics-compressor-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/dynamics-compressor-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/encoding-error-factory.js.map","//# sourceMappingURL=/build/es2019/types/error-event-handler.js.map","//# sourceMappingURL=/build/es2019/types/evaluate-audio-worklet-global-scope-function.js.map","//# sourceMappingURL=/build/es2019/types/evaluate-source-factory.js.map","//# sourceMappingURL=/build/es2019/types/evaluate-source-function.js.map","//# sourceMappingURL=/build/es2019/types/event-handler.js.map","//# sourceMappingURL=/build/es2019/types/event-target-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/event-target-constructor.js.map","//# sourceMappingURL=/build/es2019/types/expose-current-frame-and-current-time-factory.js.map","//# sourceMappingURL=/build/es2019/types/expose-current-frame-and-current-time-function.js.map","//# sourceMappingURL=/build/es2019/types/fetch-source-factory.js.map","//# sourceMappingURL=/build/es2019/types/fetch-source-function.js.map","//# sourceMappingURL=/build/es2019/types/gain-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/gain-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/gain-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/gain-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/get-audio-node-connections-function.js.map","//# sourceMappingURL=/build/es2019/types/get-audio-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/get-audio-node-renderer-function.js.map","//# sourceMappingURL=/build/es2019/types/get-audio-param-connections-function.js.map","//# sourceMappingURL=/build/es2019/types/get-audio-param-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/get-audio-param-renderer-function.js.map","//# sourceMappingURL=/build/es2019/types/get-backup-native-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/get-backup-native-context-function.js.map","//# sourceMappingURL=/build/es2019/types/get-native-audio-node-function.js.map","//# sourceMappingURL=/build/es2019/types/get-native-audio-param-function.js.map","//# sourceMappingURL=/build/es2019/types/get-native-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/get-native-context-function.js.map","//# sourceMappingURL=/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js.map","//# sourceMappingURL=/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js.map","//# sourceMappingURL=/build/es2019/types/get-value-for-key-function.js.map","//# sourceMappingURL=/build/es2019/types/iir-filter-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/iir-filter-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/iir-filter-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/iir-filter-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/increment-cycle-counter-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/increment-cycle-counter-factory.js.map","//# sourceMappingURL=/build/es2019/types/increment-cycle-counter-function.js.map","//# sourceMappingURL=/build/es2019/types/index-size-error-factory.js.map","export * from './abort-error-factory';\nexport * from './active-input-connection';\nexport * from './add-audio-node-connections-factory';\nexport * from './add-audio-node-connections-function';\nexport * from './add-audio-param-connections-factory';\nexport * from './add-audio-param-connections-function';\nexport * from './add-audio-worklet-module-factory';\nexport * from './add-audio-worklet-module-function';\nexport * from './add-silent-connection-factory';\nexport * from './add-silent-connection-function';\nexport * from './add-unrendered-audio-worklet-node-factory';\nexport * from './add-unrendered-audio-worklet-node-function';\nexport * from './analyser-node-constructor';\nexport * from './analyser-node-constructor-factory';\nexport * from './analyser-node-renderer-factory';\nexport * from './analyser-node-renderer-factory-factory';\nexport * from './any-audio-buffer';\nexport * from './any-context';\nexport * from './audio-buffer-constructor';\nexport * from './audio-buffer-constructor-factory';\nexport * from './audio-buffer-source-node-constructor';\nexport * from './audio-buffer-source-node-constructor-factory';\nexport * from './audio-buffer-source-node-renderer';\nexport * from './audio-buffer-source-node-renderer-factory';\nexport * from './audio-buffer-source-node-renderer-factory-factory';\nexport * from './audio-buffer-store';\nexport * from './audio-context-constructor';\nexport * from './audio-context-constructor-factory';\nexport * from './audio-context-latency-category';\nexport * from './audio-context-state';\nexport * from './audio-destination-node-constructor';\nexport * from './audio-destination-node-constructor-factory';\nexport * from './audio-destination-node-renderer-factory';\nexport * from './audio-listener-factory';\nexport * from './audio-listener-factory-factory';\nexport * from './audio-node-connections';\nexport * from './audio-node-connections-store';\nexport * from './audio-node-constructor';\nexport * from './audio-node-constructor-factory';\nexport * from './audio-node-output-connection';\nexport * from './audio-node-renderer';\nexport * from './audio-node-store';\nexport * from './audio-param-audio-node-store';\nexport * from './audio-param-connections';\nexport * from './audio-param-connections-store';\nexport * from './audio-param-factory';\nexport * from './audio-param-factory-factory';\nexport * from './audio-param-map';\nexport * from './audio-param-output-connection';\nexport * from './audio-param-renderer-factory';\nexport * from './audio-param-store';\nexport * from './audio-worklet-node-constructor';\nexport * from './audio-worklet-node-constructor-factory';\nexport * from './audio-worklet-node-renderer-factory';\nexport * from './audio-worklet-node-renderer-factory-factory';\nexport * from './auxiliary-gain-node-store';\nexport * from './base-audio-context-constructor';\nexport * from './base-audio-context-constructor-factory';\nexport * from './biquad-filter-node-constructor';\nexport * from './biquad-filter-node-constructor-factory';\nexport * from './biquad-filter-node-renderer-factory';\nexport * from './biquad-filter-node-renderer-factory-factory';\nexport * from './biquad-filter-type';\nexport * from './channel-count-mode';\nexport * from './channel-interpretation';\nexport * from './channel-merger-node-constructor';\nexport * from './channel-merger-node-constructor-factory';\nexport * from './channel-merger-node-renderer-factory';\nexport * from './channel-merger-node-renderer-factory-factory';\nexport * from './channel-splitter-node-constructor';\nexport * from './channel-splitter-node-constructor-factory';\nexport * from './channel-splitter-node-renderer-factory';\nexport * from './channel-splitter-node-renderer-factory-factory';\nexport * from './cache-test-result-factory';\nexport * from './cache-test-result-function';\nexport * from './connect-audio-param-factory';\nexport * from './connect-audio-param-function';\nexport * from './connect-multiple-outputs-factory';\nexport * from './connect-multiple-outputs-function';\nexport * from './connect-native-audio-node-to-native-audio-node-function';\nexport * from './connected-native-audio-buffer-source-node-factory';\nexport * from './connected-native-audio-buffer-source-node-factory-factory';\nexport * from './constant-source-node-constructor';\nexport * from './constant-source-node-constructor-factory';\nexport * from './constant-source-node-renderer';\nexport * from './constant-source-node-renderer-factory';\nexport * from './constant-source-node-renderer-factory-factory';\nexport * from './constructor';\nexport * from './context';\nexport * from './context-store';\nexport * from './convert-number-to-unsigned-long-factory';\nexport * from './convert-number-to-unsigned-long-function';\nexport * from './convolver-node-constructor';\nexport * from './convolver-node-constructor-factory';\nexport * from './convolver-node-renderer-factory';\nexport * from './convolver-node-renderer-factory-factory';\nexport * from './create-native-offline-audio-context-factory';\nexport * from './create-native-offline-audio-context-function';\nexport * from './cycle-counters';\nexport * from './data-clone-error-factory';\nexport * from './decode-audio-data-factory';\nexport * from './decode-audio-data-function';\nexport * from './decode-error-callback';\nexport * from './decode-success-callback';\nexport * from './decrement-cycle-counter-factory';\nexport * from './decrement-cycle-counter-function';\nexport * from './delay-node-constructor';\nexport * from './delay-node-constructor-factory';\nexport * from './delay-node-renderer-factory';\nexport * from './delay-node-renderer-factory-factory';\nexport * from './delete-unrendered-audio-worklet-node-factory';\nexport * from './delete-unrendered-audio-worklet-node-function';\nexport * from './detect-cycles-factory';\nexport * from './detect-cycles-function';\nexport * from './disconnect-multiple-outputs-factory';\nexport * from './disconnect-multiple-outputs-function';\nexport * from './disconnect-native-audio-node-from-native-audio-node-function';\nexport * from './distance-model-type';\nexport * from './dynamics-compressor-node-constructor';\nexport * from './dynamics-compressor-node-constructor-factory';\nexport * from './dynamics-compressor-node-renderer-factory';\nexport * from './dynamics-compressor-node-renderer-factory-factory';\nexport * from './encoding-error-factory';\nexport * from './error-event-handler';\nexport * from './evaluate-audio-worklet-global-scope-function';\nexport * from './evaluate-source-factory';\nexport * from './evaluate-source-function';\nexport * from './event-handler';\nexport * from './event-target-constructor';\nexport * from './event-target-constructor-factory';\nexport * from './expose-current-frame-and-current-time-factory';\nexport * from './expose-current-frame-and-current-time-function';\nexport * from './fetch-source-factory';\nexport * from './fetch-source-function';\nexport * from './gain-node-constructor';\nexport * from './gain-node-constructor-factory';\nexport * from './gain-node-renderer-factory';\nexport * from './gain-node-renderer-factory-factory';\nexport * from './get-audio-node-connections-function';\nexport * from './get-audio-node-renderer-factory';\nexport * from './get-audio-node-renderer-function';\nexport * from './get-audio-param-connections-function';\nexport * from './get-audio-param-renderer-factory';\nexport * from './get-audio-param-renderer-function';\nexport * from './get-backup-native-context-factory';\nexport * from './get-backup-native-context-function';\nexport * from './get-native-audio-node-function';\nexport * from './get-native-audio-param-function';\nexport * from './get-native-context-function';\nexport * from './get-native-context-factory';\nexport * from './get-unrendered-audio-worklet-nodes-factory';\nexport * from './get-unrendered-audio-worklet-nodes-function';\nexport * from './get-value-for-key-function';\nexport * from './iir-filter-node-constructor';\nexport * from './iir-filter-node-constructor-factory';\nexport * from './iir-filter-node-renderer-factory';\nexport * from './iir-filter-node-renderer-factory-factory';\nexport * from './increment-cycle-counter-factory';\nexport * from './increment-cycle-counter-factory-factory';\nexport * from './increment-cycle-counter-function';\nexport * from './index-size-error-factory';\nexport * from './insert-element-in-set-function';\nexport * from './internal-state-event-listener';\nexport * from './invalid-access-error-factory';\nexport * from './invalid-state-error-factory';\nexport * from './is-active-audio-node-function';\nexport * from './is-any-audio-context-factory';\nexport * from './is-any-audio-context-function';\nexport * from './is-any-audio-node-factory';\nexport * from './is-any-audio-node-function';\nexport * from './is-any-audio-param-factory';\nexport * from './is-any-audio-param-function';\nexport * from './is-any-offline-audio-context-factory';\nexport * from './is-any-offline-audio-context-function';\nexport * from './is-dc-curve-function';\nexport * from './is-native-audio-context-factory';\nexport * from './is-native-audio-context-function';\nexport * from './is-native-audio-node-factory';\nexport * from './is-native-audio-node-function';\nexport * from './is-native-audio-param-factory';\nexport * from './is-native-audio-param-function';\nexport * from './is-native-context-factory';\nexport * from './is-native-context-function';\nexport * from './is-native-offline-audio-context-factory';\nexport * from './is-native-offline-audio-context-function';\nexport * from './is-part-of-a-cycle-function';\nexport * from './is-secure-context-factory';\nexport * from './is-supported-promise-factory';\nexport * from './media-element-audio-source-node-constructor';\nexport * from './media-element-audio-source-node-constructor-factory';\nexport * from './media-stream-audio-destination-node-constructor';\nexport * from './media-stream-audio-destination-node-constructor-factory';\nexport * from './media-stream-audio-source-node-constructor';\nexport * from './media-stream-audio-source-node-constructor-factory';\nexport * from './media-stream-track-audio-source-node-constructor';\nexport * from './media-stream-track-audio-source-node-constructor-factory';\nexport * from './minimal-audio-context-constructor';\nexport * from './minimal-audio-context-constructor-factory';\nexport * from './minimal-base-audio-context-constructor';\nexport * from './minimal-base-audio-context-constructor-factory';\nexport * from './minimal-offline-audio-context-constructor';\nexport * from './minimal-offline-audio-context-constructor-factory';\nexport * from './monitor-connections-factory';\nexport * from './monitor-connections-function';\nexport * from './native-analyser-node';\nexport * from './native-analyser-node-factory';\nexport * from './native-analyser-node-factory-factory';\nexport * from './native-audio-buffer';\nexport * from './native-audio-buffer-constructor';\nexport * from './native-audio-buffer-constructor-factory';\nexport * from './native-audio-buffer-source-node';\nexport * from './native-audio-buffer-source-node-factory';\nexport * from './native-audio-buffer-source-node-factory-factory';\nexport * from './native-audio-context';\nexport * from './native-audio-context-constructor';\nexport * from './native-audio-context-constructor-factory';\nexport * from './native-audio-destination-node';\nexport * from './native-audio-destination-node-factory';\nexport * from './native-audio-destination-node-factory-factory';\nexport * from './native-audio-listener';\nexport * from './native-audio-node';\nexport * from './native-audio-node-factory';\nexport * from './native-audio-node-factory-factory';\nexport * from './native-audio-param';\nexport * from './native-audio-param-map';\nexport * from './native-audio-worklet';\nexport * from './native-audio-worklet-node';\nexport * from './native-audio-worklet-node-constructor';\nexport * from './native-audio-worklet-node-constructor-factory';\nexport * from './native-audio-worklet-node-factory';\nexport * from './native-audio-worklet-node-factory-factory';\nexport * from './native-audio-worklet-node-faker-factory';\nexport * from './native-audio-worklet-node-faker-factory-factory';\nexport * from './native-audio-worklet-node-options';\nexport * from './native-biquad-filter-node';\nexport * from './native-biquad-filter-node-factory';\nexport * from './native-biquad-filter-node-factory-factory';\nexport * from './native-channel-merger-node';\nexport * from './native-channel-merger-node-factory';\nexport * from './native-channel-merger-node-factory-factory';\nexport * from './native-channel-splitter-node';\nexport * from './native-channel-splitter-node-factory';\nexport * from './native-channel-splitter-node-factory-factory';\nexport * from './native-constant-source-node';\nexport * from './native-constant-source-node-factory';\nexport * from './native-constant-source-node-factory-factory';\nexport * from './native-constant-source-node-faker-factory';\nexport * from './native-constant-source-node-faker-factory-factory';\nexport * from './native-context';\nexport * from './native-convolver-node';\nexport * from './native-convolver-node-factory';\nexport * from './native-convolver-node-factory-factory';\nexport * from './native-convolver-node-faker-factory';\nexport * from './native-convolver-node-faker-factory-factory';\nexport * from './native-delay-node-factory';\nexport * from './native-delay-node-factory-factory';\nexport * from './native-delay-node';\nexport * from './native-dynamics-compressor-node';\nexport * from './native-dynamics-compressor-node-factory';\nexport * from './native-dynamics-compressor-node-factory-factory';\nexport * from './native-event-target';\nexport * from './native-gain-node';\nexport * from './native-gain-node-factory';\nexport * from './native-gain-node-factory-factory';\nexport * from './native-iir-filter-node';\nexport * from './native-iir-filter-node-factory';\nexport * from './native-iir-filter-node-factory-factory';\nexport * from './native-iir-filter-node-faker-factory';\nexport * from './native-iir-filter-node-faker-factory-factory';\nexport * from './native-media-element-audio-source-node';\nexport * from './native-media-element-audio-source-node-factory';\nexport * from './native-media-element-audio-source-node-factory-factory';\nexport * from './native-media-stream-audio-destination-node';\nexport * from './native-media-stream-audio-destination-node-factory';\nexport * from './native-media-stream-audio-destination-node-factory-factory';\nexport * from './native-media-stream-audio-source-node';\nexport * from './native-media-stream-audio-source-node-factory';\nexport * from './native-media-stream-audio-source-node-factory-factory';\nexport * from './native-media-stream-track-audio-source-node';\nexport * from './native-media-stream-track-audio-source-node-factory';\nexport * from './native-media-stream-track-audio-source-node-factory-factory';\nexport * from './native-offline-audio-context';\nexport * from './native-offline-audio-context-constructor';\nexport * from './native-offline-audio-context-constructor-factory';\nexport * from './native-oscillator-node';\nexport * from './native-oscillator-node-factory';\nexport * from './native-oscillator-node-factory-factory';\nexport * from './native-panner-node';\nexport * from './native-panner-node-factory';\nexport * from './native-panner-node-factory-factory';\nexport * from './native-panner-node-faker-factory';\nexport * from './native-panner-node-faker-factory-factory';\nexport * from './native-periodic-wave';\nexport * from './native-periodic-wave-factory';\nexport * from './native-periodic-wave-factory-factory';\nexport * from './native-script-processor-node';\nexport * from './native-script-processor-node-factory';\nexport * from './native-script-processor-node-factory-factory';\nexport * from './native-stereo-panner-node';\nexport * from './native-stereo-panner-node-factory';\nexport * from './native-stereo-panner-node-factory-factory';\nexport * from './native-stereo-panner-node-faker-factory';\nexport * from './native-stereo-panner-node-faker-factory-factory';\nexport * from './native-wave-shaper-node';\nexport * from './native-wave-shaper-node-factory';\nexport * from './native-wave-shaper-node-factory-factory';\nexport * from './native-wave-shaper-node-faker-factory';\nexport * from './native-wave-shaper-node-faker-factory-factory';\nexport * from './not-supported-error-factory';\nexport * from './offline-audio-context-constructor-factory';\nexport * from './oscillator-node-constructor';\nexport * from './oscillator-node-constructor-factory';\nexport * from './oscillator-node-renderer';\nexport * from './oscillator-node-renderer-factory';\nexport * from './oscillator-node-renderer-factory-factory';\nexport * from './oscillator-type';\nexport * from './output-connection';\nexport * from './over-sample-type';\nexport * from './overwrite-accessors-function';\nexport * from './panner-node-constructor';\nexport * from './panner-node-constructor-factory';\nexport * from './panner-node-renderer-factory';\nexport * from './panner-node-renderer-factory-factory';\nexport * from './panning-model-type';\nexport * from './passive-audio-node-input-connection';\nexport * from './passive-audio-param-input-connection';\nexport * from './periodic-wave-constructor';\nexport * from './periodic-wave-constructor-factory';\nexport * from './render-automation-factory';\nexport * from './render-automation-function';\nexport * from './render-inputs-of-audio-node-factory';\nexport * from './render-inputs-of-audio-node-function';\nexport * from './render-inputs-of-audio-param-factory';\nexport * from './render-inputs-of-audio-param-function';\nexport * from './render-native-offline-audio-context-factory';\nexport * from './render-native-offline-audio-context-function';\nexport * from './start-rendering-factory';\nexport * from './start-rendering-function';\nexport * from './stereo-panner-node-constructor';\nexport * from './stereo-panner-node-constructor-factory';\nexport * from './stereo-panner-node-renderer-factory-factory';\nexport * from './stereo-panner-node-renderer-factory';\nexport * from './test-audio-buffer-copy-channel-methods-subarray-support-factory';\nexport * from './test-audio-buffer-constructor-support-factory';\nexport * from './test-audio-buffer-source-node-start-method-consecutive-calls-support-factory';\nexport * from './test-audio-buffer-source-node-start-method-duration-parameter-support-factory';\nexport * from './test-audio-buffer-source-node-start-method-offset-clamping-support-factory';\nexport * from './test-audio-buffer-source-node-stop-method-nullified-buffer-support-factory';\nexport * from './test-audio-context-close-method-support-factory';\nexport * from './test-audio-context-decode-audio-data-method-type-error-support-factory';\nexport * from './test-audio-context-options-support-factory';\nexport * from './test-audio-node-connect-method-support-factory';\nexport * from './test-audio-scheduled-source-node-start-method-consecutive-calls-support-factory';\nexport * from './test-audio-scheduled-source-node-stop-method-consecutive-calls-support-factory';\nexport * from './test-audio-scheduled-source-node-stop-method-negative-parameters-support-factory';\nexport * from './test-audio-worklet-processor-no-outputs-support-factory';\nexport * from './test-channel-merger-node-channel-count-support-factory';\nexport * from './test-constant-source-node-accurate-scheduling-support-factory';\nexport * from './test-convolver-node-buffer-reassignability-support-factory';\nexport * from './test-is-secure-context-support-factory';\nexport * from './test-media-stream-audio-source-node-media-stream-without-audio-track-support';\nexport * from './test-offline-audio-context-current-time-support-factory';\nexport * from './test-stereo-panner-node-default-value-support-factory';\nexport * from './typed-array';\nexport * from './unknown-error-factory';\nexport * from './unrendered-audio-worklet-node-store';\nexport * from './unrendered-audio-worklet-nodes';\nexport * from './wave-shaper-node-constructor';\nexport * from './wave-shaper-node-constructor-factory';\nexport * from './wave-shaper-node-renderer-factory-factory';\nexport * from './wave-shaper-node-renderer-factory';\nexport * from './window-factory';\nexport * from './wrap-audio-buffer-copy-channel-methods-factory';\nexport * from './wrap-audio-buffer-copy-channel-methods-function';\nexport * from './wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory';\nexport * from './wrap-audio-buffer-copy-channel-methods-out-of-bounds-function';\nexport * from './wrap-audio-buffer-source-node-start-method-offset-clamping-function';\nexport * from './wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory';\nexport * from './wrap-audio-buffer-source-node-stop-method-nullified-buffer-function';\nexport * from './wrap-audio-scheduled-source-node-stop-method-consecutive-calls-factory';\nexport * from './wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function';\nexport * from './wrap-channel-merger-node-factory';\nexport * from './wrap-channel-merger-node-function';\nexport * from './wrap-event-listener-function';\n//# sourceMappingURL=/build/es2019/types/index.js.map","//# sourceMappingURL=/build/es2019/types/insert-element-in-set-function.js.map","//# sourceMappingURL=/build/es2019/types/internal-state-event-listener.js.map","//# sourceMappingURL=/build/es2019/types/invalid-access-error-factory.js.map","//# sourceMappingURL=/build/es2019/types/invalid-state-error-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-active-audio-node-function.js.map","//# sourceMappingURL=/build/es2019/types/is-any-audio-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-any-audio-context-function.js.map","//# sourceMappingURL=/build/es2019/types/is-any-audio-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-any-audio-node-function.js.map","//# sourceMappingURL=/build/es2019/types/is-any-audio-param-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-any-audio-param-function.js.map","//# sourceMappingURL=/build/es2019/types/is-any-offline-audio-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-any-offline-audio-context-function.js.map","//# sourceMappingURL=/build/es2019/types/is-dc-curve-function.js.map","//# sourceMappingURL=/build/es2019/types/is-native-audio-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-native-audio-context-function.js.map","//# sourceMappingURL=/build/es2019/types/is-native-audio-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-native-audio-node-function.js.map","//# sourceMappingURL=/build/es2019/types/is-native-audio-param-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-native-audio-param-function.js.map","//# sourceMappingURL=/build/es2019/types/is-native-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-native-context-function.js.map","//# sourceMappingURL=/build/es2019/types/is-native-offline-audio-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-native-offline-audio-context-function.js.map","//# sourceMappingURL=/build/es2019/types/is-part-of-a-cycle-function.js.map","//# sourceMappingURL=/build/es2019/types/is-secure-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/is-supported-promise-factory.js.map","//# sourceMappingURL=/build/es2019/types/media-element-audio-source-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/media-element-audio-source-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/media-stream-audio-destination-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/media-stream-audio-source-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/media-stream-audio-source-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/media-stream-track-audio-source-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/minimal-audio-context-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/minimal-audio-context-constructor.js.map","//# sourceMappingURL=/build/es2019/types/minimal-base-audio-context-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/minimal-base-audio-context-constructor.js.map","//# sourceMappingURL=/build/es2019/types/minimal-offline-audio-context-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/minimal-offline-audio-context-constructor.js.map","//# sourceMappingURL=/build/es2019/types/monitor-connections-factory.js.map","//# sourceMappingURL=/build/es2019/types/monitor-connections-function.js.map","//# sourceMappingURL=/build/es2019/types/native-analyser-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-analyser-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-analyser-node.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-buffer-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-buffer-constructor.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-buffer-source-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-buffer-source-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-buffer-source-node.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-buffer.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-context-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-context-constructor.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-context.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-destination-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-destination-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-destination-node.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-listener.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-node.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-param-map.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-param.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet-node-faker-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet-node-options.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet-node.js.map","//# sourceMappingURL=/build/es2019/types/native-audio-worklet.js.map","//# sourceMappingURL=/build/es2019/types/native-biquad-filter-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-biquad-filter-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-biquad-filter-node.js.map","//# sourceMappingURL=/build/es2019/types/native-channel-merger-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-channel-merger-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-channel-merger-node.js.map","//# sourceMappingURL=/build/es2019/types/native-channel-splitter-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-channel-splitter-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-channel-splitter-node.js.map","//# sourceMappingURL=/build/es2019/types/native-constant-source-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-constant-source-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-constant-source-node-faker-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-constant-source-node-faker-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-constant-source-node.js.map","//# sourceMappingURL=/build/es2019/types/native-context.js.map","//# sourceMappingURL=/build/es2019/types/native-convolver-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-convolver-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-convolver-node-faker-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-convolver-node-faker-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-convolver-node.js.map","//# sourceMappingURL=/build/es2019/types/native-delay-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-delay-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-delay-node.js.map","//# sourceMappingURL=/build/es2019/types/native-dynamics-compressor-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-dynamics-compressor-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-dynamics-compressor-node.js.map","//# sourceMappingURL=/build/es2019/types/native-event-target.js.map","//# sourceMappingURL=/build/es2019/types/native-gain-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-gain-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-gain-node.js.map","//# sourceMappingURL=/build/es2019/types/native-iir-filter-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-iir-filter-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-iir-filter-node-faker-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-iir-filter-node-faker-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-iir-filter-node.js.map","//# sourceMappingURL=/build/es2019/types/native-media-element-audio-source-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-media-element-audio-source-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-media-element-audio-source-node.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-audio-destination-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-audio-destination-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-audio-destination-node.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-audio-source-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-audio-source-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-audio-source-node.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-track-audio-source-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-media-stream-track-audio-source-node.js.map","//# sourceMappingURL=/build/es2019/types/native-offline-audio-context-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-offline-audio-context-constructor.js.map","//# sourceMappingURL=/build/es2019/types/native-offline-audio-context.js.map","//# sourceMappingURL=/build/es2019/types/native-oscillator-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-oscillator-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-oscillator-node.js.map","//# sourceMappingURL=/build/es2019/types/native-panner-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-panner-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-panner-node-faker-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-panner-node-faker-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-panner-node.js.map","//# sourceMappingURL=/build/es2019/types/native-periodic-wave-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-periodic-wave-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-periodic-wave.js.map","//# sourceMappingURL=/build/es2019/types/native-script-processor-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-script-processor-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-script-processor-node.js.map","//# sourceMappingURL=/build/es2019/types/native-stereo-panner-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-stereo-panner-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-stereo-panner-node-faker-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-stereo-panner-node.js.map","//# sourceMappingURL=/build/es2019/types/native-wave-shaper-node-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-wave-shaper-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-wave-shaper-node-faker-factory.js.map","//# sourceMappingURL=/build/es2019/types/native-wave-shaper-node.js.map","//# sourceMappingURL=/build/es2019/types/not-supported-error-factory.js.map","//# sourceMappingURL=/build/es2019/types/offline-audio-context-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/oscillator-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/oscillator-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/oscillator-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/oscillator-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/oscillator-node-renderer.js.map","//# sourceMappingURL=/build/es2019/types/oscillator-type.js.map","//# sourceMappingURL=/build/es2019/types/output-connection.js.map","//# sourceMappingURL=/build/es2019/types/over-sample-type.js.map","//# sourceMappingURL=/build/es2019/types/overwrite-accessors-function.js.map","//# sourceMappingURL=/build/es2019/types/panner-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/panner-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/panner-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/panner-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/panning-model-type.js.map","//# sourceMappingURL=/build/es2019/types/passive-audio-node-input-connection.js.map","//# sourceMappingURL=/build/es2019/types/passive-audio-param-input-connection.js.map","//# sourceMappingURL=/build/es2019/types/periodic-wave-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/periodic-wave-constructor.js.map","//# sourceMappingURL=/build/es2019/types/render-automation-factory.js.map","//# sourceMappingURL=/build/es2019/types/render-automation-function.js.map","//# sourceMappingURL=/build/es2019/types/render-inputs-of-audio-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/render-inputs-of-audio-node-function.js.map","//# sourceMappingURL=/build/es2019/types/render-inputs-of-audio-param-factory.js.map","//# sourceMappingURL=/build/es2019/types/render-inputs-of-audio-param-function.js.map","//# sourceMappingURL=/build/es2019/types/render-native-offline-audio-context-factory.js.map","//# sourceMappingURL=/build/es2019/types/render-native-offline-audio-context-function.js.map","//# sourceMappingURL=/build/es2019/types/start-rendering-factory.js.map","//# sourceMappingURL=/build/es2019/types/start-rendering-function.js.map","//# sourceMappingURL=/build/es2019/types/stereo-panner-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/stereo-panner-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/stereo-panner-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/stereo-panner-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-buffer-constructor-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-buffer-source-node-start-method-consecutive-calls-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-buffer-source-node-start-method-duration-parameter-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-buffer-source-node-start-method-offset-clamping-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-buffer-source-node-stop-method-nullified-buffer-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-context-close-method-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-context-options-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-node-connect-method-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-scheduled-source-node-start-method-consecutive-calls-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-scheduled-source-node-stop-method-consecutive-calls-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-scheduled-source-node-stop-method-negative-parameters-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-is-secure-context-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js.map","//# sourceMappingURL=/build/es2019/types/test-offline-audio-context-current-time-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js.map","//# sourceMappingURL=/build/es2019/types/typed-array.js.map","//# sourceMappingURL=/build/es2019/types/unknown-error-factory.js.map","//# sourceMappingURL=/build/es2019/types/unrendered-audio-worklet-node-store.js.map","//# sourceMappingURL=/build/es2019/types/unrendered-audio-worklet-nodes.js.map","//# sourceMappingURL=/build/es2019/types/wave-shaper-node-constructor-factory.js.map","//# sourceMappingURL=/build/es2019/types/wave-shaper-node-constructor.js.map","//# sourceMappingURL=/build/es2019/types/wave-shaper-node-renderer-factory-factory.js.map","//# sourceMappingURL=/build/es2019/types/wave-shaper-node-renderer-factory.js.map","//# sourceMappingURL=/build/es2019/types/window-factory.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-factory.js.map","//# sourceMappingURL=/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js.map","//# sourceMappingURL=/build/es2019/types/wrap-channel-merger-node-factory.js.map","//# sourceMappingURL=/build/es2019/types/wrap-channel-merger-node-function.js.map","//# sourceMappingURL=/build/es2019/types/wrap-event-listener-function.js.map","export * from \"./core/index\";\nexport * from \"./source/index\";\nexport * from \"./signal/index\";\nexport * from \"./instrument/index\";\nexport * from \"./event/index\";\nexport * from \"./effect/index\";\nexport * from \"./component/index\";\n//# sourceMappingURL=classes.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Split } from \"../channel/Split\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { assert, assertRange } from \"../../core/util/Debug\";\n/**\n * Wrapper around the native Web Audio's [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).\n * Extracts FFT or Waveform data from the incoming signal.\n * @category Component\n */\nexport class Analyser extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Analyser.getDefaults(), arguments, [\"type\", \"size\"]));\n        this.name = \"Analyser\";\n        /**\n         * The analyser node.\n         */\n        this._analysers = [];\n        /**\n         * The buffer that the FFT data is written to\n         */\n        this._buffers = [];\n        const options = optionsFromArguments(Analyser.getDefaults(), arguments, [\"type\", \"size\"]);\n        this.input = this.output = this._gain = new Gain({ context: this.context });\n        this._split = new Split({\n            context: this.context,\n            channels: options.channels,\n        });\n        this.input.connect(this._split);\n        assertRange(options.channels, 1);\n        // create the analysers\n        for (let channel = 0; channel < options.channels; channel++) {\n            this._analysers[channel] = this.context.createAnalyser();\n            this._split.connect(this._analysers[channel], channel, 0);\n        }\n        // set the values initially\n        this.size = options.size;\n        this.type = options.type;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            size: 1024,\n            smoothing: 0.8,\n            type: \"fft\",\n            channels: 1,\n        });\n    }\n    /**\n     * Run the analysis given the current settings. If [[channels]] = 1,\n     * it will return a Float32Array. If [[channels]] > 1, it will\n     * return an array of Float32Arrays where each index in the array\n     * represents the analysis done on a channel.\n     */\n    getValue() {\n        this._analysers.forEach((analyser, index) => {\n            const buffer = this._buffers[index];\n            if (this._type === \"fft\") {\n                analyser.getFloatFrequencyData(buffer);\n            }\n            else if (this._type === \"waveform\") {\n                analyser.getFloatTimeDomainData(buffer);\n            }\n        });\n        if (this.channels === 1) {\n            return this._buffers[0];\n        }\n        else {\n            return this._buffers;\n        }\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     */\n    get size() {\n        return this._analysers[0].frequencyBinCount;\n    }\n    set size(size) {\n        this._analysers.forEach((analyser, index) => {\n            analyser.fftSize = size * 2;\n            this._buffers[index] = new Float32Array(size);\n        });\n    }\n    /**\n     * The number of channels the analyser does the analysis on. Channel\n     * separation is done using [[Split]]\n     */\n    get channels() {\n        return this._analysers.length;\n    }\n    /**\n     * The analysis function returned by analyser.getValue(), either \"fft\" or \"waveform\".\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        assert(type === \"waveform\" || type === \"fft\", `Analyser: invalid type: ${type}`);\n        this._type = type;\n    }\n    /**\n     * 0 represents no time averaging with the last analysis frame.\n     */\n    get smoothing() {\n        return this._analysers[0].smoothingTimeConstant;\n    }\n    set smoothing(val) {\n        this._analysers.forEach(a => a.smoothingTimeConstant = val);\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._analysers.forEach(a => a.disconnect());\n        this._split.dispose();\n        this._gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Analyser.js.map","import { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { MeterBase } from \"./MeterBase\";\n/**\n * DCMeter gets the raw value of the input signal at the current time.\n *\n * @example\n * const meter = new Tone.DCMeter();\n * const mic = new Tone.UserMedia();\n * mic.open();\n * // connect mic to the meter\n * mic.connect(meter);\n * // the current level of the mic\n * const level = meter.getValue();\n * @category Component\n */\nexport class DCMeter extends MeterBase {\n    constructor() {\n        super(optionsFromArguments(DCMeter.getDefaults(), arguments));\n        this.name = \"DCMeter\";\n        this._analyser.type = \"waveform\";\n        this._analyser.size = 256;\n    }\n    /**\n     * Get the signal value of the incoming signal\n     */\n    getValue() {\n        const value = this._analyser.getValue();\n        return value[0];\n    }\n}\n//# sourceMappingURL=DCMeter.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { dbToGain } from \"../../core/type/Conversions\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { MeterBase } from \"./MeterBase\";\n/**\n * Get the current frequency data of the connected audio source using a fast Fourier transform.\n * @category Component\n */\nexport class FFT extends MeterBase {\n    constructor() {\n        super(optionsFromArguments(FFT.getDefaults(), arguments, [\"size\"]));\n        this.name = \"FFT\";\n        const options = optionsFromArguments(FFT.getDefaults(), arguments, [\"size\"]);\n        this.normalRange = options.normalRange;\n        this._analyser.type = \"fft\";\n        this.size = options.size;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            normalRange: false,\n            size: 1024,\n            smoothing: 0.8,\n        });\n    }\n    /**\n     * Gets the current frequency data from the connected audio source.\n     * Returns the frequency data of length [[size]] as a Float32Array of decibel values.\n     */\n    getValue() {\n        const values = this._analyser.getValue();\n        return values.map(v => this.normalRange ? dbToGain(v) : v);\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     * Determines the size of the array returned by [[getValue]] (i.e. the number of\n     * frequency bins). Large FFT sizes may be costly to compute.\n     */\n    get size() {\n        return this._analyser.size;\n    }\n    set size(size) {\n        this._analyser.size = size;\n    }\n    /**\n     * 0 represents no time averaging with the last analysis frame.\n     */\n    get smoothing() {\n        return this._analyser.smoothing;\n    }\n    set smoothing(val) {\n        this._analyser.smoothing = val;\n    }\n}\n//# sourceMappingURL=FFT.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { OnePoleFilter } from \"../filter/OnePoleFilter\";\nimport { Abs } from \"../../signal/Abs\";\n/**\n * Follower is a simple envelope follower.\n * It's implemented by applying a lowpass filter to the absolute value of the incoming signal.\n * ```\n *          +-----+    +---------------+\n * Input +--> Abs +----> OnePoleFilter +--> Output\n *          +-----+    +---------------+\n * ```\n * @category Component\n */\nexport class Follower extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Follower.getDefaults(), arguments, [\"smoothing\"]));\n        this.name = \"Follower\";\n        const options = optionsFromArguments(Follower.getDefaults(), arguments, [\"smoothing\"]);\n        this._abs = this.input = new Abs({ context: this.context });\n        this._lowpass = this.output = new OnePoleFilter({\n            context: this.context,\n            frequency: 1 / this.toSeconds(options.smoothing),\n            type: \"lowpass\"\n        });\n        this._abs.connect(this._lowpass);\n        this._smoothing = options.smoothing;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            smoothing: 0.05\n        });\n    }\n    /**\n     * The amount of time it takes a value change to arrive at the updated value.\n     */\n    get smoothing() {\n        return this._smoothing;\n    }\n    set smoothing(smoothing) {\n        this._smoothing = smoothing;\n        this._lowpass.frequency = 1 / this.toSeconds(this.smoothing);\n    }\n    dispose() {\n        super.dispose();\n        this._abs.dispose();\n        this._lowpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Follower.js.map","import { gainToDb } from \"../../core/type/Conversions\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { MeterBase } from \"./MeterBase\";\nimport { warn } from \"../../core/util/Debug\";\nimport { Analyser } from \"./Analyser\";\n/**\n * Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)\n * of an input signal. It can also get the raw value of the input signal.\n *\n * @example\n * const meter = new Tone.Meter();\n * const mic = new Tone.UserMedia();\n * mic.open();\n * // connect mic to the meter\n * mic.connect(meter);\n * // the current level of the mic\n * const level = meter.getValue();\n * @category Component\n */\nexport class Meter extends MeterBase {\n    constructor() {\n        super(optionsFromArguments(Meter.getDefaults(), arguments, [\"smoothing\"]));\n        this.name = \"Meter\";\n        /**\n         * The previous frame's value\n         */\n        this._rms = 0;\n        const options = optionsFromArguments(Meter.getDefaults(), arguments, [\"smoothing\"]);\n        this.input = this.output = this._analyser = new Analyser({\n            context: this.context,\n            size: 256,\n            type: \"waveform\",\n            channels: options.channels,\n        });\n        this.smoothing = options.smoothing,\n            this.normalRange = options.normalRange;\n    }\n    static getDefaults() {\n        return Object.assign(MeterBase.getDefaults(), {\n            smoothing: 0.8,\n            normalRange: false,\n            channels: 1,\n        });\n    }\n    /**\n     * Use [[getValue]] instead. For the previous getValue behavior, use DCMeter.\n     * @deprecated\n     */\n    getLevel() {\n        warn(\"'getLevel' has been changed to 'getValue'\");\n        return this.getValue();\n    }\n    /**\n     * Get the current value of the incoming signal.\n     * Output is in decibels when [[normalRange]] is `false`.\n     * If [[channels]] = 1, then the output is a single number\n     * representing the value of the input signal. When [[channels]] > 1,\n     * then each channel is returned as a value in a number array.\n     */\n    getValue() {\n        const aValues = this._analyser.getValue();\n        const channelValues = this.channels === 1 ? [aValues] : aValues;\n        const vals = channelValues.map(values => {\n            const totalSquared = values.reduce((total, current) => total + current * current, 0);\n            const rms = Math.sqrt(totalSquared / values.length);\n            // the rms can only fall at the rate of the smoothing\n            // but can jump up instantly\n            this._rms = Math.max(rms, this._rms * this.smoothing);\n            return this.normalRange ? this._rms : gainToDb(this._rms);\n        });\n        if (this.channels === 1) {\n            return vals[0];\n        }\n        else {\n            return vals;\n        }\n    }\n    /**\n     * The number of channels of analysis.\n     */\n    get channels() {\n        return this._analyser.channels;\n    }\n    dispose() {\n        super.dispose();\n        this._analyser.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Meter.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Analyser } from \"./Analyser\";\n/**\n * The base class for Metering classes.\n */\nexport class MeterBase extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(MeterBase.getDefaults(), arguments));\n        this.name = \"MeterBase\";\n        this.input = this.output = this._analyser = new Analyser({\n            context: this.context,\n            size: 256,\n            type: \"waveform\",\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._analyser.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MeterBase.js.map","import { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { MeterBase } from \"./MeterBase\";\n/**\n * Get the current waveform data of the connected audio source.\n * @category Component\n */\nexport class Waveform extends MeterBase {\n    constructor() {\n        super(optionsFromArguments(Waveform.getDefaults(), arguments, [\"size\"]));\n        this.name = \"Waveform\";\n        const options = optionsFromArguments(Waveform.getDefaults(), arguments, [\"size\"]);\n        this._analyser.type = \"waveform\";\n        this.size = options.size;\n    }\n    static getDefaults() {\n        return Object.assign(MeterBase.getDefaults(), {\n            size: 1024,\n        });\n    }\n    /**\n     * Return the waveform for the current time as a Float32Array where each value in the array\n     * represents a sample in the waveform.\n     */\n    getValue() {\n        return this._analyser.getValue();\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     * Determines the size of the array returned by [[getValue]].\n     */\n    get size() {\n        return this._analyser.size;\n    }\n    set size(size) {\n        this._analyser.size = size;\n    }\n}\n//# sourceMappingURL=Waveform.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Solo } from \"./Solo\";\nimport { PanVol } from \"./PanVol\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { Gain } from \"../../core/context/Gain\";\n/**\n * Channel provides a channel strip interface with volume, pan, solo and mute controls.\n * See [[PanVol]] and [[Solo]]\n * @example\n * // pan the incoming signal left and drop the volume 12db\n * const channel = new Tone.Channel(-0.25, -12);\n * @category Component\n */\nexport class Channel extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Channel.getDefaults(), arguments, [\"volume\", \"pan\"]));\n        this.name = \"Channel\";\n        const options = optionsFromArguments(Channel.getDefaults(), arguments, [\"volume\", \"pan\"]);\n        this._solo = this.input = new Solo({\n            solo: options.solo,\n            context: this.context,\n        });\n        this._panVol = this.output = new PanVol({\n            context: this.context,\n            pan: options.pan,\n            volume: options.volume,\n            mute: options.mute,\n        });\n        this.pan = this._panVol.pan;\n        this.volume = this._panVol.volume;\n        this._solo.connect(this._panVol);\n        readOnly(this, [\"pan\", \"volume\"]);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            pan: 0,\n            volume: 0,\n            mute: false,\n            solo: false\n        });\n    }\n    /**\n     * Solo/unsolo the channel. Soloing is only relative to other [[Channels]] and [[Solo]] instances\n     */\n    get solo() {\n        return this._solo.solo;\n    }\n    set solo(solo) {\n        this._solo.solo = solo;\n    }\n    /**\n     * If the current instance is muted, i.e. another instance is soloed,\n     * or the channel is muted\n     */\n    get muted() {\n        return this._solo.muted || this.mute;\n    }\n    /**\n     * Mute/unmute the volume\n     */\n    get mute() {\n        return this._panVol.mute;\n    }\n    set mute(mute) {\n        this._panVol.mute = mute;\n    }\n    /**\n     * Get the gain node belonging to the bus name. Create it if\n     * it doesn't exist\n     * @param name The bus name\n     */\n    _getBus(name) {\n        if (!Channel.buses.has(name)) {\n            Channel.buses.set(name, new Gain({ context: this.context }));\n        }\n        return Channel.buses.get(name);\n    }\n    /**\n     * Send audio to another channel using a string. `send` is a lot like\n     * [[connect]], except it uses a string instead of an object. This can\n     * be useful in large applications to decouple sections since [[send]]\n     * and [[receive]] can be invoked separately in order to connect an object\n     * @param name The channel name to send the audio\n     * @param volume The amount of the signal to send.\n     * \tDefaults to 0db, i.e. send the entire signal\n     * @returns Returns the gain node of this connection.\n     */\n    send(name, volume = 0) {\n        const bus = this._getBus(name);\n        const sendKnob = new Gain({\n            context: this.context,\n            units: \"decibels\",\n            gain: volume,\n        });\n        this.connect(sendKnob);\n        sendKnob.connect(bus);\n        return sendKnob;\n    }\n    /**\n     * Receive audio from a channel which was connected with [[send]].\n     * @param name The channel name to receive audio from.\n     */\n    receive(name) {\n        const bus = this._getBus(name);\n        bus.connect(this);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._panVol.dispose();\n        this.pan.dispose();\n        this.volume.dispose();\n        this._solo.dispose();\n        return this;\n    }\n}\n/**\n * Store the send/receive channels by name.\n */\nChannel.buses = new Map();\n//# sourceMappingURL=Channel.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { connect, ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { GainToAudio } from \"../../signal/GainToAudio\";\nimport { Signal } from \"../../signal/Signal\";\n/**\n * Tone.Crossfade provides equal power fading between two inputs.\n * More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).\n * ```\n *                                             +---------+\n *                                            +> input a +>--+\n * +-----------+   +---------------------+     |         |   |\n * | 1s signal +>--> stereoPannerNode  L +>----> gain    |   |\n * +-----------+   |                     |     +---------+   |\n *               +-> pan               R +>-+                |   +--------+\n *               | +---------------------+  |                +---> output +>\n *  +------+     |                          |  +---------+   |   +--------+\n *  | fade +>----+                          | +> input b +>--+\n *  +------+                                |  |         |\n *                                          +--> gain    |\n *                                             +---------+\n * ```\n * @example\n * const crossFade = new Tone.CrossFade().toDestination();\n * // connect two inputs Tone.to a/b\n * const inputA = new Tone.Oscillator(440, \"square\").connect(crossFade.a).start();\n * const inputB = new Tone.Oscillator(440, \"sine\").connect(crossFade.b).start();\n * // use the fade to control the mix between the two\n * crossFade.fade.value = 0.5;\n * @category Component\n */\nexport class CrossFade extends ToneAudioNode {\n    constructor() {\n        super(Object.assign(optionsFromArguments(CrossFade.getDefaults(), arguments, [\"fade\"])));\n        this.name = \"CrossFade\";\n        /**\n         * The crossfading is done by a StereoPannerNode\n         */\n        this._panner = this.context.createStereoPanner();\n        /**\n         * Split the output of the panner node into two values used to control the gains.\n         */\n        this._split = this.context.createChannelSplitter(2);\n        /**\n         * Convert the fade value into an audio range value so it can be connected\n         * to the panner.pan AudioParam\n         */\n        this._g2a = new GainToAudio({ context: this.context });\n        /**\n         * The input which is at full level when fade = 0\n         */\n        this.a = new Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The input which is at full level when fade = 1\n         */\n        this.b = new Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The output is a mix between `a` and `b` at the ratio of `fade`\n         */\n        this.output = new Gain({ context: this.context });\n        this._internalChannels = [this.a, this.b];\n        const options = optionsFromArguments(CrossFade.getDefaults(), arguments, [\"fade\"]);\n        this.fade = new Signal({\n            context: this.context,\n            units: \"normalRange\",\n            value: options.fade,\n        });\n        readOnly(this, \"fade\");\n        this.context.getConstant(1).connect(this._panner);\n        this._panner.connect(this._split);\n        // this is necessary for standardized-audio-context\n        // doesn't make any difference for the native AudioContext\n        // https://github.com/chrisguttandin/standardized-audio-context/issues/647\n        this._panner.channelCount = 1;\n        this._panner.channelCountMode = \"explicit\";\n        connect(this._split, this.a.gain, 0);\n        connect(this._split, this.b.gain, 1);\n        this.fade.chain(this._g2a, this._panner.pan);\n        this.a.connect(this.output);\n        this.b.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            fade: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.a.dispose();\n        this.b.dispose();\n        this.output.dispose();\n        this.fade.dispose();\n        this._g2a.dispose();\n        this._panner.disconnect();\n        this._split.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=CrossFade.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\n/**\n * Merge brings multiple mono input channels into a single multichannel output channel.\n *\n * @example\n * const merge = new Tone.Merge().toDestination();\n * // routing a sine tone in the left channel\n * const osc = new Tone.Oscillator().connect(merge, 0, 0).start();\n * // and noise in the right channel\n * const noise = new Tone.Noise().connect(merge, 0, 1).start();;\n * @category Component\n */\nexport class Merge extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Merge.getDefaults(), arguments, [\"channels\"]));\n        this.name = \"Merge\";\n        const options = optionsFromArguments(Merge.getDefaults(), arguments, [\"channels\"]);\n        this._merger = this.output = this.input = this.context.createChannelMerger(options.channels);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            channels: 2,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._merger.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Merge.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { Merge } from \"./Merge\";\nimport { Add } from \"../../signal/Add\";\nimport { Multiply } from \"../../signal/Multiply\";\nimport { Subtract } from \"../../signal/Subtract\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\n/**\n * MidSideMerge merges the mid and side signal after they've been separated by [[MidSideMerge]]\n * ```\n * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right\n * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and righ\n * ```\n */\nexport class MidSideMerge extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(MidSideMerge.getDefaults(), arguments));\n        this.name = \"MidSideMerge\";\n        this.mid = new Gain({ context: this.context });\n        this.side = new Gain({ context: this.context });\n        this._left = new Add({ context: this.context });\n        this._leftMult = new Multiply({\n            context: this.context,\n            value: Math.SQRT1_2\n        });\n        this._right = new Subtract({ context: this.context });\n        this._rightMult = new Multiply({\n            context: this.context,\n            value: Math.SQRT1_2\n        });\n        this._merge = this.output = new Merge({ context: this.context });\n        this.mid.fan(this._left);\n        this.side.connect(this._left.addend);\n        this.mid.connect(this._right);\n        this.side.connect(this._right.subtrahend);\n        this._left.connect(this._leftMult);\n        this._right.connect(this._rightMult);\n        this._leftMult.connect(this._merge, 0, 0);\n        this._rightMult.connect(this._merge, 0, 1);\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._leftMult.dispose();\n        this._rightMult.dispose();\n        this._left.dispose();\n        this._right.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideMerge.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { Split } from \"./Split\";\nimport { Add } from \"../../signal/Add\";\nimport { Multiply } from \"../../signal/Multiply\";\nimport { Subtract } from \"../../signal/Subtract\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\n/**\n * Mid/Side processing separates the the 'mid' signal (which comes out of both the left and the right channel)\n * and the 'side' (which only comes out of the the side channels).\n * ```\n * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right\n * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right\n * ```\n */\nexport class MidSideSplit extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(MidSideSplit.getDefaults(), arguments));\n        this.name = \"MidSideSplit\";\n        this._split = this.input = new Split({\n            channels: 2,\n            context: this.context\n        });\n        this._midAdd = new Add({ context: this.context });\n        this.mid = new Multiply({\n            context: this.context,\n            value: Math.SQRT1_2,\n        });\n        this._sideSubtract = new Subtract({ context: this.context });\n        this.side = new Multiply({\n            context: this.context,\n            value: Math.SQRT1_2,\n        });\n        this._split.connect(this._midAdd, 0);\n        this._split.connect(this._midAdd.addend, 1);\n        this._split.connect(this._sideSubtract, 0);\n        this._split.connect(this._sideSubtract.subtrahend, 1);\n        this._midAdd.connect(this.mid);\n        this._sideSubtract.connect(this.side);\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._midAdd.dispose();\n        this._sideSubtract.dispose();\n        this._split.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideSplit.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly, writable } from \"../../core/util/Interface\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Filter } from \"../filter/Filter\";\n/**\n * Split the incoming signal into three bands (low, mid, high)\n * with two crossover frequency controls.\n * ```\n *            +----------------------+\n *          +-> input < lowFrequency +------------------> low\n *          | +----------------------+\n *          |\n *          | +--------------------------------------+\n * input ---+-> lowFrequency < input < highFrequency +--> mid\n *          | +--------------------------------------+\n *          |\n *          | +-----------------------+\n *          +-> highFrequency < input +-----------------> high\n *            +-----------------------+\n * ```\n * @category Component\n */\nexport class MultibandSplit extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(MultibandSplit.getDefaults(), arguments, [\"lowFrequency\", \"highFrequency\"]));\n        this.name = \"MultibandSplit\";\n        /**\n         * the input\n         */\n        this.input = new Gain({ context: this.context });\n        /**\n         * no output node, use either low, mid or high outputs\n         */\n        this.output = undefined;\n        /**\n         * The low band.\n         */\n        this.low = new Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"lowpass\",\n        });\n        /**\n         * the lower filter of the mid band\n         */\n        this._lowMidFilter = new Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"highpass\",\n        });\n        /**\n         * The mid band output.\n         */\n        this.mid = new Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"lowpass\",\n        });\n        /**\n         * The high band output.\n         */\n        this.high = new Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"highpass\",\n        });\n        this._internalChannels = [this.low, this.mid, this.high];\n        const options = optionsFromArguments(MultibandSplit.getDefaults(), arguments, [\"lowFrequency\", \"highFrequency\"]);\n        this.lowFrequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.lowFrequency,\n        });\n        this.highFrequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.highFrequency,\n        });\n        this.Q = new Signal({\n            context: this.context,\n            units: \"positive\",\n            value: options.Q,\n        });\n        this.input.fan(this.low, this.high);\n        this.input.chain(this._lowMidFilter, this.mid);\n        // the frequency control signal\n        this.lowFrequency.fan(this.low.frequency, this._lowMidFilter.frequency);\n        this.highFrequency.fan(this.mid.frequency, this.high.frequency);\n        // the Q value\n        this.Q.connect(this.low.Q);\n        this.Q.connect(this._lowMidFilter.Q);\n        this.Q.connect(this.mid.Q);\n        this.Q.connect(this.high.Q);\n        readOnly(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            Q: 1,\n            highFrequency: 2500,\n            lowFrequency: 400,\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        writable(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n        this.low.dispose();\n        this._lowMidFilter.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.lowFrequency.dispose();\n        this.highFrequency.dispose();\n        this.Q.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MultibandSplit.js.map","import { readOnly } from \"../../core/util/Interface\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Panner } from \"./Panner\";\nimport { Volume } from \"./Volume\";\n/**\n * PanVol is a Tone.Panner and Tone.Volume in one.\n * @example\n * // pan the incoming signal left and drop the volume\n * const panVol = new Tone.PanVol(-0.25, -12).toDestination();\n * const osc = new Tone.Oscillator().connect(panVol).start();\n * @category Component\n */\nexport class PanVol extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(PanVol.getDefaults(), arguments, [\"pan\", \"volume\"]));\n        this.name = \"PanVol\";\n        const options = optionsFromArguments(PanVol.getDefaults(), arguments, [\"pan\", \"volume\"]);\n        this._panner = this.input = new Panner({\n            context: this.context,\n            pan: options.pan,\n            channelCount: options.channelCount,\n        });\n        this.pan = this._panner.pan;\n        this._volume = this.output = new Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        // connections\n        this._panner.connect(this._volume);\n        this.mute = options.mute;\n        readOnly(this, [\"pan\", \"volume\"]);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            mute: false,\n            pan: 0,\n            volume: 0,\n            channelCount: 1,\n        });\n    }\n    /**\n     * Mute/unmute the volume\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    dispose() {\n        super.dispose();\n        this._panner.dispose();\n        this.pan.dispose();\n        this._volume.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PanVol.js.map","import { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\n/**\n * Panner is an equal power Left/Right Panner. It is a wrapper around the StereoPannerNode.\n * @offline 0.5 2\n * @example\n * // move the input signal from right to left\n * const panner = new Tone.Panner(1).toDestination();\n * panner.pan.rampTo(-1, 0.5);\n * const osc = new Tone.Oscillator(100).connect(panner).start();\n * @category Component\n */\nexport class Panner extends ToneAudioNode {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Panner.getDefaults(), arguments, [\"pan\"])));\n        this.name = \"Panner\";\n        /**\n         * the panner node\n         */\n        this._panner = this.context.createStereoPanner();\n        this.input = this._panner;\n        this.output = this._panner;\n        const options = optionsFromArguments(Panner.getDefaults(), arguments, [\"pan\"]);\n        this.pan = new Param({\n            context: this.context,\n            param: this._panner.pan,\n            value: options.pan,\n            minValue: -1,\n            maxValue: 1,\n        });\n        // this is necessary for standardized-audio-context\n        // doesn't make any difference for the native AudioContext\n        // https://github.com/chrisguttandin/standardized-audio-context/issues/647\n        this._panner.channelCount = options.channelCount;\n        this._panner.channelCountMode = \"explicit\";\n        // initial value\n        readOnly(this, \"pan\");\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            pan: 0,\n            channelCount: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._panner.disconnect();\n        this.pan.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Panner.js.map","import { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport \"../../core/context/Listener\";\n/**\n * A spatialized panner node which supports equalpower or HRTF panning.\n * @category Component\n */\nexport class Panner3D extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Panner3D.getDefaults(), arguments, [\"positionX\", \"positionY\", \"positionZ\"]));\n        this.name = \"Panner3D\";\n        const options = optionsFromArguments(Panner3D.getDefaults(), arguments, [\"positionX\", \"positionY\", \"positionZ\"]);\n        this._panner = this.input = this.output = this.context.createPanner();\n        // set some values\n        this.panningModel = options.panningModel;\n        this.maxDistance = options.maxDistance;\n        this.distanceModel = options.distanceModel;\n        this.coneOuterGain = options.coneOuterGain;\n        this.coneOuterAngle = options.coneOuterAngle;\n        this.coneInnerAngle = options.coneInnerAngle;\n        this.refDistance = options.refDistance;\n        this.rolloffFactor = options.rolloffFactor;\n        this.positionX = new Param({\n            context: this.context,\n            param: this._panner.positionX,\n            value: options.positionX,\n        });\n        this.positionY = new Param({\n            context: this.context,\n            param: this._panner.positionY,\n            value: options.positionY,\n        });\n        this.positionZ = new Param({\n            context: this.context,\n            param: this._panner.positionZ,\n            value: options.positionZ,\n        });\n        this.orientationX = new Param({\n            context: this.context,\n            param: this._panner.orientationX,\n            value: options.orientationX,\n        });\n        this.orientationY = new Param({\n            context: this.context,\n            param: this._panner.orientationY,\n            value: options.orientationY,\n        });\n        this.orientationZ = new Param({\n            context: this.context,\n            param: this._panner.orientationZ,\n            value: options.orientationZ,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            coneInnerAngle: 360,\n            coneOuterAngle: 360,\n            coneOuterGain: 0,\n            distanceModel: \"inverse\",\n            maxDistance: 10000,\n            orientationX: 0,\n            orientationY: 0,\n            orientationZ: 0,\n            panningModel: \"equalpower\",\n            positionX: 0,\n            positionY: 0,\n            positionZ: 0,\n            refDistance: 1,\n            rolloffFactor: 1,\n        });\n    }\n    /**\n     * Sets the position of the source in 3d space.\n     */\n    setPosition(x, y, z) {\n        this.positionX.value = x;\n        this.positionY.value = y;\n        this.positionZ.value = z;\n        return this;\n    }\n    /**\n     * Sets the orientation of the source in 3d space.\n     */\n    setOrientation(x, y, z) {\n        this.orientationX.value = x;\n        this.orientationY.value = y;\n        this.orientationZ.value = z;\n        return this;\n    }\n    /**\n     * The panning model. Either \"equalpower\" or \"HRTF\".\n     */\n    get panningModel() {\n        return this._panner.panningModel;\n    }\n    set panningModel(val) {\n        this._panner.panningModel = val;\n    }\n    /**\n     * A reference distance for reducing volume as source move further from the listener\n     */\n    get refDistance() {\n        return this._panner.refDistance;\n    }\n    set refDistance(val) {\n        this._panner.refDistance = val;\n    }\n    /**\n     * Describes how quickly the volume is reduced as source moves away from listener.\n     */\n    get rolloffFactor() {\n        return this._panner.rolloffFactor;\n    }\n    set rolloffFactor(val) {\n        this._panner.rolloffFactor = val;\n    }\n    /**\n     * The distance model used by,  \"linear\", \"inverse\", or \"exponential\".\n     */\n    get distanceModel() {\n        return this._panner.distanceModel;\n    }\n    set distanceModel(val) {\n        this._panner.distanceModel = val;\n    }\n    /**\n     * The angle, in degrees, inside of which there will be no volume reduction\n     */\n    get coneInnerAngle() {\n        return this._panner.coneInnerAngle;\n    }\n    set coneInnerAngle(val) {\n        this._panner.coneInnerAngle = val;\n    }\n    /**\n     * The angle, in degrees, outside of which the volume will be reduced\n     * to a constant value of coneOuterGain\n     */\n    get coneOuterAngle() {\n        return this._panner.coneOuterAngle;\n    }\n    set coneOuterAngle(val) {\n        this._panner.coneOuterAngle = val;\n    }\n    /**\n     * The gain outside of the coneOuterAngle\n     */\n    get coneOuterGain() {\n        return this._panner.coneOuterGain;\n    }\n    set coneOuterGain(val) {\n        this._panner.coneOuterGain = val;\n    }\n    /**\n     * The maximum distance between source and listener,\n     * after which the volume will not be reduced any further.\n     */\n    get maxDistance() {\n        return this._panner.maxDistance;\n    }\n    set maxDistance(val) {\n        this._panner.maxDistance = val;\n    }\n    dispose() {\n        super.dispose();\n        this._panner.disconnect();\n        this.orientationX.dispose();\n        this.orientationY.dispose();\n        this.orientationZ.dispose();\n        this.positionX.dispose();\n        this.positionY.dispose();\n        this.positionZ.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Panner3D.js.map","import { __awaiter } from \"tslib\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { assert } from \"../../core/util/Debug\";\nimport { theWindow } from \"../../core/context/AudioContext\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\n/**\n * This is only natively supported in Chrome and Firefox.\n * For a cross-browser shim, install (audio-recorder-polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].\n * @example\n * const recorder = new Tone.Recorder();\n * const synth = new Tone.Synth().connect(recorder);\n * // start recording\n * recorder.start();\n * // generate a few notes\n * synth.triggerAttackRelease(\"C3\", 0.5);\n * synth.triggerAttackRelease(\"C4\", 0.5, \"+1\");\n * synth.triggerAttackRelease(\"C5\", 0.5, \"+2\");\n * // wait for the notes to end and stop the recording\n * setTimeout(async () => {\n * \t// the recorded audio is returned as a blob\n * \tconst recording = await recorder.stop();\n * \t// download the recording by creating an anchor element and blob url\n * \tconst url = URL.createObjectURL(recording);\n * \tconst anchor = document.createElement(\"a\");\n * \tanchor.download = \"recording.webm\";\n * \tanchor.href = url;\n * \tanchor.click();\n * }, 4000);\n */\nexport class Recorder extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Recorder.getDefaults(), arguments, [\"gain\", \"units\"]));\n        this.name = \"Recorder\";\n        const options = optionsFromArguments(Recorder.getDefaults(), arguments, [\"gain\", \"units\"]);\n        this.input = new Gain({\n            context: this.context\n        });\n        assert(Recorder.supported, \"Media Recorder API is not available\");\n        this._stream = this.context.createMediaStreamDestination();\n        this.input.connect(this._stream);\n        this._recorder = new MediaRecorder(this._stream.stream, {\n            mimeType: options.mimeType\n        });\n    }\n    static getDefaults() {\n        return ToneAudioNode.getDefaults();\n    }\n    /**\n     * The mime type is the format that the audio is encoded in. For Chrome\n     * that is typically webm encoded as \"vorbis\".\n     */\n    get mimeType() {\n        return this._recorder.mimeType;\n    }\n    /**\n     * Test if your platform supports the Media Recorder API. If it's not available,\n     * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].\n     */\n    static get supported() {\n        return theWindow !== null && Reflect.has(theWindow, \"MediaRecorder\");\n    }\n    /**\n     * Get the playback state of the Recorder, either \"started\", \"stopped\" or \"paused\"\n     */\n    get state() {\n        if (this._recorder.state === \"inactive\") {\n            return \"stopped\";\n        }\n        else if (this._recorder.state === \"paused\") {\n            return \"paused\";\n        }\n        else {\n            return \"started\";\n        }\n    }\n    start() {\n        return __awaiter(this, void 0, void 0, function* () {\n            assert(this.state !== \"started\", \"Recorder is already started\");\n            const startPromise = new Promise(done => {\n                const handleStart = () => {\n                    this._recorder.removeEventListener(\"start\", handleStart, false);\n                    done();\n                };\n                this._recorder.addEventListener(\"start\", handleStart, false);\n            });\n            this._recorder.start();\n            return yield startPromise;\n        });\n    }\n    stop() {\n        return __awaiter(this, void 0, void 0, function* () {\n            assert(this.state !== \"stopped\", \"Recorder is not started\");\n            const dataPromise = new Promise(done => {\n                const handleData = (e) => {\n                    this._recorder.removeEventListener(\"dataavailable\", handleData, false);\n                    done(e.data);\n                };\n                this._recorder.addEventListener(\"dataavailable\", handleData, false);\n            });\n            this._recorder.stop();\n            return yield dataPromise;\n        });\n    }\n    pause() {\n        assert(this.state === \"started\", \"Recorder must be started\");\n        this._recorder.pause();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this._stream.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Recorder.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\n/**\n * Solo lets you isolate a specific audio stream. When an instance is set to `solo=true`,\n * it will mute all other instances of Solo.\n * @example\n * const soloA = new Tone.Solo().toDestination();\n * const oscA = new Tone.Oscillator(\"C4\", \"sawtooth\").connect(soloA);\n * const soloB = new Tone.Solo().toDestination();\n * const oscB = new Tone.Oscillator(\"E4\", \"square\").connect(soloB);\n * soloA.solo = true;\n * // no audio will pass through soloB\n * @category Component\n */\nexport class Solo extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Solo.getDefaults(), arguments, [\"solo\"]));\n        this.name = \"Solo\";\n        const options = optionsFromArguments(Solo.getDefaults(), arguments, [\"solo\"]);\n        this.input = this.output = new Gain({\n            context: this.context,\n        });\n        if (!Solo._allSolos.has(this.context)) {\n            Solo._allSolos.set(this.context, new Set());\n        }\n        Solo._allSolos.get(this.context).add(this);\n        // set initially\n        this.solo = options.solo;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            solo: false,\n        });\n    }\n    /**\n     * Isolates this instance and mutes all other instances of Solo.\n     * Only one instance can be soloed at a time. A soloed\n     * instance will report `solo=false` when another instance is soloed.\n     */\n    get solo() {\n        return this._isSoloed();\n    }\n    set solo(solo) {\n        if (solo) {\n            this._addSolo();\n        }\n        else {\n            this._removeSolo();\n        }\n        Solo._allSolos.get(this.context).forEach(instance => instance._updateSolo());\n    }\n    /**\n     * If the current instance is muted, i.e. another instance is soloed\n     */\n    get muted() {\n        return this.input.gain.value === 0;\n    }\n    /**\n     * Add this to the soloed array\n     */\n    _addSolo() {\n        if (!Solo._soloed.has(this.context)) {\n            Solo._soloed.set(this.context, new Set());\n        }\n        Solo._soloed.get(this.context).add(this);\n    }\n    /**\n     * Remove this from the soloed array\n     */\n    _removeSolo() {\n        if (Solo._soloed.has(this.context)) {\n            Solo._soloed.get(this.context).delete(this);\n        }\n    }\n    /**\n     * Is this on the soloed array\n     */\n    _isSoloed() {\n        return Solo._soloed.has(this.context) && Solo._soloed.get(this.context).has(this);\n    }\n    /**\n     * Returns true if no one is soloed\n     */\n    _noSolos() {\n        // either does not have any soloed added\n        return !Solo._soloed.has(this.context) ||\n            // or has a solo set but doesn't include any items\n            (Solo._soloed.has(this.context) && Solo._soloed.get(this.context).size === 0);\n    }\n    /**\n     * Solo the current instance and unsolo all other instances.\n     */\n    _updateSolo() {\n        if (this._isSoloed()) {\n            this.input.gain.value = 1;\n        }\n        else if (this._noSolos()) {\n            // no one is soloed\n            this.input.gain.value = 1;\n        }\n        else {\n            this.input.gain.value = 0;\n        }\n    }\n    dispose() {\n        super.dispose();\n        Solo._allSolos.get(this.context).delete(this);\n        this._removeSolo();\n        return this;\n    }\n}\n/**\n * Hold all of the solo'ed tracks belonging to a specific context\n */\nSolo._allSolos = new Map();\n/**\n * Hold the currently solo'ed instance(s)\n */\nSolo._soloed = new Map();\n//# sourceMappingURL=Solo.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\n/**\n * Split splits an incoming signal into the number of given channels.\n *\n * @example\n * const split = new Tone.Split();\n * // stereoSignal.connect(split);\n * @category Component\n */\nexport class Split extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Split.getDefaults(), arguments, [\"channels\"]));\n        this.name = \"Split\";\n        const options = optionsFromArguments(Split.getDefaults(), arguments, [\"channels\"]);\n        this._splitter = this.input = this.output = this.context.createChannelSplitter(options.channels);\n        this._internalChannels = [this._splitter];\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            channels: 2,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._splitter.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Split.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\n/**\n * Volume is a simple volume node, useful for creating a volume fader.\n *\n * @example\n * const vol = new Tone.Volume(-12).toDestination();\n * const osc = new Tone.Oscillator().connect(vol).start();\n * @category Component\n */\nexport class Volume extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Volume.getDefaults(), arguments, [\"volume\"]));\n        this.name = \"Volume\";\n        const options = optionsFromArguments(Volume.getDefaults(), arguments, [\"volume\"]);\n        this.input = this.output = new Gain({\n            context: this.context,\n            gain: options.volume,\n            units: \"decibels\",\n        });\n        this.volume = this.output.gain;\n        readOnly(this, \"volume\");\n        this._unmutedVolume = options.volume;\n        // set the mute initially\n        this.mute = options.mute;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const vol = new Tone.Volume(-12).toDestination();\n     * const osc = new Tone.Oscillator().connect(vol).start();\n     * // mute the output\n     * vol.mute = true;\n     */\n    get mute() {\n        return this.volume.value === -Infinity;\n    }\n    set mute(mute) {\n        if (!this.mute && mute) {\n            this._unmutedVolume = this.volume.value;\n            // maybe it should ramp here?\n            this.volume.value = -Infinity;\n        }\n        else if (this.mute && !mute) {\n            this.volume.value = this._unmutedVolume;\n        }\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Volume.js.map","import { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\n/**\n * Compressor is a thin wrapper around the Web Audio\n * [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).\n * Compression reduces the volume of loud sounds or amplifies quiet sounds\n * by narrowing or \"compressing\" an audio signal's dynamic range.\n * Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).\n * @example\n * const comp = new Tone.Compressor(-30, 3);\n * @category Component\n */\nexport class Compressor extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Compressor.getDefaults(), arguments, [\"threshold\", \"ratio\"]));\n        this.name = \"Compressor\";\n        /**\n         * the compressor node\n         */\n        this._compressor = this.context.createDynamicsCompressor();\n        this.input = this._compressor;\n        this.output = this._compressor;\n        const options = optionsFromArguments(Compressor.getDefaults(), arguments, [\"threshold\", \"ratio\"]);\n        this.threshold = new Param({\n            minValue: this._compressor.threshold.minValue,\n            maxValue: this._compressor.threshold.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.threshold,\n            units: \"decibels\",\n            value: options.threshold,\n        });\n        this.attack = new Param({\n            minValue: this._compressor.attack.minValue,\n            maxValue: this._compressor.attack.maxValue,\n            context: this.context,\n            param: this._compressor.attack,\n            units: \"time\",\n            value: options.attack,\n        });\n        this.release = new Param({\n            minValue: this._compressor.release.minValue,\n            maxValue: this._compressor.release.maxValue,\n            context: this.context,\n            param: this._compressor.release,\n            units: \"time\",\n            value: options.release,\n        });\n        this.knee = new Param({\n            minValue: this._compressor.knee.minValue,\n            maxValue: this._compressor.knee.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.knee,\n            units: \"decibels\",\n            value: options.knee,\n        });\n        this.ratio = new Param({\n            minValue: this._compressor.ratio.minValue,\n            maxValue: this._compressor.ratio.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.ratio,\n            units: \"positive\",\n            value: options.ratio,\n        });\n        // set the defaults\n        readOnly(this, [\"knee\", \"release\", \"attack\", \"ratio\", \"threshold\"]);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            attack: 0.003,\n            knee: 30,\n            ratio: 12,\n            release: 0.25,\n            threshold: -24,\n        });\n    }\n    /**\n     * A read-only decibel value for metering purposes, representing the current amount of gain\n     * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).\n     */\n    get reduction() {\n        return this._compressor.reduction;\n    }\n    dispose() {\n        super.dispose();\n        this._compressor.disconnect();\n        this.attack.dispose();\n        this.release.dispose();\n        this.threshold.dispose();\n        this.ratio.dispose();\n        this.knee.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Compressor.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { GreaterThan } from \"../../signal/GreaterThan\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { Follower } from \"../analysis/Follower\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { dbToGain, gainToDb } from \"../../core/type/Conversions\";\n/**\n * Gate only passes a signal through when the incoming\n * signal exceeds a specified threshold. It uses [[Follower]] to follow the ampltiude\n * of the incoming signal and compares it to the [[threshold]] value using [[GreaterThan]].\n *\n * @example\n * const gate = new Tone.Gate(-30, 0.2).toDestination();\n * const mic = new Tone.UserMedia().connect(gate);\n * // the gate will only pass through the incoming\n * // signal when it's louder than -30db\n */\nexport class Gate extends ToneAudioNode {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Gate.getDefaults(), arguments, [\"threshold\", \"smoothing\"])));\n        this.name = \"Gate\";\n        const options = optionsFromArguments(Gate.getDefaults(), arguments, [\"threshold\", \"smoothing\"]);\n        this._follower = new Follower({\n            context: this.context,\n            smoothing: options.smoothing,\n        });\n        this._gt = new GreaterThan({\n            context: this.context,\n            value: dbToGain(options.threshold),\n        });\n        this.input = new Gain({ context: this.context });\n        this._gate = this.output = new Gain({ context: this.context });\n        // connections\n        this.input.connect(this._gate);\n        // the control signal\n        this.input.chain(this._follower, this._gt, this._gate.gain);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            smoothing: 0.1,\n            threshold: -40\n        });\n    }\n    /**\n     * The threshold of the gate in decibels\n     */\n    get threshold() {\n        return gainToDb(this._gt.value);\n    }\n    set threshold(thresh) {\n        this._gt.value = dbToGain(thresh);\n    }\n    /**\n     * The attack/decay speed of the gate. See [[Follower.smoothing]]\n     */\n    get smoothing() {\n        return this._follower.smoothing;\n    }\n    set smoothing(smoothingTime) {\n        this._follower.smoothing = smoothingTime;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this._follower.dispose();\n        this._gt.dispose();\n        this._gate.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Gate.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Compressor } from \"./Compressor\";\nimport { readOnly } from \"../../core/util/Interface\";\n;\n/**\n * Limiter will limit the loudness of an incoming signal.\n * It is composed of a [[Compressor]] with a fast attack\n * and release and max ratio. Limiters are commonly used to safeguard against\n * signal clipping. Unlike a compressor, limiters do not provide\n * smooth gain reduction and almost completely prevent\n * additional gain above the threshold.\n *\n * @example\n * const limiter = new Tone.Limiter(-20).toDestination();\n * const oscillator = new Tone.Oscillator().connect(limiter);\n * oscillator.start();\n */\nexport class Limiter extends ToneAudioNode {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Limiter.getDefaults(), arguments, [\"threshold\"])));\n        this.name = \"Limiter\";\n        const options = optionsFromArguments(Limiter.getDefaults(), arguments, [\"threshold\"]);\n        this._compressor = this.input = this.output = new Compressor({\n            context: this.context,\n            ratio: 20,\n            attack: 0,\n            release: 0,\n            threshold: options.threshold\n        });\n        this.threshold = this._compressor.threshold;\n        readOnly(this, \"threshold\");\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            threshold: -12\n        });\n    }\n    /**\n     * A read-only decibel value for metering purposes, representing the current amount of gain\n     * reduction that the compressor is applying to the signal.\n     */\n    get reduction() {\n        return this._compressor.reduction;\n    }\n    dispose() {\n        super.dispose();\n        this._compressor.dispose();\n        this.threshold.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Limiter.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { Compressor } from \"./Compressor\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { MidSideSplit } from \"../channel/MidSideSplit\";\nimport { MidSideMerge } from \"../channel/MidSideMerge\";\nimport { readOnly } from \"../../core/util/Interface\";\n/**\n * MidSideCompressor applies two different compressors to the [[mid]]\n * and [[side]] signal components of the input. See [[MidSideSplit]] and [[MidSideMerge]].\n */\nexport class MidSideCompressor extends ToneAudioNode {\n    constructor() {\n        super(Object.assign(optionsFromArguments(MidSideCompressor.getDefaults(), arguments)));\n        this.name = \"MidSideCompressor\";\n        const options = optionsFromArguments(MidSideCompressor.getDefaults(), arguments);\n        this._midSideSplit = this.input = new MidSideSplit({ context: this.context });\n        this._midSideMerge = this.output = new MidSideMerge({ context: this.context });\n        this.mid = new Compressor(Object.assign(options.mid, { context: this.context }));\n        this.side = new Compressor(Object.assign(options.side, { context: this.context }));\n        this._midSideSplit.mid.chain(this.mid, this._midSideMerge.mid);\n        this._midSideSplit.side.chain(this.side, this._midSideMerge.side);\n        readOnly(this, [\"mid\", \"side\"]);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            mid: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n            side: {\n                ratio: 6,\n                threshold: -30,\n                release: 0.25,\n                attack: 0.03,\n                knee: 10\n            }\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._midSideSplit.dispose();\n        this._midSideMerge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideCompressor.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { Compressor } from \"./Compressor\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { MultibandSplit } from \"../channel/MultibandSplit\";\nimport { Gain } from \"../../core/context/Gain\";\n/**\n * A compressor with separate controls over low/mid/high dynamics. See [[Compressor]] and [[MultibandSplit]]\n *\n * @example\n * const multiband = new Tone.MultibandCompressor({\n * \tlowFrequency: 200,\n * \thighFrequency: 1300,\n * \tlow: {\n * \t\tthreshold: -12\n * \t}\n * });\n */\nexport class MultibandCompressor extends ToneAudioNode {\n    constructor() {\n        super(Object.assign(optionsFromArguments(MultibandCompressor.getDefaults(), arguments)));\n        this.name = \"MultibandCompressor\";\n        const options = optionsFromArguments(MultibandCompressor.getDefaults(), arguments);\n        this._splitter = this.input = new MultibandSplit({\n            context: this.context,\n            lowFrequency: options.lowFrequency,\n            highFrequency: options.highFrequency\n        });\n        this.lowFrequency = this._splitter.lowFrequency;\n        this.highFrequency = this._splitter.highFrequency;\n        this.output = new Gain({ context: this.context });\n        this.low = new Compressor(Object.assign(options.low, { context: this.context }));\n        this.mid = new Compressor(Object.assign(options.mid, { context: this.context }));\n        this.high = new Compressor(Object.assign(options.high, { context: this.context }));\n        // connect the compressor\n        this._splitter.low.chain(this.low, this.output);\n        this._splitter.mid.chain(this.mid, this.output);\n        this._splitter.high.chain(this.high, this.output);\n        readOnly(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            lowFrequency: 250,\n            highFrequency: 2000,\n            low: {\n                ratio: 6,\n                threshold: -30,\n                release: 0.25,\n                attack: 0.03,\n                knee: 10\n            },\n            mid: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n            high: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._splitter.dispose();\n        this.low.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.output.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MultibandCompressor.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Envelope } from \"./Envelope\";\n/**\n * AmplitudeEnvelope is a Tone.Envelope connected to a gain node.\n * Unlike Tone.Envelope, which outputs the envelope's value, AmplitudeEnvelope accepts\n * an audio signal as the input and will apply the envelope to the amplitude\n * of the signal.\n * Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).\n *\n * @offline 1.5 1\n * @example\n * const ampEnv = new Tone.AmplitudeEnvelope({\n * \tattack: 0.1,\n * \tdecay: 0.2,\n * \tsustain: 1.0,\n * \trelease: 0.8\n * }).toDestination();\n * // create an oscillator and connect it\n * const osc = new Tone.Oscillator().connect(ampEnv).start();\n * // trigger the envelopes attack and release \"8t\" apart\n * ampEnv.triggerAttackRelease(\"8t\");\n * @category Component\n */\nexport class AmplitudeEnvelope extends Envelope {\n    constructor() {\n        super(optionsFromArguments(AmplitudeEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"AmplitudeEnvelope\";\n        this._gainNode = new Gain({\n            context: this.context,\n            gain: 0,\n        });\n        this.output = this._gainNode;\n        this.input = this._gainNode;\n        this._sig.connect(this._gainNode.gain);\n        this.output = this._gainNode;\n        this.input = this._gainNode;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._gainNode.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AmplitudeEnvelope.js.map","import { __awaiter, __decorate } from \"tslib\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { isArray, isObject, isString } from \"../../core/util/TypeCheck\";\nimport { connectSignal, Signal } from \"../../signal/Signal\";\nimport { OfflineContext } from \"../../core/context/OfflineContext\";\nimport { assert } from \"../../core/util/Debug\";\nimport { range, timeRange } from \"../../core/util/Decorator\";\n/**\n * Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)\n * envelope generator. Envelope outputs a signal which\n * can be connected to an AudioParam or Tone.Signal.\n * ```\n *           /\\\n *          /  \\\n *         /    \\\n *        /      \\\n *       /        \\___________\n *      /                     \\\n *     /                       \\\n *    /                         \\\n *   /                           \\\n * ```\n * @offline 1.5 1\n * @example\n * const env = new Tone.Envelope({\n * \tattack: 0.1,\n * \tdecay: 0.2,\n * \tsustain: 0.5,\n * \trelease: 0.8,\n * }).toDestination();\n * env.triggerAttackRelease(0.5);\n * @category Component\n */\nexport class Envelope extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Envelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"Envelope\";\n        /**\n         * the signal which is output.\n         */\n        this._sig = new Signal({\n            context: this.context,\n            value: 0,\n        });\n        /**\n         * The output signal of the envelope\n         */\n        this.output = this._sig;\n        /**\n         * Envelope has no input\n         */\n        this.input = undefined;\n        const options = optionsFromArguments(Envelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]);\n        this.attack = options.attack;\n        this.decay = options.decay;\n        this.sustain = options.sustain;\n        this.release = options.release;\n        this.attackCurve = options.attackCurve;\n        this.releaseCurve = options.releaseCurve;\n        this.decayCurve = options.decayCurve;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            attack: 0.01,\n            attackCurve: \"linear\",\n            decay: 0.1,\n            decayCurve: \"exponential\",\n            release: 1,\n            releaseCurve: \"exponential\",\n            sustain: 0.5,\n        });\n    }\n    /**\n     * Read the current value of the envelope. Useful for\n     * synchronizing visual output to the envelope.\n     */\n    get value() {\n        return this.getValueAtTime(this.now());\n    }\n    /**\n     * Get the curve\n     * @param  curve\n     * @param  direction  In/Out\n     * @return The curve name\n     */\n    _getCurve(curve, direction) {\n        if (isString(curve)) {\n            return curve;\n        }\n        else {\n            // look up the name in the curves array\n            let curveName;\n            for (curveName in EnvelopeCurves) {\n                if (EnvelopeCurves[curveName][direction] === curve) {\n                    return curveName;\n                }\n            }\n            // return the custom curve\n            return curve;\n        }\n    }\n    /**\n     * Assign a the curve to the given name using the direction\n     * @param  name\n     * @param  direction In/Out\n     * @param  curve\n     */\n    _setCurve(name, direction, curve) {\n        // check if it's a valid type\n        if (isString(curve) && Reflect.has(EnvelopeCurves, curve)) {\n            const curveDef = EnvelopeCurves[curve];\n            if (isObject(curveDef)) {\n                if (name !== \"_decayCurve\") {\n                    this[name] = curveDef[direction];\n                }\n            }\n            else {\n                this[name] = curveDef;\n            }\n        }\n        else if (isArray(curve) && name !== \"_decayCurve\") {\n            this[name] = curve;\n        }\n        else {\n            throw new Error(\"Envelope: invalid curve: \" + curve);\n        }\n    }\n    /**\n     * The shape of the attack.\n     * Can be any of these strings:\n     * * \"linear\"\n     * * \"exponential\"\n     * * \"sine\"\n     * * \"cosine\"\n     * * \"bounce\"\n     * * \"ripple\"\n     * * \"step\"\n     *\n     * Can also be an array which describes the curve. Values\n     * in the array are evenly subdivided and linearly\n     * interpolated over the duration of the attack.\n     * @offline 1 1\n     * @example\n     * const env = new Tone.Envelope(0.4).toDestination();\n     * env.attackCurve = \"linear\";\n     * env.triggerAttack();\n     */\n    get attackCurve() {\n        return this._getCurve(this._attackCurve, \"In\");\n    }\n    set attackCurve(curve) {\n        this._setCurve(\"_attackCurve\", \"In\", curve);\n    }\n    /**\n     * The shape of the release. See the attack curve types.\n     * @offline 1 1\n     * @example\n     * const env = new Tone.Envelope({\n     * \trelease: 0.8\n     * }).toDestination();\n     * env.triggerAttack();\n     * // release curve could also be defined by an array\n     * env.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];\n     * env.triggerRelease(0.2);\n     */\n    get releaseCurve() {\n        return this._getCurve(this._releaseCurve, \"Out\");\n    }\n    set releaseCurve(curve) {\n        this._setCurve(\"_releaseCurve\", \"Out\", curve);\n    }\n    /**\n     * The shape of the decay either \"linear\" or \"exponential\"\n     * @offline 1 1\n     * @example\n     * const env = new Tone.Envelope({\n     * \tsustain: 0.1,\n     * \tdecay: 0.5\n     * }).toDestination();\n     * env.decayCurve = \"linear\";\n     * env.triggerAttack();\n     */\n    get decayCurve() {\n        return this._decayCurve;\n    }\n    set decayCurve(curve) {\n        assert([\"linear\", \"exponential\"].some(c => c === curve), `Invalid envelope curve: ${curve}`);\n        this._decayCurve = curve;\n    }\n    /**\n     * Trigger the attack/decay portion of the ADSR envelope.\n     * @param  time When the attack should start.\n     * @param velocity The velocity of the envelope scales the vales.\n     *                             number between 0-1\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator().connect(env).start();\n     * // trigger the attack 0.5 seconds from now with a velocity of 0.2\n     * env.triggerAttack(\"+0.5\", 0.2);\n     */\n    triggerAttack(time, velocity = 1) {\n        this.log(\"triggerAttack\", time, velocity);\n        time = this.toSeconds(time);\n        const originalAttack = this.toSeconds(this.attack);\n        let attack = originalAttack;\n        const decay = this.toSeconds(this.decay);\n        // check if it's not a complete attack\n        const currentValue = this.getValueAtTime(time);\n        if (currentValue > 0) {\n            // subtract the current value from the attack time\n            const attackRate = 1 / attack;\n            const remainingDistance = 1 - currentValue;\n            // the attack is now the remaining time\n            attack = remainingDistance / attackRate;\n        }\n        // attack\n        if (attack < this.sampleTime) {\n            this._sig.cancelScheduledValues(time);\n            // case where the attack time is 0 should set instantly\n            this._sig.setValueAtTime(velocity, time);\n        }\n        else if (this._attackCurve === \"linear\") {\n            this._sig.linearRampTo(velocity, attack, time);\n        }\n        else if (this._attackCurve === \"exponential\") {\n            this._sig.targetRampTo(velocity, attack, time);\n        }\n        else {\n            this._sig.cancelAndHoldAtTime(time);\n            let curve = this._attackCurve;\n            // find the starting position in the curve\n            for (let i = 1; i < curve.length; i++) {\n                // the starting index is between the two values\n                if (curve[i - 1] <= currentValue && currentValue <= curve[i]) {\n                    curve = this._attackCurve.slice(i);\n                    // the first index is the current value\n                    curve[0] = currentValue;\n                    break;\n                }\n            }\n            this._sig.setValueCurveAtTime(curve, time, attack, velocity);\n        }\n        // decay\n        if (decay && this.sustain < 1) {\n            const decayValue = velocity * this.sustain;\n            const decayStart = time + attack;\n            this.log(\"decay\", decayStart);\n            if (this._decayCurve === \"linear\") {\n                this._sig.linearRampToValueAtTime(decayValue, decay + decayStart);\n            }\n            else {\n                this._sig.exponentialApproachValueAtTime(decayValue, decayStart, decay);\n            }\n        }\n        return this;\n    }\n    /**\n     * Triggers the release of the envelope.\n     * @param  time When the release portion of the envelope should start.\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator({\n     * \ttype: \"sawtooth\"\n     * }).connect(env).start();\n     * env.triggerAttack();\n     * // trigger the release half a second after the attack\n     * env.triggerRelease(\"+0.5\");\n     */\n    triggerRelease(time) {\n        this.log(\"triggerRelease\", time);\n        time = this.toSeconds(time);\n        const currentValue = this.getValueAtTime(time);\n        if (currentValue > 0) {\n            const release = this.toSeconds(this.release);\n            if (release < this.sampleTime) {\n                this._sig.setValueAtTime(0, time);\n            }\n            else if (this._releaseCurve === \"linear\") {\n                this._sig.linearRampTo(0, release, time);\n            }\n            else if (this._releaseCurve === \"exponential\") {\n                this._sig.targetRampTo(0, release, time);\n            }\n            else {\n                assert(isArray(this._releaseCurve), \"releaseCurve must be either 'linear', 'exponential' or an array\");\n                this._sig.cancelAndHoldAtTime(time);\n                this._sig.setValueCurveAtTime(this._releaseCurve, time, release, currentValue);\n            }\n        }\n        return this;\n    }\n    /**\n     * Get the scheduled value at the given time. This will\n     * return the unconverted (raw) value.\n     * @example\n     * const env = new Tone.Envelope(0.5, 1, 0.4, 2);\n     * env.triggerAttackRelease(2);\n     * setInterval(() => console.log(env.getValueAtTime), 100);\n     */\n    getValueAtTime(time) {\n        return this._sig.getValueAtTime(time);\n    }\n    /**\n     * triggerAttackRelease is shorthand for triggerAttack, then waiting\n     * some duration, then triggerRelease.\n     * @param duration The duration of the sustain.\n     * @param time When the attack should be triggered.\n     * @param velocity The velocity of the envelope.\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator().connect(env).start();\n     * // trigger the release 0.5 seconds after the attack\n     * env.triggerAttackRelease(0.5);\n     */\n    triggerAttackRelease(duration, time, velocity = 1) {\n        time = this.toSeconds(time);\n        this.triggerAttack(time, velocity);\n        this.triggerRelease(time + this.toSeconds(duration));\n        return this;\n    }\n    /**\n     * Cancels all scheduled envelope changes after the given time.\n     */\n    cancel(after) {\n        this._sig.cancelScheduledValues(this.toSeconds(after));\n        return this;\n    }\n    /**\n     * Connect the envelope to a destination node.\n     */\n    connect(destination, outputNumber = 0, inputNumber = 0) {\n        connectSignal(this, destination, outputNumber, inputNumber);\n        return this;\n    }\n    /**\n     * Render the envelope curve to an array of the given length.\n     * Good for visualizing the envelope curve. Rescales the duration of the\n     * envelope to fit the length.\n     */\n    asArray(length = 1024) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const duration = length / this.context.sampleRate;\n            const context = new OfflineContext(1, duration, this.context.sampleRate);\n            // normalize the ADSR for the given duration with 20% sustain time\n            const attackPortion = this.toSeconds(this.attack) + this.toSeconds(this.decay);\n            const envelopeDuration = attackPortion + this.toSeconds(this.release);\n            const sustainTime = envelopeDuration * 0.1;\n            const totalDuration = envelopeDuration + sustainTime;\n            // @ts-ignore\n            const clone = new this.constructor(Object.assign(this.get(), {\n                attack: duration * this.toSeconds(this.attack) / totalDuration,\n                decay: duration * this.toSeconds(this.decay) / totalDuration,\n                release: duration * this.toSeconds(this.release) / totalDuration,\n                context\n            }));\n            clone._sig.toDestination();\n            clone.triggerAttackRelease(duration * (attackPortion + sustainTime) / totalDuration, 0);\n            const buffer = yield context.render();\n            return buffer.getChannelData(0);\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._sig.dispose();\n        return this;\n    }\n}\n__decorate([\n    timeRange(0)\n], Envelope.prototype, \"attack\", void 0);\n__decorate([\n    timeRange(0)\n], Envelope.prototype, \"decay\", void 0);\n__decorate([\n    range(0, 1)\n], Envelope.prototype, \"sustain\", void 0);\n__decorate([\n    timeRange(0)\n], Envelope.prototype, \"release\", void 0);\n/**\n * Generate some complex envelope curves.\n */\nconst EnvelopeCurves = (() => {\n    const curveLen = 128;\n    let i;\n    let k;\n    // cosine curve\n    const cosineCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        cosineCurve[i] = Math.sin((i / (curveLen - 1)) * (Math.PI / 2));\n    }\n    // ripple curve\n    const rippleCurve = [];\n    const rippleCurveFreq = 6.4;\n    for (i = 0; i < curveLen - 1; i++) {\n        k = (i / (curveLen - 1));\n        const sineWave = Math.sin(k * (Math.PI * 2) * rippleCurveFreq - Math.PI / 2) + 1;\n        rippleCurve[i] = sineWave / 10 + k * 0.83;\n    }\n    rippleCurve[curveLen - 1] = 1;\n    // stairs curve\n    const stairsCurve = [];\n    const steps = 5;\n    for (i = 0; i < curveLen; i++) {\n        stairsCurve[i] = Math.ceil((i / (curveLen - 1)) * steps) / steps;\n    }\n    // in-out easing curve\n    const sineCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        k = i / (curveLen - 1);\n        sineCurve[i] = 0.5 * (1 - Math.cos(Math.PI * k));\n    }\n    // a bounce curve\n    const bounceCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        k = i / (curveLen - 1);\n        const freq = Math.pow(k, 3) * 4 + 0.2;\n        const val = Math.cos(freq * Math.PI * 2 * k);\n        bounceCurve[i] = Math.abs(val * (1 - k));\n    }\n    /**\n     * Invert a value curve to make it work for the release\n     */\n    function invertCurve(curve) {\n        const out = new Array(curve.length);\n        for (let j = 0; j < curve.length; j++) {\n            out[j] = 1 - curve[j];\n        }\n        return out;\n    }\n    /**\n     * reverse the curve\n     */\n    function reverseCurve(curve) {\n        return curve.slice(0).reverse();\n    }\n    /**\n     * attack and release curve arrays\n     */\n    return {\n        bounce: {\n            In: invertCurve(bounceCurve),\n            Out: bounceCurve,\n        },\n        cosine: {\n            In: cosineCurve,\n            Out: reverseCurve(cosineCurve),\n        },\n        exponential: \"exponential\",\n        linear: \"linear\",\n        ripple: {\n            In: rippleCurve,\n            Out: invertCurve(rippleCurve),\n        },\n        sine: {\n            In: sineCurve,\n            Out: invertCurve(sineCurve),\n        },\n        step: {\n            In: stairsCurve,\n            Out: invertCurve(stairsCurve),\n        },\n    };\n})();\n//# sourceMappingURL=Envelope.js.map","import { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Envelope } from \"./Envelope\";\nimport { Scale } from \"../../signal/Scale\";\nimport { Pow } from \"../../signal/Pow\";\nimport { assertRange } from \"../../core/util/Debug\";\n/**\n * FrequencyEnvelope is an [[Envelope]] which ramps between [[baseFrequency]]\n * and [[octaves]]. It can also have an optional [[exponent]] to adjust the curve\n * which it ramps.\n * @example\n * const oscillator = new Tone.Oscillator().toDestination().start();\n * const freqEnv = new Tone.FrequencyEnvelope({\n * \tattack: 0.2,\n * \tbaseFrequency: \"C2\",\n * \toctaves: 4\n * });\n * freqEnv.connect(oscillator.frequency);\n * freqEnv.triggerAttack();\n */\nexport class FrequencyEnvelope extends Envelope {\n    constructor() {\n        super(optionsFromArguments(FrequencyEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"FrequencyEnvelope\";\n        const options = optionsFromArguments(FrequencyEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]);\n        this._octaves = options.octaves;\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._exponent = this.input = new Pow({\n            context: this.context,\n            value: options.exponent\n        });\n        this._scale = this.output = new Scale({\n            context: this.context,\n            min: this._baseFrequency,\n            max: this._baseFrequency * Math.pow(2, this._octaves),\n        });\n        this._sig.chain(this._exponent, this._scale);\n    }\n    static getDefaults() {\n        return Object.assign(Envelope.getDefaults(), {\n            baseFrequency: 200,\n            exponent: 1,\n            octaves: 4,\n        });\n    }\n    /**\n     * The envelope's minimum output value. This is the value which it\n     * starts at.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(min) {\n        const freq = this.toFrequency(min);\n        assertRange(freq, 0);\n        this._baseFrequency = freq;\n        this._scale.min = this._baseFrequency;\n        // update the max value when the min changes\n        this.octaves = this._octaves;\n    }\n    /**\n     * The number of octaves above the baseFrequency that the\n     * envelope will scale to.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        assertRange(octaves, 0);\n        this._octaves = octaves;\n        this._scale.max = this._baseFrequency * Math.pow(2, octaves);\n    }\n    /**\n     * The envelope's exponent value.\n     */\n    get exponent() {\n        return this._exponent.value;\n    }\n    set exponent(exponent) {\n        this._exponent.value = exponent;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._exponent.dispose();\n        this._scale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FrequencyEnvelope.js.map","import { __awaiter } from \"tslib\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { noOp } from \"../../core/util/Interface\";\n/**\n * Convolver is a wrapper around the Native Web Audio\n * [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).\n * Convolution is useful for reverb and filter emulation. Read more about convolution reverb on\n * [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).\n *\n * @example\n * // initializing the convolver with an impulse response\n * const convolver = new Tone.Convolver(\"./path/to/ir.wav\").toDestination();\n * @category Component\n */\nexport class Convolver extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Convolver.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"Convolver\";\n        /**\n         * The native ConvolverNode\n         */\n        this._convolver = this.context.createConvolver();\n        const options = optionsFromArguments(Convolver.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this._buffer = new ToneAudioBuffer(options.url, buffer => {\n            this.buffer = buffer;\n            options.onload();\n        });\n        this.input = new Gain({ context: this.context });\n        this.output = new Gain({ context: this.context });\n        // set if it's already loaded, set it immediately\n        if (this._buffer.loaded) {\n            this.buffer = this._buffer;\n        }\n        // initially set normalization\n        this.normalize = options.normalize;\n        // connect it up\n        this.input.chain(this._convolver, this.output);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            normalize: true,\n            onload: noOp,\n        });\n    }\n    /**\n     * Load an impulse response url as an audio buffer.\n     * Decodes the audio asynchronously and invokes\n     * the callback once the audio buffer loads.\n     * @param url The url of the buffer to load. filetype support depends on the browser.\n     */\n    load(url) {\n        return __awaiter(this, void 0, void 0, function* () {\n            this.buffer = yield this._buffer.load(url);\n        });\n    }\n    /**\n     * The convolver's buffer\n     */\n    get buffer() {\n        if (this._buffer.length) {\n            return this._buffer;\n        }\n        else {\n            return null;\n        }\n    }\n    set buffer(buffer) {\n        if (buffer) {\n            this._buffer.set(buffer);\n        }\n        // if it's already got a buffer, create a new one\n        if (this._convolver.buffer) {\n            // disconnect the old one\n            this.input.disconnect();\n            this._convolver.disconnect();\n            // create and connect a new one\n            this._convolver = this.context.createConvolver();\n            this.input.chain(this._convolver, this.output);\n        }\n        const buff = this._buffer.get();\n        this._convolver.buffer = buff ? buff : null;\n    }\n    /**\n     * The normalize property of the ConvolverNode interface is a boolean that\n     * controls whether the impulse response from the buffer will be scaled by\n     * an equal-power normalization when the buffer attribute is set, or not.\n     */\n    get normalize() {\n        return this._convolver.normalize;\n    }\n    set normalize(norm) {\n        this._convolver.normalize = norm;\n    }\n    dispose() {\n        super.dispose();\n        this._buffer.dispose();\n        this._convolver.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Convolver.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly, writable } from \"../../core/util/Interface\";\nimport { MultibandSplit } from \"../channel/MultibandSplit\";\n/**\n * EQ3 provides 3 equalizer bins: Low/Mid/High.\n * @category Component\n */\nexport class EQ3 extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(EQ3.getDefaults(), arguments, [\"low\", \"mid\", \"high\"]));\n        this.name = \"EQ3\";\n        /**\n         * the output\n         */\n        this.output = new Gain({ context: this.context });\n        this._internalChannels = [];\n        const options = optionsFromArguments(EQ3.getDefaults(), arguments, [\"low\", \"mid\", \"high\"]);\n        this.input = this._multibandSplit = new MultibandSplit({\n            context: this.context,\n            highFrequency: options.highFrequency,\n            lowFrequency: options.lowFrequency,\n        });\n        this._lowGain = new Gain({\n            context: this.context,\n            gain: options.low,\n            units: \"decibels\",\n        });\n        this._midGain = new Gain({\n            context: this.context,\n            gain: options.mid,\n            units: \"decibels\",\n        });\n        this._highGain = new Gain({\n            context: this.context,\n            gain: options.high,\n            units: \"decibels\",\n        });\n        this.low = this._lowGain.gain;\n        this.mid = this._midGain.gain;\n        this.high = this._highGain.gain;\n        this.Q = this._multibandSplit.Q;\n        this.lowFrequency = this._multibandSplit.lowFrequency;\n        this.highFrequency = this._multibandSplit.highFrequency;\n        // the frequency bands\n        this._multibandSplit.low.chain(this._lowGain, this.output);\n        this._multibandSplit.mid.chain(this._midGain, this.output);\n        this._multibandSplit.high.chain(this._highGain, this.output);\n        readOnly(this, [\"low\", \"mid\", \"high\", \"lowFrequency\", \"highFrequency\"]);\n        this._internalChannels = [this._multibandSplit];\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            high: 0,\n            highFrequency: 2500,\n            low: 0,\n            lowFrequency: 400,\n            mid: 0,\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        writable(this, [\"low\", \"mid\", \"high\", \"lowFrequency\", \"highFrequency\"]);\n        this._multibandSplit.dispose();\n        this.lowFrequency.dispose();\n        this.highFrequency.dispose();\n        this._lowGain.dispose();\n        this._midGain.dispose();\n        this._highGain.dispose();\n        this.low.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.Q.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=EQ3.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { Param } from \"../../core/context/Param\";\nimport { connectSeries, ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { ToneAudioWorklet } from \"../../core/worklet/ToneAudioWorklet\";\nimport { workletName } from \"./FeedbackCombFilter.worklet\";\n/**\n * Comb filters are basic building blocks for physical modeling. Read more\n * about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).\n *\n * This comb filter is implemented with the AudioWorkletNode which allows it to have feedback delays less than the\n * Web Audio processing block of 128 samples. There is a polyfill for browsers that don't yet support the\n * AudioWorkletNode, but it will add some latency and have slower performance than the AudioWorkletNode.\n * @category Component\n */\nexport class FeedbackCombFilter extends ToneAudioWorklet {\n    constructor() {\n        super(optionsFromArguments(FeedbackCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\"]));\n        this.name = \"FeedbackCombFilter\";\n        const options = optionsFromArguments(FeedbackCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\"]);\n        this.input = new Gain({ context: this.context });\n        this.output = new Gain({ context: this.context });\n        this.delayTime = new Param({\n            context: this.context,\n            value: options.delayTime,\n            units: \"time\",\n            minValue: 0,\n            maxValue: 1,\n            param: this._dummyParam,\n            swappable: true,\n        });\n        this.resonance = new Param({\n            context: this.context,\n            value: options.resonance,\n            units: \"normalRange\",\n            param: this._dummyParam,\n            swappable: true,\n        });\n        readOnly(this, [\"resonance\", \"delayTime\"]);\n    }\n    _audioWorkletName() {\n        return workletName;\n    }\n    /**\n     * The default parameters\n     */\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            delayTime: 0.1,\n            resonance: 0.5,\n        });\n    }\n    onReady(node) {\n        connectSeries(this.input, node, this.output);\n        const delayTime = node.parameters.get(\"delayTime\");\n        ;\n        this.delayTime.setParam(delayTime);\n        const feedback = node.parameters.get(\"feedback\");\n        ;\n        this.resonance.setParam(feedback);\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.delayTime.dispose();\n        this.resonance.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackCombFilter.js.map","import \"../../core/worklet/SingleIOProcessor.worklet\";\nimport \"../../core/worklet/DelayLine.worklet\";\nimport { registerProcessor } from \"../../core/worklet/WorkletGlobalScope\";\nexport const workletName = \"feedback-comb-filter\";\nconst feedbackCombFilter = /* javascript */ `\n\tclass FeedbackCombFilterWorklet extends SingleIOProcessor {\n\n\t\tconstructor(options) {\n\t\t\tsuper(options);\n\t\t\tthis.delayLine = new DelayLine(this.sampleRate, options.channelCount || 2);\n\t\t}\n\n\t\tstatic get parameterDescriptors() {\n\t\t\treturn [{\n\t\t\t\tname: \"delayTime\",\n\t\t\t\tdefaultValue: 0.1,\n\t\t\t\tminValue: 0,\n\t\t\t\tmaxValue: 1\n\t\t\t}, {\n\t\t\t\tname: \"feedback\",\n\t\t\t\tdefaultValue: 0.5,\n\t\t\t\tminValue: 0,\n\t\t\t\tmaxValue: 0.9999,\n\t\t\t}];\n\t\t}\n\n\t\tgenerate(input, channel, parameters) {\n\t\t\tconst delayedSample = this.delayLine.get(channel, parameters.delayTime * this.sampleRate);\n\t\t\tthis.delayLine.push(channel, input + delayedSample * parameters.feedback);\n\t\t\treturn delayedSample;\n\t\t}\n\t}\n`;\nregisterProcessor(workletName, feedbackCombFilter);\n//# sourceMappingURL=FeedbackCombFilter.worklet.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { connectSeries, ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly, writable } from \"../../core/util/Interface\";\nimport { isNumber } from \"../../core/util/TypeCheck\";\nimport { Signal } from \"../../signal/Signal\";\nimport { assert } from \"../../core/util/Debug\";\n/**\n * Tone.Filter is a filter which allows for all of the same native methods\n * as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).\n * Tone.Filter has the added ability to set the filter rolloff at -12\n * (default), -24 and -48.\n * @example\n * const filter = new Tone.Filter(1500, \"highpass\").toDestination();\n * filter.frequency.rampTo(20000, 10);\n * const noise = new Tone.Noise().connect(filter).start();\n * @category Component\n */\nexport class Filter extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Filter.getDefaults(), arguments, [\"frequency\", \"type\", \"rolloff\"]));\n        this.name = \"Filter\";\n        this.input = new Gain({ context: this.context });\n        this.output = new Gain({ context: this.context });\n        this._filters = [];\n        const options = optionsFromArguments(Filter.getDefaults(), arguments, [\"frequency\", \"type\", \"rolloff\"]);\n        this._filters = [];\n        this.Q = new Signal({\n            context: this.context,\n            units: \"positive\",\n            value: options.Q,\n        });\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this.gain = new Signal({\n            context: this.context,\n            units: \"decibels\",\n            value: options.gain,\n        });\n        this._type = options.type;\n        this.rolloff = options.rolloff;\n        readOnly(this, [\"detune\", \"frequency\", \"gain\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            Q: 1,\n            detune: 0,\n            frequency: 350,\n            gain: 0,\n            rolloff: -12,\n            type: \"lowpass\",\n        });\n    }\n    /**\n     * The type of the filter. Types: \"lowpass\", \"highpass\",\n     * \"bandpass\", \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", or \"peaking\".\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        const types = [\"lowpass\", \"highpass\", \"bandpass\",\n            \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", \"peaking\"];\n        assert(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);\n        this._type = type;\n        this._filters.forEach(filter => filter.type = type);\n    }\n    /**\n     * The rolloff of the filter which is the drop in db\n     * per octave. Implemented internally by cascading filters.\n     * Only accepts the values -12, -24, -48 and -96.\n     */\n    get rolloff() {\n        return this._rolloff;\n    }\n    set rolloff(rolloff) {\n        const rolloffNum = isNumber(rolloff) ? rolloff : parseInt(rolloff, 10);\n        const possibilities = [-12, -24, -48, -96];\n        let cascadingCount = possibilities.indexOf(rolloffNum);\n        // check the rolloff is valid\n        assert(cascadingCount !== -1, `rolloff can only be ${possibilities.join(\", \")}`);\n        cascadingCount += 1;\n        this._rolloff = rolloffNum;\n        this.input.disconnect();\n        this._filters.forEach(filter => filter.disconnect());\n        this._filters = new Array(cascadingCount);\n        for (let count = 0; count < cascadingCount; count++) {\n            const filter = this.context.createBiquadFilter();\n            filter.type = this._type;\n            this.frequency.connect(filter.frequency);\n            this.detune.connect(filter.detune);\n            this.Q.connect(filter.Q);\n            this.gain.connect(filter.gain);\n            this._filters[count] = filter;\n        }\n        this._internalChannels = this._filters;\n        connectSeries(this.input, ...this._internalChannels, this.output);\n    }\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len = 128) {\n        // start with all 1s\n        const totalResponse = new Float32Array(len).map(() => 1);\n        const freqValues = new Float32Array(len);\n        for (let i = 0; i < len; i++) {\n            const norm = Math.pow(i / len, 2);\n            const freq = norm * (20000 - 20) + 20;\n            freqValues[i] = freq;\n        }\n        const magValues = new Float32Array(len);\n        const phaseValues = new Float32Array(len);\n        this._filters.forEach(() => {\n            const filterClone = this.context.createBiquadFilter();\n            filterClone.type = this._type;\n            filterClone.Q.value = this.Q.value;\n            filterClone.frequency.value = this.frequency.value;\n            filterClone.gain.value = this.gain.value;\n            filterClone.getFrequencyResponse(freqValues, magValues, phaseValues);\n            magValues.forEach((val, i) => {\n                totalResponse[i] *= val;\n            });\n        });\n        return totalResponse;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._filters.forEach(filter => {\n            filter.disconnect();\n        });\n        writable(this, [\"detune\", \"frequency\", \"gain\", \"Q\"]);\n        this.frequency.dispose();\n        this.Q.dispose();\n        this.detune.dispose();\n        this.gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Filter.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { FeedbackCombFilter } from \"./FeedbackCombFilter\";\nimport { OnePoleFilter } from \"./OnePoleFilter\";\n/**\n * A lowpass feedback comb filter. It is similar to\n * [[FeedbackCombFilter]], but includes a lowpass filter.\n * @category Component\n */\nexport class LowpassCombFilter extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(LowpassCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\", \"dampening\"]));\n        this.name = \"LowpassCombFilter\";\n        const options = optionsFromArguments(LowpassCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\", \"dampening\"]);\n        this._combFilter = this.output = new FeedbackCombFilter({\n            context: this.context,\n            delayTime: options.delayTime,\n            resonance: options.resonance,\n        });\n        this.delayTime = this._combFilter.delayTime;\n        this.resonance = this._combFilter.resonance;\n        this._lowpass = this.input = new OnePoleFilter({\n            context: this.context,\n            frequency: options.dampening,\n            type: \"lowpass\",\n        });\n        // connections\n        this._lowpass.connect(this._combFilter);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            dampening: 3000,\n            delayTime: 0.1,\n            resonance: 0.5,\n        });\n    }\n    /**\n     * The dampening control of the feedback\n     */\n    get dampening() {\n        return this._lowpass.frequency;\n    }\n    set dampening(fq) {\n        this._lowpass.frequency = fq;\n    }\n    dispose() {\n        super.dispose();\n        this._combFilter.dispose();\n        this._lowpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LowpassCombFilter.js.map","import { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Gain } from \"../../core/context/Gain\";\n/**\n * A one pole filter with 6db-per-octave rolloff. Either \"highpass\" or \"lowpass\".\n * Note that changing the type or frequency may result in a discontinuity which\n * can sound like a click or pop.\n * References:\n * * http://www.earlevel.com/main/2012/12/15/a-one-pole-filter/\n * * http://www.dspguide.com/ch19/2.htm\n * * https://github.com/vitaliy-bobrov/js-rocks/blob/master/src/app/audio/effects/one-pole-filters.ts\n * @category Component\n */\nexport class OnePoleFilter extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(OnePoleFilter.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"OnePoleFilter\";\n        const options = optionsFromArguments(OnePoleFilter.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this._frequency = options.frequency;\n        this._type = options.type;\n        this.input = new Gain({ context: this.context });\n        this.output = new Gain({ context: this.context });\n        this._createFilter();\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            frequency: 880,\n            type: \"lowpass\"\n        });\n    }\n    /**\n     * Create a filter and dispose the old one\n     */\n    _createFilter() {\n        const oldFilter = this._filter;\n        const freq = this.toFrequency(this._frequency);\n        const t = 1 / (2 * Math.PI * freq);\n        if (this._type === \"lowpass\") {\n            const a0 = 1 / (t * this.context.sampleRate);\n            const b1 = a0 - 1;\n            this._filter = this.context.createIIRFilter([a0, 0], [1, b1]);\n        }\n        else {\n            const b1 = 1 / (t * this.context.sampleRate) - 1;\n            this._filter = this.context.createIIRFilter([1, -1], [1, b1]);\n        }\n        this.input.chain(this._filter, this.output);\n        if (oldFilter) {\n            // dispose it on the next block\n            this.context.setTimeout(() => {\n                if (!this.disposed) {\n                    this.input.disconnect(oldFilter);\n                    oldFilter.disconnect();\n                }\n            }, this.blockTime);\n        }\n    }\n    /**\n     * The frequency value.\n     */\n    get frequency() {\n        return this._frequency;\n    }\n    set frequency(fq) {\n        this._frequency = fq;\n        this._createFilter();\n    }\n    /**\n     * The OnePole Filter type, either \"highpass\" or \"lowpass\"\n     */\n    get type() {\n        return this._type;\n    }\n    set type(t) {\n        this._type = t;\n        this._createFilter();\n    }\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len = 128) {\n        const freqValues = new Float32Array(len);\n        for (let i = 0; i < len; i++) {\n            const norm = Math.pow(i / len, 2);\n            const freq = norm * (20000 - 20) + 20;\n            freqValues[i] = freq;\n        }\n        const magValues = new Float32Array(len);\n        const phaseValues = new Float32Array(len);\n        this._filter.getFrequencyResponse(freqValues, magValues, phaseValues);\n        return magValues;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this._filter.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=OnePoleFilter.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { connectSeries, ToneAudioNode } from \"../../core/context/ToneAudioNode\";\n/**\n * PhaseShiftAllpass is an very efficient implementation of a Hilbert Transform\n * using two Allpass filter banks whose outputs have a phase difference of 90.\n * Here the `offset90` phase is offset by +90 in relation to `output`.\n * Coefficients and structure was developed by Olli Niemitalo.\n * For more details see: http://yehar.com/blog/?p=368\n * @category Component\n */\nexport class PhaseShiftAllpass extends ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"PhaseShiftAllpass\";\n        this.input = new Gain({ context: this.context });\n        /**\n         * The phase shifted output\n         */\n        this.output = new Gain({ context: this.context });\n        /**\n         * The PhaseShifted allpass output\n         */\n        this.offset90 = new Gain({ context: this.context });\n        const allpassBank1Values = [0.6923878, 0.9360654322959, 0.9882295226860, 0.9987488452737];\n        const allpassBank2Values = [0.4021921162426, 0.8561710882420, 0.9722909545651, 0.9952884791278];\n        this._bank0 = this._createAllPassFilterBank(allpassBank1Values);\n        this._bank1 = this._createAllPassFilterBank(allpassBank2Values);\n        this._oneSampleDelay = this.context.createIIRFilter([0.0, 1.0], [1.0, 0.0]);\n        // connect Allpass filter banks\n        connectSeries(this.input, ...this._bank0, this._oneSampleDelay, this.output);\n        connectSeries(this.input, ...this._bank1, this.offset90);\n    }\n    /**\n     * Create all of the IIR filters from an array of values using the coefficient calculation.\n     */\n    _createAllPassFilterBank(bankValues) {\n        const nodes = bankValues.map(value => {\n            const coefficients = [[value * value, 0, -1], [1, 0, -(value * value)]];\n            return this.context.createIIRFilter(coefficients[0], coefficients[1]);\n        });\n        return nodes;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.offset90.dispose();\n        this._bank0.forEach(f => f.disconnect());\n        this._bank1.forEach(f => f.disconnect());\n        this._oneSampleDelay.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=PhaseShiftAllpass.js.map","export * from \"./analysis/Analyser\";\nexport * from \"./analysis/Meter\";\nexport * from \"./analysis/FFT\";\nexport * from \"./analysis/DCMeter\";\nexport * from \"./analysis/Waveform\";\nexport * from \"./analysis/Follower\";\nexport * from \"./channel/Channel\";\nexport * from \"./channel/CrossFade\";\nexport * from \"./channel/Merge\";\nexport * from \"./channel/MidSideMerge\";\nexport * from \"./channel/MidSideSplit\";\nexport * from \"./channel/MultibandSplit\";\nexport * from \"./channel/Panner\";\nexport * from \"./channel/Panner3D\";\nexport * from \"./channel/PanVol\";\nexport * from \"./channel/Recorder\";\nexport * from \"./channel/Solo\";\nexport * from \"./channel/Split\";\nexport * from \"./channel/Volume\";\nexport * from \"./dynamics/Compressor\";\nexport * from \"./dynamics/Gate\";\nexport * from \"./dynamics/Limiter\";\nexport * from \"./dynamics/MidSideCompressor\";\nexport * from \"./dynamics/MultibandCompressor\";\nexport * from \"./envelope/AmplitudeEnvelope\";\nexport * from \"./envelope/Envelope\";\nexport * from \"./envelope/FrequencyEnvelope\";\nexport * from \"./filter/EQ3\";\nexport * from \"./filter/Filter\";\nexport * from \"./filter/OnePoleFilter\";\nexport * from \"./filter/FeedbackCombFilter\";\nexport * from \"./filter/LowpassCombFilter\";\nexport * from \"./filter/Convolver\";\n//# sourceMappingURL=index.js.map","import { version } from \"../version\";\nimport { hasAudioContext, theWindow } from \"./context/AudioContext\";\nimport { Context } from \"./context/Context\";\nimport { DummyContext } from \"./context/DummyContext\";\nimport { OfflineContext } from \"./context/OfflineContext\";\nimport { isAudioContext, isOfflineAudioContext } from \"./util/AdvancedTypeCheck\";\n/**\n * This dummy context is used to avoid throwing immediate errors when importing in Node.js\n */\nconst dummyContext = new DummyContext();\n/**\n * The global audio context which is getable and assignable through\n * getContext and setContext\n */\nlet globalContext = dummyContext;\n/**\n * Returns the default system-wide [[Context]]\n * @category Core\n */\nexport function getContext() {\n    if (globalContext === dummyContext && hasAudioContext) {\n        setContext(new Context());\n    }\n    return globalContext;\n}\n/**\n * Set the default audio context\n * @category Core\n */\nexport function setContext(context) {\n    if (isAudioContext(context)) {\n        globalContext = new Context(context);\n    }\n    else if (isOfflineAudioContext(context)) {\n        globalContext = new OfflineContext(context);\n    }\n    else {\n        globalContext = context;\n    }\n}\n/**\n * Most browsers will not play _any_ audio until a user\n * clicks something (like a play button). Invoke this method\n * on a click or keypress event handler to start the audio context.\n * More about the Autoplay policy\n * [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)\n * @example\n * document.querySelector(\"button\").addEventListener(\"click\", async () => {\n * \tawait Tone.start();\n * \tconsole.log(\"context started\");\n * });\n * @category Core\n */\nexport function start() {\n    return globalContext.resume();\n}\n/**\n * Log Tone.js + version in the console.\n */\nif (theWindow && !theWindow.TONE_SILENCE_LOGGING) {\n    let prefix = \"v\";\n    if (version === \"dev\") {\n        prefix = \"\";\n    }\n    const printString = ` * Tone.js ${prefix}${version} * `;\n    // eslint-disable-next-line no-console\n    console.log(`%c${printString}`, \"background: #000; color: #fff\");\n}\n//# sourceMappingURL=Global.js.map","/**\n * Tone.js\n * @author Yotam Mann\n * @license http://opensource.org/licenses/MIT MIT License\n * @copyright 2014-2019 Yotam Mann\n */\nimport { version } from \"../version\";\nimport { theWindow } from \"./context/AudioContext\";\nimport { log } from \"./util/Debug\";\n/**\n * @class  Tone is the base class of all other classes.\n * @constructor\n */\nexport class Tone {\n    constructor() {\n        //-------------------------------------\n        // \tDEBUGGING\n        //-------------------------------------\n        /**\n         * Set this debug flag to log all events that happen in this class.\n         */\n        this.debug = false;\n        //-------------------------------------\n        // \tDISPOSING\n        //-------------------------------------\n        /**\n         * Indicates if the instance was disposed\n         */\n        this._wasDisposed = false;\n    }\n    /**\n     * Returns all of the default options belonging to the class.\n     */\n    static getDefaults() {\n        return {};\n    }\n    /**\n     * Prints the outputs to the console log for debugging purposes.\n     * Prints the contents only if either the object has a property\n     * called `debug` set to true, or a variable called TONE_DEBUG_CLASS\n     * is set to the name of the class.\n     * @example\n     * const osc = new Tone.Oscillator();\n     * // prints all logs originating from this oscillator\n     * osc.debug = true;\n     * // calls to start/stop will print in the console\n     * osc.start();\n     */\n    log(...args) {\n        // if the object is either set to debug = true\n        // or if there is a string on the Tone.global.with the class name\n        if (this.debug || (theWindow && this.toString() === theWindow.TONE_DEBUG_CLASS)) {\n            log(this, ...args);\n        }\n    }\n    /**\n     * disconnect and dispose.\n     */\n    dispose() {\n        this._wasDisposed = true;\n        return this;\n    }\n    /**\n     * Indicates if the instance was disposed. 'Disposing' an\n     * instance means that all of the Web Audio nodes that were\n     * created for the instance are disconnected and freed for garbage collection.\n     */\n    get disposed() {\n        return this._wasDisposed;\n    }\n    /**\n     * Convert the class to a string\n     * @example\n     * const osc = new Tone.Oscillator();\n     * console.log(osc.toString());\n     */\n    toString() {\n        return this.name;\n    }\n}\n/**\n * The version number semver\n */\nTone.version = version;\n//# sourceMappingURL=Tone.js.map","import { ToneWithContext } from \"../context/ToneWithContext\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { Emitter } from \"../util/Emitter\";\nimport { noOp, readOnly } from \"../util/Interface\";\nimport { StateTimeline } from \"../util/StateTimeline\";\nimport { TickSource } from \"./TickSource\";\nimport { assertContextRunning } from \"../util/Debug\";\n/**\n * A sample accurate clock which provides a callback at the given rate.\n * While the callback is not sample-accurate (it is still susceptible to\n * loose JS timing), the time passed in as the argument to the callback\n * is precise. For most applications, it is better to use Tone.Transport\n * instead of the Clock by itself since you can synchronize multiple callbacks.\n * @example\n * // the callback will be invoked approximately once a second\n * // and will print the time exactly once a second apart.\n * const clock = new Tone.Clock(time => {\n * \tconsole.log(time);\n * }, 1);\n * clock.start();\n * @category Core\n */\nexport class Clock extends ToneWithContext {\n    constructor() {\n        super(optionsFromArguments(Clock.getDefaults(), arguments, [\"callback\", \"frequency\"]));\n        this.name = \"Clock\";\n        /**\n         * The callback function to invoke at the scheduled tick.\n         */\n        this.callback = noOp;\n        /**\n         * The last time the loop callback was invoked\n         */\n        this._lastUpdate = 0;\n        /**\n         * Keep track of the playback state\n         */\n        this._state = new StateTimeline(\"stopped\");\n        /**\n         * Context bound reference to the _loop method\n         * This is necessary to remove the event in the end.\n         */\n        this._boundLoop = this._loop.bind(this);\n        const options = optionsFromArguments(Clock.getDefaults(), arguments, [\"callback\", \"frequency\"]);\n        this.callback = options.callback;\n        this._tickSource = new TickSource({\n            context: this.context,\n            frequency: options.frequency,\n            units: options.units,\n        });\n        this._lastUpdate = 0;\n        this.frequency = this._tickSource.frequency;\n        readOnly(this, \"frequency\");\n        // add an initial state\n        this._state.setStateAtTime(\"stopped\", 0);\n        // bind a callback to the worker thread\n        this.context.on(\"tick\", this._boundLoop);\n    }\n    static getDefaults() {\n        return Object.assign(ToneWithContext.getDefaults(), {\n            callback: noOp,\n            frequency: 1,\n            units: \"hertz\",\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n     */\n    get state() {\n        return this._state.getValueAtTime(this.now());\n    }\n    /**\n     * Start the clock at the given time. Optionally pass in an offset\n     * of where to start the tick counter from.\n     * @param  time    The time the clock should start\n     * @param offset  Where the tick counter starts counting from.\n     */\n    start(time, offset) {\n        // make sure the context is running\n        assertContextRunning(this.context);\n        // start the loop\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        if (this._state.getValueAtTime(computedTime) !== \"started\") {\n            this._state.setStateAtTime(\"started\", computedTime);\n            this._tickSource.start(computedTime, offset);\n            if (computedTime < this._lastUpdate) {\n                this.emit(\"start\", computedTime, offset);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the clock. Stopping the clock resets the tick counter to 0.\n     * @param time The time when the clock should stop.\n     * @example\n     * const clock = new Tone.Clock(time => {\n     * \tconsole.log(time);\n     * }, 1);\n     * clock.start();\n     * // stop the clock after 10 seconds\n     * clock.stop(\"+10\");\n     */\n    stop(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"stop\", computedTime);\n        this._state.cancel(computedTime);\n        this._state.setStateAtTime(\"stopped\", computedTime);\n        this._tickSource.stop(computedTime);\n        if (computedTime < this._lastUpdate) {\n            this.emit(\"stop\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Pause the clock. Pausing does not reset the tick counter.\n     * @param time The time when the clock should stop.\n     */\n    pause(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            this._state.setStateAtTime(\"paused\", computedTime);\n            this._tickSource.pause(computedTime);\n            if (computedTime < this._lastUpdate) {\n                this.emit(\"pause\", computedTime);\n            }\n        }\n        return this;\n    }\n    /**\n     * The number of times the callback was invoked. Starts counting at 0\n     * and increments after the callback was invoked.\n     */\n    get ticks() {\n        return Math.ceil(this.getTicksAtTime(this.now()));\n    }\n    set ticks(t) {\n        this._tickSource.ticks = t;\n    }\n    /**\n     * The time since ticks=0 that the Clock has been running. Accounts for tempo curves\n     */\n    get seconds() {\n        return this._tickSource.seconds;\n    }\n    set seconds(s) {\n        this._tickSource.seconds = s;\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        return this._tickSource.getSecondsAtTime(time);\n    }\n    /**\n     * Set the clock's ticks at the given time.\n     * @param  ticks The tick value to set\n     * @param  time  When to set the tick value\n     */\n    setTicksAtTime(ticks, time) {\n        this._tickSource.setTicksAtTime(ticks, time);\n        return this;\n    }\n    /**\n     * Get the time of the given tick. The second argument\n     * is when to test before. Since ticks can be set (with setTicksAtTime)\n     * there may be multiple times for a given tick value.\n     * @param  tick The tick number.\n     * @param  before When to measure the tick value from.\n     * @return The time of the tick\n     */\n    getTimeOfTick(tick, before = this.now()) {\n        return this._tickSource.getTimeOfTick(tick, before);\n    }\n    /**\n     * Get the clock's ticks at the given time.\n     * @param  time  When to get the tick value\n     * @return The tick value at the given time.\n     */\n    getTicksAtTime(time) {\n        return this._tickSource.getTicksAtTime(time);\n    }\n    /**\n     * Get the time of the next tick\n     * @param  offset The tick number.\n     */\n    nextTickTime(offset, when) {\n        const computedTime = this.toSeconds(when);\n        const currentTick = this.getTicksAtTime(computedTime);\n        return this._tickSource.getTimeOfTick(currentTick + offset, computedTime);\n    }\n    /**\n     * The scheduling loop.\n     */\n    _loop() {\n        const startTime = this._lastUpdate;\n        const endTime = this.now();\n        this._lastUpdate = endTime;\n        this.log(\"loop\", startTime, endTime);\n        if (startTime !== endTime) {\n            // the state change events\n            this._state.forEachBetween(startTime, endTime, e => {\n                switch (e.state) {\n                    case \"started\":\n                        const offset = this._tickSource.getTicksAtTime(e.time);\n                        this.emit(\"start\", e.time, offset);\n                        break;\n                    case \"stopped\":\n                        if (e.time !== 0) {\n                            this.emit(\"stop\", e.time);\n                        }\n                        break;\n                    case \"paused\":\n                        this.emit(\"pause\", e.time);\n                        break;\n                }\n            });\n            // the tick callbacks\n            this._tickSource.forEachTickBetween(startTime, endTime, (time, ticks) => {\n                this.callback(time, ticks);\n            });\n        }\n    }\n    /**\n     * Returns the scheduled state at the given time.\n     * @param  time  The time to query.\n     * @return  The name of the state input in setStateAtTime.\n     * @example\n     * const clock = new Tone.Clock();\n     * clock.start(\"+0.1\");\n     * clock.getStateAtTime(\"+0.1\"); // returns \"started\"\n     */\n    getStateAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        return this._state.getValueAtTime(computedTime);\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.context.off(\"tick\", this._boundLoop);\n        this._tickSource.dispose();\n        this._state.dispose();\n        return this;\n    }\n}\nEmitter.mixin(Clock);\n//# sourceMappingURL=Clock.js.map","import { Param } from \"../context/Param\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { Timeline } from \"../util/Timeline\";\nimport { isUndef } from \"../util/TypeCheck\";\n/**\n * A Param class just for computing ticks. Similar to the [[Param]] class,\n * but offers conversion to BPM values as well as ability to compute tick\n * duration and elapsed ticks\n */\nexport class TickParam extends Param {\n    constructor() {\n        super(optionsFromArguments(TickParam.getDefaults(), arguments, [\"value\"]));\n        this.name = \"TickParam\";\n        /**\n         * The timeline which tracks all of the automations.\n         */\n        this._events = new Timeline(Infinity);\n        /**\n         * The internal holder for the multiplier value\n         */\n        this._multiplier = 1;\n        const options = optionsFromArguments(TickParam.getDefaults(), arguments, [\"value\"]);\n        // set the multiplier\n        this._multiplier = options.multiplier;\n        // clear the ticks from the beginning\n        this._events.cancel(0);\n        // set an initial event\n        this._events.add({\n            ticks: 0,\n            time: 0,\n            type: \"setValueAtTime\",\n            value: this._fromType(options.value),\n        });\n        this.setValueAtTime(options.value, 0);\n    }\n    static getDefaults() {\n        return Object.assign(Param.getDefaults(), {\n            multiplier: 1,\n            units: \"hertz\",\n            value: 1,\n        });\n    }\n    setTargetAtTime(value, time, constant) {\n        // approximate it with multiple linear ramps\n        time = this.toSeconds(time);\n        this.setRampPoint(time);\n        const computedValue = this._fromType(value);\n        // start from previously scheduled value\n        const prevEvent = this._events.get(time);\n        const segments = Math.round(Math.max(1 / constant, 1));\n        for (let i = 0; i <= segments; i++) {\n            const segTime = constant * i + time;\n            const rampVal = this._exponentialApproach(prevEvent.time, prevEvent.value, computedValue, constant, segTime);\n            this.linearRampToValueAtTime(this._toType(rampVal), segTime);\n        }\n        return this;\n    }\n    setValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        super.setValueAtTime(value, time);\n        const event = this._events.get(computedTime);\n        const previousEvent = this._events.previousEvent(event);\n        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);\n        event.ticks = Math.max(ticksUntilTime, 0);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        super.linearRampToValueAtTime(value, time);\n        const event = this._events.get(computedTime);\n        const previousEvent = this._events.previousEvent(event);\n        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);\n        event.ticks = Math.max(ticksUntilTime, 0);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        // aproximate it with multiple linear ramps\n        time = this.toSeconds(time);\n        const computedVal = this._fromType(value);\n        // start from previously scheduled value\n        const prevEvent = this._events.get(time);\n        // approx 10 segments per second\n        const segments = Math.round(Math.max((time - prevEvent.time) * 10, 1));\n        const segmentDur = ((time - prevEvent.time) / segments);\n        for (let i = 0; i <= segments; i++) {\n            const segTime = segmentDur * i + prevEvent.time;\n            const rampVal = this._exponentialInterpolate(prevEvent.time, prevEvent.value, time, computedVal, segTime);\n            this.linearRampToValueAtTime(this._toType(rampVal), segTime);\n        }\n        return this;\n    }\n    /**\n     * Returns the tick value at the time. Takes into account\n     * any automation curves scheduled on the signal.\n     * @param  event The time to get the tick count at\n     * @return The number of ticks which have elapsed at the time given any automations.\n     */\n    _getTicksUntilEvent(event, time) {\n        if (event === null) {\n            event = {\n                ticks: 0,\n                time: 0,\n                type: \"setValueAtTime\",\n                value: 0,\n            };\n        }\n        else if (isUndef(event.ticks)) {\n            const previousEvent = this._events.previousEvent(event);\n            event.ticks = this._getTicksUntilEvent(previousEvent, event.time);\n        }\n        const val0 = this._fromType(this.getValueAtTime(event.time));\n        let val1 = this._fromType(this.getValueAtTime(time));\n        // if it's right on the line, take the previous value\n        const onTheLineEvent = this._events.get(time);\n        if (onTheLineEvent && onTheLineEvent.time === time && onTheLineEvent.type === \"setValueAtTime\") {\n            val1 = this._fromType(this.getValueAtTime(time - this.sampleTime));\n        }\n        return 0.5 * (time - event.time) * (val0 + val1) + event.ticks;\n    }\n    /**\n     * Returns the tick value at the time. Takes into account\n     * any automation curves scheduled on the signal.\n     * @param  time The time to get the tick count at\n     * @return The number of ticks which have elapsed at the time given any automations.\n     */\n    getTicksAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const event = this._events.get(computedTime);\n        return Math.max(this._getTicksUntilEvent(event, computedTime), 0);\n    }\n    /**\n     * Return the elapsed time of the number of ticks from the given time\n     * @param ticks The number of ticks to calculate\n     * @param  time The time to get the next tick from\n     * @return The duration of the number of ticks from the given time in seconds\n     */\n    getDurationOfTicks(ticks, time) {\n        const computedTime = this.toSeconds(time);\n        const currentTick = this.getTicksAtTime(time);\n        return this.getTimeOfTick(currentTick + ticks) - computedTime;\n    }\n    /**\n     * Given a tick, returns the time that tick occurs at.\n     * @return The time that the tick occurs.\n     */\n    getTimeOfTick(tick) {\n        const before = this._events.get(tick, \"ticks\");\n        const after = this._events.getAfter(tick, \"ticks\");\n        if (before && before.ticks === tick) {\n            return before.time;\n        }\n        else if (before && after &&\n            after.type === \"linearRampToValueAtTime\" &&\n            before.value !== after.value) {\n            const val0 = this._fromType(this.getValueAtTime(before.time));\n            const val1 = this._fromType(this.getValueAtTime(after.time));\n            const delta = (val1 - val0) / (after.time - before.time);\n            const k = Math.sqrt(Math.pow(val0, 2) - 2 * delta * (before.ticks - tick));\n            const sol1 = (-val0 + k) / delta;\n            const sol2 = (-val0 - k) / delta;\n            return (sol1 > 0 ? sol1 : sol2) + before.time;\n        }\n        else if (before) {\n            if (before.value === 0) {\n                return Infinity;\n            }\n            else {\n                return before.time + (tick - before.ticks) / before.value;\n            }\n        }\n        else {\n            return tick / this._initialValue;\n        }\n    }\n    /**\n     * Convert some number of ticks their the duration in seconds accounting\n     * for any automation curves starting at the given time.\n     * @param  ticks The number of ticks to convert to seconds.\n     * @param  when  When along the automation timeline to convert the ticks.\n     * @return The duration in seconds of the ticks.\n     */\n    ticksToTime(ticks, when) {\n        return this.getDurationOfTicks(ticks, when);\n    }\n    /**\n     * The inverse of [[ticksToTime]]. Convert a duration in\n     * seconds to the corresponding number of ticks accounting for any\n     * automation curves starting at the given time.\n     * @param  duration The time interval to convert to ticks.\n     * @param  when When along the automation timeline to convert the ticks.\n     * @return The duration in ticks.\n     */\n    timeToTicks(duration, when) {\n        const computedTime = this.toSeconds(when);\n        const computedDuration = this.toSeconds(duration);\n        const startTicks = this.getTicksAtTime(computedTime);\n        const endTicks = this.getTicksAtTime(computedTime + computedDuration);\n        return endTicks - startTicks;\n    }\n    /**\n     * Convert from the type when the unit value is BPM\n     */\n    _fromType(val) {\n        if (this.units === \"bpm\" && this.multiplier) {\n            return 1 / (60 / val / this.multiplier);\n        }\n        else {\n            return super._fromType(val);\n        }\n    }\n    /**\n     * Special case of type conversion where the units === \"bpm\"\n     */\n    _toType(val) {\n        if (this.units === \"bpm\" && this.multiplier) {\n            return (val / this.multiplier) * 60;\n        }\n        else {\n            return super._toType(val);\n        }\n    }\n    /**\n     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.\n     */\n    get multiplier() {\n        return this._multiplier;\n    }\n    set multiplier(m) {\n        // get and reset the current value with the new multiplier\n        // might be necessary to clear all the previous values\n        const currentVal = this.value;\n        this._multiplier = m;\n        this.cancelScheduledValues(0);\n        this.setValueAtTime(currentVal, 0);\n    }\n}\n//# sourceMappingURL=TickParam.js.map","import { Signal } from \"../../signal/Signal\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { TickParam } from \"./TickParam\";\n/**\n * TickSignal extends Tone.Signal, but adds the capability\n * to calculate the number of elapsed ticks. exponential and target curves\n * are approximated with multiple linear ramps.\n *\n * Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos,\n * for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)\n * describing integrating timing functions for tempo calculations.\n */\nexport class TickSignal extends Signal {\n    constructor() {\n        super(optionsFromArguments(TickSignal.getDefaults(), arguments, [\"value\"]));\n        this.name = \"TickSignal\";\n        const options = optionsFromArguments(TickSignal.getDefaults(), arguments, [\"value\"]);\n        this.input = this._param = new TickParam({\n            context: this.context,\n            convert: options.convert,\n            multiplier: options.multiplier,\n            param: this._constantSource.offset,\n            units: options.units,\n            value: options.value,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(Signal.getDefaults(), {\n            multiplier: 1,\n            units: \"hertz\",\n            value: 1,\n        });\n    }\n    ticksToTime(ticks, when) {\n        return this._param.ticksToTime(ticks, when);\n    }\n    timeToTicks(duration, when) {\n        return this._param.timeToTicks(duration, when);\n    }\n    getTimeOfTick(tick) {\n        return this._param.getTimeOfTick(tick);\n    }\n    getDurationOfTicks(ticks, time) {\n        return this._param.getDurationOfTicks(ticks, time);\n    }\n    getTicksAtTime(time) {\n        return this._param.getTicksAtTime(time);\n    }\n    /**\n     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.\n     */\n    get multiplier() {\n        return this._param.multiplier;\n    }\n    set multiplier(m) {\n        this._param.multiplier = m;\n    }\n    dispose() {\n        super.dispose();\n        this._param.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=TickSignal.js.map","import { ToneWithContext } from \"../context/ToneWithContext\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { readOnly } from \"../util/Interface\";\nimport { StateTimeline } from \"../util/StateTimeline\";\nimport { Timeline } from \"../util/Timeline\";\nimport { isDefined } from \"../util/TypeCheck\";\nimport { TickSignal } from \"./TickSignal\";\nimport { EQ } from \"../util/Math\";\n/**\n * Uses [TickSignal](TickSignal) to track elapsed ticks with complex automation curves.\n */\nexport class TickSource extends ToneWithContext {\n    constructor() {\n        super(optionsFromArguments(TickSource.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"TickSource\";\n        /**\n         * The state timeline\n         */\n        this._state = new StateTimeline();\n        /**\n         * The offset values of the ticks\n         */\n        this._tickOffset = new Timeline();\n        const options = optionsFromArguments(TickSource.getDefaults(), arguments, [\"frequency\"]);\n        this.frequency = new TickSignal({\n            context: this.context,\n            units: options.units,\n            value: options.frequency,\n        });\n        readOnly(this, \"frequency\");\n        // set the initial state\n        this._state.setStateAtTime(\"stopped\", 0);\n        // add the first event\n        this.setTicksAtTime(0, 0);\n    }\n    static getDefaults() {\n        return Object.assign({\n            frequency: 1,\n            units: \"hertz\",\n        }, ToneWithContext.getDefaults());\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n     */\n    get state() {\n        return this.getStateAtTime(this.now());\n    }\n    /**\n     * Start the clock at the given time. Optionally pass in an offset\n     * of where to start the tick counter from.\n     * @param  time    The time the clock should start\n     * @param offset The number of ticks to start the source at\n     */\n    start(time, offset) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) !== \"started\") {\n            this._state.setStateAtTime(\"started\", computedTime);\n            if (isDefined(offset)) {\n                this.setTicksAtTime(offset, computedTime);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the clock. Stopping the clock resets the tick counter to 0.\n     * @param time The time when the clock should stop.\n     */\n    stop(time) {\n        const computedTime = this.toSeconds(time);\n        // cancel the previous stop\n        if (this._state.getValueAtTime(computedTime) === \"stopped\") {\n            const event = this._state.get(computedTime);\n            if (event && event.time > 0) {\n                this._tickOffset.cancel(event.time);\n                this._state.cancel(event.time);\n            }\n        }\n        this._state.cancel(computedTime);\n        this._state.setStateAtTime(\"stopped\", computedTime);\n        this.setTicksAtTime(0, computedTime);\n        return this;\n    }\n    /**\n     * Pause the clock. Pausing does not reset the tick counter.\n     * @param time The time when the clock should stop.\n     */\n    pause(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            this._state.setStateAtTime(\"paused\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Cancel start/stop/pause and setTickAtTime events scheduled after the given time.\n     * @param time When to clear the events after\n     */\n    cancel(time) {\n        time = this.toSeconds(time);\n        this._state.cancel(time);\n        this._tickOffset.cancel(time);\n        return this;\n    }\n    /**\n     * Get the elapsed ticks at the given time\n     * @param  time  When to get the tick value\n     * @return The number of ticks\n     */\n    getTicksAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const stopEvent = this._state.getLastState(\"stopped\", computedTime);\n        // this event allows forEachBetween to iterate until the current time\n        const tmpEvent = { state: \"paused\", time: computedTime };\n        this._state.add(tmpEvent);\n        // keep track of the previous offset event\n        let lastState = stopEvent;\n        let elapsedTicks = 0;\n        // iterate through all the events since the last stop\n        this._state.forEachBetween(stopEvent.time, computedTime + this.sampleTime, e => {\n            let periodStartTime = lastState.time;\n            // if there is an offset event in this period use that\n            const offsetEvent = this._tickOffset.get(e.time);\n            if (offsetEvent && offsetEvent.time >= lastState.time) {\n                elapsedTicks = offsetEvent.ticks;\n                periodStartTime = offsetEvent.time;\n            }\n            if (lastState.state === \"started\" && e.state !== \"started\") {\n                elapsedTicks += this.frequency.getTicksAtTime(e.time) - this.frequency.getTicksAtTime(periodStartTime);\n            }\n            lastState = e;\n        });\n        // remove the temporary event\n        this._state.remove(tmpEvent);\n        // return the ticks\n        return elapsedTicks;\n    }\n    /**\n     * The number of times the callback was invoked. Starts counting at 0\n     * and increments after the callback was invoked. Returns -1 when stopped.\n     */\n    get ticks() {\n        return this.getTicksAtTime(this.now());\n    }\n    set ticks(t) {\n        this.setTicksAtTime(t, this.now());\n    }\n    /**\n     * The time since ticks=0 that the TickSource has been running. Accounts\n     * for tempo curves\n     */\n    get seconds() {\n        return this.getSecondsAtTime(this.now());\n    }\n    set seconds(s) {\n        const now = this.now();\n        const ticks = this.frequency.timeToTicks(s, now);\n        this.setTicksAtTime(ticks, now);\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        time = this.toSeconds(time);\n        const stopEvent = this._state.getLastState(\"stopped\", time);\n        // this event allows forEachBetween to iterate until the current time\n        const tmpEvent = { state: \"paused\", time };\n        this._state.add(tmpEvent);\n        // keep track of the previous offset event\n        let lastState = stopEvent;\n        let elapsedSeconds = 0;\n        // iterate through all the events since the last stop\n        this._state.forEachBetween(stopEvent.time, time + this.sampleTime, e => {\n            let periodStartTime = lastState.time;\n            // if there is an offset event in this period use that\n            const offsetEvent = this._tickOffset.get(e.time);\n            if (offsetEvent && offsetEvent.time >= lastState.time) {\n                elapsedSeconds = offsetEvent.seconds;\n                periodStartTime = offsetEvent.time;\n            }\n            if (lastState.state === \"started\" && e.state !== \"started\") {\n                elapsedSeconds += e.time - periodStartTime;\n            }\n            lastState = e;\n        });\n        // remove the temporary event\n        this._state.remove(tmpEvent);\n        // return the ticks\n        return elapsedSeconds;\n    }\n    /**\n     * Set the clock's ticks at the given time.\n     * @param  ticks The tick value to set\n     * @param  time  When to set the tick value\n     */\n    setTicksAtTime(ticks, time) {\n        time = this.toSeconds(time);\n        this._tickOffset.cancel(time);\n        this._tickOffset.add({\n            seconds: this.frequency.getDurationOfTicks(ticks, time),\n            ticks,\n            time,\n        });\n        return this;\n    }\n    /**\n     * Returns the scheduled state at the given time.\n     * @param  time  The time to query.\n     */\n    getStateAtTime(time) {\n        time = this.toSeconds(time);\n        return this._state.getValueAtTime(time);\n    }\n    /**\n     * Get the time of the given tick. The second argument\n     * is when to test before. Since ticks can be set (with setTicksAtTime)\n     * there may be multiple times for a given tick value.\n     * @param  tick The tick number.\n     * @param  before When to measure the tick value from.\n     * @return The time of the tick\n     */\n    getTimeOfTick(tick, before = this.now()) {\n        const offset = this._tickOffset.get(before);\n        const event = this._state.get(before);\n        const startTime = Math.max(offset.time, event.time);\n        const absoluteTicks = this.frequency.getTicksAtTime(startTime) + tick - offset.ticks;\n        return this.frequency.getTimeOfTick(absoluteTicks);\n    }\n    /**\n     * Invoke the callback event at all scheduled ticks between the\n     * start time and the end time\n     * @param  startTime  The beginning of the search range\n     * @param  endTime    The end of the search range\n     * @param  callback   The callback to invoke with each tick\n     */\n    forEachTickBetween(startTime, endTime, callback) {\n        // only iterate through the sections where it is \"started\"\n        let lastStateEvent = this._state.get(startTime);\n        this._state.forEachBetween(startTime, endTime, event => {\n            if (lastStateEvent && lastStateEvent.state === \"started\" && event.state !== \"started\") {\n                this.forEachTickBetween(Math.max(lastStateEvent.time, startTime), event.time - this.sampleTime, callback);\n            }\n            lastStateEvent = event;\n        });\n        let error = null;\n        if (lastStateEvent && lastStateEvent.state === \"started\") {\n            const maxStartTime = Math.max(lastStateEvent.time, startTime);\n            // figure out the difference between the frequency ticks and the\n            const startTicks = this.frequency.getTicksAtTime(maxStartTime);\n            const ticksAtStart = this.frequency.getTicksAtTime(lastStateEvent.time);\n            const diff = startTicks - ticksAtStart;\n            let offset = Math.ceil(diff) - diff;\n            // guard against floating point issues\n            offset = EQ(offset, 1) ? 0 : offset;\n            let nextTickTime = this.frequency.getTimeOfTick(startTicks + offset);\n            while (nextTickTime < endTime) {\n                try {\n                    callback(nextTickTime, Math.round(this.getTicksAtTime(nextTickTime)));\n                }\n                catch (e) {\n                    error = e;\n                    break;\n                }\n                nextTickTime += this.frequency.getDurationOfTicks(1, nextTickTime);\n            }\n        }\n        if (error) {\n            throw error;\n        }\n        return this;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._state.dispose();\n        this._tickOffset.dispose();\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=TickSource.js.map","/**\n * A class which provides a reliable callback using either\n * a Web Worker, or if that isn't supported, falls back to setTimeout.\n */\nexport class Ticker {\n    constructor(callback, type, updateInterval) {\n        this._callback = callback;\n        this._type = type;\n        this._updateInterval = updateInterval;\n        // create the clock source for the first time\n        this._createClock();\n    }\n    /**\n     * Generate a web worker\n     */\n    _createWorker() {\n        const blob = new Blob([\n            /* javascript */ `\n\t\t\t// the initial timeout time\n\t\t\tlet timeoutTime =  ${(this._updateInterval * 1000).toFixed(1)};\n\t\t\t// onmessage callback\n\t\t\tself.onmessage = function(msg){\n\t\t\t\ttimeoutTime = parseInt(msg.data);\n\t\t\t};\n\t\t\t// the tick function which posts a message\n\t\t\t// and schedules a new tick\n\t\t\tfunction tick(){\n\t\t\t\tsetTimeout(tick, timeoutTime);\n\t\t\t\tself.postMessage('tick');\n\t\t\t}\n\t\t\t// call tick initially\n\t\t\ttick();\n\t\t\t`\n        ], { type: \"text/javascript\" });\n        const blobUrl = URL.createObjectURL(blob);\n        const worker = new Worker(blobUrl);\n        worker.onmessage = this._callback.bind(this);\n        this._worker = worker;\n    }\n    /**\n     * Create a timeout loop\n     */\n    _createTimeout() {\n        this._timeout = setTimeout(() => {\n            this._createTimeout();\n            this._callback();\n        }, this._updateInterval * 1000);\n    }\n    /**\n     * Create the clock source.\n     */\n    _createClock() {\n        if (this._type === \"worker\") {\n            try {\n                this._createWorker();\n            }\n            catch (e) {\n                // workers not supported, fallback to timeout\n                this._type = \"timeout\";\n                this._createClock();\n            }\n        }\n        else if (this._type === \"timeout\") {\n            this._createTimeout();\n        }\n    }\n    /**\n     * Clean up the current clock source\n     */\n    _disposeClock() {\n        if (this._timeout) {\n            clearTimeout(this._timeout);\n            this._timeout = 0;\n        }\n        if (this._worker) {\n            this._worker.terminate();\n            this._worker.onmessage = null;\n        }\n    }\n    /**\n     * The rate in seconds the ticker will update\n     */\n    get updateInterval() {\n        return this._updateInterval;\n    }\n    set updateInterval(interval) {\n        this._updateInterval = Math.max(interval, 128 / 44100);\n        if (this._type === \"worker\") {\n            this._worker.postMessage(Math.max(interval * 1000, 1));\n        }\n    }\n    /**\n     * The type of the ticker, either a worker or a timeout\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._disposeClock();\n        this._type = type;\n        this._createClock();\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        this._disposeClock();\n    }\n}\n//# sourceMappingURL=Ticker.js.map","import { TimeClass } from \"../../core/type/Time\";\nimport { TimelineValue } from \"../../core/util/TimelineValue\";\nimport { onContextClose, onContextInit } from \"../context/ContextInitialization\";\nimport { Gain } from \"../context/Gain\";\nimport { ToneWithContext } from \"../context/ToneWithContext\";\nimport { TicksClass } from \"../type/Ticks\";\nimport { TransportTimeClass } from \"../type/TransportTime\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { Emitter } from \"../util/Emitter\";\nimport { readOnly, writable } from \"../util/Interface\";\nimport { IntervalTimeline } from \"../util/IntervalTimeline\";\nimport { Timeline } from \"../util/Timeline\";\nimport { isArray, isDefined } from \"../util/TypeCheck\";\nimport { Clock } from \"./Clock\";\nimport { TransportEvent } from \"./TransportEvent\";\nimport { TransportRepeatEvent } from \"./TransportRepeatEvent\";\n/**\n * Transport for timing musical events.\n * Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)\n * Transport timing events pass in the exact time of the scheduled event\n * in the argument of the callback function. Pass that time value to the object\n * you're scheduling. <br><br>\n * A single transport is created for you when the library is initialized.\n * <br><br>\n * The transport emits the events: \"start\", \"stop\", \"pause\", and \"loop\" which are\n * called with the time of that event as the argument.\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination();\n * // repeated event every 8th note\n * Tone.Transport.scheduleRepeat((time) => {\n * \t// use the callback time to schedule events\n * \tosc.start(time).stop(time + 0.1);\n * }, \"8n\");\n * // transport must be started before it starts invoking events\n * Tone.Transport.start();\n * @category Core\n */\nexport class Transport extends ToneWithContext {\n    constructor() {\n        super(optionsFromArguments(Transport.getDefaults(), arguments));\n        this.name = \"Transport\";\n        //-------------------------------------\n        // \tLOOPING\n        //-------------------------------------\n        /**\n         * If the transport loops or not.\n         */\n        this._loop = new TimelineValue(false);\n        /**\n         * The loop start position in ticks\n         */\n        this._loopStart = 0;\n        /**\n         * The loop end position in ticks\n         */\n        this._loopEnd = 0;\n        //-------------------------------------\n        // \tTIMELINE EVENTS\n        //-------------------------------------\n        /**\n         * All the events in an object to keep track by ID\n         */\n        this._scheduledEvents = {};\n        /**\n         * The scheduled events.\n         */\n        this._timeline = new Timeline();\n        /**\n         * Repeated events\n         */\n        this._repeatedEvents = new IntervalTimeline();\n        /**\n         * All of the synced Signals\n         */\n        this._syncedSignals = [];\n        /**\n         * The swing amount\n         */\n        this._swingAmount = 0;\n        const options = optionsFromArguments(Transport.getDefaults(), arguments);\n        // CLOCK/TEMPO\n        this._ppq = options.ppq;\n        this._clock = new Clock({\n            callback: this._processTick.bind(this),\n            context: this.context,\n            frequency: 0,\n            units: \"bpm\",\n        });\n        this._bindClockEvents();\n        this.bpm = this._clock.frequency;\n        this._clock.frequency.multiplier = options.ppq;\n        this.bpm.setValueAtTime(options.bpm, 0);\n        readOnly(this, \"bpm\");\n        this._timeSignature = options.timeSignature;\n        // SWING\n        this._swingTicks = options.ppq / 2; // 8n\n    }\n    static getDefaults() {\n        return Object.assign(ToneWithContext.getDefaults(), {\n            bpm: 120,\n            loopEnd: \"4m\",\n            loopStart: 0,\n            ppq: 192,\n            swing: 0,\n            swingSubdivision: \"8n\",\n            timeSignature: 4,\n        });\n    }\n    //-------------------------------------\n    // \tTICKS\n    //-------------------------------------\n    /**\n     * called on every tick\n     * @param  tickTime clock relative tick time\n     */\n    _processTick(tickTime, ticks) {\n        // handle swing\n        if (this._swingAmount > 0 &&\n            ticks % this._ppq !== 0 && // not on a downbeat\n            ticks % (this._swingTicks * 2) !== 0) {\n            // add some swing\n            const progress = (ticks % (this._swingTicks * 2)) / (this._swingTicks * 2);\n            const amount = Math.sin((progress) * Math.PI) * this._swingAmount;\n            tickTime += new TicksClass(this.context, this._swingTicks * 2 / 3).toSeconds() * amount;\n        }\n        // do the loop test\n        if (this._loop.get(tickTime)) {\n            if (ticks >= this._loopEnd) {\n                this.emit(\"loopEnd\", tickTime);\n                this._clock.setTicksAtTime(this._loopStart, tickTime);\n                ticks = this._loopStart;\n                this.emit(\"loopStart\", tickTime, this._clock.getSecondsAtTime(tickTime));\n                this.emit(\"loop\", tickTime);\n            }\n        }\n        // invoke the timeline events scheduled on this tick\n        this._timeline.forEachAtTime(ticks, event => event.invoke(tickTime));\n    }\n    //-------------------------------------\n    // \tSCHEDULABLE EVENTS\n    //-------------------------------------\n    /**\n     * Schedule an event along the timeline.\n     * @param callback The callback to be invoked at the time.\n     * @param time The time to invoke the callback at.\n     * @return The id of the event which can be used for canceling the event.\n     * @example\n     * // schedule an event on the 16th measure\n     * Tone.Transport.schedule((time) => {\n     * \t// invoked on measure 16\n     * \tconsole.log(\"measure 16!\");\n     * }, \"16:0:0\");\n     */\n    schedule(callback, time) {\n        const event = new TransportEvent(this, {\n            callback,\n            time: new TransportTimeClass(this.context, time).toTicks(),\n        });\n        return this._addEvent(event, this._timeline);\n    }\n    /**\n     * Schedule a repeated event along the timeline. The event will fire\n     * at the `interval` starting at the `startTime` and for the specified\n     * `duration`.\n     * @param  callback   The callback to invoke.\n     * @param  interval   The duration between successive callbacks. Must be a positive number.\n     * @param  startTime  When along the timeline the events should start being invoked.\n     * @param  duration How long the event should repeat.\n     * @return  The ID of the scheduled event. Use this to cancel the event.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // a callback invoked every eighth note after the first measure\n     * Tone.Transport.scheduleRepeat((time) => {\n     * \tosc.start(time).stop(time + 0.1);\n     * }, \"8n\", \"1m\");\n     */\n    scheduleRepeat(callback, interval, startTime, duration = Infinity) {\n        const event = new TransportRepeatEvent(this, {\n            callback,\n            duration: new TimeClass(this.context, duration).toTicks(),\n            interval: new TimeClass(this.context, interval).toTicks(),\n            time: new TransportTimeClass(this.context, startTime).toTicks(),\n        });\n        // kick it off if the Transport is started\n        // @ts-ignore\n        return this._addEvent(event, this._repeatedEvents);\n    }\n    /**\n     * Schedule an event that will be removed after it is invoked.\n     * @param callback The callback to invoke once.\n     * @param time The time the callback should be invoked.\n     * @returns The ID of the scheduled event.\n     */\n    scheduleOnce(callback, time) {\n        const event = new TransportEvent(this, {\n            callback,\n            once: true,\n            time: new TransportTimeClass(this.context, time).toTicks(),\n        });\n        return this._addEvent(event, this._timeline);\n    }\n    /**\n     * Clear the passed in event id from the timeline\n     * @param eventId The id of the event.\n     */\n    clear(eventId) {\n        if (this._scheduledEvents.hasOwnProperty(eventId)) {\n            const item = this._scheduledEvents[eventId.toString()];\n            item.timeline.remove(item.event);\n            item.event.dispose();\n            delete this._scheduledEvents[eventId.toString()];\n        }\n        return this;\n    }\n    /**\n     * Add an event to the correct timeline. Keep track of the\n     * timeline it was added to.\n     * @returns the event id which was just added\n     */\n    _addEvent(event, timeline) {\n        this._scheduledEvents[event.id.toString()] = {\n            event,\n            timeline,\n        };\n        timeline.add(event);\n        return event.id;\n    }\n    /**\n     * Remove scheduled events from the timeline after\n     * the given time. Repeated events will be removed\n     * if their startTime is after the given time\n     * @param after Clear all events after this time.\n     */\n    cancel(after = 0) {\n        const computedAfter = this.toTicks(after);\n        this._timeline.forEachFrom(computedAfter, event => this.clear(event.id));\n        this._repeatedEvents.forEachFrom(computedAfter, event => this.clear(event.id));\n        return this;\n    }\n    //-------------------------------------\n    // \tSTART/STOP/PAUSE\n    //-------------------------------------\n    /**\n     * Bind start/stop/pause events from the clock and emit them.\n     */\n    _bindClockEvents() {\n        this._clock.on(\"start\", (time, offset) => {\n            offset = new TicksClass(this.context, offset).toSeconds();\n            this.emit(\"start\", time, offset);\n        });\n        this._clock.on(\"stop\", (time) => {\n            this.emit(\"stop\", time);\n        });\n        this._clock.on(\"pause\", (time) => {\n            this.emit(\"pause\", time);\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\", or \"paused\"\n     */\n    get state() {\n        return this._clock.getStateAtTime(this.now());\n    }\n    /**\n     * Start the transport and all sources synced to the transport.\n     * @param  time The time when the transport should start.\n     * @param  offset The timeline offset to start the transport.\n     * @example\n     * // start the transport in one second starting at beginning of the 5th measure.\n     * Tone.Transport.start(\"+1\", \"4:0:0\");\n     */\n    start(time, offset) {\n        let offsetTicks;\n        if (isDefined(offset)) {\n            offsetTicks = this.toTicks(offset);\n        }\n        // start the clock\n        this._clock.start(time, offsetTicks);\n        return this;\n    }\n    /**\n     * Stop the transport and all sources synced to the transport.\n     * @param time The time when the transport should stop.\n     * @example\n     * Tone.Transport.stop();\n     */\n    stop(time) {\n        this._clock.stop(time);\n        return this;\n    }\n    /**\n     * Pause the transport and all sources synced to the transport.\n     */\n    pause(time) {\n        this._clock.pause(time);\n        return this;\n    }\n    /**\n     * Toggle the current state of the transport. If it is\n     * started, it will stop it, otherwise it will start the Transport.\n     * @param  time The time of the event\n     */\n    toggle(time) {\n        time = this.toSeconds(time);\n        if (this._clock.getStateAtTime(time) !== \"started\") {\n            this.start(time);\n        }\n        else {\n            this.stop(time);\n        }\n        return this;\n    }\n    //-------------------------------------\n    // \tSETTERS/GETTERS\n    //-------------------------------------\n    /**\n     * The time signature as just the numerator over 4.\n     * For example 4/4 would be just 4 and 6/8 would be 3.\n     * @example\n     * // common time\n     * Tone.Transport.timeSignature = 4;\n     * // 7/8\n     * Tone.Transport.timeSignature = [7, 8];\n     * // this will be reduced to a single number\n     * Tone.Transport.timeSignature; // returns 3.5\n     */\n    get timeSignature() {\n        return this._timeSignature;\n    }\n    set timeSignature(timeSig) {\n        if (isArray(timeSig)) {\n            timeSig = (timeSig[0] / timeSig[1]) * 4;\n        }\n        this._timeSignature = timeSig;\n    }\n    /**\n     * When the Transport.loop = true, this is the starting position of the loop.\n     */\n    get loopStart() {\n        return new TimeClass(this.context, this._loopStart, \"i\").toSeconds();\n    }\n    set loopStart(startPosition) {\n        this._loopStart = this.toTicks(startPosition);\n    }\n    /**\n     * When the Transport.loop = true, this is the ending position of the loop.\n     */\n    get loopEnd() {\n        return new TimeClass(this.context, this._loopEnd, \"i\").toSeconds();\n    }\n    set loopEnd(endPosition) {\n        this._loopEnd = this.toTicks(endPosition);\n    }\n    /**\n     * If the transport loops or not.\n     */\n    get loop() {\n        return this._loop.get(this.now());\n    }\n    set loop(loop) {\n        this._loop.set(loop, this.now());\n    }\n    /**\n     * Set the loop start and stop at the same time.\n     * @example\n     * // loop over the first measure\n     * Tone.Transport.setLoopPoints(0, \"1m\");\n     * Tone.Transport.loop = true;\n     */\n    setLoopPoints(startPosition, endPosition) {\n        this.loopStart = startPosition;\n        this.loopEnd = endPosition;\n        return this;\n    }\n    /**\n     * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.\n     */\n    get swing() {\n        return this._swingAmount;\n    }\n    set swing(amount) {\n        // scale the values to a normal range\n        this._swingAmount = amount;\n    }\n    /**\n     * Set the subdivision which the swing will be applied to.\n     * The default value is an 8th note. Value must be less\n     * than a quarter note.\n     */\n    get swingSubdivision() {\n        return new TicksClass(this.context, this._swingTicks).toNotation();\n    }\n    set swingSubdivision(subdivision) {\n        this._swingTicks = this.toTicks(subdivision);\n    }\n    /**\n     * The Transport's position in Bars:Beats:Sixteenths.\n     * Setting the value will jump to that position right away.\n     */\n    get position() {\n        const now = this.now();\n        const ticks = this._clock.getTicksAtTime(now);\n        return new TicksClass(this.context, ticks).toBarsBeatsSixteenths();\n    }\n    set position(progress) {\n        const ticks = this.toTicks(progress);\n        this.ticks = ticks;\n    }\n    /**\n     * The Transport's position in seconds\n     * Setting the value will jump to that position right away.\n     */\n    get seconds() {\n        return this._clock.seconds;\n    }\n    set seconds(s) {\n        const now = this.now();\n        const ticks = this._clock.frequency.timeToTicks(s, now);\n        this.ticks = ticks;\n    }\n    /**\n     * The Transport's loop position as a normalized value. Always\n     * returns 0 if the transport if loop is not true.\n     */\n    get progress() {\n        if (this.loop) {\n            const now = this.now();\n            const ticks = this._clock.getTicksAtTime(now);\n            return (ticks - this._loopStart) / (this._loopEnd - this._loopStart);\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The transports current tick position.\n     */\n    get ticks() {\n        return this._clock.ticks;\n    }\n    set ticks(t) {\n        if (this._clock.ticks !== t) {\n            const now = this.now();\n            // stop everything synced to the transport\n            if (this.state === \"started\") {\n                const ticks = this._clock.getTicksAtTime(now);\n                // schedule to start on the next tick, #573\n                const time = this._clock.getTimeOfTick(Math.ceil(ticks));\n                this.emit(\"stop\", time);\n                this._clock.setTicksAtTime(t, time);\n                // restart it with the new time\n                this.emit(\"start\", time, this._clock.getSecondsAtTime(time));\n            }\n            else {\n                this._clock.setTicksAtTime(t, now);\n            }\n        }\n    }\n    /**\n     * Get the clock's ticks at the given time.\n     * @param  time  When to get the tick value\n     * @return The tick value at the given time.\n     */\n    getTicksAtTime(time) {\n        return Math.round(this._clock.getTicksAtTime(time));\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        return this._clock.getSecondsAtTime(time);\n    }\n    /**\n     * Pulses Per Quarter note. This is the smallest resolution\n     * the Transport timing supports. This should be set once\n     * on initialization and not set again. Changing this value\n     * after other objects have been created can cause problems.\n     */\n    get PPQ() {\n        return this._clock.frequency.multiplier;\n    }\n    set PPQ(ppq) {\n        this._clock.frequency.multiplier = ppq;\n    }\n    //-------------------------------------\n    // \tSYNCING\n    //-------------------------------------\n    /**\n     * Returns the time aligned to the next subdivision\n     * of the Transport. If the Transport is not started,\n     * it will return 0.\n     * Note: this will not work precisely during tempo ramps.\n     * @param  subdivision  The subdivision to quantize to\n     * @return  The context time of the next subdivision.\n     * @example\n     * // the transport must be started, otherwise returns 0\n     * Tone.Transport.start();\n     * Tone.Transport.nextSubdivision(\"4n\");\n     */\n    nextSubdivision(subdivision) {\n        subdivision = this.toTicks(subdivision);\n        if (this.state !== \"started\") {\n            // if the transport's not started, return 0\n            return 0;\n        }\n        else {\n            const now = this.now();\n            // the remainder of the current ticks and the subdivision\n            const transportPos = this.getTicksAtTime(now);\n            const remainingTicks = subdivision - transportPos % subdivision;\n            return this._clock.nextTickTime(remainingTicks, now);\n        }\n    }\n    /**\n     * Attaches the signal to the tempo control signal so that\n     * any changes in the tempo will change the signal in the same\n     * ratio.\n     *\n     * @param signal\n     * @param ratio Optionally pass in the ratio between the two signals.\n     * \t\t\tOtherwise it will be computed based on their current values.\n     */\n    syncSignal(signal, ratio) {\n        if (!ratio) {\n            // get the sync ratio\n            const now = this.now();\n            if (signal.getValueAtTime(now) !== 0) {\n                const bpm = this.bpm.getValueAtTime(now);\n                const computedFreq = 1 / (60 / bpm / this.PPQ);\n                ratio = signal.getValueAtTime(now) / computedFreq;\n            }\n            else {\n                ratio = 0;\n            }\n        }\n        const ratioSignal = new Gain(ratio);\n        // @ts-ignore\n        this.bpm.connect(ratioSignal);\n        // @ts-ignore\n        ratioSignal.connect(signal._param);\n        this._syncedSignals.push({\n            initial: signal.value,\n            ratio: ratioSignal,\n            signal,\n        });\n        signal.value = 0;\n        return this;\n    }\n    /**\n     * Unsyncs a previously synced signal from the transport's control.\n     * See Transport.syncSignal.\n     */\n    unsyncSignal(signal) {\n        for (let i = this._syncedSignals.length - 1; i >= 0; i--) {\n            const syncedSignal = this._syncedSignals[i];\n            if (syncedSignal.signal === signal) {\n                syncedSignal.ratio.dispose();\n                syncedSignal.signal.value = syncedSignal.initial;\n                this._syncedSignals.splice(i, 1);\n            }\n        }\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._clock.dispose();\n        writable(this, \"bpm\");\n        this._timeline.dispose();\n        this._repeatedEvents.dispose();\n        return this;\n    }\n}\nEmitter.mixin(Transport);\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\nonContextInit(context => {\n    context.transport = new Transport({ context });\n});\nonContextClose(context => {\n    context.transport.dispose();\n});\n//# sourceMappingURL=Transport.js.map","import { noOp } from \"../util/Interface\";\n/**\n * TransportEvent is an internal class used by [[Transport]]\n * to schedule events. Do no invoke this class directly, it is\n * handled from within Tone.Transport.\n */\nexport class TransportEvent {\n    /**\n     * @param transport The transport object which the event belongs to\n     */\n    constructor(transport, opts) {\n        /**\n         * The unique id of the event\n         */\n        this.id = TransportEvent._eventId++;\n        const options = Object.assign(TransportEvent.getDefaults(), opts);\n        this.transport = transport;\n        this.callback = options.callback;\n        this._once = options.once;\n        this.time = options.time;\n    }\n    static getDefaults() {\n        return {\n            callback: noOp,\n            once: false,\n            time: 0,\n        };\n    }\n    /**\n     * Invoke the event callback.\n     * @param  time  The AudioContext time in seconds of the event\n     */\n    invoke(time) {\n        if (this.callback) {\n            this.callback(time);\n            if (this._once) {\n                this.transport.clear(this.id);\n            }\n        }\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        this.callback = undefined;\n        return this;\n    }\n}\n/**\n * Current ID counter\n */\nTransportEvent._eventId = 0;\n//# sourceMappingURL=TransportEvent.js.map","import { TicksClass } from \"../type/Ticks\";\nimport { TransportEvent } from \"./TransportEvent\";\n/**\n * TransportRepeatEvent is an internal class used by Tone.Transport\n * to schedule repeat events. This class should not be instantiated directly.\n */\nexport class TransportRepeatEvent extends TransportEvent {\n    /**\n     * @param transport The transport object which the event belongs to\n     */\n    constructor(transport, opts) {\n        super(transport, opts);\n        /**\n         * The ID of the current timeline event\n         */\n        this._currentId = -1;\n        /**\n         * The ID of the next timeline event\n         */\n        this._nextId = -1;\n        /**\n         * The time of the next event\n         */\n        this._nextTick = this.time;\n        /**\n         * a reference to the bound start method\n         */\n        this._boundRestart = this._restart.bind(this);\n        const options = Object.assign(TransportRepeatEvent.getDefaults(), opts);\n        this.duration = new TicksClass(transport.context, options.duration).valueOf();\n        this._interval = new TicksClass(transport.context, options.interval).valueOf();\n        this._nextTick = options.time;\n        this.transport.on(\"start\", this._boundRestart);\n        this.transport.on(\"loopStart\", this._boundRestart);\n        this.context = this.transport.context;\n        this._restart();\n    }\n    static getDefaults() {\n        return Object.assign({}, TransportEvent.getDefaults(), {\n            duration: Infinity,\n            interval: 1,\n            once: false,\n        });\n    }\n    /**\n     * Invoke the callback. Returns the tick time which\n     * the next event should be scheduled at.\n     * @param  time  The AudioContext time in seconds of the event\n     */\n    invoke(time) {\n        // create more events if necessary\n        this._createEvents(time);\n        // call the super class\n        super.invoke(time);\n    }\n    /**\n     * Push more events onto the timeline to keep up with the position of the timeline\n     */\n    _createEvents(time) {\n        // schedule the next event\n        const ticks = this.transport.getTicksAtTime(time);\n        if (ticks >= this.time && ticks >= this._nextTick && this._nextTick + this._interval < this.time + this.duration) {\n            this._nextTick += this._interval;\n            this._currentId = this._nextId;\n            this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new TicksClass(this.context, this._nextTick).toSeconds());\n        }\n    }\n    /**\n     * Push more events onto the timeline to keep up with the position of the timeline\n     */\n    _restart(time) {\n        this.transport.clear(this._currentId);\n        this.transport.clear(this._nextId);\n        this._nextTick = this.time;\n        const ticks = this.transport.getTicksAtTime(time);\n        if (ticks > this.time) {\n            this._nextTick = this.time + Math.ceil((ticks - this.time) / this._interval) * this._interval;\n        }\n        this._currentId = this.transport.scheduleOnce(this.invoke.bind(this), new TicksClass(this.context, this._nextTick).toSeconds());\n        this._nextTick += this._interval;\n        this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new TicksClass(this.context, this._nextTick).toSeconds());\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.transport.clear(this._currentId);\n        this.transport.clear(this._nextId);\n        this.transport.off(\"start\", this._boundRestart);\n        this.transport.off(\"loopStart\", this._boundRestart);\n        return this;\n    }\n}\n//# sourceMappingURL=TransportRepeatEvent.js.map","import { AudioContext as stdAudioContext, AudioWorkletNode as stdAudioWorkletNode, OfflineAudioContext as stdOfflineAudioContext } from \"standardized-audio-context\";\nimport { assert } from \"../util/Debug\";\nimport { isDefined } from \"../util/TypeCheck\";\n/**\n * Create a new AudioContext\n */\nexport function createAudioContext(options) {\n    return new stdAudioContext(options);\n}\n/**\n * Create a new OfflineAudioContext\n */\nexport function createOfflineAudioContext(channels, length, sampleRate) {\n    return new stdOfflineAudioContext(channels, length, sampleRate);\n}\n/**\n * A reference to the window object\n * @hidden\n */\nexport const theWindow = typeof self === \"object\" ? self : null;\n/**\n * If the browser has a window object which has an AudioContext\n * @hidden\n */\nexport const hasAudioContext = theWindow &&\n    (theWindow.hasOwnProperty(\"AudioContext\") || theWindow.hasOwnProperty(\"webkitAudioContext\"));\nexport function createAudioWorkletNode(context, name, options) {\n    assert(isDefined(stdAudioWorkletNode), \"This node only works in a secure context (https or localhost)\");\n    // @ts-ignore\n    return new stdAudioWorkletNode(context, name, options);\n}\n/**\n * This promise resolves to a boolean which indicates if the\n * functionality is supported within the currently used browse.\n * Taken from [standardized-audio-context](https://github.com/chrisguttandin/standardized-audio-context#issupported)\n */\nexport { isSupported as supported } from \"standardized-audio-context\";\n//# sourceMappingURL=AudioContext.js.map","import { Emitter } from \"../util/Emitter\";\nexport class BaseContext extends Emitter {\n    constructor() {\n        super(...arguments);\n        this.isOffline = false;\n    }\n}\n//# sourceMappingURL=BaseContext.js.map","import { __awaiter } from \"tslib\";\nimport { Ticker } from \"../clock/Ticker\";\nimport { isAudioContext } from \"../util/AdvancedTypeCheck\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { Timeline } from \"../util/Timeline\";\nimport { isDefined, isString } from \"../util/TypeCheck\";\nimport { createAudioContext, createAudioWorkletNode } from \"./AudioContext\";\nimport { closeContext, initializeContext } from \"./ContextInitialization\";\nimport { BaseContext } from \"./BaseContext\";\nimport { assert } from \"../util/Debug\";\n/**\n * Wrapper around the native AudioContext.\n * @category Core\n */\nexport class Context extends BaseContext {\n    constructor() {\n        super();\n        this.name = \"Context\";\n        /**\n         * An object containing all of the constants AudioBufferSourceNodes\n         */\n        this._constants = new Map();\n        /**\n         * All of the setTimeout events.\n         */\n        this._timeouts = new Timeline();\n        /**\n         * The timeout id counter\n         */\n        this._timeoutIds = 0;\n        /**\n         * Private indicator if the context has been initialized\n         */\n        this._initialized = false;\n        /**\n         * Indicates if the context is an OfflineAudioContext or an AudioContext\n         */\n        this.isOffline = false;\n        //--------------------------------------------\n        // AUDIO WORKLET\n        //--------------------------------------------\n        /**\n         * Maps a module name to promise of the addModule method\n         */\n        this._workletModules = new Map();\n        const options = optionsFromArguments(Context.getDefaults(), arguments, [\"context\"]);\n        if (options.context) {\n            this._context = options.context;\n        }\n        else {\n            this._context = createAudioContext({\n                latencyHint: options.latencyHint,\n            });\n        }\n        this._ticker = new Ticker(this.emit.bind(this, \"tick\"), options.clockSource, options.updateInterval);\n        this.on(\"tick\", this._timeoutLoop.bind(this));\n        // fwd events from the context\n        this._context.onstatechange = () => {\n            this.emit(\"statechange\", this.state);\n        };\n        this._setLatencyHint(options.latencyHint);\n        this.lookAhead = options.lookAhead;\n    }\n    static getDefaults() {\n        return {\n            clockSource: \"worker\",\n            latencyHint: \"interactive\",\n            lookAhead: 0.1,\n            updateInterval: 0.05,\n        };\n    }\n    /**\n     * Finish setting up the context. **You usually do not need to do this manually.**\n     */\n    initialize() {\n        if (!this._initialized) {\n            // add any additional modules\n            initializeContext(this);\n            this._initialized = true;\n        }\n        return this;\n    }\n    //---------------------------\n    // BASE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAnalyser() {\n        return this._context.createAnalyser();\n    }\n    createOscillator() {\n        return this._context.createOscillator();\n    }\n    createBufferSource() {\n        return this._context.createBufferSource();\n    }\n    createBiquadFilter() {\n        return this._context.createBiquadFilter();\n    }\n    createBuffer(numberOfChannels, length, sampleRate) {\n        return this._context.createBuffer(numberOfChannels, length, sampleRate);\n    }\n    createChannelMerger(numberOfInputs) {\n        return this._context.createChannelMerger(numberOfInputs);\n    }\n    createChannelSplitter(numberOfOutputs) {\n        return this._context.createChannelSplitter(numberOfOutputs);\n    }\n    createConstantSource() {\n        return this._context.createConstantSource();\n    }\n    createConvolver() {\n        return this._context.createConvolver();\n    }\n    createDelay(maxDelayTime) {\n        return this._context.createDelay(maxDelayTime);\n    }\n    createDynamicsCompressor() {\n        return this._context.createDynamicsCompressor();\n    }\n    createGain() {\n        return this._context.createGain();\n    }\n    createIIRFilter(feedForward, feedback) {\n        // @ts-ignore\n        return this._context.createIIRFilter(feedForward, feedback);\n    }\n    createPanner() {\n        return this._context.createPanner();\n    }\n    createPeriodicWave(real, imag, constraints) {\n        return this._context.createPeriodicWave(real, imag, constraints);\n    }\n    createStereoPanner() {\n        return this._context.createStereoPanner();\n    }\n    createWaveShaper() {\n        return this._context.createWaveShaper();\n    }\n    createMediaStreamSource(stream) {\n        assert(isAudioContext(this._context), \"Not available if OfflineAudioContext\");\n        const context = this._context;\n        return context.createMediaStreamSource(stream);\n    }\n    createMediaStreamDestination() {\n        assert(isAudioContext(this._context), \"Not available if OfflineAudioContext\");\n        const context = this._context;\n        return context.createMediaStreamDestination();\n    }\n    decodeAudioData(audioData) {\n        return this._context.decodeAudioData(audioData);\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get currentTime() {\n        return this._context.currentTime;\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get state() {\n        return this._context.state;\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get sampleRate() {\n        return this._context.sampleRate;\n    }\n    /**\n     * The listener\n     */\n    get listener() {\n        this.initialize();\n        return this._listener;\n    }\n    set listener(l) {\n        assert(!this._initialized, \"The listener cannot be set after initialization.\");\n        this._listener = l;\n    }\n    /**\n     * There is only one Transport per Context. It is created on initialization.\n     */\n    get transport() {\n        this.initialize();\n        return this._transport;\n    }\n    set transport(t) {\n        assert(!this._initialized, \"The transport cannot be set after initialization.\");\n        this._transport = t;\n    }\n    /**\n     * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.\n     */\n    get draw() {\n        this.initialize();\n        return this._draw;\n    }\n    set draw(d) {\n        assert(!this._initialized, \"Draw cannot be set after initialization.\");\n        this._draw = d;\n    }\n    /**\n     * A reference to the Context's destination node.\n     */\n    get destination() {\n        this.initialize();\n        return this._destination;\n    }\n    set destination(d) {\n        assert(!this._initialized, \"The destination cannot be set after initialization.\");\n        this._destination = d;\n    }\n    /**\n     * Create an audio worklet node from a name and options. The module\n     * must first be loaded using [[addAudioWorkletModule]].\n     */\n    createAudioWorkletNode(name, options) {\n        return createAudioWorkletNode(this.rawContext, name, options);\n    }\n    /**\n     * Add an AudioWorkletProcessor module\n     * @param url The url of the module\n     * @param name The name of the module\n     */\n    addAudioWorkletModule(url, name) {\n        return __awaiter(this, void 0, void 0, function* () {\n            assert(isDefined(this.rawContext.audioWorklet), \"AudioWorkletNode is only available in a secure context (https or localhost)\");\n            if (!this._workletModules.has(name)) {\n                this._workletModules.set(name, this.rawContext.audioWorklet.addModule(url));\n            }\n            yield this._workletModules.get(name);\n        });\n    }\n    /**\n     * Returns a promise which resolves when all of the worklets have been loaded on this context\n     */\n    workletsAreReady() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const promises = [];\n            this._workletModules.forEach(promise => promises.push(promise));\n            yield Promise.all(promises);\n        });\n    }\n    //---------------------------\n    // TICKER\n    //---------------------------\n    /**\n     * How often the interval callback is invoked.\n     * This number corresponds to how responsive the scheduling\n     * can be. context.updateInterval + context.lookAhead gives you the\n     * total latency between scheduling an event and hearing it.\n     */\n    get updateInterval() {\n        return this._ticker.updateInterval;\n    }\n    set updateInterval(interval) {\n        this._ticker.updateInterval = interval;\n    }\n    /**\n     * What the source of the clock is, either \"worker\" (default),\n     * \"timeout\", or \"offline\" (none).\n     */\n    get clockSource() {\n        return this._ticker.type;\n    }\n    set clockSource(type) {\n        this._ticker.type = type;\n    }\n    /**\n     * The type of playback, which affects tradeoffs between audio\n     * output latency and responsiveness.\n     * In addition to setting the value in seconds, the latencyHint also\n     * accepts the strings \"interactive\" (prioritizes low latency),\n     * \"playback\" (prioritizes sustained playback), \"balanced\" (balances\n     * latency and performance), and \"fastest\" (lowest latency, might glitch more often).\n     * @example\n     * // prioritize sustained playback\n     * const context = new Tone.Context({ latencyHint: \"playback\" });\n     * // set this context as the global Context\n     * Tone.setContext(context);\n     */\n    get latencyHint() {\n        return this._latencyHint;\n    }\n    /**\n     * Update the lookAhead and updateInterval based on the latencyHint\n     */\n    _setLatencyHint(hint) {\n        let lookAheadValue = 0;\n        this._latencyHint = hint;\n        if (isString(hint)) {\n            switch (hint) {\n                case \"interactive\":\n                    lookAheadValue = 0.1;\n                    break;\n                case \"playback\":\n                    lookAheadValue = 0.5;\n                    break;\n                case \"balanced\":\n                    lookAheadValue = 0.25;\n                    break;\n            }\n        }\n        this.lookAhead = lookAheadValue;\n        this.updateInterval = lookAheadValue / 2;\n    }\n    /**\n     * The unwrapped AudioContext or OfflineAudioContext\n     */\n    get rawContext() {\n        return this._context;\n    }\n    /**\n     * The current audio context time plus a short [[lookAhead]].\n     */\n    now() {\n        return this._context.currentTime + this.lookAhead;\n    }\n    /**\n     * The current audio context time without the [[lookAhead]].\n     * In most cases it is better to use [[now]] instead of [[immediate]] since\n     * with [[now]] the [[lookAhead]] is applied equally to _all_ components including internal components,\n     * to making sure that everything is scheduled in sync. Mixing [[now]] and [[immediate]]\n     * can cause some timing issues. If no lookAhead is desired, you can set the [[lookAhead]] to `0`.\n     */\n    immediate() {\n        return this._context.currentTime;\n    }\n    /**\n     * Starts the audio context from a suspended state. This is required\n     * to initially start the AudioContext. See [[Tone.start]]\n     */\n    resume() {\n        if (this._context.state === \"suspended\" && isAudioContext(this._context)) {\n            return this._context.resume();\n        }\n        else {\n            return Promise.resolve();\n        }\n    }\n    /**\n     * Close the context. Once closed, the context can no longer be used and\n     * any AudioNodes created from the context will be silent.\n     */\n    close() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (isAudioContext(this._context)) {\n                yield this._context.close();\n            }\n            if (this._initialized) {\n                closeContext(this);\n            }\n        });\n    }\n    /**\n     * **Internal** Generate a looped buffer at some constant value.\n     */\n    getConstant(val) {\n        if (this._constants.has(val)) {\n            return this._constants.get(val);\n        }\n        else {\n            const buffer = this._context.createBuffer(1, 128, this._context.sampleRate);\n            const arr = buffer.getChannelData(0);\n            for (let i = 0; i < arr.length; i++) {\n                arr[i] = val;\n            }\n            const constant = this._context.createBufferSource();\n            constant.channelCount = 1;\n            constant.channelCountMode = \"explicit\";\n            constant.buffer = buffer;\n            constant.loop = true;\n            constant.start(0);\n            this._constants.set(val, constant);\n            return constant;\n        }\n    }\n    /**\n     * Clean up. Also closes the audio context.\n     */\n    dispose() {\n        super.dispose();\n        this._ticker.dispose();\n        this._timeouts.dispose();\n        Object.keys(this._constants).map(val => this._constants[val].disconnect());\n        return this;\n    }\n    //---------------------------\n    // TIMEOUTS\n    //---------------------------\n    /**\n     * The private loop which keeps track of the context scheduled timeouts\n     * Is invoked from the clock source\n     */\n    _timeoutLoop() {\n        const now = this.now();\n        let firstEvent = this._timeouts.peek();\n        while (this._timeouts.length && firstEvent && firstEvent.time <= now) {\n            // invoke the callback\n            firstEvent.callback();\n            // shift the first event off\n            this._timeouts.shift();\n            // get the next one\n            firstEvent = this._timeouts.peek();\n        }\n    }\n    /**\n     * A setTimeout which is guaranteed by the clock source.\n     * Also runs in the offline context.\n     * @param  fn       The callback to invoke\n     * @param  timeout  The timeout in seconds\n     * @returns ID to use when invoking Context.clearTimeout\n     */\n    setTimeout(fn, timeout) {\n        this._timeoutIds++;\n        const now = this.now();\n        this._timeouts.add({\n            callback: fn,\n            id: this._timeoutIds,\n            time: now + timeout,\n        });\n        return this._timeoutIds;\n    }\n    /**\n     * Clears a previously scheduled timeout with Tone.context.setTimeout\n     * @param  id  The ID returned from setTimeout\n     */\n    clearTimeout(id) {\n        this._timeouts.forEach(event => {\n            if (event.id === id) {\n                this._timeouts.remove(event);\n            }\n        });\n        return this;\n    }\n    /**\n     * Clear the function scheduled by [[setInterval]]\n     */\n    clearInterval(id) {\n        return this.clearTimeout(id);\n    }\n    /**\n     * Adds a repeating event to the context's callback clock\n     */\n    setInterval(fn, interval) {\n        const id = ++this._timeoutIds;\n        const intervalFn = () => {\n            const now = this.now();\n            this._timeouts.add({\n                callback: () => {\n                    // invoke the callback\n                    fn();\n                    // invoke the event to repeat it\n                    intervalFn();\n                },\n                id,\n                time: now + interval,\n            });\n        };\n        // kick it off\n        intervalFn();\n        return id;\n    }\n}\n//# sourceMappingURL=Context.js.map","//-------------------------------------\n// INITIALIZING NEW CONTEXT\n//-------------------------------------\n/**\n * Array of callbacks to invoke when a new context is created\n */\nconst notifyNewContext = [];\n/**\n * Used internally to setup a new Context\n */\nexport function onContextInit(cb) {\n    notifyNewContext.push(cb);\n}\n/**\n * Invoke any classes which need to also be initialized when a new context is created.\n */\nexport function initializeContext(ctx) {\n    // add any additional modules\n    notifyNewContext.forEach(cb => cb(ctx));\n}\n/**\n * Array of callbacks to invoke when a new context is created\n */\nconst notifyCloseContext = [];\n/**\n * Used internally to tear down a Context\n */\nexport function onContextClose(cb) {\n    notifyCloseContext.push(cb);\n}\nexport function closeContext(ctx) {\n    // add any additional modules\n    notifyCloseContext.forEach(cb => cb(ctx));\n}\n//# sourceMappingURL=ContextInitialization.js.map","import { Param } from \"../context/Param\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { readOnly } from \"../util/Interface\";\nimport { ToneAudioNode } from \"./ToneAudioNode\";\n/**\n * Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).\n * @category Core\n * @offline 0.5 1\n * @example\n * const delay = new Tone.Delay(0.1).toDestination();\n * // connect the signal to both the delay and the destination\n * const pulse = new Tone.PulseOscillator().fan(delay, Tone.Destination);\n * // start and stop the pulse\n * pulse.start(0).stop(0.01);\n */\nexport class Delay extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Delay.getDefaults(), arguments, [\"delayTime\", \"maxDelay\"]));\n        this.name = \"Delay\";\n        const options = optionsFromArguments(Delay.getDefaults(), arguments, [\"delayTime\", \"maxDelay\"]);\n        const maxDelayInSeconds = this.toSeconds(options.maxDelay);\n        this._maxDelay = Math.max(maxDelayInSeconds, this.toSeconds(options.delayTime));\n        this._delayNode = this.input = this.output = this.context.createDelay(maxDelayInSeconds);\n        this.delayTime = new Param({\n            context: this.context,\n            param: this._delayNode.delayTime,\n            units: \"time\",\n            value: options.delayTime,\n            minValue: 0,\n            maxValue: this.maxDelay,\n        });\n        readOnly(this, \"delayTime\");\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            delayTime: 0,\n            maxDelay: 1,\n        });\n    }\n    /**\n     * The maximum delay time. This cannot be changed after\n     * the value is passed into the constructor.\n     */\n    get maxDelay() {\n        return this._maxDelay;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._delayNode.disconnect();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Delay.js.map","import { Volume } from \"../../component/channel/Volume\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { onContextClose, onContextInit } from \"./ContextInitialization\";\nimport { Gain } from \"./Gain\";\nimport { connectSeries, ToneAudioNode } from \"./ToneAudioNode\";\n/**\n * A single master output which is connected to the\n * AudioDestinationNode (aka your speakers).\n * It provides useful conveniences such as the ability\n * to set the volume and mute the entire application.\n * It also gives you the ability to apply master effects to your application.\n *\n * @example\n * const oscillator = new Tone.Oscillator().start();\n * // the audio will go from the oscillator to the speakers\n * oscillator.connect(Tone.Destination);\n * // a convenience for connecting to the master output is also provided:\n * oscillator.toDestination();\n * @category Core\n */\nexport class Destination extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Destination.getDefaults(), arguments));\n        this.name = \"Destination\";\n        this.input = new Volume({ context: this.context });\n        this.output = new Gain({ context: this.context });\n        /**\n         * The volume of the master output.\n         */\n        this.volume = this.input.volume;\n        const options = optionsFromArguments(Destination.getDefaults(), arguments);\n        connectSeries(this.input, this.output, this.context.rawContext.destination);\n        this.mute = options.mute;\n        this._internalChannels = [this.input, this.context.rawContext.destination, this.output];\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const oscillator = new Tone.Oscillator().start().toDestination();\n     * setTimeout(() => {\n     * \t// mute the output\n     * \tTone.Destination.mute = true;\n     * }, 1000);\n     */\n    get mute() {\n        return this.input.mute;\n    }\n    set mute(mute) {\n        this.input.mute = mute;\n    }\n    /**\n     * Add a master effects chain. NOTE: this will disconnect any nodes which were previously\n     * chained in the master effects chain.\n     * @param args All arguments will be connected in a row and the Master will be routed through it.\n     * @example\n     * // route all audio through a filter and compressor\n     * const lowpass = new Tone.Filter(800, \"lowpass\");\n     * const compressor = new Tone.Compressor(-18);\n     * Tone.Destination.chain(lowpass, compressor);\n     */\n    chain(...args) {\n        this.input.disconnect();\n        args.unshift(this.input);\n        args.push(this.output);\n        connectSeries(...args);\n        return this;\n    }\n    /**\n     * The maximum number of channels the system can output\n     * @example\n     * console.log(Tone.Destination.maxChannelCount);\n     */\n    get maxChannelCount() {\n        return this.context.rawContext.destination.maxChannelCount;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\nonContextInit(context => {\n    context.destination = new Destination({ context });\n});\nonContextClose(context => {\n    context.destination.dispose();\n});\n//# sourceMappingURL=Destination.js.map","import { __awaiter } from \"tslib\";\nimport { BaseContext } from \"./BaseContext\";\nexport class DummyContext extends BaseContext {\n    constructor() {\n        super(...arguments);\n        this.lookAhead = 0;\n        this.latencyHint = 0;\n        this.isOffline = false;\n    }\n    //---------------------------\n    // BASE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAnalyser() {\n        return {};\n    }\n    createOscillator() {\n        return {};\n    }\n    createBufferSource() {\n        return {};\n    }\n    createBiquadFilter() {\n        return {};\n    }\n    createBuffer(_numberOfChannels, _length, _sampleRate) {\n        return {};\n    }\n    createChannelMerger(_numberOfInputs) {\n        return {};\n    }\n    createChannelSplitter(_numberOfOutputs) {\n        return {};\n    }\n    createConstantSource() {\n        return {};\n    }\n    createConvolver() {\n        return {};\n    }\n    createDelay(_maxDelayTime) {\n        return {};\n    }\n    createDynamicsCompressor() {\n        return {};\n    }\n    createGain() {\n        return {};\n    }\n    createIIRFilter(_feedForward, _feedback) {\n        return {};\n    }\n    createPanner() {\n        return {};\n    }\n    createPeriodicWave(_real, _imag, _constraints) {\n        return {};\n    }\n    createStereoPanner() {\n        return {};\n    }\n    createWaveShaper() {\n        return {};\n    }\n    createMediaStreamSource(_stream) {\n        return {};\n    }\n    createMediaStreamDestination() {\n        return {};\n    }\n    decodeAudioData(_audioData) {\n        return Promise.resolve({});\n    }\n    //---------------------------\n    // TONE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAudioWorkletNode(_name, _options) {\n        return {};\n    }\n    get rawContext() {\n        return {};\n    }\n    addAudioWorkletModule(_url, _name) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return Promise.resolve();\n        });\n    }\n    resume() {\n        return Promise.resolve();\n    }\n    setTimeout(_fn, _timeout) {\n        return 0;\n    }\n    clearTimeout(_id) {\n        return this;\n    }\n    setInterval(_fn, _interval) {\n        return 0;\n    }\n    clearInterval(_id) {\n        return this;\n    }\n    getConstant(_val) {\n        return {};\n    }\n    get currentTime() {\n        return 0;\n    }\n    get state() {\n        return {};\n    }\n    get sampleRate() {\n        return 0;\n    }\n    get listener() {\n        return {};\n    }\n    get transport() {\n        return {};\n    }\n    get draw() {\n        return {};\n    }\n    set draw(_d) { }\n    get destination() {\n        return {};\n    }\n    set destination(_d) { }\n    now() {\n        return 0;\n    }\n    immediate() {\n        return 0;\n    }\n}\n//# sourceMappingURL=DummyContext.js.map","import { Param } from \"../context/Param\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { readOnly } from \"../util/Interface\";\nimport { ToneAudioNode } from \"./ToneAudioNode\";\n/**\n * A thin wrapper around the Native Web Audio GainNode.\n * The GainNode is a basic building block of the Web Audio\n * API and is useful for routing audio and adjusting gains.\n * @category Core\n * @offline 0.7 1\n * @example\n * const gainNode = new Tone.Gain(0).toDestination();\n * const osc = new Tone.Oscillator(30).connect(gainNode).start();\n * gainNode.gain.rampTo(1, 0.1);\n * gainNode.gain.rampTo(0, 0.4, 0.2);\n */\nexport class Gain extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Gain.getDefaults(), arguments, [\"gain\", \"units\"]));\n        this.name = \"Gain\";\n        /**\n         * The wrapped GainNode.\n         */\n        this._gainNode = this.context.createGain();\n        // input = output\n        this.input = this._gainNode;\n        this.output = this._gainNode;\n        const options = optionsFromArguments(Gain.getDefaults(), arguments, [\"gain\", \"units\"]);\n        this.gain = new Param({\n            context: this.context,\n            convert: options.convert,\n            param: this._gainNode.gain,\n            units: options.units,\n            value: options.gain,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        readOnly(this, \"gain\");\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            convert: true,\n            gain: 1,\n            units: \"gain\",\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._gainNode.disconnect();\n        this.gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Gain.js.map","import { ToneAudioNode } from \"./ToneAudioNode\";\nimport { Param } from \"./Param\";\nimport { onContextClose, onContextInit } from \"./ContextInitialization\";\n/**\n * Tone.Listener is a thin wrapper around the AudioListener. Listener combined\n * with [[Panner3D]] makes up the Web Audio API's 3D panning system. Panner3D allows you\n * to place sounds in 3D and Listener allows you to navigate the 3D sound environment from\n * a first-person perspective. There is only one listener per audio context.\n */\nexport class Listener extends ToneAudioNode {\n    constructor() {\n        super(...arguments);\n        this.name = \"Listener\";\n        this.positionX = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionX,\n        });\n        this.positionY = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionY,\n        });\n        this.positionZ = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionZ,\n        });\n        this.forwardX = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardX,\n        });\n        this.forwardY = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardY,\n        });\n        this.forwardZ = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardZ,\n        });\n        this.upX = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upX,\n        });\n        this.upY = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upY,\n        });\n        this.upZ = new Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upZ,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            positionX: 0,\n            positionY: 0,\n            positionZ: 0,\n            forwardX: 0,\n            forwardY: 0,\n            forwardZ: -1,\n            upX: 0,\n            upY: 1,\n            upZ: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.positionX.dispose();\n        this.positionY.dispose();\n        this.positionZ.dispose();\n        this.forwardX.dispose();\n        this.forwardY.dispose();\n        this.forwardZ.dispose();\n        this.upX.dispose();\n        this.upY.dispose();\n        this.upZ.dispose();\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\nonContextInit(context => {\n    context.listener = new Listener({ context });\n});\nonContextClose(context => {\n    context.listener.dispose();\n});\n//# sourceMappingURL=Listener.js.map","import { __awaiter } from \"tslib\";\nimport { getContext, setContext } from \"../Global\";\nimport { OfflineContext } from \"./OfflineContext\";\nimport { ToneAudioBuffer } from \"./ToneAudioBuffer\";\n/**\n * Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.\n * The OfflineAudioContext is capable of rendering much faster than real time in many cases.\n * The callback function also passes in an offline instance of [[Context]] which can be used\n * to schedule events along the Transport.\n * @param  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.\n * @param  duration     the amount of time to record for.\n * @return  The promise which is invoked with the ToneAudioBuffer of the recorded output.\n * @example\n * // render 2 seconds of the oscillator\n * Tone.Offline(() => {\n * \t// only nodes created in this callback will be recorded\n * \tconst oscillator = new Tone.Oscillator().toDestination().start(0);\n * }, 2).then((buffer) => {\n * \t// do something with the output buffer\n * \tconsole.log(buffer);\n * });\n * @example\n * // can also schedule events along the Transport\n * // using the passed in Offline Transport\n * Tone.Offline(({ transport }) => {\n * \tconst osc = new Tone.Oscillator().toDestination();\n * \ttransport.schedule(time => {\n * \t\tosc.start(time).stop(time + 0.1);\n * \t}, 1);\n * \t// make sure to start the transport\n * \ttransport.start(0.2);\n * }, 4).then((buffer) => {\n * \t// do something with the output buffer\n * \tconsole.log(buffer);\n * });\n * @category Core\n */\nexport function Offline(callback, duration, channels = 2, sampleRate = getContext().sampleRate) {\n    return __awaiter(this, void 0, void 0, function* () {\n        // set the OfflineAudioContext based on the current context\n        const originalContext = getContext();\n        const context = new OfflineContext(channels, duration, sampleRate);\n        setContext(context);\n        // invoke the callback/scheduling\n        yield callback(context);\n        // then render the audio\n        const bufferPromise = context.render();\n        // return the original AudioContext\n        setContext(originalContext);\n        // await the rendering\n        const buffer = yield bufferPromise;\n        // return the audio\n        return new ToneAudioBuffer(buffer);\n    });\n}\n//# sourceMappingURL=Offline.js.map","import { __awaiter } from \"tslib\";\nimport { createOfflineAudioContext } from \"../context/AudioContext\";\nimport { Context } from \"../context/Context\";\nimport { isOfflineAudioContext } from \"../util/AdvancedTypeCheck\";\nimport { ToneAudioBuffer } from \"./ToneAudioBuffer\";\n/**\n * Wrapper around the OfflineAudioContext\n * @category Core\n * @example\n * // generate a single channel, 0.5 second buffer\n * const context = new Tone.OfflineContext(1, 0.5);\n * const osc = new Tone.Oscillator({ context });\n * context.render().then(buffer => {\n * \tconsole.log(buffer.numberOfChannels, buffer.duration);\n * });\n */\nexport class OfflineContext extends Context {\n    constructor() {\n        super({\n            clockSource: \"offline\",\n            context: isOfflineAudioContext(arguments[0]) ?\n                arguments[0] : createOfflineAudioContext(arguments[0], arguments[1] * arguments[2], arguments[2]),\n            lookAhead: 0,\n            updateInterval: isOfflineAudioContext(arguments[0]) ?\n                128 / arguments[0].sampleRate : 128 / arguments[2],\n        });\n        this.name = \"OfflineContext\";\n        /**\n         * An artificial clock source\n         */\n        this._currentTime = 0;\n        this.isOffline = true;\n        this._duration = isOfflineAudioContext(arguments[0]) ?\n            arguments[0].length / arguments[0].sampleRate : arguments[1];\n    }\n    /**\n     * Override the now method to point to the internal clock time\n     */\n    now() {\n        return this._currentTime;\n    }\n    /**\n     * Same as this.now()\n     */\n    get currentTime() {\n        return this._currentTime;\n    }\n    /**\n     * Render just the clock portion of the audio context.\n     */\n    _renderClock(asynchronous) {\n        return __awaiter(this, void 0, void 0, function* () {\n            let index = 0;\n            while (this._duration - this._currentTime >= 0) {\n                // invoke all the callbacks on that time\n                this.emit(\"tick\");\n                // increment the clock in block-sized chunks\n                this._currentTime += 128 / this.sampleRate;\n                // yield once a second of audio\n                index++;\n                const yieldEvery = Math.floor(this.sampleRate / 128);\n                if (asynchronous && index % yieldEvery === 0) {\n                    yield new Promise(done => setTimeout(done, 1));\n                }\n            }\n        });\n    }\n    /**\n     * Render the output of the OfflineContext\n     * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.\n     */\n    render(asynchronous = true) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this.workletsAreReady();\n            yield this._renderClock(asynchronous);\n            const buffer = yield this._context.startRendering();\n            return new ToneAudioBuffer(buffer);\n        });\n    }\n    /**\n     * Close the context\n     */\n    close() {\n        return Promise.resolve();\n    }\n}\n//# sourceMappingURL=OfflineContext.js.map","import { dbToGain, gainToDb } from \"../type/Conversions\";\nimport { isAudioParam } from \"../util/AdvancedTypeCheck\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { Timeline } from \"../util/Timeline\";\nimport { isDefined } from \"../util/TypeCheck\";\nimport { ToneWithContext } from \"./ToneWithContext\";\nimport { EQ } from \"../util/Math\";\nimport { assert, assertRange } from \"../util/Debug\";\n/**\n * Param wraps the native Web Audio's AudioParam to provide\n * additional unit conversion functionality. It also\n * serves as a base-class for classes which have a single,\n * automatable parameter.\n */\nexport class Param extends ToneWithContext {\n    constructor() {\n        super(optionsFromArguments(Param.getDefaults(), arguments, [\"param\", \"units\", \"convert\"]));\n        this.name = \"Param\";\n        this.overridden = false;\n        /**\n         * The minimum output value\n         */\n        this._minOutput = 1e-7;\n        const options = optionsFromArguments(Param.getDefaults(), arguments, [\"param\", \"units\", \"convert\"]);\n        assert(isDefined(options.param) &&\n            (isAudioParam(options.param) || options.param instanceof Param), \"param must be an AudioParam\");\n        while (!isAudioParam(options.param)) {\n            options.param = options.param._param;\n        }\n        this._swappable = isDefined(options.swappable) ? options.swappable : false;\n        if (this._swappable) {\n            this.input = this.context.createGain();\n            // initialize\n            this._param = options.param;\n            this.input.connect(this._param);\n        }\n        else {\n            this._param = this.input = options.param;\n        }\n        this._events = new Timeline(1000);\n        this._initialValue = this._param.defaultValue;\n        this.units = options.units;\n        this.convert = options.convert;\n        this._minValue = options.minValue;\n        this._maxValue = options.maxValue;\n        // if the value is defined, set it immediately\n        if (isDefined(options.value) && options.value !== this._toType(this._initialValue)) {\n            this.setValueAtTime(options.value, 0);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(ToneWithContext.getDefaults(), {\n            convert: true,\n            units: \"number\",\n        });\n    }\n    get value() {\n        const now = this.now();\n        return this.getValueAtTime(now);\n    }\n    set value(value) {\n        this.cancelScheduledValues(this.now());\n        this.setValueAtTime(value, this.now());\n    }\n    get minValue() {\n        // if it's not the default minValue, return it\n        if (isDefined(this._minValue)) {\n            return this._minValue;\n        }\n        else if (this.units === \"time\" || this.units === \"frequency\" ||\n            this.units === \"normalRange\" || this.units === \"positive\" ||\n            this.units === \"transportTime\" || this.units === \"ticks\" ||\n            this.units === \"bpm\" || this.units === \"hertz\" || this.units === \"samples\") {\n            return 0;\n        }\n        else if (this.units === \"audioRange\") {\n            return -1;\n        }\n        else if (this.units === \"decibels\") {\n            return -Infinity;\n        }\n        else {\n            return this._param.minValue;\n        }\n    }\n    get maxValue() {\n        if (isDefined(this._maxValue)) {\n            return this._maxValue;\n        }\n        else if (this.units === \"normalRange\" ||\n            this.units === \"audioRange\") {\n            return 1;\n        }\n        else {\n            return this._param.maxValue;\n        }\n    }\n    /**\n     * Type guard based on the unit name\n     */\n    _is(arg, type) {\n        return this.units === type;\n    }\n    /**\n     * Make sure the value is always in the defined range\n     */\n    _assertRange(value) {\n        if (isDefined(this.maxValue) && isDefined(this.minValue)) {\n            assertRange(value, this._fromType(this.minValue), this._fromType(this.maxValue));\n        }\n        return value;\n    }\n    /**\n     * Convert the given value from the type specified by Param.units\n     * into the destination value (such as Gain or Frequency).\n     */\n    _fromType(val) {\n        if (this.convert && !this.overridden) {\n            if (this._is(val, \"time\")) {\n                return this.toSeconds(val);\n            }\n            else if (this._is(val, \"decibels\")) {\n                return dbToGain(val);\n            }\n            else if (this._is(val, \"frequency\")) {\n                return this.toFrequency(val);\n            }\n            else {\n                return val;\n            }\n        }\n        else if (this.overridden) {\n            // if it's overridden, should only schedule 0s\n            return 0;\n        }\n        else {\n            return val;\n        }\n    }\n    /**\n     * Convert the parameters value into the units specified by Param.units.\n     */\n    _toType(val) {\n        if (this.convert && this.units === \"decibels\") {\n            return gainToDb(val);\n        }\n        else {\n            return val;\n        }\n    }\n    //-------------------------------------\n    // ABSTRACT PARAM INTERFACE\n    // all docs are generated from ParamInterface.ts\n    //-------------------------------------\n    setValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        const numericValue = this._fromType(value);\n        assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(time)}`);\n        this._assertRange(numericValue);\n        this.log(this.units, \"setValueAtTime\", value, computedTime);\n        this._events.add({\n            time: computedTime,\n            type: \"setValueAtTime\",\n            value: numericValue,\n        });\n        this._param.setValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    getValueAtTime(time) {\n        const computedTime = Math.max(this.toSeconds(time), 0);\n        const after = this._events.getAfter(computedTime);\n        const before = this._events.get(computedTime);\n        let value = this._initialValue;\n        // if it was set by\n        if (before === null) {\n            value = this._initialValue;\n        }\n        else if (before.type === \"setTargetAtTime\" && (after === null || after.type === \"setValueAtTime\")) {\n            const previous = this._events.getBefore(before.time);\n            let previousVal;\n            if (previous === null) {\n                previousVal = this._initialValue;\n            }\n            else {\n                previousVal = previous.value;\n            }\n            if (before.type === \"setTargetAtTime\") {\n                value = this._exponentialApproach(before.time, previousVal, before.value, before.constant, computedTime);\n            }\n        }\n        else if (after === null) {\n            value = before.value;\n        }\n        else if (after.type === \"linearRampToValueAtTime\" || after.type === \"exponentialRampToValueAtTime\") {\n            let beforeValue = before.value;\n            if (before.type === \"setTargetAtTime\") {\n                const previous = this._events.getBefore(before.time);\n                if (previous === null) {\n                    beforeValue = this._initialValue;\n                }\n                else {\n                    beforeValue = previous.value;\n                }\n            }\n            if (after.type === \"linearRampToValueAtTime\") {\n                value = this._linearInterpolate(before.time, beforeValue, after.time, after.value, computedTime);\n            }\n            else {\n                value = this._exponentialInterpolate(before.time, beforeValue, after.time, after.value, computedTime);\n            }\n        }\n        else {\n            value = before.value;\n        }\n        return this._toType(value);\n    }\n    setRampPoint(time) {\n        time = this.toSeconds(time);\n        let currentVal = this.getValueAtTime(time);\n        this.cancelAndHoldAtTime(time);\n        if (this._fromType(currentVal) === 0) {\n            currentVal = this._toType(this._minOutput);\n        }\n        this.setValueAtTime(currentVal, time);\n        return this;\n    }\n    linearRampToValueAtTime(value, endTime) {\n        const numericValue = this._fromType(value);\n        const computedTime = this.toSeconds(endTime);\n        assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to linearRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);\n        this._assertRange(numericValue);\n        this._events.add({\n            time: computedTime,\n            type: \"linearRampToValueAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"linearRampToValueAtTime\", value, computedTime);\n        this._param.linearRampToValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, endTime) {\n        let numericValue = this._fromType(value);\n        numericValue = Math.max(this._minOutput, numericValue);\n        this._assertRange(numericValue);\n        const computedTime = this.toSeconds(endTime);\n        assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to exponentialRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);\n        // store the event\n        this._events.add({\n            time: computedTime,\n            type: \"exponentialRampToValueAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"exponentialRampToValueAtTime\", value, computedTime);\n        this._param.exponentialRampToValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.exponentialApproachValueAtTime(value, startTime, rampTime);\n        return this;\n    }\n    exponentialApproachValueAtTime(value, time, rampTime) {\n        time = this.toSeconds(time);\n        rampTime = this.toSeconds(rampTime);\n        const timeConstant = Math.log(rampTime + 1) / Math.log(200);\n        this.setTargetAtTime(value, time, timeConstant);\n        // at 90% start a linear ramp to the final value\n        this.cancelAndHoldAtTime(time + rampTime * 0.9);\n        this.linearRampToValueAtTime(value, time + rampTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        const numericValue = this._fromType(value);\n        // The value will never be able to approach without timeConstant > 0.\n        assert(isFinite(timeConstant) && timeConstant > 0, \"timeConstant must be a number greater than 0\");\n        const computedTime = this.toSeconds(startTime);\n        this._assertRange(numericValue);\n        assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setTargetAtTime: ${JSON.stringify(value)}, ${JSON.stringify(startTime)}`);\n        this._events.add({\n            constant: timeConstant,\n            time: computedTime,\n            type: \"setTargetAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"setTargetAtTime\", value, computedTime, timeConstant);\n        this._param.setTargetAtTime(numericValue, computedTime, timeConstant);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling = 1) {\n        duration = this.toSeconds(duration);\n        startTime = this.toSeconds(startTime);\n        const startingValue = this._fromType(values[0]) * scaling;\n        this.setValueAtTime(this._toType(startingValue), startTime);\n        const segTime = duration / (values.length - 1);\n        for (let i = 1; i < values.length; i++) {\n            const numericValue = this._fromType(values[i]) * scaling;\n            this.linearRampToValueAtTime(this._toType(numericValue), startTime + i * segTime);\n        }\n        return this;\n    }\n    cancelScheduledValues(time) {\n        const computedTime = this.toSeconds(time);\n        assert(isFinite(computedTime), `Invalid argument to cancelScheduledValues: ${JSON.stringify(time)}`);\n        this._events.cancel(computedTime);\n        this._param.cancelScheduledValues(computedTime);\n        this.log(this.units, \"cancelScheduledValues\", computedTime);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const valueAtTime = this._fromType(this.getValueAtTime(computedTime));\n        // remove the schedule events\n        assert(isFinite(computedTime), `Invalid argument to cancelAndHoldAtTime: ${JSON.stringify(time)}`);\n        this.log(this.units, \"cancelAndHoldAtTime\", computedTime, \"value=\" + valueAtTime);\n        // if there is an event at the given computedTime\n        // and that even is not a \"set\"\n        const before = this._events.get(computedTime);\n        const after = this._events.getAfter(computedTime);\n        if (before && EQ(before.time, computedTime)) {\n            // remove everything after\n            if (after) {\n                this._param.cancelScheduledValues(after.time);\n                this._events.cancel(after.time);\n            }\n            else {\n                this._param.cancelAndHoldAtTime(computedTime);\n                this._events.cancel(computedTime + this.sampleTime);\n            }\n        }\n        else if (after) {\n            this._param.cancelScheduledValues(after.time);\n            // cancel the next event(s)\n            this._events.cancel(after.time);\n            if (after.type === \"linearRampToValueAtTime\") {\n                this.linearRampToValueAtTime(this._toType(valueAtTime), computedTime);\n            }\n            else if (after.type === \"exponentialRampToValueAtTime\") {\n                this.exponentialRampToValueAtTime(this._toType(valueAtTime), computedTime);\n            }\n        }\n        // set the value at the given time\n        this._events.add({\n            time: computedTime,\n            type: \"setValueAtTime\",\n            value: valueAtTime,\n        });\n        this._param.setValueAtTime(valueAtTime, computedTime);\n        return this;\n    }\n    rampTo(value, rampTime = 0.1, startTime) {\n        if (this.units === \"frequency\" || this.units === \"bpm\" || this.units === \"decibels\") {\n            this.exponentialRampTo(value, rampTime, startTime);\n        }\n        else {\n            this.linearRampTo(value, rampTime, startTime);\n        }\n        return this;\n    }\n    /**\n     * Apply all of the previously scheduled events to the passed in Param or AudioParam.\n     * The applied values will start at the context's current time and schedule\n     * all of the events which are scheduled on this Param onto the passed in param.\n     */\n    apply(param) {\n        const now = this.context.currentTime;\n        // set the param's value at the current time and schedule everything else\n        param.setValueAtTime(this.getValueAtTime(now), now);\n        // if the previous event was a curve, then set the rest of it\n        const previousEvent = this._events.get(now);\n        if (previousEvent && previousEvent.type === \"setTargetAtTime\") {\n            // approx it until the next event with linear ramps\n            const nextEvent = this._events.getAfter(previousEvent.time);\n            // or for 2 seconds if there is no event\n            const endTime = nextEvent ? nextEvent.time : now + 2;\n            const subdivisions = (endTime - now) / 10;\n            for (let i = now; i < endTime; i += subdivisions) {\n                param.linearRampToValueAtTime(this.getValueAtTime(i), i);\n            }\n        }\n        this._events.forEachAfter(this.context.currentTime, event => {\n            if (event.type === \"cancelScheduledValues\") {\n                param.cancelScheduledValues(event.time);\n            }\n            else if (event.type === \"setTargetAtTime\") {\n                param.setTargetAtTime(event.value, event.time, event.constant);\n            }\n            else {\n                param[event.type](event.value, event.time);\n            }\n        });\n        return this;\n    }\n    /**\n     * Replace the Param's internal AudioParam. Will apply scheduled curves\n     * onto the parameter and replace the connections.\n     */\n    setParam(param) {\n        assert(this._swappable, \"The Param must be assigned as 'swappable' in the constructor\");\n        const input = this.input;\n        input.disconnect(this._param);\n        this.apply(param);\n        this._param = param;\n        input.connect(this._param);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._events.dispose();\n        return this;\n    }\n    get defaultValue() {\n        return this._toType(this._param.defaultValue);\n    }\n    //-------------------------------------\n    // \tAUTOMATION CURVE CALCULATIONS\n    // \tMIT License, copyright (c) 2014 Jordan Santell\n    //-------------------------------------\n    // Calculates the the value along the curve produced by setTargetAtTime\n    _exponentialApproach(t0, v0, v1, timeConstant, t) {\n        return v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);\n    }\n    // Calculates the the value along the curve produced by linearRampToValueAtTime\n    _linearInterpolate(t0, v0, t1, v1, t) {\n        return v0 + (v1 - v0) * ((t - t0) / (t1 - t0));\n    }\n    // Calculates the the value along the curve produced by exponentialRampToValueAtTime\n    _exponentialInterpolate(t0, v0, t1, v1, t) {\n        return v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));\n    }\n}\n//# sourceMappingURL=Param.js.map","import { __awaiter } from \"tslib\";\nimport { getContext } from \"../Global\";\nimport { Tone } from \"../Tone\";\nimport { isAudioBuffer } from \"../util/AdvancedTypeCheck\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { noOp } from \"../util/Interface\";\nimport { isArray, isNumber, isString } from \"../util/TypeCheck\";\nimport { assert } from \"../util/Debug\";\n/**\n * AudioBuffer loading and storage. ToneAudioBuffer is used internally by all\n * classes that make requests for audio files such as Tone.Player,\n * Tone.Sampler and Tone.Convolver.\n * Aside from load callbacks from individual buffers, ToneAudioBuffer\n * provides events which keep track of the loading progress\n * of _all_ of the buffers. These are ToneAudioBuffer.on(\"load\" / \"progress\" / \"error\")\n * @example\n * const buffer = new Tone.ToneAudioBuffer(\"https://tonejs.github.io/examples/audio/FWDL.mp3\", () => {\n * \tconsole.log(\"loaded\");\n * });\n * @category Core\n */\nexport class ToneAudioBuffer extends Tone {\n    constructor() {\n        super();\n        this.name = \"ToneAudioBuffer\";\n        /**\n         * Callback when the buffer is loaded.\n         */\n        this.onload = noOp;\n        const options = optionsFromArguments(ToneAudioBuffer.getDefaults(), arguments, [\"url\", \"onload\", \"onerror\"]);\n        this.reverse = options.reverse;\n        this.onload = options.onload;\n        if (options.url && isAudioBuffer(options.url) || options.url instanceof ToneAudioBuffer) {\n            this.set(options.url);\n        }\n        else if (isString(options.url)) {\n            // initiate the download\n            this.load(options.url).catch(options.onerror);\n        }\n    }\n    static getDefaults() {\n        return {\n            onerror: noOp,\n            onload: noOp,\n            reverse: false,\n        };\n    }\n    /**\n     * The sample rate of the AudioBuffer\n     */\n    get sampleRate() {\n        if (this._buffer) {\n            return this._buffer.sampleRate;\n        }\n        else {\n            return getContext().sampleRate;\n        }\n    }\n    /**\n     * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.\n     */\n    set(buffer) {\n        if (buffer instanceof ToneAudioBuffer) {\n            // if it's loaded, set it\n            if (buffer.loaded) {\n                this._buffer = buffer.get();\n            }\n            else {\n                // otherwise when it's loaded, invoke it's callback\n                buffer.onload = () => {\n                    this.set(buffer);\n                    this.onload(this);\n                };\n            }\n        }\n        else {\n            this._buffer = buffer;\n        }\n        // reverse it initially\n        if (this._reversed) {\n            this._reverse();\n        }\n        return this;\n    }\n    /**\n     * The audio buffer stored in the object.\n     */\n    get() {\n        return this._buffer;\n    }\n    /**\n     * Makes an fetch request for the selected url then decodes the file as an audio buffer.\n     * Invokes the callback once the audio buffer loads.\n     * @param url The url of the buffer to load. filetype support depends on the browser.\n     * @returns A Promise which resolves with this ToneAudioBuffer\n     */\n    load(url) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const doneLoading = ToneAudioBuffer.load(url).then(audioBuffer => {\n                this.set(audioBuffer);\n                // invoke the onload method\n                this.onload(this);\n            });\n            ToneAudioBuffer.downloads.push(doneLoading);\n            try {\n                yield doneLoading;\n            }\n            finally {\n                // remove the downloaded file\n                const index = ToneAudioBuffer.downloads.indexOf(doneLoading);\n                ToneAudioBuffer.downloads.splice(index, 1);\n            }\n            return this;\n        });\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._buffer = undefined;\n        return this;\n    }\n    /**\n     * Set the audio buffer from the array.\n     * To create a multichannel AudioBuffer, pass in a multidimensional array.\n     * @param array The array to fill the audio buffer\n     */\n    fromArray(array) {\n        const isMultidimensional = isArray(array) && array[0].length > 0;\n        const channels = isMultidimensional ? array.length : 1;\n        const len = isMultidimensional ? array[0].length : array.length;\n        const context = getContext();\n        const buffer = context.createBuffer(channels, len, context.sampleRate);\n        const multiChannelArray = !isMultidimensional && channels === 1 ?\n            [array] : array;\n        for (let c = 0; c < channels; c++) {\n            buffer.copyToChannel(multiChannelArray[c], c);\n        }\n        this._buffer = buffer;\n        return this;\n    }\n    /**\n     * Sums multiple channels into 1 channel\n     * @param chanNum Optionally only copy a single channel from the array.\n     */\n    toMono(chanNum) {\n        if (isNumber(chanNum)) {\n            this.fromArray(this.toArray(chanNum));\n        }\n        else {\n            let outputArray = new Float32Array(this.length);\n            const numChannels = this.numberOfChannels;\n            for (let channel = 0; channel < numChannels; channel++) {\n                const channelArray = this.toArray(channel);\n                for (let i = 0; i < channelArray.length; i++) {\n                    outputArray[i] += channelArray[i];\n                }\n            }\n            // divide by the number of channels\n            outputArray = outputArray.map(sample => sample / numChannels);\n            this.fromArray(outputArray);\n        }\n        return this;\n    }\n    /**\n     * Get the buffer as an array. Single channel buffers will return a 1-dimensional\n     * Float32Array, and multichannel buffers will return multidimensional arrays.\n     * @param channel Optionally only copy a single channel from the array.\n     */\n    toArray(channel) {\n        if (isNumber(channel)) {\n            return this.getChannelData(channel);\n        }\n        else if (this.numberOfChannels === 1) {\n            return this.toArray(0);\n        }\n        else {\n            const ret = [];\n            for (let c = 0; c < this.numberOfChannels; c++) {\n                ret[c] = this.getChannelData(c);\n            }\n            return ret;\n        }\n    }\n    /**\n     * Returns the Float32Array representing the PCM audio data for the specific channel.\n     * @param  channel  The channel number to return\n     * @return The audio as a TypedArray\n     */\n    getChannelData(channel) {\n        if (this._buffer) {\n            return this._buffer.getChannelData(channel);\n        }\n        else {\n            return new Float32Array(0);\n        }\n    }\n    /**\n     * Cut a subsection of the array and return a buffer of the\n     * subsection. Does not modify the original buffer\n     * @param start The time to start the slice\n     * @param end The end time to slice. If none is given will default to the end of the buffer\n     */\n    slice(start, end = this.duration) {\n        const startSamples = Math.floor(start * this.sampleRate);\n        const endSamples = Math.floor(end * this.sampleRate);\n        assert(startSamples < endSamples, \"The start time must be less than the end time\");\n        const length = endSamples - startSamples;\n        const retBuffer = getContext().createBuffer(this.numberOfChannels, length, this.sampleRate);\n        for (let channel = 0; channel < this.numberOfChannels; channel++) {\n            retBuffer.copyToChannel(this.getChannelData(channel).subarray(startSamples, endSamples), channel);\n        }\n        return new ToneAudioBuffer(retBuffer);\n    }\n    /**\n     * Reverse the buffer.\n     */\n    _reverse() {\n        if (this.loaded) {\n            for (let i = 0; i < this.numberOfChannels; i++) {\n                this.getChannelData(i).reverse();\n            }\n        }\n        return this;\n    }\n    /**\n     * If the buffer is loaded or not\n     */\n    get loaded() {\n        return this.length > 0;\n    }\n    /**\n     * The duration of the buffer in seconds.\n     */\n    get duration() {\n        if (this._buffer) {\n            return this._buffer.duration;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The length of the buffer in samples\n     */\n    get length() {\n        if (this._buffer) {\n            return this._buffer.length;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The number of discrete audio channels. Returns 0 if no buffer is loaded.\n     */\n    get numberOfChannels() {\n        if (this._buffer) {\n            return this._buffer.numberOfChannels;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * Reverse the buffer.\n     */\n    get reverse() {\n        return this._reversed;\n    }\n    set reverse(rev) {\n        if (this._reversed !== rev) {\n            this._reversed = rev;\n            this._reverse();\n        }\n    }\n    /**\n     * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,\n     * pass in a multidimensional array.\n     * @param array The array to fill the audio buffer\n     * @return A ToneAudioBuffer created from the array\n     */\n    static fromArray(array) {\n        return (new ToneAudioBuffer()).fromArray(array);\n    }\n    /**\n     * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer\n     * @param  url The url to load.\n     * @return A promise which resolves to a ToneAudioBuffer\n     */\n    static fromUrl(url) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const buffer = new ToneAudioBuffer();\n            return yield buffer.load(url);\n        });\n    }\n    /**\n     * Loads a url using fetch and returns the AudioBuffer.\n     */\n    static load(url) {\n        return __awaiter(this, void 0, void 0, function* () {\n            // test if the url contains multiple extensions\n            const matches = url.match(/\\[(.+\\|?)+\\]$/);\n            if (matches) {\n                const extensions = matches[1].split(\"|\");\n                let extension = extensions[0];\n                for (const ext of extensions) {\n                    if (ToneAudioBuffer.supportsType(ext)) {\n                        extension = ext;\n                        break;\n                    }\n                }\n                url = url.replace(matches[0], extension);\n            }\n            // make sure there is a slash between the baseUrl and the url\n            const baseUrl = ToneAudioBuffer.baseUrl === \"\" || ToneAudioBuffer.baseUrl.endsWith(\"/\") ? ToneAudioBuffer.baseUrl : ToneAudioBuffer.baseUrl + \"/\";\n            const response = yield fetch(baseUrl + url);\n            if (!response.ok) {\n                throw new Error(`could not load url: ${url}`);\n            }\n            const arrayBuffer = yield response.arrayBuffer();\n            const audioBuffer = yield getContext().decodeAudioData(arrayBuffer);\n            return audioBuffer;\n        });\n    }\n    /**\n     * Checks a url's extension to see if the current browser can play that file type.\n     * @param url The url/extension to test\n     * @return If the file extension can be played\n     * @static\n     * @example\n     * Tone.ToneAudioBuffer.supportsType(\"wav\"); // returns true\n     * Tone.ToneAudioBuffer.supportsType(\"path/to/file.wav\"); // returns true\n     */\n    static supportsType(url) {\n        const extensions = url.split(\".\");\n        const extension = extensions[extensions.length - 1];\n        const response = document.createElement(\"audio\").canPlayType(\"audio/\" + extension);\n        return response !== \"\";\n    }\n    /**\n     * Returns a Promise which resolves when all of the buffers have loaded\n     */\n    static loaded() {\n        return __awaiter(this, void 0, void 0, function* () {\n            // this makes sure that the function is always async\n            yield Promise.resolve();\n            while (ToneAudioBuffer.downloads.length) {\n                yield ToneAudioBuffer.downloads[0];\n            }\n        });\n    }\n}\n//-------------------------------------\n// STATIC METHODS\n//-------------------------------------\n/**\n * A path which is prefixed before every url.\n */\nToneAudioBuffer.baseUrl = \"\";\n/**\n * All of the downloads\n */\nToneAudioBuffer.downloads = [];\n//# sourceMappingURL=ToneAudioBuffer.js.map","import { Tone } from \"../Tone\";\nimport { optionsFromArguments } from \"../util/Defaults\";\nimport { noOp } from \"../util/Interface\";\nimport { isString } from \"../util/TypeCheck\";\nimport { ToneAudioBuffer } from \"./ToneAudioBuffer\";\nimport { assert } from \"../util/Debug\";\n/**\n * A data structure for holding multiple buffers in a Map-like datastructure.\n *\n * @example\n * const pianoSamples = new Tone.ToneAudioBuffers({\n * \tC1: \"https://tonejs.github.io/examples/audio/casio/C1.mp3\",\n * \tC2: \"https://tonejs.github.io/examples/audio/casio/C2.mp3\",\n * }, () => {\n * \tconst player = new Tone.Player().toDestination();\n * \t// play one of the samples when they all load\n * \tplayer.buffer = pianoSamples.get(\"C2\");\n * \tplayer.start();\n * });\n * @example\n * // To pass in additional parameters in the second parameter\n * const buffers = new Tone.ToneAudioBuffers({\n * \t urls: {\n * \t\t C1: \"C1.mp3\",\n * \t\t C2: \"C2.mp3\",\n * \t },\n * \t onload: () => console.log(\"loaded\"),\n * \t baseUrl: \"https://tonejs.github.io/examples/audio/casio/\"\n * });\n * @category Core\n */\nexport class ToneAudioBuffers extends Tone {\n    constructor() {\n        super();\n        this.name = \"ToneAudioBuffers\";\n        /**\n         * All of the buffers\n         */\n        this._buffers = new Map();\n        /**\n         * Keep track of the number of loaded buffers\n         */\n        this._loadingCount = 0;\n        const options = optionsFromArguments(ToneAudioBuffers.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\");\n        this.baseUrl = options.baseUrl;\n        // add each one\n        Object.keys(options.urls).forEach(name => {\n            this._loadingCount++;\n            const url = options.urls[name];\n            this.add(name, url, this._bufferLoaded.bind(this, options.onload), options.onerror);\n        });\n    }\n    static getDefaults() {\n        return {\n            baseUrl: \"\",\n            onerror: noOp,\n            onload: noOp,\n            urls: {},\n        };\n    }\n    /**\n     * True if the buffers object has a buffer by that name.\n     * @param  name  The key or index of the buffer.\n     */\n    has(name) {\n        return this._buffers.has(name.toString());\n    }\n    /**\n     * Get a buffer by name. If an array was loaded,\n     * then use the array index.\n     * @param  name  The key or index of the buffer.\n     */\n    get(name) {\n        assert(this.has(name), `ToneAudioBuffers has no buffer named: ${name}`);\n        return this._buffers.get(name.toString());\n    }\n    /**\n     * A buffer was loaded. decrement the counter.\n     */\n    _bufferLoaded(callback) {\n        this._loadingCount--;\n        if (this._loadingCount === 0 && callback) {\n            callback();\n        }\n    }\n    /**\n     * If the buffers are loaded or not\n     */\n    get loaded() {\n        return Array.from(this._buffers).every(([_, buffer]) => buffer.loaded);\n    }\n    /**\n     * Add a buffer by name and url to the Buffers\n     * @param  name      A unique name to give the buffer\n     * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.\n     * @param  callback  The callback to invoke when the url is loaded.\n     * @param  onerror  Invoked if the buffer can't be loaded\n     */\n    add(name, url, callback = noOp, onerror = noOp) {\n        if (isString(url)) {\n            this._buffers.set(name.toString(), new ToneAudioBuffer(this.baseUrl + url, callback, onerror));\n        }\n        else {\n            this._buffers.set(name.toString(), new ToneAudioBuffer(url, callback, onerror));\n        }\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._buffers.forEach(buffer => buffer.dispose());\n        this._buffers.clear();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneAudioBuffers.js.map","import { isAudioNode, isAudioParam } from \"../util/AdvancedTypeCheck\";\nimport { isDefined } from \"../util/TypeCheck\";\nimport { Param } from \"./Param\";\nimport { ToneWithContext } from \"./ToneWithContext\";\nimport { assert, warn } from \"../util/Debug\";\n/**\n * ToneAudioNode is the base class for classes which process audio.\n */\nexport class ToneAudioNode extends ToneWithContext {\n    constructor() {\n        super(...arguments);\n        /**\n         * The name of the class\n         */\n        this.name = \"ToneAudioNode\";\n        /**\n         * List all of the node that must be set to match the ChannelProperties\n         */\n        this._internalChannels = [];\n    }\n    /**\n     * The number of inputs feeding into the AudioNode.\n     * For source nodes, this will be 0.\n     * @example\n     * const node = new Tone.Gain();\n     * console.log(node.numberOfInputs);\n     */\n    get numberOfInputs() {\n        if (isDefined(this.input)) {\n            if (isAudioParam(this.input) || this.input instanceof Param) {\n                return 1;\n            }\n            else {\n                return this.input.numberOfInputs;\n            }\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The number of outputs of the AudioNode.\n     * @example\n     * const node = new Tone.Gain();\n     * console.log(node.numberOfOutputs);\n     */\n    get numberOfOutputs() {\n        if (isDefined(this.output)) {\n            return this.output.numberOfOutputs;\n        }\n        else {\n            return 0;\n        }\n    }\n    //-------------------------------------\n    // AUDIO PROPERTIES\n    //-------------------------------------\n    /**\n     * Used to decide which nodes to get/set properties on\n     */\n    _isAudioNode(node) {\n        return isDefined(node) && (node instanceof ToneAudioNode || isAudioNode(node));\n    }\n    /**\n     * Get all of the audio nodes (either internal or input/output) which together\n     * make up how the class node responds to channel input/output\n     */\n    _getInternalNodes() {\n        const nodeList = this._internalChannels.slice(0);\n        if (this._isAudioNode(this.input)) {\n            nodeList.push(this.input);\n        }\n        if (this._isAudioNode(this.output)) {\n            if (this.input !== this.output) {\n                nodeList.push(this.output);\n            }\n        }\n        return nodeList;\n    }\n    /**\n     * Set the audio options for this node such as channelInterpretation\n     * channelCount, etc.\n     * @param options\n     */\n    _setChannelProperties(options) {\n        const nodeList = this._getInternalNodes();\n        nodeList.forEach(node => {\n            node.channelCount = options.channelCount;\n            node.channelCountMode = options.channelCountMode;\n            node.channelInterpretation = options.channelInterpretation;\n        });\n    }\n    /**\n     * Get the current audio options for this node such as channelInterpretation\n     * channelCount, etc.\n     */\n    _getChannelProperties() {\n        const nodeList = this._getInternalNodes();\n        assert(nodeList.length > 0, \"ToneAudioNode does not have any internal nodes\");\n        // use the first node to get properties\n        // they should all be the same\n        const node = nodeList[0];\n        return {\n            channelCount: node.channelCount,\n            channelCountMode: node.channelCountMode,\n            channelInterpretation: node.channelInterpretation,\n        };\n    }\n    /**\n     * channelCount is the number of channels used when up-mixing and down-mixing\n     * connections to any inputs to the node. The default value is 2 except for\n     * specific nodes where its value is specially determined.\n     */\n    get channelCount() {\n        return this._getChannelProperties().channelCount;\n    }\n    set channelCount(channelCount) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelCount }));\n    }\n    /**\n     * channelCountMode determines how channels will be counted when up-mixing and\n     * down-mixing connections to any inputs to the node.\n     * The default value is \"max\". This attribute has no effect for nodes with no inputs.\n     * * \"max\" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.\n     * * \"clamped-max\" - computedNumberOfChannels is determined as for \"max\" and then clamped to a maximum value of the given channelCount.\n     * * \"explicit\" - computedNumberOfChannels is the exact value as specified by the channelCount.\n     */\n    get channelCountMode() {\n        return this._getChannelProperties().channelCountMode;\n    }\n    set channelCountMode(channelCountMode) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelCountMode }));\n    }\n    /**\n     * channelInterpretation determines how individual channels will be treated\n     * when up-mixing and down-mixing connections to any inputs to the node.\n     * The default value is \"speakers\".\n     */\n    get channelInterpretation() {\n        return this._getChannelProperties().channelInterpretation;\n    }\n    set channelInterpretation(channelInterpretation) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelInterpretation }));\n    }\n    //-------------------------------------\n    // CONNECTIONS\n    //-------------------------------------\n    /**\n     * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode\n     * @param destination The output to connect to\n     * @param outputNum The output to connect from\n     * @param inputNum The input to connect to\n     */\n    connect(destination, outputNum = 0, inputNum = 0) {\n        connect(this, destination, outputNum, inputNum);\n        return this;\n    }\n    /**\n     * Connect the output to the context's destination node.\n     * @example\n     * const osc = new Tone.Oscillator().start();\n     * osc.toDestination();\n     */\n    toDestination() {\n        this.connect(this.context.destination);\n        return this;\n    }\n    /**\n     * Connect the output to the context's destination node.\n     * See [[toDestination]]\n     * @deprecated\n     */\n    toMaster() {\n        warn(\"toMaster() has been renamed toDestination()\");\n        return this.toDestination();\n    }\n    /**\n     * disconnect the output\n     */\n    disconnect(destination, outputNum = 0, inputNum = 0) {\n        disconnect(this, destination, outputNum, inputNum);\n        return this;\n    }\n    /**\n     * Connect the output of this node to the rest of the nodes in series.\n     * @example\n     * const osc = new Tone.Oscillator().start();\n     * const filter = new Tone.Filter();\n     * const volume = new Tone.Volume(-8);\n     * // connect a node to the filter, volume and then to the master output\n     * osc.chain(filter, volume, Tone.Destination);\n     */\n    chain(...nodes) {\n        connectSeries(this, ...nodes);\n        return this;\n    }\n    /**\n     * connect the output of this node to the rest of the nodes in parallel.\n     */\n    fan(...nodes) {\n        nodes.forEach(node => this.connect(node));\n        return this;\n    }\n    /**\n     * Dispose and disconnect\n     */\n    dispose() {\n        super.dispose();\n        if (isDefined(this.input)) {\n            if (this.input instanceof ToneAudioNode) {\n                this.input.dispose();\n            }\n            else if (isAudioNode(this.input)) {\n                this.input.disconnect();\n            }\n        }\n        if (isDefined(this.output)) {\n            if (this.output instanceof ToneAudioNode) {\n                this.output.dispose();\n            }\n            else if (isAudioNode(this.output)) {\n                this.output.disconnect();\n            }\n        }\n        this._internalChannels = [];\n        return this;\n    }\n}\n//-------------------------------------\n// CONNECTIONS\n//-------------------------------------\n/**\n * connect together all of the arguments in series\n * @param nodes\n */\nexport function connectSeries(...nodes) {\n    const first = nodes.shift();\n    nodes.reduce((prev, current) => {\n        if (prev instanceof ToneAudioNode) {\n            prev.connect(current);\n        }\n        else if (isAudioNode(prev)) {\n            connect(prev, current);\n        }\n        return current;\n    }, first);\n}\n/**\n * Connect two nodes together so that signal flows from the\n * first node to the second. Optionally specify the input and output channels.\n * @param srcNode The source node\n * @param dstNode The destination node\n * @param outputNumber The output channel of the srcNode\n * @param inputNumber The input channel of the dstNode\n */\nexport function connect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {\n    assert(isDefined(srcNode), \"Cannot connect from undefined node\");\n    assert(isDefined(dstNode), \"Cannot connect to undefined node\");\n    if (dstNode instanceof ToneAudioNode || isAudioNode(dstNode)) {\n        assert(dstNode.numberOfInputs > 0, \"Cannot connect to node with no inputs\");\n    }\n    assert(srcNode.numberOfOutputs > 0, \"Cannot connect from node with no outputs\");\n    // resolve the input of the dstNode\n    while ((dstNode instanceof ToneAudioNode || dstNode instanceof Param)) {\n        if (isDefined(dstNode.input)) {\n            dstNode = dstNode.input;\n        }\n    }\n    while (srcNode instanceof ToneAudioNode) {\n        if (isDefined(srcNode.output)) {\n            srcNode = srcNode.output;\n        }\n    }\n    // make the connection\n    if (isAudioParam(dstNode)) {\n        srcNode.connect(dstNode, outputNumber);\n    }\n    else {\n        srcNode.connect(dstNode, outputNumber, inputNumber);\n    }\n}\n/**\n * Disconnect a node from all nodes or optionally include a destination node and input/output channels.\n * @param srcNode The source node\n * @param dstNode The destination node\n * @param outputNumber The output channel of the srcNode\n * @param inputNumber The input channel of the dstNode\n */\nexport function disconnect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {\n    // resolve the destination node\n    if (isDefined(dstNode)) {\n        while (dstNode instanceof ToneAudioNode) {\n            dstNode = dstNode.input;\n        }\n    }\n    // resolve the src node\n    while (!(isAudioNode(srcNode))) {\n        if (isDefined(srcNode.output)) {\n            srcNode = srcNode.output;\n        }\n    }\n    if (isAudioParam(dstNode)) {\n        srcNode.disconnect(dstNode, outputNumber);\n    }\n    else if (isAudioNode(dstNode)) {\n        srcNode.disconnect(dstNode, outputNumber, inputNumber);\n    }\n    else {\n        srcNode.disconnect();\n    }\n}\n//# sourceMappingURL=ToneAudioNode.js.map","import { getContext } from \"../Global\";\nimport { Tone } from \"../Tone\";\nimport { FrequencyClass } from \"../type/Frequency\";\nimport { TimeClass } from \"../type/Time\";\nimport { TransportTimeClass } from \"../type/TransportTime\";\nimport { getDefaultsFromInstance, optionsFromArguments } from \"../util/Defaults\";\nimport { isArray, isBoolean, isDefined, isNumber, isString, isUndef } from \"../util/TypeCheck\";\n/**\n * The Base class for all nodes that have an AudioContext.\n */\nexport class ToneWithContext extends Tone {\n    constructor() {\n        super();\n        const options = optionsFromArguments(ToneWithContext.getDefaults(), arguments, [\"context\"]);\n        if (this.defaultContext) {\n            this.context = this.defaultContext;\n        }\n        else {\n            this.context = options.context;\n        }\n    }\n    static getDefaults() {\n        return {\n            context: getContext(),\n        };\n    }\n    /**\n     * Return the current time of the Context clock plus the lookAhead.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(Tone.now());\n     * }, 100)\n     */\n    now() {\n        return this.context.currentTime + this.context.lookAhead;\n    }\n    /**\n     * Return the current time of the Context clock without any lookAhead.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(Tone.immediate());\n     * }, 100)\n     */\n    immediate() {\n        return this.context.currentTime;\n    }\n    /**\n     * The duration in seconds of one sample.\n     * @example\n     * console.log(Tone.Transport.sampleTime);\n     */\n    get sampleTime() {\n        return 1 / this.context.sampleRate;\n    }\n    /**\n     * The number of seconds of 1 processing block (128 samples)\n     * @example\n     * console.log(Tone.Destination.blockTime);\n     */\n    get blockTime() {\n        return 128 / this.context.sampleRate;\n    }\n    /**\n     * Convert the incoming time to seconds\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toSeconds(\"4n\"));\n     */\n    toSeconds(time) {\n        return new TimeClass(this.context, time).toSeconds();\n    }\n    /**\n     * Convert the input to a frequency number\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toFrequency(\"4n\"));\n     */\n    toFrequency(freq) {\n        return new FrequencyClass(this.context, freq).toFrequency();\n    }\n    /**\n     * Convert the input time into ticks\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toTicks(\"4n\"));\n     */\n    toTicks(time) {\n        return new TransportTimeClass(this.context, time).toTicks();\n    }\n    //-------------------------------------\n    // \tGET/SET\n    //-------------------------------------\n    /**\n     * Get a subset of the properties which are in the partial props\n     */\n    _getPartialProperties(props) {\n        const options = this.get();\n        // remove attributes from the prop that are not in the partial\n        Object.keys(options).forEach(name => {\n            if (isUndef(props[name])) {\n                delete options[name];\n            }\n        });\n        return options;\n    }\n    /**\n     * Get the object's attributes.\n     * @example\n     * const osc = new Tone.Oscillator();\n     * console.log(osc.get());\n     */\n    get() {\n        const defaults = getDefaultsFromInstance(this);\n        Object.keys(defaults).forEach(attribute => {\n            if (Reflect.has(this, attribute)) {\n                const member = this[attribute];\n                if (isDefined(member) && isDefined(member.value) && isDefined(member.setValueAtTime)) {\n                    defaults[attribute] = member.value;\n                }\n                else if (member instanceof ToneWithContext) {\n                    defaults[attribute] = member._getPartialProperties(defaults[attribute]);\n                    // otherwise make sure it's a serializable type\n                }\n                else if (isArray(member) || isNumber(member) || isString(member) || isBoolean(member)) {\n                    defaults[attribute] = member;\n                }\n                else {\n                    // remove all undefined and unserializable attributes\n                    delete defaults[attribute];\n                }\n            }\n        });\n        return defaults;\n    }\n    /**\n     * Set multiple properties at once with an object.\n     * @example\n     * const filter = new Tone.Filter();\n     * // set values using an object\n     * filter.set({\n     * \tfrequency: 300,\n     * \ttype: \"highpass\"\n     * });\n     */\n    set(props) {\n        Object.keys(props).forEach(attribute => {\n            if (Reflect.has(this, attribute) && isDefined(this[attribute])) {\n                if (this[attribute] && isDefined(this[attribute].value) && isDefined(this[attribute].setValueAtTime)) {\n                    // small optimization\n                    if (this[attribute].value !== props[attribute]) {\n                        this[attribute].value = props[attribute];\n                    }\n                }\n                else if (this[attribute] instanceof ToneWithContext) {\n                    this[attribute].set(props[attribute]);\n                }\n                else {\n                    this[attribute] = props[attribute];\n                }\n            }\n        });\n        return this;\n    }\n}\n//# sourceMappingURL=ToneWithContext.js.map","export * from \"./clock/Clock\";\nexport * from \"./clock/Transport\";\nexport * from \"./context/Context\";\nexport * from \"./context/BaseContext\";\nexport * from \"./context/Delay\";\nexport * from \"./context/Destination\";\nexport * from \"./context/Gain\";\nexport * from \"./context/Offline\";\nexport * from \"./context/OfflineContext\";\nexport * from \"./context/Param\";\nexport * from \"./context/ToneAudioBuffer\";\nexport * from \"./context/ToneAudioBuffers\";\nexport * from \"./context/ToneAudioNode\";\nexport * from \"./type/Frequency\";\nexport * from \"./type/Midi\";\nexport * from \"./type/Time\";\nexport * from \"./type/Ticks\";\nexport * from \"./type/TransportTime\";\nexport * from \"./util/Draw\";\nexport * from \"./util/Emitter\";\nexport * from \"./util/IntervalTimeline\";\nexport * from \"./util/StateTimeline\";\nexport * from \"./util/Timeline\";\nexport * from \"./util/TypeCheck\";\nexport { dbToGain, gainToDb, intervalToFrequencyRatio, ftom, mtof } from \"./type/Conversions\";\nexport { optionsFromArguments, defaultArg } from \"./util/Defaults\";\n// get the units and export them under the \"Unit\" namespace\nimport * as Unit from \"./type/Units\";\nexport { Unit };\n// export the debug stuff as Debug\nimport * as debug from \"./util/Debug\";\nexport { debug };\n//# sourceMappingURL=index.js.map","/**\n * Equal power gain scale. Good for cross-fading.\n * @param  percent (0-1)\n */\nexport function equalPowerScale(percent) {\n    const piFactor = 0.5 * Math.PI;\n    return Math.sin(percent * piFactor);\n}\n/**\n * Convert decibels into gain.\n */\nexport function dbToGain(db) {\n    return Math.pow(10, db / 20);\n}\n/**\n * Convert gain to decibels.\n */\nexport function gainToDb(gain) {\n    return 20 * (Math.log(gain) / Math.LN10);\n}\n/**\n * Convert an interval (in semitones) to a frequency ratio.\n * @param interval the number of semitones above the base note\n * @example\n * Tone.intervalToFrequencyRatio(0); // 1\n * Tone.intervalToFrequencyRatio(12); // 2\n * Tone.intervalToFrequencyRatio(-12); // 0.5\n */\nexport function intervalToFrequencyRatio(interval) {\n    return Math.pow(2, (interval / 12));\n}\n/**\n * The Global [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used\n * to generate all the other pitch values from notes. A4's values in Hertz.\n */\nlet A4 = 440;\nexport function getA4() {\n    return A4;\n}\nexport function setA4(freq) {\n    A4 = freq;\n}\n/**\n * Convert a frequency value to a MIDI note.\n * @param frequency The value to frequency value to convert.\n * @example\n * Tone.ftom(440); // returns 69\n */\nexport function ftom(frequency) {\n    return Math.round(ftomf(frequency));\n}\n/**\n * Convert a frequency to a floating point midi value\n */\nexport function ftomf(frequency) {\n    return 69 + 12 * Math.log2(frequency / A4);\n}\n/**\n * Convert a MIDI note to frequency value.\n * @param  midi The midi number to convert.\n * @return The corresponding frequency value\n * @example\n * Tone.mtof(69); // 440\n */\nexport function mtof(midi) {\n    return A4 * Math.pow(2, (midi - 69) / 12);\n}\n//# sourceMappingURL=Conversions.js.map","import { getContext } from \"../Global\";\nimport { intervalToFrequencyRatio, mtof } from \"./Conversions\";\nimport { ftom, getA4, setA4 } from \"./Conversions\";\nimport { TimeClass } from \"./Time\";\n/**\n * Frequency is a primitive type for encoding Frequency values.\n * Eventually all time values are evaluated to hertz using the `eval` method.\n * @example\n * Tone.Frequency(\"C3\"); // 261\n * Tone.Frequency(38, \"midi\");\n * Tone.Frequency(\"C3\").transpose(4);\n * @category Unit\n */\nexport class FrequencyClass extends TimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"Frequency\";\n        this.defaultUnits = \"hz\";\n    }\n    /**\n     * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used\n     * to generate all the other pitch values from notes. A4's values in Hertz.\n     */\n    static get A4() {\n        return getA4();\n    }\n    static set A4(freq) {\n        setA4(freq);\n    }\n    //-------------------------------------\n    // \tAUGMENT BASE EXPRESSIONS\n    //-------------------------------------\n    _getExpressions() {\n        return Object.assign({}, super._getExpressions(), {\n            midi: {\n                regexp: /^(\\d+(?:\\.\\d+)?midi)/,\n                method(value) {\n                    if (this.defaultUnits === \"midi\") {\n                        return value;\n                    }\n                    else {\n                        return FrequencyClass.mtof(value);\n                    }\n                },\n            },\n            note: {\n                regexp: /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,\n                method(pitch, octave) {\n                    const index = noteToScaleIndex[pitch.toLowerCase()];\n                    const noteNumber = index + (parseInt(octave, 10) + 1) * 12;\n                    if (this.defaultUnits === \"midi\") {\n                        return noteNumber;\n                    }\n                    else {\n                        return FrequencyClass.mtof(noteNumber);\n                    }\n                },\n            },\n            tr: {\n                regexp: /^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?/,\n                method(m, q, s) {\n                    let total = 1;\n                    if (m && m !== \"0\") {\n                        total *= this._beatsToUnits(this._getTimeSignature() * parseFloat(m));\n                    }\n                    if (q && q !== \"0\") {\n                        total *= this._beatsToUnits(parseFloat(q));\n                    }\n                    if (s && s !== \"0\") {\n                        total *= this._beatsToUnits(parseFloat(s) / 4);\n                    }\n                    return total;\n                },\n            },\n        });\n    }\n    //-------------------------------------\n    // \tEXPRESSIONS\n    //-------------------------------------\n    /**\n     * Transposes the frequency by the given number of semitones.\n     * @return  A new transposed frequency\n     * @example\n     * Tone.Frequency(\"A4\").transpose(3); // \"C5\"\n     */\n    transpose(interval) {\n        return new FrequencyClass(this.context, this.valueOf() * intervalToFrequencyRatio(interval));\n    }\n    /**\n     * Takes an array of semitone intervals and returns\n     * an array of frequencies transposed by those intervals.\n     * @return  Returns an array of Frequencies\n     * @example\n     * Tone.Frequency(\"A4\").harmonize([0, 3, 7]); // [\"A4\", \"C5\", \"E5\"]\n     */\n    harmonize(intervals) {\n        return intervals.map(interval => {\n            return this.transpose(interval);\n        });\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS\n    //-------------------------------------\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Frequency(\"C4\").toMidi(); // 60\n     */\n    toMidi() {\n        return ftom(this.valueOf());\n    }\n    /**\n     * Return the value of the frequency in Scientific Pitch Notation\n     * @example\n     * Tone.Frequency(69, \"midi\").toNote(); // \"A4\"\n     */\n    toNote() {\n        const freq = this.toFrequency();\n        const log = Math.log2(freq / FrequencyClass.A4);\n        let noteNumber = Math.round(12 * log) + 57;\n        const octave = Math.floor(noteNumber / 12);\n        if (octave < 0) {\n            noteNumber += -12 * octave;\n        }\n        const noteName = scaleIndexToNote[noteNumber % 12];\n        return noteName + octave.toString();\n    }\n    /**\n     * Return the duration of one cycle in seconds.\n     */\n    toSeconds() {\n        return 1 / super.toSeconds();\n    }\n    /**\n     * Return the duration of one cycle in ticks\n     */\n    toTicks() {\n        const quarterTime = this._beatsToUnits(1);\n        const quarters = this.valueOf() / quarterTime;\n        return Math.floor(quarters * this._getPPQ());\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS HELPERS\n    //-------------------------------------\n    /**\n     * With no arguments, return 0\n     */\n    _noArg() {\n        return 0;\n    }\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return freq;\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return 1 / ((ticks * 60) / (this._getBpm() * this._getPPQ()));\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return 1 / super._beatsToUnits(beats);\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return 1 / seconds;\n    }\n    /**\n     * Convert a MIDI note to frequency value.\n     * @param  midi The midi number to convert.\n     * @return The corresponding frequency value\n     */\n    static mtof(midi) {\n        return mtof(midi);\n    }\n    /**\n     * Convert a frequency value to a MIDI note.\n     * @param frequency The value to frequency value to convert.\n     */\n    static ftom(frequency) {\n        return ftom(frequency);\n    }\n}\n//-------------------------------------\n// \tFREQUENCY CONVERSIONS\n//-------------------------------------\n/**\n * Note to scale index.\n * @hidden\n */\nconst noteToScaleIndex = {\n    cbb: -2, cb: -1, c: 0, \"c#\": 1, cx: 2,\n    dbb: 0, db: 1, d: 2, \"d#\": 3, dx: 4,\n    ebb: 2, eb: 3, e: 4, \"e#\": 5, ex: 6,\n    fbb: 3, fb: 4, f: 5, \"f#\": 6, fx: 7,\n    gbb: 5, gb: 6, g: 7, \"g#\": 8, gx: 9,\n    abb: 7, ab: 8, a: 9, \"a#\": 10, ax: 11,\n    bbb: 9, bb: 10, b: 11, \"b#\": 12, bx: 13,\n};\n/**\n * scale index to note (sharps)\n * @hidden\n */\nconst scaleIndexToNote = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"];\n/**\n * Convert a value into a FrequencyClass object.\n * @category Unit\n */\nexport function Frequency(value, units) {\n    return new FrequencyClass(getContext(), value, units);\n}\n//# sourceMappingURL=Frequency.js.map","import { getContext } from \"../Global\";\nimport { ftom, mtof } from \"./Conversions\";\nimport { FrequencyClass } from \"./Frequency\";\n/**\n * Midi is a primitive type for encoding Time values.\n * Midi can be constructed with or without the `new` keyword. Midi can be passed\n * into the parameter of any method which takes time as an argument.\n * @category Unit\n */\nexport class MidiClass extends FrequencyClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"MidiClass\";\n        this.defaultUnits = \"midi\";\n    }\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return ftom(super._frequencyToUnits(freq));\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return ftom(super._ticksToUnits(ticks));\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return ftom(super._beatsToUnits(beats));\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return ftom(super._secondsToUnits(seconds));\n    }\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Midi(60).toMidi(); // 60\n     */\n    toMidi() {\n        return this.valueOf();\n    }\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Midi(60).toFrequency(); // 261.6255653005986\n     */\n    toFrequency() {\n        return mtof(this.toMidi());\n    }\n    /**\n     * Transposes the frequency by the given number of semitones.\n     * @return A new transposed MidiClass\n     * @example\n     * Tone.Midi(\"A4\").transpose(3); // \"C5\"\n     */\n    transpose(interval) {\n        return new MidiClass(this.context, this.toMidi() + interval);\n    }\n}\n/**\n * Convert a value into a FrequencyClass object.\n * @category Unit\n */\nexport function Midi(value, units) {\n    return new MidiClass(getContext(), value, units);\n}\n//# sourceMappingURL=Midi.js.map","import { getContext } from \"../Global\";\nimport { TransportTimeClass } from \"./TransportTime\";\n/**\n * Ticks is a primitive type for encoding Time values.\n * Ticks can be constructed with or without the `new` keyword. Ticks can be passed\n * into the parameter of any method which takes time as an argument.\n * @example\n * const t = Tone.Ticks(\"4n\"); // a quarter note as ticks\n * @category Unit\n */\nexport class TicksClass extends TransportTimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"Ticks\";\n        this.defaultUnits = \"i\";\n    }\n    /**\n     * Get the current time in the given units\n     */\n    _now() {\n        return this.context.transport.ticks;\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return this._getPPQ() * beats;\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return Math.floor(seconds / (60 / this._getBpm()) * this._getPPQ());\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return ticks;\n    }\n    /**\n     * Return the time in ticks\n     */\n    toTicks() {\n        return this.valueOf();\n    }\n    /**\n     * Return the time in seconds\n     */\n    toSeconds() {\n        return (this.valueOf() / this._getPPQ()) * (60 / this._getBpm());\n    }\n}\n/**\n * Convert a time representation to ticks\n * @category Unit\n */\nexport function Ticks(value, units) {\n    return new TicksClass(getContext(), value, units);\n}\n//# sourceMappingURL=Ticks.js.map","import { getContext } from \"../Global\";\nimport { ftom } from \"./Conversions\";\nimport { TimeBaseClass } from \"./TimeBase\";\n/**\n * TimeClass is a primitive type for encoding and decoding Time values.\n * TimeClass can be passed into the parameter of any method which takes time as an argument.\n * @param  val    The time value.\n * @param  units  The units of the value.\n * @example\n * const time = Tone.Time(\"4n\"); // a quarter note\n * @category Unit\n */\nexport class TimeClass extends TimeBaseClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"TimeClass\";\n    }\n    _getExpressions() {\n        return Object.assign(super._getExpressions(), {\n            now: {\n                method: (capture) => {\n                    return this._now() + new this.constructor(this.context, capture).valueOf();\n                },\n                regexp: /^\\+(.+)/,\n            },\n            quantize: {\n                method: (capture) => {\n                    const quantTo = new TimeClass(this.context, capture).valueOf();\n                    return this._secondsToUnits(this.context.transport.nextSubdivision(quantTo));\n                },\n                regexp: /^@(.+)/,\n            },\n        });\n    }\n    /**\n     * Quantize the time by the given subdivision. Optionally add a\n     * percentage which will move the time value towards the ideal\n     * quantized value by that percentage.\n     * @param  subdiv    The subdivision to quantize to\n     * @param  percent  Move the time value towards the quantized value by a percentage.\n     * @example\n     * Tone.Time(21).quantize(2); // returns 22\n     * Tone.Time(0.6).quantize(\"4n\", 0.5); // returns 0.55\n     */\n    quantize(subdiv, percent = 1) {\n        const subdivision = new this.constructor(this.context, subdiv).valueOf();\n        const value = this.valueOf();\n        const multiple = Math.round(value / subdivision);\n        const ideal = multiple * subdivision;\n        const diff = ideal - value;\n        return value + diff * percent;\n    }\n    //-------------------------------------\n    // CONVERSIONS\n    //-------------------------------------\n    /**\n     * Convert a Time to Notation. The notation values are will be the\n     * closest representation between 1m to 128th note.\n     * @return {Notation}\n     * @example\n     * // if the Transport is at 120bpm:\n     * Tone.Time(2).toNotation(); // returns \"1m\"\n     */\n    toNotation() {\n        const time = this.toSeconds();\n        const testNotations = [\"1m\"];\n        for (let power = 1; power < 9; power++) {\n            const subdiv = Math.pow(2, power);\n            testNotations.push(subdiv + \"n.\");\n            testNotations.push(subdiv + \"n\");\n            testNotations.push(subdiv + \"t\");\n        }\n        testNotations.push(\"0\");\n        // find the closets notation representation\n        let closest = testNotations[0];\n        let closestSeconds = new TimeClass(this.context, testNotations[0]).toSeconds();\n        testNotations.forEach(notation => {\n            const notationSeconds = new TimeClass(this.context, notation).toSeconds();\n            if (Math.abs(notationSeconds - time) < Math.abs(closestSeconds - time)) {\n                closest = notation;\n                closestSeconds = notationSeconds;\n            }\n        });\n        return closest;\n    }\n    /**\n     * Return the time encoded as Bars:Beats:Sixteenths.\n     */\n    toBarsBeatsSixteenths() {\n        const quarterTime = this._beatsToUnits(1);\n        let quarters = this.valueOf() / quarterTime;\n        quarters = parseFloat(quarters.toFixed(4));\n        const measures = Math.floor(quarters / this._getTimeSignature());\n        let sixteenths = (quarters % 1) * 4;\n        quarters = Math.floor(quarters) % this._getTimeSignature();\n        const sixteenthString = sixteenths.toString();\n        if (sixteenthString.length > 3) {\n            // the additional parseFloat removes insignificant trailing zeroes\n            sixteenths = parseFloat(parseFloat(sixteenthString).toFixed(3));\n        }\n        const progress = [measures, quarters, sixteenths];\n        return progress.join(\":\");\n    }\n    /**\n     * Return the time in ticks.\n     */\n    toTicks() {\n        const quarterTime = this._beatsToUnits(1);\n        const quarters = this.valueOf() / quarterTime;\n        return Math.round(quarters * this._getPPQ());\n    }\n    /**\n     * Return the time in seconds.\n     */\n    toSeconds() {\n        return this.valueOf();\n    }\n    /**\n     * Return the value as a midi note.\n     */\n    toMidi() {\n        return ftom(this.toFrequency());\n    }\n    _now() {\n        return this.context.now();\n    }\n}\n/**\n * Create a TimeClass from a time string or number.\n * @param value A value which reprsents time\n * @param units The value's units if they can't be inferred by the value.\n * @category Unit\n */\nexport function Time(value, units) {\n    return new TimeClass(getContext(), value, units);\n}\n//# sourceMappingURL=Time.js.map","import { Tone } from \"../Tone\";\nimport { isDefined, isObject, isString, isUndef } from \"../util/TypeCheck\";\n/**\n * TimeBase is a flexible encoding of time which can be evaluated to and from a string.\n */\nexport class TimeBaseClass extends Tone {\n    /**\n     * @param context The context associated with the time value. Used to compute\n     * Transport and context-relative timing.\n     * @param  value  The time value as a number, string or object\n     * @param  units  Unit values\n     */\n    constructor(context, value, units) {\n        super();\n        /**\n         * The default units\n         */\n        this.defaultUnits = \"s\";\n        this._val = value;\n        this._units = units;\n        this.context = context;\n        this._expressions = this._getExpressions();\n    }\n    /**\n     * All of the time encoding expressions\n     */\n    _getExpressions() {\n        return {\n            hz: {\n                method: (value) => {\n                    return this._frequencyToUnits(parseFloat(value));\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)hz$/i,\n            },\n            i: {\n                method: (value) => {\n                    return this._ticksToUnits(parseInt(value, 10));\n                },\n                regexp: /^(\\d+)i$/i,\n            },\n            m: {\n                method: (value) => {\n                    return this._beatsToUnits(parseInt(value, 10) * this._getTimeSignature());\n                },\n                regexp: /^(\\d+)m$/i,\n            },\n            n: {\n                method: (value, dot) => {\n                    const numericValue = parseInt(value, 10);\n                    const scalar = dot === \".\" ? 1.5 : 1;\n                    if (numericValue === 1) {\n                        return this._beatsToUnits(this._getTimeSignature()) * scalar;\n                    }\n                    else {\n                        return this._beatsToUnits(4 / numericValue) * scalar;\n                    }\n                },\n                regexp: /^(\\d+)n(\\.?)$/i,\n            },\n            number: {\n                method: (value) => {\n                    return this._expressions[this.defaultUnits].method.call(this, value);\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)$/,\n            },\n            s: {\n                method: (value) => {\n                    return this._secondsToUnits(parseFloat(value));\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)s$/,\n            },\n            samples: {\n                method: (value) => {\n                    return parseInt(value, 10) / this.context.sampleRate;\n                },\n                regexp: /^(\\d+)samples$/,\n            },\n            t: {\n                method: (value) => {\n                    const numericValue = parseInt(value, 10);\n                    return this._beatsToUnits(8 / (Math.floor(numericValue) * 3));\n                },\n                regexp: /^(\\d+)t$/i,\n            },\n            tr: {\n                method: (m, q, s) => {\n                    let total = 0;\n                    if (m && m !== \"0\") {\n                        total += this._beatsToUnits(this._getTimeSignature() * parseFloat(m));\n                    }\n                    if (q && q !== \"0\") {\n                        total += this._beatsToUnits(parseFloat(q));\n                    }\n                    if (s && s !== \"0\") {\n                        total += this._beatsToUnits(parseFloat(s) / 4);\n                    }\n                    return total;\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?$/,\n            },\n        };\n    }\n    //-------------------------------------\n    // \tVALUE OF\n    //-------------------------------------\n    /**\n     * Evaluate the time value. Returns the time in seconds.\n     */\n    valueOf() {\n        if (this._val instanceof TimeBaseClass) {\n            this.fromType(this._val);\n        }\n        if (isUndef(this._val)) {\n            return this._noArg();\n        }\n        else if (isString(this._val) && isUndef(this._units)) {\n            for (const units in this._expressions) {\n                if (this._expressions[units].regexp.test(this._val.trim())) {\n                    this._units = units;\n                    break;\n                }\n            }\n        }\n        else if (isObject(this._val)) {\n            let total = 0;\n            for (const typeName in this._val) {\n                if (isDefined(this._val[typeName])) {\n                    const quantity = this._val[typeName];\n                    // @ts-ignore\n                    const time = (new this.constructor(this.context, typeName)).valueOf() * quantity;\n                    total += time;\n                }\n            }\n            return total;\n        }\n        if (isDefined(this._units)) {\n            const expr = this._expressions[this._units];\n            const matching = this._val.toString().trim().match(expr.regexp);\n            if (matching) {\n                return expr.method.apply(this, matching.slice(1));\n            }\n            else {\n                return expr.method.call(this, this._val);\n            }\n        }\n        else if (isString(this._val)) {\n            return parseFloat(this._val);\n        }\n        else {\n            return this._val;\n        }\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS\n    //-------------------------------------\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return 1 / freq;\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return (60 / this._getBpm()) * beats;\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return seconds;\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return (ticks * (this._beatsToUnits(1)) / this._getPPQ());\n    }\n    /**\n     * With no arguments, return 'now'\n     */\n    _noArg() {\n        return this._now();\n    }\n    //-------------------------------------\n    // \tTEMPO CONVERSIONS\n    //-------------------------------------\n    /**\n     * Return the bpm\n     */\n    _getBpm() {\n        return this.context.transport.bpm.value;\n    }\n    /**\n     * Return the timeSignature\n     */\n    _getTimeSignature() {\n        return this.context.transport.timeSignature;\n    }\n    /**\n     * Return the PPQ or 192 if Transport is not available\n     */\n    _getPPQ() {\n        return this.context.transport.PPQ;\n    }\n    //-------------------------------------\n    // \tCONVERSION INTERFACE\n    //-------------------------------------\n    /**\n     * Coerce a time type into this units type.\n     * @param type Any time type units\n     */\n    fromType(type) {\n        this._units = undefined;\n        switch (this.defaultUnits) {\n            case \"s\":\n                this._val = type.toSeconds();\n                break;\n            case \"i\":\n                this._val = type.toTicks();\n                break;\n            case \"hz\":\n                this._val = type.toFrequency();\n                break;\n            case \"midi\":\n                this._val = type.toMidi();\n                break;\n        }\n        return this;\n    }\n    /**\n     * Return the value in hertz\n     */\n    toFrequency() {\n        return 1 / this.toSeconds();\n    }\n    /**\n     * Return the time in samples\n     */\n    toSamples() {\n        return this.toSeconds() * this.context.sampleRate;\n    }\n    /**\n     * Return the time in milliseconds.\n     */\n    toMilliseconds() {\n        return this.toSeconds() * 1000;\n    }\n}\n//# sourceMappingURL=TimeBase.js.map","import { getContext } from \"../Global\";\nimport { TimeClass } from \"./Time\";\n/**\n * TransportTime is a the time along the Transport's\n * timeline. It is similar to Tone.Time, but instead of evaluating\n * against the AudioContext's clock, it is evaluated against\n * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n * @category Unit\n */\nexport class TransportTimeClass extends TimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"TransportTime\";\n    }\n    /**\n     * Return the current time in whichever context is relevant\n     */\n    _now() {\n        return this.context.transport.seconds;\n    }\n}\n/**\n * TransportTime is a the time along the Transport's\n * timeline. It is similar to [[Time]], but instead of evaluating\n * against the AudioContext's clock, it is evaluated against\n * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n * @category Unit\n */\nexport function TransportTime(value, units) {\n    return new TransportTimeClass(getContext(), value, units);\n}\n//# sourceMappingURL=TransportTime.js.map","//# sourceMappingURL=Units.js.map","import { isAnyAudioContext, isAnyAudioNode, isAnyAudioParam, isAnyOfflineAudioContext, } from \"standardized-audio-context\";\n/**\n * Test if the given value is an instanceof AudioParam\n */\nexport function isAudioParam(arg) {\n    return isAnyAudioParam(arg);\n}\n/**\n * Test if the given value is an instanceof AudioNode\n */\nexport function isAudioNode(arg) {\n    return isAnyAudioNode(arg);\n}\n/**\n * Test if the arg is instanceof an OfflineAudioContext\n */\nexport function isOfflineAudioContext(arg) {\n    return isAnyOfflineAudioContext(arg);\n}\n/**\n * Test if the arg is an instanceof AudioContext\n */\nexport function isAudioContext(arg) {\n    return isAnyAudioContext(arg);\n}\n/**\n * Test if the arg is instanceof an AudioBuffer\n */\nexport function isAudioBuffer(arg) {\n    return arg instanceof AudioBuffer;\n}\n//# sourceMappingURL=AdvancedTypeCheck.js.map","/**\n * Assert that the statement is true, otherwise invoke the error.\n * @param statement\n * @param error The message which is passed into an Error\n */\nexport function assert(statement, error) {\n    if (!statement) {\n        throw new Error(error);\n    }\n}\n/**\n * Make sure that the given value is within the range\n */\nexport function assertRange(value, gte, lte = Infinity) {\n    if (!(gte <= value && value <= lte)) {\n        throw new RangeError(`Value must be within [${gte}, ${lte}], got: ${value}`);\n    }\n}\n/**\n * Make sure that the given value is within the range\n */\nexport function assertContextRunning(context) {\n    // add a warning if the context is not started\n    if (!context.isOffline && context.state !== \"running\") {\n        warn(\"The AudioContext is \\\"suspended\\\". Invoke Tone.start() from a user action to start the audio.\");\n    }\n}\n/**\n * The default logger is the console\n */\nlet defaultLogger = console;\n/**\n * Set the logging interface\n */\nexport function setLogger(logger) {\n    defaultLogger = logger;\n}\n/**\n * Log anything\n */\nexport function log(...args) {\n    defaultLogger.log(...args);\n}\n/**\n * Warn anything\n */\nexport function warn(...args) {\n    defaultLogger.warn(...args);\n}\n//# sourceMappingURL=Debug.js.map","import { assertRange } from \"./Debug\";\n/**\n * Assert that the number is in the given range.\n */\nexport function range(min, max = Infinity) {\n    const valueMap = new WeakMap();\n    return function (target, propertyKey) {\n        Reflect.defineProperty(target, propertyKey, {\n            configurable: true,\n            enumerable: true,\n            get: function () {\n                return valueMap.get(this);\n            },\n            set: function (newValue) {\n                assertRange(newValue, min, max);\n                valueMap.set(this, newValue);\n            }\n        });\n    };\n}\n/**\n * Convert the time to seconds and assert that the time is in between the two\n * values when being set.\n */\nexport function timeRange(min, max = Infinity) {\n    const valueMap = new WeakMap();\n    return function (target, propertyKey) {\n        Reflect.defineProperty(target, propertyKey, {\n            configurable: true,\n            enumerable: true,\n            get: function () {\n                return valueMap.get(this);\n            },\n            set: function (newValue) {\n                assertRange(this.toSeconds(newValue), min, max);\n                valueMap.set(this, newValue);\n            }\n        });\n    };\n}\n//# sourceMappingURL=Decorator.js.map","import { isAudioBuffer, isAudioNode, isAudioParam } from \"./AdvancedTypeCheck\";\nimport { isDefined, isObject, isUndef } from \"./TypeCheck\";\n/**\n * Some objects should not be merged\n */\nfunction noCopy(key, arg) {\n    return key === \"value\" || isAudioParam(arg) || isAudioNode(arg) || isAudioBuffer(arg);\n}\nexport function deepMerge(target, ...sources) {\n    if (!sources.length) {\n        return target;\n    }\n    const source = sources.shift();\n    if (isObject(target) && isObject(source)) {\n        for (const key in source) {\n            if (noCopy(key, source[key])) {\n                target[key] = source[key];\n            }\n            else if (isObject(source[key])) {\n                if (!target[key]) {\n                    Object.assign(target, { [key]: {} });\n                }\n                deepMerge(target[key], source[key]);\n            }\n            else {\n                Object.assign(target, { [key]: source[key] });\n            }\n        }\n    }\n    // @ts-ignore\n    return deepMerge(target, ...sources);\n}\n/**\n * Returns true if the two arrays have the same value for each of the elements\n */\nexport function deepEquals(arrayA, arrayB) {\n    return arrayA.length === arrayB.length && arrayA.every((element, index) => arrayB[index] === element);\n}\n/**\n * Convert an args array into an object.\n */\nexport function optionsFromArguments(defaults, argsArray, keys = [], objKey) {\n    const opts = {};\n    const args = Array.from(argsArray);\n    // if the first argument is an object and has an object key\n    if (isObject(args[0]) && objKey && !Reflect.has(args[0], objKey)) {\n        // if it's not part of the defaults\n        const partOfDefaults = Object.keys(args[0]).some(key => Reflect.has(defaults, key));\n        if (!partOfDefaults) {\n            // merge that key\n            deepMerge(opts, { [objKey]: args[0] });\n            // remove the obj key from the keys\n            keys.splice(keys.indexOf(objKey), 1);\n            // shift the first argument off\n            args.shift();\n        }\n    }\n    if (args.length === 1 && isObject(args[0])) {\n        deepMerge(opts, args[0]);\n    }\n    else {\n        for (let i = 0; i < keys.length; i++) {\n            if (isDefined(args[i])) {\n                opts[keys[i]] = args[i];\n            }\n        }\n    }\n    return deepMerge(defaults, opts);\n}\n/**\n * Return this instances default values by calling Constructor.getDefaults()\n */\nexport function getDefaultsFromInstance(instance) {\n    return instance.constructor.getDefaults();\n}\n/**\n * Returns the fallback if the given object is undefined.\n * Take an array of arguments and return a formatted options object.\n */\nexport function defaultArg(given, fallback) {\n    if (isUndef(given)) {\n        return fallback;\n    }\n    else {\n        return given;\n    }\n}\n/**\n * Remove all of the properties belonging to omit from obj.\n */\nexport function omitFromObject(obj, omit) {\n    omit.forEach(prop => {\n        if (Reflect.has(obj, prop)) {\n            delete obj[prop];\n        }\n    });\n    return obj;\n}\n//# sourceMappingURL=Defaults.js.map","import { ToneWithContext } from \"../context/ToneWithContext\";\nimport { Timeline } from \"./Timeline\";\nimport { onContextClose, onContextInit } from \"../context/ContextInitialization\";\n/**\n * Draw is useful for synchronizing visuals and audio events.\n * Callbacks from Tone.Transport or any of the Tone.Event classes\n * always happen _before_ the scheduled time and are not synchronized\n * to the animation frame so they are not good for triggering tightly\n * synchronized visuals and sound. Draw makes it easy to schedule\n * callbacks using the AudioContext time and uses requestAnimationFrame.\n * @example\n * Tone.Transport.schedule((time) => {\n * \t// use the time argument to schedule a callback with Draw\n * \tTone.Draw.schedule(() => {\n * \t\t// do drawing or DOM manipulation here\n * \t\tconsole.log(time);\n * \t}, time);\n * }, \"+0.5\");\n * Tone.Transport.start();\n * @category Core\n */\nexport class Draw extends ToneWithContext {\n    constructor() {\n        super(...arguments);\n        this.name = \"Draw\";\n        /**\n         * The duration after which events are not invoked.\n         */\n        this.expiration = 0.25;\n        /**\n         * The amount of time before the scheduled time\n         * that the callback can be invoked. Default is\n         * half the time of an animation frame (0.008 seconds).\n         */\n        this.anticipation = 0.008;\n        /**\n         * All of the events.\n         */\n        this._events = new Timeline();\n        /**\n         * The draw loop\n         */\n        this._boundDrawLoop = this._drawLoop.bind(this);\n        /**\n         * The animation frame id\n         */\n        this._animationFrame = -1;\n    }\n    /**\n     * Schedule a function at the given time to be invoked\n     * on the nearest animation frame.\n     * @param  callback  Callback is invoked at the given time.\n     * @param  time      The time relative to the AudioContext time to invoke the callback.\n     * @example\n     * Tone.Transport.scheduleRepeat(time => {\n     * \tTone.Draw.schedule(() => console.log(time), time);\n     * }, 1);\n     * Tone.Transport.start();\n     */\n    schedule(callback, time) {\n        this._events.add({\n            callback,\n            time: this.toSeconds(time),\n        });\n        // start the draw loop on the first event\n        if (this._events.length === 1) {\n            this._animationFrame = requestAnimationFrame(this._boundDrawLoop);\n        }\n        return this;\n    }\n    /**\n     * Cancel events scheduled after the given time\n     * @param  after  Time after which scheduled events will be removed from the scheduling timeline.\n     */\n    cancel(after) {\n        this._events.cancel(this.toSeconds(after));\n        return this;\n    }\n    /**\n     * The draw loop\n     */\n    _drawLoop() {\n        const now = this.context.currentTime;\n        while (this._events.length && this._events.peek().time - this.anticipation <= now) {\n            const event = this._events.shift();\n            if (event && now - event.time <= this.expiration) {\n                event.callback();\n            }\n        }\n        if (this._events.length > 0) {\n            this._animationFrame = requestAnimationFrame(this._boundDrawLoop);\n        }\n    }\n    dispose() {\n        super.dispose();\n        this._events.dispose();\n        cancelAnimationFrame(this._animationFrame);\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\nonContextInit(context => {\n    context.draw = new Draw({ context });\n});\nonContextClose(context => {\n    context.draw.dispose();\n});\n//# sourceMappingURL=Draw.js.map","import { Tone } from \"../Tone\";\nimport { isUndef } from \"./TypeCheck\";\n/**\n * Emitter gives classes which extend it\n * the ability to listen for and emit events.\n * Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).\n * MIT (c) 2011 Jerome Etienne.\n */\nexport class Emitter extends Tone {\n    constructor() {\n        super(...arguments);\n        this.name = \"Emitter\";\n    }\n    /**\n     * Bind a callback to a specific event.\n     * @param  event     The name of the event to listen for.\n     * @param  callback  The callback to invoke when the event is emitted\n     */\n    on(event, callback) {\n        // split the event\n        const events = event.split(/\\W+/);\n        events.forEach(eventName => {\n            if (isUndef(this._events)) {\n                this._events = {};\n            }\n            if (!this._events.hasOwnProperty(eventName)) {\n                this._events[eventName] = [];\n            }\n            this._events[eventName].push(callback);\n        });\n        return this;\n    }\n    /**\n     * Bind a callback which is only invoked once\n     * @param  event     The name of the event to listen for.\n     * @param  callback  The callback to invoke when the event is emitted\n     */\n    once(event, callback) {\n        const boundCallback = (...args) => {\n            // invoke the callback\n            callback(...args);\n            // remove the event\n            this.off(event, boundCallback);\n        };\n        this.on(event, boundCallback);\n        return this;\n    }\n    /**\n     * Remove the event listener.\n     * @param  event     The event to stop listening to.\n     * @param  callback  The callback which was bound to the event with Emitter.on.\n     *                   If no callback is given, all callbacks events are removed.\n     */\n    off(event, callback) {\n        const events = event.split(/\\W+/);\n        events.forEach(eventName => {\n            if (isUndef(this._events)) {\n                this._events = {};\n            }\n            if (this._events.hasOwnProperty(event)) {\n                if (isUndef(callback)) {\n                    this._events[event] = [];\n                }\n                else {\n                    const eventList = this._events[event];\n                    for (let i = 0; i < eventList.length; i++) {\n                        if (eventList[i] === callback) {\n                            eventList.splice(i, 1);\n                        }\n                    }\n                }\n            }\n        });\n        return this;\n    }\n    /**\n     * Invoke all of the callbacks bound to the event\n     * with any arguments passed in.\n     * @param  event  The name of the event.\n     * @param args The arguments to pass to the functions listening.\n     */\n    emit(event, ...args) {\n        if (this._events) {\n            if (this._events.hasOwnProperty(event)) {\n                const eventList = this._events[event].slice(0);\n                for (let i = 0, len = eventList.length; i < len; i++) {\n                    eventList[i].apply(this, args);\n                }\n            }\n        }\n        return this;\n    }\n    /**\n     * Add Emitter functions (on/off/emit) to the object\n     */\n    static mixin(constr) {\n        // instance._events = {};\n        [\"on\", \"once\", \"off\", \"emit\"].forEach(name => {\n            const property = Object.getOwnPropertyDescriptor(Emitter.prototype, name);\n            Object.defineProperty(constr.prototype, name, property);\n        });\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._events = undefined;\n        return this;\n    }\n}\n//# sourceMappingURL=Emitter.js.map","import { isArray } from \"./TypeCheck\";\n/**\n * Make the property not writable using `defineProperty`. Internal use only.\n */\nexport function readOnly(target, property) {\n    if (isArray(property)) {\n        property.forEach(str => readOnly(target, str));\n    }\n    else {\n        Object.defineProperty(target, property, {\n            enumerable: true,\n            writable: false,\n        });\n    }\n}\n/**\n * Make an attribute writeable. Internal use only.\n */\nexport function writable(target, property) {\n    if (isArray(property)) {\n        property.forEach(str => writable(target, str));\n    }\n    else {\n        Object.defineProperty(target, property, {\n            writable: true,\n        });\n    }\n}\nexport const noOp = () => {\n    // no operation here!\n};\n//# sourceMappingURL=Interface.js.map","import { Tone } from \"../Tone\";\nimport { isDefined } from \"./TypeCheck\";\nimport { assert } from \"./Debug\";\n/**\n * Similar to Tone.Timeline, but all events represent\n * intervals with both \"time\" and \"duration\" times. The\n * events are placed in a tree structure optimized\n * for querying an intersection point with the timeline\n * events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)\n * to represent the data.\n */\nexport class IntervalTimeline extends Tone {\n    constructor() {\n        super(...arguments);\n        this.name = \"IntervalTimeline\";\n        /**\n         * The root node of the inteval tree\n         */\n        this._root = null;\n        /**\n         * Keep track of the length of the timeline.\n         */\n        this._length = 0;\n    }\n    /**\n     * The event to add to the timeline. All events must\n     * have a time and duration value\n     * @param  event  The event to add to the timeline\n     */\n    add(event) {\n        assert(isDefined(event.time), \"Events must have a time property\");\n        assert(isDefined(event.duration), \"Events must have a duration parameter\");\n        event.time = event.time.valueOf();\n        let node = new IntervalNode(event.time, event.time + event.duration, event);\n        if (this._root === null) {\n            this._root = node;\n        }\n        else {\n            this._root.insert(node);\n        }\n        this._length++;\n        // Restructure tree to be balanced\n        while (node !== null) {\n            node.updateHeight();\n            node.updateMax();\n            this._rebalance(node);\n            node = node.parent;\n        }\n        return this;\n    }\n    /**\n     * Remove an event from the timeline.\n     * @param  event  The event to remove from the timeline\n     */\n    remove(event) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(event.time, results);\n            for (const node of results) {\n                if (node.event === event) {\n                    this._removeNode(node);\n                    this._length--;\n                    break;\n                }\n            }\n        }\n        return this;\n    }\n    /**\n     * The number of items in the timeline.\n     * @readOnly\n     */\n    get length() {\n        return this._length;\n    }\n    /**\n     * Remove events whose time time is after the given time\n     * @param  after  The time to query.\n     */\n    cancel(after) {\n        this.forEachFrom(after, event => this.remove(event));\n        return this;\n    }\n    /**\n     * Set the root node as the given node\n     */\n    _setRoot(node) {\n        this._root = node;\n        if (this._root !== null) {\n            this._root.parent = null;\n        }\n    }\n    /**\n     * Replace the references to the node in the node's parent\n     * with the replacement node.\n     */\n    _replaceNodeInParent(node, replacement) {\n        if (node.parent !== null) {\n            if (node.isLeftChild()) {\n                node.parent.left = replacement;\n            }\n            else {\n                node.parent.right = replacement;\n            }\n            this._rebalance(node.parent);\n        }\n        else {\n            this._setRoot(replacement);\n        }\n    }\n    /**\n     * Remove the node from the tree and replace it with\n     * a successor which follows the schema.\n     */\n    _removeNode(node) {\n        if (node.left === null && node.right === null) {\n            this._replaceNodeInParent(node, null);\n        }\n        else if (node.right === null) {\n            this._replaceNodeInParent(node, node.left);\n        }\n        else if (node.left === null) {\n            this._replaceNodeInParent(node, node.right);\n        }\n        else {\n            const balance = node.getBalance();\n            let replacement;\n            let temp = null;\n            if (balance > 0) {\n                if (node.left.right === null) {\n                    replacement = node.left;\n                    replacement.right = node.right;\n                    temp = replacement;\n                }\n                else {\n                    replacement = node.left.right;\n                    while (replacement.right !== null) {\n                        replacement = replacement.right;\n                    }\n                    if (replacement.parent) {\n                        replacement.parent.right = replacement.left;\n                        temp = replacement.parent;\n                        replacement.left = node.left;\n                        replacement.right = node.right;\n                    }\n                }\n            }\n            else if (node.right.left === null) {\n                replacement = node.right;\n                replacement.left = node.left;\n                temp = replacement;\n            }\n            else {\n                replacement = node.right.left;\n                while (replacement.left !== null) {\n                    replacement = replacement.left;\n                }\n                if (replacement.parent) {\n                    replacement.parent.left = replacement.right;\n                    temp = replacement.parent;\n                    replacement.left = node.left;\n                    replacement.right = node.right;\n                }\n            }\n            if (node.parent !== null) {\n                if (node.isLeftChild()) {\n                    node.parent.left = replacement;\n                }\n                else {\n                    node.parent.right = replacement;\n                }\n            }\n            else {\n                this._setRoot(replacement);\n            }\n            if (temp) {\n                this._rebalance(temp);\n            }\n        }\n        node.dispose();\n    }\n    /**\n     * Rotate the tree to the left\n     */\n    _rotateLeft(node) {\n        const parent = node.parent;\n        const isLeftChild = node.isLeftChild();\n        // Make node.right the new root of this sub tree (instead of node)\n        const pivotNode = node.right;\n        if (pivotNode) {\n            node.right = pivotNode.left;\n            pivotNode.left = node;\n        }\n        if (parent !== null) {\n            if (isLeftChild) {\n                parent.left = pivotNode;\n            }\n            else {\n                parent.right = pivotNode;\n            }\n        }\n        else {\n            this._setRoot(pivotNode);\n        }\n    }\n    /**\n     * Rotate the tree to the right\n     */\n    _rotateRight(node) {\n        const parent = node.parent;\n        const isLeftChild = node.isLeftChild();\n        // Make node.left the new root of this sub tree (instead of node)\n        const pivotNode = node.left;\n        if (pivotNode) {\n            node.left = pivotNode.right;\n            pivotNode.right = node;\n        }\n        if (parent !== null) {\n            if (isLeftChild) {\n                parent.left = pivotNode;\n            }\n            else {\n                parent.right = pivotNode;\n            }\n        }\n        else {\n            this._setRoot(pivotNode);\n        }\n    }\n    /**\n     * Balance the BST\n     */\n    _rebalance(node) {\n        const balance = node.getBalance();\n        if (balance > 1 && node.left) {\n            if (node.left.getBalance() < 0) {\n                this._rotateLeft(node.left);\n            }\n            else {\n                this._rotateRight(node);\n            }\n        }\n        else if (balance < -1 && node.right) {\n            if (node.right.getBalance() > 0) {\n                this._rotateRight(node.right);\n            }\n            else {\n                this._rotateLeft(node);\n            }\n        }\n    }\n    /**\n     * Get an event whose time and duration span the give time. Will\n     * return the match whose \"time\" value is closest to the given time.\n     * @return  The event which spans the desired time\n     */\n    get(time) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(time, results);\n            if (results.length > 0) {\n                let max = results[0];\n                for (let i = 1; i < results.length; i++) {\n                    if (results[i].low > max.low) {\n                        max = results[i];\n                    }\n                }\n                return max.event;\n            }\n        }\n        return null;\n    }\n    /**\n     * Iterate over everything in the timeline.\n     * @param  callback The callback to invoke with every item\n     */\n    forEach(callback) {\n        if (this._root !== null) {\n            const allNodes = [];\n            this._root.traverse(node => allNodes.push(node));\n            allNodes.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array in which the given time\n     * overlaps with the time and duration time of the event.\n     * @param  time The time to check if items are overlapping\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAtTime(time, callback) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(time, results);\n            results.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array in which the time is greater\n     * than or equal to the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachFrom(time, callback) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.searchAfter(time, results);\n            results.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        if (this._root !== null) {\n            this._root.traverse(node => node.dispose());\n        }\n        this._root = null;\n        return this;\n    }\n}\n//-------------------------------------\n// \tINTERVAL NODE HELPER\n//-------------------------------------\n/**\n * Represents a node in the binary search tree, with the addition\n * of a \"high\" value which keeps track of the highest value of\n * its children.\n * References:\n * https://brooknovak.wordpress.com/2013/12/07/augmented-interval-tree-in-c/\n * http://www.mif.vu.lt/~valdas/ALGORITMAI/LITERATURA/Cormen/Cormen.pdf\n * @param low\n * @param high\n */\nclass IntervalNode {\n    constructor(low, high, event) {\n        // the nodes to the left\n        this._left = null;\n        // the nodes to the right\n        this._right = null;\n        // the parent node\n        this.parent = null;\n        // the number of child nodes\n        this.height = 0;\n        this.event = event;\n        // the low value\n        this.low = low;\n        // the high value\n        this.high = high;\n        // the high value for this and all child nodes\n        this.max = this.high;\n    }\n    /**\n     * Insert a node into the correct spot in the tree\n     */\n    insert(node) {\n        if (node.low <= this.low) {\n            if (this.left === null) {\n                this.left = node;\n            }\n            else {\n                this.left.insert(node);\n            }\n        }\n        else if (this.right === null) {\n            this.right = node;\n        }\n        else {\n            this.right.insert(node);\n        }\n    }\n    /**\n     * Search the tree for nodes which overlap\n     * with the given point\n     * @param  point  The point to query\n     * @param  results  The array to put the results\n     */\n    search(point, results) {\n        // If p is to the right of the rightmost point of any interval\n        // in this node and all children, there won't be any matches.\n        if (point > this.max) {\n            return;\n        }\n        // Search left children\n        if (this.left !== null) {\n            this.left.search(point, results);\n        }\n        // Check this node\n        if (this.low <= point && this.high > point) {\n            results.push(this);\n        }\n        // If p is to the left of the time of this interval,\n        // then it can't be in any child to the right.\n        if (this.low > point) {\n            return;\n        }\n        // Search right children\n        if (this.right !== null) {\n            this.right.search(point, results);\n        }\n    }\n    /**\n     * Search the tree for nodes which are less\n     * than the given point\n     * @param  point  The point to query\n     * @param  results  The array to put the results\n     */\n    searchAfter(point, results) {\n        // Check this node\n        if (this.low >= point) {\n            results.push(this);\n            if (this.left !== null) {\n                this.left.searchAfter(point, results);\n            }\n        }\n        // search the right side\n        if (this.right !== null) {\n            this.right.searchAfter(point, results);\n        }\n    }\n    /**\n     * Invoke the callback on this element and both it's branches\n     * @param  {Function}  callback\n     */\n    traverse(callback) {\n        callback(this);\n        if (this.left !== null) {\n            this.left.traverse(callback);\n        }\n        if (this.right !== null) {\n            this.right.traverse(callback);\n        }\n    }\n    /**\n     * Update the height of the node\n     */\n    updateHeight() {\n        if (this.left !== null && this.right !== null) {\n            this.height = Math.max(this.left.height, this.right.height) + 1;\n        }\n        else if (this.right !== null) {\n            this.height = this.right.height + 1;\n        }\n        else if (this.left !== null) {\n            this.height = this.left.height + 1;\n        }\n        else {\n            this.height = 0;\n        }\n    }\n    /**\n     * Update the height of the node\n     */\n    updateMax() {\n        this.max = this.high;\n        if (this.left !== null) {\n            this.max = Math.max(this.max, this.left.max);\n        }\n        if (this.right !== null) {\n            this.max = Math.max(this.max, this.right.max);\n        }\n    }\n    /**\n     * The balance is how the leafs are distributed on the node\n     * @return  Negative numbers are balanced to the right\n     */\n    getBalance() {\n        let balance = 0;\n        if (this.left !== null && this.right !== null) {\n            balance = this.left.height - this.right.height;\n        }\n        else if (this.left !== null) {\n            balance = this.left.height + 1;\n        }\n        else if (this.right !== null) {\n            balance = -(this.right.height + 1);\n        }\n        return balance;\n    }\n    /**\n     * @returns true if this node is the left child of its parent\n     */\n    isLeftChild() {\n        return this.parent !== null && this.parent.left === this;\n    }\n    /**\n     * get/set the left node\n     */\n    get left() {\n        return this._left;\n    }\n    set left(node) {\n        this._left = node;\n        if (node !== null) {\n            node.parent = this;\n        }\n        this.updateHeight();\n        this.updateMax();\n    }\n    /**\n     * get/set the right node\n     */\n    get right() {\n        return this._right;\n    }\n    set right(node) {\n        this._right = node;\n        if (node !== null) {\n            node.parent = this;\n        }\n        this.updateHeight();\n        this.updateMax();\n    }\n    /**\n     * null out references.\n     */\n    dispose() {\n        this.parent = null;\n        this._left = null;\n        this._right = null;\n        this.event = null;\n    }\n}\n//# sourceMappingURL=IntervalTimeline.js.map","/**\n * The threshold for correctness for operators. Less than one sample even\n * at very high sampling rates (e.g. `1e-6 < 1 / 192000`).\n */\nconst EPSILON = 1e-6;\n/**\n * Test if A is greater than B\n */\nexport function GT(a, b) {\n    return a > b + EPSILON;\n}\n/**\n * Test if A is greater than or equal to B\n */\nexport function GTE(a, b) {\n    return GT(a, b) || EQ(a, b);\n}\n/**\n * Test if A is less than B\n */\nexport function LT(a, b) {\n    return a + EPSILON < b;\n}\n/**\n * Test if A is less than B\n */\nexport function EQ(a, b) {\n    return Math.abs(a - b) < EPSILON;\n}\n/**\n * Clamp the value within the given range\n */\nexport function clamp(value, min, max) {\n    return Math.max(Math.min(value, max), min);\n}\n//# sourceMappingURL=Math.js.map","import { Timeline } from \"./Timeline\";\nimport { assertRange } from \"./Debug\";\n/**\n * A Timeline State. Provides the methods: `setStateAtTime(\"state\", time)` and `getValueAtTime(time)`\n * @param initial The initial state of the StateTimeline.  Defaults to `undefined`\n */\nexport class StateTimeline extends Timeline {\n    constructor(initial = \"stopped\") {\n        super();\n        this.name = \"StateTimeline\";\n        this._initial = initial;\n        this.setStateAtTime(this._initial, 0);\n    }\n    /**\n     * Returns the scheduled state scheduled before or at\n     * the given time.\n     * @param  time  The time to query.\n     * @return  The name of the state input in setStateAtTime.\n     */\n    getValueAtTime(time) {\n        const event = this.get(time);\n        if (event !== null) {\n            return event.state;\n        }\n        else {\n            return this._initial;\n        }\n    }\n    /**\n     * Add a state to the timeline.\n     * @param  state The name of the state to set.\n     * @param  time  The time to query.\n     * @param options Any additional options that are needed in the timeline.\n     */\n    setStateAtTime(state, time, options) {\n        assertRange(time, 0);\n        this.add(Object.assign({}, options, {\n            state,\n            time,\n        }));\n        return this;\n    }\n    /**\n     * Return the event before the time with the given state\n     * @param  state The state to look for\n     * @param  time  When to check before\n     * @return  The event with the given state before the time\n     */\n    getLastState(state, time) {\n        // time = this.toSeconds(time);\n        const index = this._search(time);\n        for (let i = index; i >= 0; i--) {\n            const event = this._timeline[i];\n            if (event.state === state) {\n                return event;\n            }\n        }\n    }\n    /**\n     * Return the event after the time with the given state\n     * @param  state The state to look for\n     * @param  time  When to check from\n     * @return  The event with the given state after the time\n     */\n    getNextState(state, time) {\n        // time = this.toSeconds(time);\n        const index = this._search(time);\n        if (index !== -1) {\n            for (let i = index; i < this._timeline.length; i++) {\n                const event = this._timeline[i];\n                if (event.state === state) {\n                    return event;\n                }\n            }\n        }\n    }\n}\n//# sourceMappingURL=StateTimeline.js.map","import { Tone } from \"../Tone\";\nimport { optionsFromArguments } from \"./Defaults\";\nimport { assert } from \"./Debug\";\nimport { EQ, GT, GTE, LT } from \"./Math\";\n/**\n * A Timeline class for scheduling and maintaining state\n * along a timeline. All events must have a \"time\" property.\n * Internally, events are stored in time order for fast\n * retrieval.\n */\nexport class Timeline extends Tone {\n    constructor() {\n        super();\n        this.name = \"Timeline\";\n        /**\n         * The array of scheduled timeline events\n         */\n        this._timeline = [];\n        const options = optionsFromArguments(Timeline.getDefaults(), arguments, [\"memory\"]);\n        this.memory = options.memory;\n        this.increasing = options.increasing;\n    }\n    static getDefaults() {\n        return {\n            memory: Infinity,\n            increasing: false,\n        };\n    }\n    /**\n     * The number of items in the timeline.\n     */\n    get length() {\n        return this._timeline.length;\n    }\n    /**\n     * Insert an event object onto the timeline. Events must have a \"time\" attribute.\n     * @param event  The event object to insert into the timeline.\n     */\n    add(event) {\n        // the event needs to have a time attribute\n        assert(Reflect.has(event, \"time\"), \"Timeline: events must have a time attribute\");\n        event.time = event.time.valueOf();\n        if (this.increasing && this.length) {\n            const lastValue = this._timeline[this.length - 1];\n            assert(GTE(event.time, lastValue.time), \"The time must be greater than or equal to the last scheduled time\");\n            this._timeline.push(event);\n        }\n        else {\n            const index = this._search(event.time);\n            this._timeline.splice(index + 1, 0, event);\n        }\n        // if the length is more than the memory, remove the previous ones\n        if (this.length > this.memory) {\n            const diff = this.length - this.memory;\n            this._timeline.splice(0, diff);\n        }\n        return this;\n    }\n    /**\n     * Remove an event from the timeline.\n     * @param  {Object}  event  The event object to remove from the list.\n     * @returns {Timeline} this\n     */\n    remove(event) {\n        const index = this._timeline.indexOf(event);\n        if (index !== -1) {\n            this._timeline.splice(index, 1);\n        }\n        return this;\n    }\n    /**\n     * Get the nearest event whose time is less than or equal to the given time.\n     * @param  time  The time to query.\n     */\n    get(time, param = \"time\") {\n        const index = this._search(time, param);\n        if (index !== -1) {\n            return this._timeline[index];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Return the first event in the timeline without removing it\n     * @returns {Object} The first event object\n     */\n    peek() {\n        return this._timeline[0];\n    }\n    /**\n     * Return the first event in the timeline and remove it\n     */\n    shift() {\n        return this._timeline.shift();\n    }\n    /**\n     * Get the event which is scheduled after the given time.\n     * @param  time  The time to query.\n     */\n    getAfter(time, param = \"time\") {\n        const index = this._search(time, param);\n        if (index + 1 < this._timeline.length) {\n            return this._timeline[index + 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Get the event before the event at the given time.\n     * @param  time  The time to query.\n     */\n    getBefore(time) {\n        const len = this._timeline.length;\n        // if it's after the last item, return the last item\n        if (len > 0 && this._timeline[len - 1].time < time) {\n            return this._timeline[len - 1];\n        }\n        const index = this._search(time);\n        if (index - 1 >= 0) {\n            return this._timeline[index - 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Cancel events at and after the given time\n     * @param  after  The time to query.\n     */\n    cancel(after) {\n        if (this._timeline.length > 1) {\n            let index = this._search(after);\n            if (index >= 0) {\n                if (EQ(this._timeline[index].time, after)) {\n                    // get the first item with that time\n                    for (let i = index; i >= 0; i--) {\n                        if (EQ(this._timeline[i].time, after)) {\n                            index = i;\n                        }\n                        else {\n                            break;\n                        }\n                    }\n                    this._timeline = this._timeline.slice(0, index);\n                }\n                else {\n                    this._timeline = this._timeline.slice(0, index + 1);\n                }\n            }\n            else {\n                this._timeline = [];\n            }\n        }\n        else if (this._timeline.length === 1) {\n            // the first item's time\n            if (GTE(this._timeline[0].time, after)) {\n                this._timeline = [];\n            }\n        }\n        return this;\n    }\n    /**\n     * Cancel events before or equal to the given time.\n     * @param  time  The time to cancel before.\n     */\n    cancelBefore(time) {\n        const index = this._search(time);\n        if (index >= 0) {\n            this._timeline = this._timeline.slice(index + 1);\n        }\n        return this;\n    }\n    /**\n     * Returns the previous event if there is one. null otherwise\n     * @param  event The event to find the previous one of\n     * @return The event right before the given event\n     */\n    previousEvent(event) {\n        const index = this._timeline.indexOf(event);\n        if (index > 0) {\n            return this._timeline[index - 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Does a binary search on the timeline array and returns the\n     * nearest event index whose time is after or equal to the given time.\n     * If a time is searched before the first index in the timeline, -1 is returned.\n     * If the time is after the end, the index of the last item is returned.\n     */\n    _search(time, param = \"time\") {\n        if (this._timeline.length === 0) {\n            return -1;\n        }\n        let beginning = 0;\n        const len = this._timeline.length;\n        let end = len;\n        if (len > 0 && this._timeline[len - 1][param] <= time) {\n            return len - 1;\n        }\n        while (beginning < end) {\n            // calculate the midpoint for roughly equal partition\n            let midPoint = Math.floor(beginning + (end - beginning) / 2);\n            const event = this._timeline[midPoint];\n            const nextEvent = this._timeline[midPoint + 1];\n            if (EQ(event[param], time)) {\n                // choose the last one that has the same time\n                for (let i = midPoint; i < this._timeline.length; i++) {\n                    const testEvent = this._timeline[i];\n                    if (EQ(testEvent[param], time)) {\n                        midPoint = i;\n                    }\n                    else {\n                        break;\n                    }\n                }\n                return midPoint;\n            }\n            else if (LT(event[param], time) && GT(nextEvent[param], time)) {\n                return midPoint;\n            }\n            else if (GT(event[param], time)) {\n                // search lower\n                end = midPoint;\n            }\n            else {\n                // search upper\n                beginning = midPoint + 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Internal iterator. Applies extra safety checks for\n     * removing items from the array.\n     */\n    _iterate(callback, lowerBound = 0, upperBound = this._timeline.length - 1) {\n        this._timeline.slice(lowerBound, upperBound + 1).forEach(callback);\n    }\n    /**\n     * Iterate over everything in the array\n     * @param  callback The callback to invoke with every item\n     */\n    forEach(callback) {\n        this._iterate(callback);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at or before the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachBefore(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const upperBound = this._search(time);\n        if (upperBound !== -1) {\n            this._iterate(callback, 0, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array after the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAfter(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const lowerBound = this._search(time);\n        this._iterate(callback, lowerBound + 1);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array between the startTime and endTime.\n     * The timerange is inclusive of the startTime, but exclusive of the endTime.\n     * range = [startTime, endTime).\n     * @param  startTime The time to check if items are before\n     * @param  endTime The end of the test interval.\n     * @param  callback The callback to invoke with every item\n     */\n    forEachBetween(startTime, endTime, callback) {\n        let lowerBound = this._search(startTime);\n        let upperBound = this._search(endTime);\n        if (lowerBound !== -1 && upperBound !== -1) {\n            if (this._timeline[lowerBound].time !== startTime) {\n                lowerBound += 1;\n            }\n            // exclusive of the end time\n            if (this._timeline[upperBound].time === endTime) {\n                upperBound -= 1;\n            }\n            this._iterate(callback, lowerBound, upperBound);\n        }\n        else if (lowerBound === -1) {\n            this._iterate(callback, 0, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at or after the given time. Similar to\n     * forEachAfter, but includes the item(s) at the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachFrom(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        let lowerBound = this._search(time);\n        // work backwards until the event time is less than time\n        while (lowerBound >= 0 && this._timeline[lowerBound].time >= time) {\n            lowerBound--;\n        }\n        this._iterate(callback, lowerBound + 1);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at the given time\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAtTime(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const upperBound = this._search(time);\n        if (upperBound !== -1 && EQ(this._timeline[upperBound].time, time)) {\n            let lowerBound = upperBound;\n            for (let i = upperBound; i >= 0; i--) {\n                if (EQ(this._timeline[i].time, time)) {\n                    lowerBound = i;\n                }\n                else {\n                    break;\n                }\n            }\n            this._iterate(event => {\n                callback(event);\n            }, lowerBound, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._timeline = [];\n        return this;\n    }\n}\n//# sourceMappingURL=Timeline.js.map","import { Timeline } from \"./Timeline\";\nimport { Tone } from \"../Tone\";\n/**\n * Represents a single value which is gettable and settable in a timed way\n */\nexport class TimelineValue extends Tone {\n    /**\n     * @param initialValue The value to return if there is no scheduled values\n     */\n    constructor(initialValue) {\n        super();\n        this.name = \"TimelineValue\";\n        /**\n         * The timeline which stores the values\n         */\n        this._timeline = new Timeline({ memory: 10 });\n        this._initialValue = initialValue;\n    }\n    /**\n     * Set the value at the given time\n     */\n    set(value, time) {\n        this._timeline.add({\n            value, time\n        });\n        return this;\n    }\n    /**\n     * Get the value at the given time\n     */\n    get(time) {\n        const event = this._timeline.get(time);\n        if (event) {\n            return event.value;\n        }\n        else {\n            return this._initialValue;\n        }\n    }\n}\n//# sourceMappingURL=TimelineValue.js.map","/**\n * Test if the arg is undefined\n */\nexport function isUndef(arg) {\n    return typeof arg === \"undefined\";\n}\n/**\n * Test if the arg is not undefined\n */\nexport function isDefined(arg) {\n    return !isUndef(arg);\n}\n/**\n * Test if the arg is a function\n */\nexport function isFunction(arg) {\n    return typeof arg === \"function\";\n}\n/**\n * Test if the argument is a number.\n */\nexport function isNumber(arg) {\n    return (typeof arg === \"number\");\n}\n/**\n * Test if the given argument is an object literal (i.e. `{}`);\n */\nexport function isObject(arg) {\n    return (Object.prototype.toString.call(arg) === \"[object Object]\" && arg.constructor === Object);\n}\n/**\n * Test if the argument is a boolean.\n */\nexport function isBoolean(arg) {\n    return (typeof arg === \"boolean\");\n}\n/**\n * Test if the argument is an Array\n */\nexport function isArray(arg) {\n    return (Array.isArray(arg));\n}\n/**\n * Test if the argument is a string.\n */\nexport function isString(arg) {\n    return (typeof arg === \"string\");\n}\n/**\n * Test if the argument is in the form of a note in scientific pitch notation.\n * e.g. \"C4\"\n */\nexport function isNote(arg) {\n    return isString(arg) && /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(arg);\n}\n//# sourceMappingURL=TypeCheck.js.map","import { addToWorklet } from \"./WorkletGlobalScope\";\nconst delayLine = /* javascript */ `\n\t/**\n\t * A multichannel buffer for use within an AudioWorkletProcessor as a delay line\n\t */\n\tclass DelayLine {\n\t\t\n\t\tconstructor(size, channels) {\n\t\t\tthis.buffer = [];\n\t\t\tthis.writeHead = []\n\t\t\tthis.size = size;\n\n\t\t\t// create the empty channels\n\t\t\tfor (let i = 0; i < channels; i++) {\n\t\t\t\tthis.buffer[i] = new Float32Array(this.size);\n\t\t\t\tthis.writeHead[i] = 0;\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Push a value onto the end\n\t\t * @param channel number\n\t\t * @param value number\n\t\t */\n\t\tpush(channel, value) {\n\t\t\tthis.writeHead[channel] += 1;\n\t\t\tif (this.writeHead[channel] > this.size) {\n\t\t\t\tthis.writeHead[channel] = 0;\n\t\t\t}\n\t\t\tthis.buffer[channel][this.writeHead[channel]] = value;\n\t\t}\n\n\t\t/**\n\t\t * Get the recorded value of the channel given the delay\n\t\t * @param channel number\n\t\t * @param delay number delay samples\n\t\t */\n\t\tget(channel, delay) {\n\t\t\tlet readHead = this.writeHead[channel] - Math.floor(delay);\n\t\t\tif (readHead < 0) {\n\t\t\t\treadHead += this.size;\n\t\t\t}\n\t\t\treturn this.buffer[channel][readHead];\n\t\t}\n\t}\n`;\naddToWorklet(delayLine);\n//# sourceMappingURL=DelayLine.worklet.js.map","import \"./ToneAudioWorkletProcessor.worklet\";\nimport { addToWorklet } from \"./WorkletGlobalScope\";\nexport const singleIOProcess = /* javascript */ `\n\t/**\n\t * Abstract class for a single input/output processor. \n\t * has a 'generate' function which processes one sample at a time\n\t */\n\tclass SingleIOProcessor extends ToneAudioWorkletProcessor {\n\n\t\tconstructor(options) {\n\t\t\tsuper(Object.assign(options, {\n\t\t\t\tnumberOfInputs: 1,\n\t\t\t\tnumberOfOutputs: 1\n\t\t\t}));\n\t\t\t/**\n\t\t\t * Holds the name of the parameter and a single value of that\n\t\t\t * parameter at the current sample\n\t\t\t * @type { [name: string]: number }\n\t\t\t */\n\t\t\tthis.params = {}\n\t\t}\n\n\t\t/**\n\t\t * Generate an output sample from the input sample and parameters\n\t\t * @abstract\n\t\t * @param input number\n\t\t * @param channel number\n\t\t * @param parameters { [name: string]: number }\n\t\t * @returns number\n\t\t */\n\t\tgenerate(){}\n\n\t\t/**\n\t\t * Update the private params object with the \n\t\t * values of the parameters at the given index\n\t\t * @param parameters { [name: string]: Float32Array },\n\t\t * @param index number\n\t\t */\n\t\tupdateParams(parameters, index) {\n\t\t\tfor (const paramName in parameters) {\n\t\t\t\tconst param = parameters[paramName];\n\t\t\t\tif (param.length > 1) {\n\t\t\t\t\tthis.params[paramName] = parameters[paramName][index];\n\t\t\t\t} else {\n\t\t\t\t\tthis.params[paramName] = parameters[paramName][0];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Process a single frame of the audio\n\t\t * @param inputs Float32Array[][]\n\t\t * @param outputs Float32Array[][]\n\t\t */\n\t\tprocess(inputs, outputs, parameters) {\n\t\t\tconst input = inputs[0];\n\t\t\tconst output = outputs[0];\n\t\t\t// get the parameter values\n\t\t\tconst channelCount = Math.max(input && input.length || 0, output.length);\n\t\t\tfor (let sample = 0; sample < this.blockSize; sample++) {\n\t\t\t\tthis.updateParams(parameters, sample);\n\t\t\t\tfor (let channel = 0; channel < channelCount; channel++) {\n\t\t\t\t\tconst inputSample = input && input.length ? input[channel][sample] : 0;\n\t\t\t\t\toutput[channel][sample] = this.generate(inputSample, channel, this.params);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn !this.disposed;\n\t\t}\n\t};\n`;\naddToWorklet(singleIOProcess);\n//# sourceMappingURL=SingleIOProcessor.worklet.js.map","import { ToneAudioNode } from \"../context/ToneAudioNode\";\nimport { noOp } from \"../util/Interface\";\nimport { getWorkletGlobalScope } from \"./WorkletGlobalScope\";\nexport class ToneAudioWorklet extends ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"ToneAudioWorklet\";\n        /**\n         * The constructor options for the node\n         */\n        this.workletOptions = {};\n        /**\n         * Callback which is invoked when there is an error in the processing\n         */\n        this.onprocessorerror = noOp;\n        const blobUrl = URL.createObjectURL(new Blob([getWorkletGlobalScope()], { type: \"text/javascript\" }));\n        const name = this._audioWorkletName();\n        this._dummyGain = this.context.createGain();\n        this._dummyParam = this._dummyGain.gain;\n        // Register the processor\n        this.context.addAudioWorkletModule(blobUrl, name).then(() => {\n            // create the worklet when it's read\n            if (!this.disposed) {\n                this._worklet = this.context.createAudioWorkletNode(name, this.workletOptions);\n                this._worklet.onprocessorerror = this.onprocessorerror.bind(this);\n                this.onReady(this._worklet);\n            }\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._dummyGain.disconnect();\n        if (this._worklet) {\n            this._worklet.port.postMessage(\"dispose\");\n            this._worklet.disconnect();\n        }\n        return this;\n    }\n}\n//# sourceMappingURL=ToneAudioWorklet.js.map","import { addToWorklet } from \"./WorkletGlobalScope\";\nconst toneAudioWorkletProcessor = /* javascript */ `\n\t/**\n\t * The base AudioWorkletProcessor for use in Tone.js. Works with the [[ToneAudioWorklet]]. \n\t */\n\tclass ToneAudioWorkletProcessor extends AudioWorkletProcessor {\n\n\t\tconstructor(options) {\n\t\t\t\n\t\t\tsuper(options);\n\t\t\t/**\n\t\t\t * If the processor was disposed or not. Keep alive until it's disposed.\n\t\t\t */\n\t\t\tthis.disposed = false;\n\t\t   \t/** \n\t\t\t * The number of samples in the processing block\n\t\t\t */\n\t\t\tthis.blockSize = 128;\n\t\t\t/**\n\t\t\t * the sample rate\n\t\t\t */\n\t\t\tthis.sampleRate = sampleRate;\n\n\t\t\tthis.port.onmessage = (event) => {\n\t\t\t\t// when it receives a dispose \n\t\t\t\tif (event.data === \"dispose\") {\n\t\t\t\t\tthis.disposed = true;\n\t\t\t\t}\n\t\t\t};\n\t\t}\n\t}\n`;\naddToWorklet(toneAudioWorkletProcessor);\n//# sourceMappingURL=ToneAudioWorkletProcessor.worklet.js.map","/**\n * All of the classes or functions which are loaded into the AudioWorkletGlobalScope\n */\nconst workletContext = new Set();\n/**\n * Add a class to the AudioWorkletGlobalScope\n */\nexport function addToWorklet(classOrFunction) {\n    workletContext.add(classOrFunction);\n}\n/**\n * Register a processor in the AudioWorkletGlobalScope with the given name\n */\nexport function registerProcessor(name, classDesc) {\n    const processor = /* javascript */ `registerProcessor(\"${name}\", ${classDesc})`;\n    workletContext.add(processor);\n}\n/**\n * Get all of the modules which have been registered to the AudioWorkletGlobalScope\n */\nexport function getWorkletGlobalScope() {\n    return Array.from(workletContext).join(\"\\n\");\n}\n//# sourceMappingURL=WorkletGlobalScope.js.map","import { Filter } from \"../component/filter/Filter\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { LFOEffect } from \"./LFOEffect\";\n/**\n * AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.\n * Setting the LFO rate and depth allows for control over the filter modulation rate\n * and depth.\n *\n * @example\n * // create an autofilter and start it's LFO\n * const autoFilter = new Tone.AutoFilter(\"4n\").toDestination().start();\n * // route an oscillator through the filter and start it\n * const oscillator = new Tone.Oscillator().connect(autoFilter).start();\n * @category Effect\n */\nexport class AutoFilter extends LFOEffect {\n    constructor() {\n        super(optionsFromArguments(AutoFilter.getDefaults(), arguments, [\"frequency\", \"baseFrequency\", \"octaves\"]));\n        this.name = \"AutoFilter\";\n        const options = optionsFromArguments(AutoFilter.getDefaults(), arguments, [\"frequency\", \"baseFrequency\", \"octaves\"]);\n        this.filter = new Filter(Object.assign(options.filter, {\n            context: this.context,\n        }));\n        // connections\n        this.connectEffect(this.filter);\n        this._lfo.connect(this.filter.frequency);\n        this.octaves = options.octaves;\n        this.baseFrequency = options.baseFrequency;\n    }\n    static getDefaults() {\n        return Object.assign(LFOEffect.getDefaults(), {\n            baseFrequency: 200,\n            octaves: 2.6,\n            filter: {\n                type: \"lowpass\",\n                rolloff: -12,\n                Q: 1,\n            }\n        });\n    }\n    /**\n     * The minimum value of the filter's cutoff frequency.\n     */\n    get baseFrequency() {\n        return this._lfo.min;\n    }\n    set baseFrequency(freq) {\n        this._lfo.min = this.toFrequency(freq);\n        // and set the max\n        this.octaves = this._octaves;\n    }\n    /**\n     * The maximum value of the filter's cutoff frequency.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(oct) {\n        this._octaves = oct;\n        this._lfo.max = this._lfo.min * Math.pow(2, oct);\n    }\n    dispose() {\n        super.dispose();\n        this.filter.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoFilter.js.map","import { Panner } from \"../component/channel/Panner\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { LFOEffect } from \"./LFOEffect\";\n/**\n * AutoPanner is a [[Panner]] with an [[LFO]] connected to the pan amount.\n * [Related Reading](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).\n *\n * @example\n * // create an autopanner and start it\n * const autoPanner = new Tone.AutoPanner(\"4n\").toDestination().start();\n * // route an oscillator through the panner and start it\n * const oscillator = new Tone.Oscillator().connect(autoPanner).start();\n * @category Effect\n */\nexport class AutoPanner extends LFOEffect {\n    constructor() {\n        super(optionsFromArguments(AutoPanner.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"AutoPanner\";\n        const options = optionsFromArguments(AutoPanner.getDefaults(), arguments, [\"frequency\"]);\n        this._panner = new Panner({\n            context: this.context,\n            channelCount: options.channelCount\n        });\n        // connections\n        this.connectEffect(this._panner);\n        this._lfo.connect(this._panner.pan);\n        this._lfo.min = -1;\n        this._lfo.max = 1;\n    }\n    static getDefaults() {\n        return Object.assign(LFOEffect.getDefaults(), {\n            channelCount: 1\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._panner.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoPanner.js.map","import { Effect } from \"./Effect\";\nimport { Filter } from \"../component/filter/Filter\";\nimport { Follower } from \"../component/analysis/Follower\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Gain } from \"../core/context/Gain\";\nimport { dbToGain, gainToDb } from \"../core/type/Conversions\";\nimport { ScaleExp } from \"../signal/ScaleExp\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * AutoWah connects a [[Follower]] to a [[Filter]].\n * The frequency of the filter, follows the input amplitude curve.\n * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).\n *\n * @example\n * const autoWah = new Tone.AutoWah(50, 6, -30).toDestination();\n * // initialize the synth and connect to autowah\n * const synth = new Tone.Synth().connect(autoWah);\n * // Q value influences the effect of the wah - default is 2\n * autoWah.Q.value = 6;\n * // more audible on higher notes\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Effect\n */\nexport class AutoWah extends Effect {\n    constructor() {\n        super(optionsFromArguments(AutoWah.getDefaults(), arguments, [\"baseFrequency\", \"octaves\", \"sensitivity\"]));\n        this.name = \"AutoWah\";\n        const options = optionsFromArguments(AutoWah.getDefaults(), arguments, [\"baseFrequency\", \"octaves\", \"sensitivity\"]);\n        this._follower = new Follower({\n            context: this.context,\n            smoothing: options.follower,\n        });\n        this._sweepRange = new ScaleExp({\n            context: this.context,\n            min: 0,\n            max: 1,\n            exponent: 0.5,\n        });\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._octaves = options.octaves;\n        this._inputBoost = new Gain({ context: this.context });\n        this._bandpass = new Filter({\n            context: this.context,\n            rolloff: -48,\n            frequency: 0,\n            Q: options.Q,\n        });\n        this._peaking = new Filter({\n            context: this.context,\n            type: \"peaking\"\n        });\n        this._peaking.gain.value = options.gain;\n        this.gain = this._peaking.gain;\n        this.Q = this._bandpass.Q;\n        // the control signal path\n        this.effectSend.chain(this._inputBoost, this._follower, this._sweepRange);\n        this._sweepRange.connect(this._bandpass.frequency);\n        this._sweepRange.connect(this._peaking.frequency);\n        // the filtered path\n        this.effectSend.chain(this._bandpass, this._peaking, this.effectReturn);\n        // set the initial value\n        this._setSweepRange();\n        this.sensitivity = options.sensitivity;\n        readOnly(this, [\"gain\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            baseFrequency: 100,\n            octaves: 6,\n            sensitivity: 0,\n            Q: 2,\n            gain: 2,\n            follower: 0.2,\n        });\n    }\n    /**\n     * The number of octaves that the filter will sweep above the baseFrequency.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        this._octaves = octaves;\n        this._setSweepRange();\n    }\n    /**\n     * The follower's smoothing time\n     */\n    get follower() {\n        return this._follower.smoothing;\n    }\n    set follower(follower) {\n        this._follower.smoothing = follower;\n    }\n    /**\n     * The base frequency from which the sweep will start from.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(baseFreq) {\n        this._baseFrequency = this.toFrequency(baseFreq);\n        this._setSweepRange();\n    }\n    /**\n     * The sensitivity to control how responsive to the input signal the filter is.\n     */\n    get sensitivity() {\n        return gainToDb(1 / this._inputBoost.gain.value);\n    }\n    set sensitivity(sensitivity) {\n        this._inputBoost.gain.value = 1 / dbToGain(sensitivity);\n    }\n    /**\n     * sets the sweep range of the scaler\n     */\n    _setSweepRange() {\n        this._sweepRange.min = this._baseFrequency;\n        this._sweepRange.max = Math.min(this._baseFrequency * Math.pow(2, this._octaves), this.context.sampleRate / 2);\n    }\n    dispose() {\n        super.dispose();\n        this._follower.dispose();\n        this._sweepRange.dispose();\n        this._bandpass.dispose();\n        this._peaking.dispose();\n        this._inputBoost.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoWah.js.map","import { ToneAudioWorklet } from \"../core/worklet/ToneAudioWorklet\";\nimport { Effect } from \"./Effect\";\nimport { Gain } from \"../core/context/Gain\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { connectSeries } from \"../core/context/ToneAudioNode\";\nimport { Param } from \"../core/context/Param\";\nimport { workletName } from \"./BitCrusher.worklet\";\n/**\n * BitCrusher down-samples the incoming signal to a different bit depth.\n * Lowering the bit depth of the signal creates distortion. Read more about BitCrushing\n * on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).\n * @example\n * // initialize crusher and route a synth through it\n * const crusher = new Tone.BitCrusher(4).toDestination();\n * const synth = new Tone.Synth().connect(crusher);\n * synth.triggerAttackRelease(\"C2\", 2);\n *\n * @category Effect\n */\nexport class BitCrusher extends Effect {\n    constructor() {\n        super(optionsFromArguments(BitCrusher.getDefaults(), arguments, [\"bits\"]));\n        this.name = \"BitCrusher\";\n        const options = optionsFromArguments(BitCrusher.getDefaults(), arguments, [\"bits\"]);\n        this._bitCrusherWorklet = new BitCrusherWorklet({\n            context: this.context,\n            bits: options.bits,\n        });\n        // connect it up\n        this.connectEffect(this._bitCrusherWorklet);\n        this.bits = this._bitCrusherWorklet.bits;\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            bits: 4,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._bitCrusherWorklet.dispose();\n        return this;\n    }\n}\n/**\n * Internal class which creates an AudioWorklet to do the bit crushing\n */\nclass BitCrusherWorklet extends ToneAudioWorklet {\n    constructor() {\n        super(optionsFromArguments(BitCrusherWorklet.getDefaults(), arguments));\n        this.name = \"BitCrusherWorklet\";\n        const options = optionsFromArguments(BitCrusherWorklet.getDefaults(), arguments);\n        this.input = new Gain({ context: this.context });\n        this.output = new Gain({ context: this.context });\n        this.bits = new Param({\n            context: this.context,\n            value: options.bits,\n            units: \"positive\",\n            minValue: 1,\n            maxValue: 16,\n            param: this._dummyParam,\n            swappable: true,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioWorklet.getDefaults(), {\n            bits: 12,\n        });\n    }\n    _audioWorkletName() {\n        return workletName;\n    }\n    onReady(node) {\n        connectSeries(this.input, node, this.output);\n        const bits = node.parameters.get(\"bits\");\n        this.bits.setParam(bits);\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.bits.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=BitCrusher.js.map","import \"../core/worklet/SingleIOProcessor.worklet\";\nimport { registerProcessor } from \"../core/worklet/WorkletGlobalScope\";\nexport const workletName = \"bit-crusher\";\nexport const bitCrusherWorklet = /* javascript */ `\n\tclass BitCrusherWorklet extends SingleIOProcessor {\n\n\t\tstatic get parameterDescriptors() {\n\t\t\treturn [{\n\t\t\t\tname: \"bits\",\n\t\t\t\tdefaultValue: 12,\n\t\t\t\tminValue: 1,\n\t\t\t\tmaxValue: 16\n\t\t\t}];\n\t\t}\n\n\t\tgenerate(input, _channel, parameters) {\n\t\t\tconst step = Math.pow(0.5, parameters.bits - 1);\n\t\t\tconst val = step * Math.floor(input / step + 0.5);\n\t\t\treturn val;\n\t\t}\n\t}\n`;\nregisterProcessor(workletName, bitCrusherWorklet);\n//# sourceMappingURL=BitCrusher.worklet.js.map","import { Effect } from \"./Effect\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { WaveShaper } from \"../signal/WaveShaper\";\n/**\n * Chebyshev is a waveshaper which is good\n * for making different types of distortion sounds.\n * Note that odd orders sound very different from even ones,\n * and order = 1 is no change.\n * Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).\n * @example\n * // create a new cheby\n * const cheby = new Tone.Chebyshev(50).toDestination();\n * // create a monosynth connected to our cheby\n * const synth = new Tone.MonoSynth().connect(cheby);\n * synth.triggerAttackRelease(\"C2\", 0.4);\n * @category Effect\n */\nexport class Chebyshev extends Effect {\n    constructor() {\n        super(optionsFromArguments(Chebyshev.getDefaults(), arguments, [\"order\"]));\n        this.name = \"Chebyshev\";\n        const options = optionsFromArguments(Chebyshev.getDefaults(), arguments, [\"order\"]);\n        this._shaper = new WaveShaper({\n            context: this.context,\n            length: 4096\n        });\n        this._order = options.order;\n        this.connectEffect(this._shaper);\n        this.order = options.order;\n        this.oversample = options.oversample;\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            order: 1,\n            oversample: \"none\"\n        });\n    }\n    /**\n     * get the coefficient for that degree\n     * @param  x the x value\n     * @param  degree\n     * @param  memo memoize the computed value. this speeds up computation greatly.\n     */\n    _getCoefficient(x, degree, memo) {\n        if (memo.has(degree)) {\n            return memo.get(degree);\n        }\n        else if (degree === 0) {\n            memo.set(degree, 0);\n        }\n        else if (degree === 1) {\n            memo.set(degree, x);\n        }\n        else {\n            memo.set(degree, 2 * x * this._getCoefficient(x, degree - 1, memo) - this._getCoefficient(x, degree - 2, memo));\n        }\n        return memo.get(degree);\n    }\n    /**\n     * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming\n     * signal through a Tone.WaveShaper. The equations are in the form:\n     * ```\n     * order 2: 2x^2 + 1\n     * order 3: 4x^3 + 3x\n     * ```\n     * @min 1\n     * @max 100\n     */\n    get order() {\n        return this._order;\n    }\n    set order(order) {\n        this._order = order;\n        this._shaper.setMap((x => {\n            return this._getCoefficient(x, order, new Map());\n        }));\n    }\n    /**\n     * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        this._shaper.oversample = oversampling;\n    }\n    dispose() {\n        super.dispose();\n        this._shaper.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Chebyshev.js.map","import { StereoFeedbackEffect } from \"../effect/StereoFeedbackEffect\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { LFO } from \"../source/oscillator/LFO\";\nimport { Delay } from \"../core/context/Delay\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Chorus is a stereo chorus effect composed of a left and right delay with an [[LFO]] applied to the delayTime of each channel.\n * When [[feedback]] is set to a value larger than 0, you also get Flanger-type effects.\n * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).\n * Read more on the chorus effect on [SoundOnSound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).\n *\n * @example\n * const chorus = new Tone.Chorus(4, 2.5, 0.5);\n * const synth = new Tone.PolySynth().connect(chorus);\n * synth.triggerAttackRelease([\"C3\", \"E3\", \"G3\"], \"8n\");\n *\n * @category Effect\n */\nexport class Chorus extends StereoFeedbackEffect {\n    constructor() {\n        super(optionsFromArguments(Chorus.getDefaults(), arguments, [\"frequency\", \"delayTime\", \"depth\"]));\n        this.name = \"Chorus\";\n        const options = optionsFromArguments(Chorus.getDefaults(), arguments, [\"frequency\", \"delayTime\", \"depth\"]);\n        this._depth = options.depth;\n        this._delayTime = options.delayTime / 1000;\n        this._lfoL = new LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n        });\n        this._lfoR = new LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n            phase: 180\n        });\n        this._delayNodeL = new Delay({ context: this.context });\n        this._delayNodeR = new Delay({ context: this.context });\n        this.frequency = this._lfoL.frequency;\n        readOnly(this, [\"frequency\"]);\n        // have one LFO frequency control the other\n        this._lfoL.frequency.connect(this._lfoR.frequency);\n        // connections\n        this.connectEffectLeft(this._delayNodeL);\n        this.connectEffectRight(this._delayNodeR);\n        // lfo setup\n        this._lfoL.connect(this._delayNodeL.delayTime);\n        this._lfoR.connect(this._delayNodeR.delayTime);\n        // set the initial values\n        this.depth = this._depth;\n        this.type = options.type;\n        this.spread = options.spread;\n    }\n    static getDefaults() {\n        return Object.assign(StereoFeedbackEffect.getDefaults(), {\n            frequency: 1.5,\n            delayTime: 3.5,\n            depth: 0.7,\n            type: \"sine\",\n            spread: 180,\n            feedback: 0,\n            wet: 0.5,\n        });\n    }\n    /**\n     * The depth of the effect. A depth of 1 makes the delayTime\n     * modulate between 0 and 2*delayTime (centered around the delayTime).\n     */\n    get depth() {\n        return this._depth;\n    }\n    set depth(depth) {\n        this._depth = depth;\n        const deviation = this._delayTime * depth;\n        this._lfoL.min = Math.max(this._delayTime - deviation, 0);\n        this._lfoL.max = this._delayTime + deviation;\n        this._lfoR.min = Math.max(this._delayTime - deviation, 0);\n        this._lfoR.max = this._delayTime + deviation;\n    }\n    /**\n     * The delayTime in milliseconds of the chorus. A larger delayTime\n     * will give a more pronounced effect. Nominal range a delayTime\n     * is between 2 and 20ms.\n     */\n    get delayTime() {\n        return this._delayTime * 1000;\n    }\n    set delayTime(delayTime) {\n        this._delayTime = delayTime / 1000;\n        this.depth = this._depth;\n    }\n    /**\n     * The oscillator type of the LFO.\n     */\n    get type() {\n        return this._lfoL.type;\n    }\n    set type(type) {\n        this._lfoL.type = type;\n        this._lfoR.type = type;\n    }\n    /**\n     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n     * When set to 180, LFO's will be panned hard left and right respectively.\n     */\n    get spread() {\n        return this._lfoR.phase - this._lfoL.phase;\n    }\n    set spread(spread) {\n        this._lfoL.phase = 90 - (spread / 2);\n        this._lfoR.phase = (spread / 2) + 90;\n    }\n    /**\n     * Start the effect.\n     */\n    start(time) {\n        this._lfoL.start(time);\n        this._lfoR.start(time);\n        return this;\n    }\n    /**\n     * Stop the lfo\n     */\n    stop(time) {\n        this._lfoL.stop(time);\n        this._lfoR.stop(time);\n        return this;\n    }\n    /**\n     * Sync the filter to the transport. See [[LFO.sync]]\n     */\n    sync() {\n        this._lfoL.sync();\n        this._lfoR.sync();\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport.\n     */\n    unsync() {\n        this._lfoL.unsync();\n        this._lfoR.unsync();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._delayNodeL.dispose();\n        this._delayNodeR.dispose();\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Chorus.js.map","import { optionsFromArguments } from \"../core/util/Defaults\";\nimport { WaveShaper } from \"../signal/WaveShaper\";\nimport { Effect } from \"./Effect\";\n/**\n * A simple distortion effect using Tone.WaveShaper.\n * Algorithm from [this stackoverflow answer](http://stackoverflow.com/a/22313408).\n *\n * @example\n * const dist = new Tone.Distortion(0.8).toDestination();\n * const fm = new Tone.FMSynth().connect(dist);\n * fm.triggerAttackRelease(\"A1\", \"8n\");\n * @category Effect\n */\nexport class Distortion extends Effect {\n    constructor() {\n        super(optionsFromArguments(Distortion.getDefaults(), arguments, [\"distortion\"]));\n        this.name = \"Distortion\";\n        const options = optionsFromArguments(Distortion.getDefaults(), arguments, [\"distortion\"]);\n        this._shaper = new WaveShaper({\n            context: this.context,\n            length: 4096,\n        });\n        this._distortion = options.distortion;\n        this.connectEffect(this._shaper);\n        this.distortion = options.distortion;\n        this.oversample = options.oversample;\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            distortion: 0.4,\n            oversample: \"none\",\n        });\n    }\n    /**\n     * The amount of distortion. Nominal range is between 0 and 1.\n     */\n    get distortion() {\n        return this._distortion;\n    }\n    set distortion(amount) {\n        this._distortion = amount;\n        const k = amount * 100;\n        const deg = Math.PI / 180;\n        this._shaper.setMap((x) => {\n            if (Math.abs(x) < 0.001) {\n                // should output 0 when input is 0\n                return 0;\n            }\n            else {\n                return (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));\n            }\n        });\n    }\n    /**\n     * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        this._shaper.oversample = oversampling;\n    }\n    dispose() {\n        super.dispose();\n        this._shaper.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Distortion.js.map","import { CrossFade } from \"../component/channel/CrossFade\";\nimport { Gain } from \"../core/context/Gain\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Effect is the base class for effects. Connect the effect between\n * the effectSend and effectReturn GainNodes, then control the amount of\n * effect which goes to the output using the wet control.\n */\nexport class Effect extends ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"Effect\";\n        /**\n         * the drywet knob to control the amount of effect\n         */\n        this._dryWet = new CrossFade({ context: this.context });\n        /**\n         * The wet control is how much of the effected\n         * will pass through to the output. 1 = 100% effected\n         * signal, 0 = 100% dry signal.\n         */\n        this.wet = this._dryWet.fade;\n        /**\n         * connect the effectSend to the input of hte effect\n         */\n        this.effectSend = new Gain({ context: this.context });\n        /**\n         * connect the output of the effect to the effectReturn\n         */\n        this.effectReturn = new Gain({ context: this.context });\n        /**\n         * The effect input node\n         */\n        this.input = new Gain({ context: this.context });\n        /**\n         * The effect output\n         */\n        this.output = this._dryWet;\n        // connections\n        this.input.fan(this._dryWet.a, this.effectSend);\n        this.effectReturn.connect(this._dryWet.b);\n        this.wet.setValueAtTime(options.wet, 0);\n        this._internalChannels = [this.effectReturn, this.effectSend];\n        readOnly(this, \"wet\");\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            wet: 1,\n        });\n    }\n    /**\n     * chains the effect in between the effectSend and effectReturn\n     */\n    connectEffect(effect) {\n        // add it to the internal channels\n        this._internalChannels.push(effect);\n        this.effectSend.chain(effect, this.effectReturn);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._dryWet.dispose();\n        this.effectSend.dispose();\n        this.effectReturn.dispose();\n        this.wet.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Effect.js.map","import { Delay } from \"../core/context/Delay\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { FeedbackEffect } from \"./FeedbackEffect\";\n/**\n * FeedbackDelay is a DelayNode in which part of output signal is fed back into the delay.\n *\n * @param delayTime The delay applied to the incoming signal.\n * @param feedback The amount of the effected signal which is fed back through the delay.\n * @example\n * const feedbackDelay = new Tone.FeedbackDelay(\"8n\", 0.5).toDestination();\n * const tom = new Tone.MembraneSynth({\n * \toctaves: 4,\n * \tpitchDecay: 0.1\n * }).connect(feedbackDelay);\n * tom.triggerAttackRelease(\"A2\", \"32n\");\n * @category Effect\n */\nexport class FeedbackDelay extends FeedbackEffect {\n    constructor() {\n        super(optionsFromArguments(FeedbackDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]));\n        this.name = \"FeedbackDelay\";\n        const options = optionsFromArguments(FeedbackDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]);\n        this._delayNode = new Delay({\n            context: this.context,\n            delayTime: options.delayTime,\n            maxDelay: options.maxDelay,\n        });\n        this.delayTime = this._delayNode.delayTime;\n        // connect it up\n        this.connectEffect(this._delayNode);\n        readOnly(this, \"delayTime\");\n    }\n    static getDefaults() {\n        return Object.assign(FeedbackEffect.getDefaults(), {\n            delayTime: 0.25,\n            maxDelay: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._delayNode.dispose();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackDelay.js.map","import { Gain } from \"../core/context/Gain\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { Effect } from \"./Effect\";\n/**\n * FeedbackEffect provides a loop between an audio source and its own output.\n * This is a base-class for feedback effects.\n */\nexport class FeedbackEffect extends Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"FeedbackEffect\";\n        this._feedbackGain = new Gain({\n            context: this.context,\n            gain: options.feedback,\n            units: \"normalRange\",\n        });\n        this.feedback = this._feedbackGain.gain;\n        readOnly(this, \"feedback\");\n        // the feedback loop\n        this.effectReturn.chain(this._feedbackGain, this.effectSend);\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            feedback: 0.125,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._feedbackGain.dispose();\n        this.feedback.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackEffect.js.map","import { StereoEffect } from \"./StereoEffect\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { Signal } from \"../signal/Signal\";\nimport { LowpassCombFilter } from \"../component/filter/LowpassCombFilter\";\n/**\n * An array of comb filter delay values from Freeverb implementation\n */\nconst combFilterTunings = [1557 / 44100, 1617 / 44100, 1491 / 44100, 1422 / 44100, 1277 / 44100, 1356 / 44100, 1188 / 44100, 1116 / 44100];\n/**\n * An array of allpass filter frequency values from Freeverb implementation\n */\nconst allpassFilterFrequencies = [225, 556, 441, 341];\n/**\n * Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).\n * Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).\n * Freeverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms\n * @example\n * const freeverb = new Tone.Freeverb().toDestination();\n * freeverb.dampening = 1000;\n * // routing synth through the reverb\n * const synth = new Tone.NoiseSynth().connect(freeverb);\n * synth.triggerAttackRelease(0.05);\n * @category Effect\n */\nexport class Freeverb extends StereoEffect {\n    constructor() {\n        super(optionsFromArguments(Freeverb.getDefaults(), arguments, [\"roomSize\", \"dampening\"]));\n        this.name = \"Freeverb\";\n        /**\n         * the comb filters\n         */\n        this._combFilters = [];\n        /**\n         * the allpass filters on the left\n         */\n        this._allpassFiltersL = [];\n        /**\n         * the allpass filters on the right\n         */\n        this._allpassFiltersR = [];\n        const options = optionsFromArguments(Freeverb.getDefaults(), arguments, [\"roomSize\", \"dampening\"]);\n        this.roomSize = new Signal({\n            context: this.context,\n            value: options.roomSize,\n            units: \"normalRange\",\n        });\n        // make the allpass filters on the right\n        this._allpassFiltersL = allpassFilterFrequencies.map(freq => {\n            const allpassL = this.context.createBiquadFilter();\n            allpassL.type = \"allpass\";\n            allpassL.frequency.value = freq;\n            return allpassL;\n        });\n        // make the allpass filters on the left\n        this._allpassFiltersR = allpassFilterFrequencies.map(freq => {\n            const allpassR = this.context.createBiquadFilter();\n            allpassR.type = \"allpass\";\n            allpassR.frequency.value = freq;\n            return allpassR;\n        });\n        // make the comb filters\n        this._combFilters = combFilterTunings.map((delayTime, index) => {\n            const lfpf = new LowpassCombFilter({\n                context: this.context,\n                dampening: options.dampening,\n                delayTime,\n            });\n            if (index < combFilterTunings.length / 2) {\n                this.connectEffectLeft(lfpf, ...this._allpassFiltersL);\n            }\n            else {\n                this.connectEffectRight(lfpf, ...this._allpassFiltersR);\n            }\n            this.roomSize.connect(lfpf.resonance);\n            return lfpf;\n        });\n        readOnly(this, [\"roomSize\"]);\n    }\n    static getDefaults() {\n        return Object.assign(StereoEffect.getDefaults(), {\n            roomSize: 0.7,\n            dampening: 3000\n        });\n    }\n    /**\n     * The amount of dampening of the reverberant signal.\n     */\n    get dampening() {\n        return this._combFilters[0].dampening;\n    }\n    set dampening(d) {\n        this._combFilters.forEach(c => c.dampening = d);\n    }\n    dispose() {\n        super.dispose();\n        this._allpassFiltersL.forEach(al => al.disconnect());\n        this._allpassFiltersR.forEach(ar => ar.disconnect());\n        this._combFilters.forEach(cf => cf.dispose());\n        this.roomSize.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Freeverb.js.map","import { PhaseShiftAllpass } from \"../component/filter/PhaseShiftAllpass\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Effect } from \"../effect/Effect\";\nimport { Add } from \"../signal/Add\";\nimport { Multiply } from \"../signal/Multiply\";\nimport { Negate } from \"../signal/Negate\";\nimport { Signal } from \"../signal/Signal\";\nimport { Oscillator } from \"../source/oscillator/Oscillator\";\nimport { ToneOscillatorNode } from \"../source/oscillator/ToneOscillatorNode\";\n/**\n * FrequencyShifter can be used to shift all frequencies of a signal by a fixed amount.\n * The amount can be changed at audio rate and the effect is applied in real time.\n * The frequency shifting is implemented with a technique called single side band modulation using a ring modulator.\n * Note: Contrary to pitch shifting, all frequencies are shifted by the same amount,\n * destroying the harmonic relationship between them. This leads to the classic ring modulator timbre distortion.\n * The algorithm will produces some aliasing towards the high end, especially if your source material\n * contains a lot of high frequencies. Unfortunatelly the webaudio API does not support resampling\n * buffers in real time, so it is not possible to fix it properly. Depending on the use case it might\n * be an option to low pass filter your input before frequency shifting it to get ride of the aliasing.\n * You can find a very detailed description of the algorithm here: https://larzeitlin.github.io/RMFS/\n *\n * @example\n * const input = new Tone.Oscillator(230, \"sawtooth\").start();\n * const shift = new Tone.FrequencyShifter(42).toDestination();\n * input.connect(shift);\n * @category Effect\n */\nexport class FrequencyShifter extends Effect {\n    constructor() {\n        super(optionsFromArguments(FrequencyShifter.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"FrequencyShifter\";\n        const options = optionsFromArguments(FrequencyShifter.getDefaults(), arguments, [\"frequency\"]);\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n            minValue: -this.context.sampleRate / 2,\n            maxValue: this.context.sampleRate / 2,\n        });\n        this._sine = new ToneOscillatorNode({\n            context: this.context,\n            type: \"sine\",\n        });\n        this._cosine = new Oscillator({\n            context: this.context,\n            phase: -90,\n            type: \"sine\",\n        });\n        this._sineMultiply = new Multiply({ context: this.context });\n        this._cosineMultiply = new Multiply({ context: this.context });\n        this._negate = new Negate({ context: this.context });\n        this._add = new Add({ context: this.context });\n        this._phaseShifter = new PhaseShiftAllpass({ context: this.context });\n        this.effectSend.connect(this._phaseShifter);\n        // connect the carrier frequency signal to the two oscillators\n        this.frequency.fan(this._sine.frequency, this._cosine.frequency);\n        this._phaseShifter.offset90.connect(this._cosineMultiply);\n        this._cosine.connect(this._cosineMultiply.factor);\n        this._phaseShifter.connect(this._sineMultiply);\n        this._sine.connect(this._sineMultiply.factor);\n        this._sineMultiply.connect(this._negate);\n        this._cosineMultiply.connect(this._add);\n        this._negate.connect(this._add.addend);\n        this._add.connect(this.effectReturn);\n        // start the oscillators at the same time\n        const now = this.immediate();\n        this._sine.start(now);\n        this._cosine.start(now);\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            frequency: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this._add.dispose();\n        this._cosine.dispose();\n        this._cosineMultiply.dispose();\n        this._negate.dispose();\n        this._phaseShifter.dispose();\n        this._sine.dispose();\n        this._sineMultiply.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FrequencyShifter.js.map","import { StereoEffect } from \"./StereoEffect\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Scale } from \"../signal/Scale\";\nimport { Signal } from \"../signal/Signal\";\nimport { FeedbackCombFilter } from \"../component/filter/FeedbackCombFilter\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * an array of the comb filter delay time values\n */\nconst combFilterDelayTimes = [1687 / 25000, 1601 / 25000, 2053 / 25000, 2251 / 25000];\n/**\n * the resonances of each of the comb filters\n */\nconst combFilterResonances = [0.773, 0.802, 0.753, 0.733];\n/**\n * the allpass filter frequencies\n */\nconst allpassFilterFreqs = [347, 113, 37];\n/**\n * JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)\n * tuned by John Chowning in 1970.\n * It is made up of three allpass filters and four [[FeedbackCombFilter]].\n * JCReverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms\n *\n * @example\n * const reverb = new Tone.JCReverb(0.4).toDestination();\n * const delay = new Tone.FeedbackDelay(0.5);\n * // connecting the synth to reverb through delay\n * const synth = new Tone.DuoSynth().chain(delay, reverb);\n * synth.triggerAttackRelease(\"A4\", \"8n\");\n *\n * @category Effect\n */\nexport class JCReverb extends StereoEffect {\n    constructor() {\n        super(optionsFromArguments(JCReverb.getDefaults(), arguments, [\"roomSize\"]));\n        this.name = \"JCReverb\";\n        /**\n         * a series of allpass filters\n         */\n        this._allpassFilters = [];\n        /**\n         * parallel feedback comb filters\n         */\n        this._feedbackCombFilters = [];\n        const options = optionsFromArguments(JCReverb.getDefaults(), arguments, [\"roomSize\"]);\n        this.roomSize = new Signal({\n            context: this.context,\n            value: options.roomSize,\n            units: \"normalRange\",\n        });\n        this._scaleRoomSize = new Scale({\n            context: this.context,\n            min: -0.733,\n            max: 0.197,\n        });\n        // make the allpass filters\n        this._allpassFilters = allpassFilterFreqs.map(freq => {\n            const allpass = this.context.createBiquadFilter();\n            allpass.type = \"allpass\";\n            allpass.frequency.value = freq;\n            return allpass;\n        });\n        // and the comb filters\n        this._feedbackCombFilters = combFilterDelayTimes.map((delayTime, index) => {\n            const fbcf = new FeedbackCombFilter({\n                context: this.context,\n                delayTime,\n            });\n            this._scaleRoomSize.connect(fbcf.resonance);\n            fbcf.resonance.value = combFilterResonances[index];\n            if (index < combFilterDelayTimes.length / 2) {\n                this.connectEffectLeft(...this._allpassFilters, fbcf);\n            }\n            else {\n                this.connectEffectRight(...this._allpassFilters, fbcf);\n            }\n            return fbcf;\n        });\n        // chain the allpass filters together\n        this.roomSize.connect(this._scaleRoomSize);\n        readOnly(this, [\"roomSize\"]);\n    }\n    static getDefaults() {\n        return Object.assign(StereoEffect.getDefaults(), {\n            roomSize: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._allpassFilters.forEach(apf => apf.disconnect());\n        this._feedbackCombFilters.forEach(fbcf => fbcf.dispose());\n        this.roomSize.dispose();\n        this._scaleRoomSize.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=JCReverb.js.map","import { Effect } from \"../effect/Effect\";\nimport { LFO } from \"../source/oscillator/LFO\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Base class for LFO-based effects.\n */\nexport class LFOEffect extends Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"LFOEffect\";\n        this._lfo = new LFO({\n            context: this.context,\n            frequency: options.frequency,\n            amplitude: options.depth,\n        });\n        this.depth = this._lfo.amplitude;\n        this.frequency = this._lfo.frequency;\n        this.type = options.type;\n        readOnly(this, [\"frequency\", \"depth\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            frequency: 1,\n            type: \"sine\",\n            depth: 1,\n        });\n    }\n    /**\n     * Start the effect.\n     */\n    start(time) {\n        this._lfo.start(time);\n        return this;\n    }\n    /**\n     * Stop the lfo\n     */\n    stop(time) {\n        this._lfo.stop(time);\n        return this;\n    }\n    /**\n     * Sync the filter to the transport. See [[LFO.sync]]\n     */\n    sync() {\n        this._lfo.sync();\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport.\n     */\n    unsync() {\n        this._lfo.unsync();\n        return this;\n    }\n    /**\n     * The type of the LFO's oscillator: See [[Oscillator.type]]\n     * @example\n     * const autoFilter = new Tone.AutoFilter().start().toDestination();\n     * const noise = new Tone.Noise().start().connect(autoFilter);\n     * autoFilter.type = \"square\";\n     */\n    get type() {\n        return this._lfo.type;\n    }\n    set type(type) {\n        this._lfo.type = type;\n    }\n    dispose() {\n        super.dispose();\n        this._lfo.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LFOEffect.js.map","import { Effect } from \"./Effect\";\nimport { MidSideSplit } from \"../component/channel/MidSideSplit\";\nimport { MidSideMerge } from \"../component/channel/MidSideMerge\";\n/**\n * Mid/Side processing separates the the 'mid' signal\n * (which comes out of both the left and the right channel)\n * and the 'side' (which only comes out of the the side channels)\n * and effects them separately before being recombined.\n * Applies a Mid/Side seperation and recombination.\n * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n * This is a base-class for Mid/Side Effects.\n */\nexport class MidSideEffect extends Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"MidSideEffect\";\n        this._midSideMerge = new MidSideMerge({ context: this.context });\n        this._midSideSplit = new MidSideSplit({ context: this.context });\n        this._midSend = this._midSideSplit.mid;\n        this._sideSend = this._midSideSplit.side;\n        this._midReturn = this._midSideMerge.mid;\n        this._sideReturn = this._midSideMerge.side;\n        // the connections\n        this.effectSend.connect(this._midSideSplit);\n        this._midSideMerge.connect(this.effectReturn);\n    }\n    /**\n     * Connect the mid chain of the effect\n     */\n    connectEffectMid(...nodes) {\n        this._midSend.chain(...nodes, this._midReturn);\n    }\n    /**\n     * Connect the side chain of the effect\n     */\n    connectEffectSide(...nodes) {\n        this._sideSend.chain(...nodes, this._sideReturn);\n    }\n    dispose() {\n        super.dispose();\n        this._midSideSplit.dispose();\n        this._midSideMerge.dispose();\n        this._midSend.dispose();\n        this._sideSend.dispose();\n        this._midReturn.dispose();\n        this._sideReturn.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideEffect.js.map","import { StereoEffect } from \"./StereoEffect\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { LFO } from \"../source/oscillator/LFO\";\nimport { Signal } from \"../signal/Signal\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Phaser is a phaser effect. Phasers work by changing the phase\n * of different frequency components of an incoming signal. Read more on\n * [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).\n * Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).\n * @example\n * const phaser = new Tone.Phaser({\n * \tfrequency: 15,\n * \toctaves: 5,\n * \tbaseFrequency: 1000\n * }).toDestination();\n * const synth = new Tone.FMSynth().connect(phaser);\n * synth.triggerAttackRelease(\"E3\", \"2n\");\n * @category Effect\n */\nexport class Phaser extends StereoEffect {\n    constructor() {\n        super(optionsFromArguments(Phaser.getDefaults(), arguments, [\"frequency\", \"octaves\", \"baseFrequency\"]));\n        this.name = \"Phaser\";\n        const options = optionsFromArguments(Phaser.getDefaults(), arguments, [\"frequency\", \"octaves\", \"baseFrequency\"]);\n        this._lfoL = new LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1\n        });\n        this._lfoR = new LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n            phase: 180,\n        });\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._octaves = options.octaves;\n        this.Q = new Signal({\n            context: this.context,\n            value: options.Q,\n            units: \"positive\",\n        });\n        this._filtersL = this._makeFilters(options.stages, this._lfoL);\n        this._filtersR = this._makeFilters(options.stages, this._lfoR);\n        this.frequency = this._lfoL.frequency;\n        this.frequency.value = options.frequency;\n        // connect them up\n        this.connectEffectLeft(...this._filtersL);\n        this.connectEffectRight(...this._filtersR);\n        // control the frequency with one LFO\n        this._lfoL.frequency.connect(this._lfoR.frequency);\n        // set the options\n        this.baseFrequency = options.baseFrequency;\n        this.octaves = options.octaves;\n        // start the lfo\n        this._lfoL.start();\n        this._lfoR.start();\n        readOnly(this, [\"frequency\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(StereoEffect.getDefaults(), {\n            frequency: 0.5,\n            octaves: 3,\n            stages: 10,\n            Q: 10,\n            baseFrequency: 350,\n        });\n    }\n    _makeFilters(stages, connectToFreq) {\n        const filters = [];\n        // make all the filters\n        for (let i = 0; i < stages; i++) {\n            const filter = this.context.createBiquadFilter();\n            filter.type = \"allpass\";\n            this.Q.connect(filter.Q);\n            connectToFreq.connect(filter.frequency);\n            filters.push(filter);\n        }\n        return filters;\n    }\n    /**\n     * The number of octaves the phase goes above the baseFrequency\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        this._octaves = octaves;\n        const max = this._baseFrequency * Math.pow(2, octaves);\n        this._lfoL.max = max;\n        this._lfoR.max = max;\n    }\n    /**\n     * The the base frequency of the filters.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(freq) {\n        this._baseFrequency = this.toFrequency(freq);\n        this._lfoL.min = this._baseFrequency;\n        this._lfoR.min = this._baseFrequency;\n        this.octaves = this._octaves;\n    }\n    dispose() {\n        super.dispose();\n        this.Q.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._filtersL.forEach(f => f.disconnect());\n        this._filtersR.forEach(f => f.disconnect());\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Phaser.js.map","import { StereoXFeedbackEffect } from \"./StereoXFeedbackEffect\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Delay } from \"../core/context/Delay\";\nimport { Signal } from \"../signal/Signal\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * PingPongDelay is a feedback delay effect where the echo is heard\n * first in one channel and next in the opposite channel. In a stereo\n * system these are the right and left channels.\n * PingPongDelay in more simplified terms is two Tone.FeedbackDelays\n * with independent delay values. Each delay is routed to one channel\n * (left or right), and the channel triggered second will always\n * trigger at the same interval after the first.\n * @example\n * const pingPong = new Tone.PingPongDelay(\"4n\", 0.2).toDestination();\n * const drum = new Tone.MembraneSynth().connect(pingPong);\n * drum.triggerAttackRelease(\"C4\", \"32n\");\n * @category Effect\n */\nexport class PingPongDelay extends StereoXFeedbackEffect {\n    constructor() {\n        super(optionsFromArguments(PingPongDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]));\n        this.name = \"PingPongDelay\";\n        const options = optionsFromArguments(PingPongDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]);\n        this._leftDelay = new Delay({\n            context: this.context,\n            maxDelay: options.maxDelay,\n        });\n        this._rightDelay = new Delay({\n            context: this.context,\n            maxDelay: options.maxDelay\n        });\n        this._rightPreDelay = new Delay({\n            context: this.context,\n            maxDelay: options.maxDelay\n        });\n        this.delayTime = new Signal({\n            context: this.context,\n            units: \"time\",\n            value: options.delayTime,\n        });\n        // connect it up\n        this.connectEffectLeft(this._leftDelay);\n        this.connectEffectRight(this._rightPreDelay, this._rightDelay);\n        this.delayTime.fan(this._leftDelay.delayTime, this._rightDelay.delayTime, this._rightPreDelay.delayTime);\n        // rearranged the feedback to be after the rightPreDelay\n        this._feedbackL.disconnect();\n        this._feedbackL.connect(this._rightDelay);\n        readOnly(this, [\"delayTime\"]);\n    }\n    static getDefaults() {\n        return Object.assign(StereoXFeedbackEffect.getDefaults(), {\n            delayTime: 0.25,\n            maxDelay: 1\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._leftDelay.dispose();\n        this._rightDelay.dispose();\n        this._rightPreDelay.dispose();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PingPongDelay.js.map","import { FeedbackEffect } from \"./FeedbackEffect\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { LFO } from \"../source/oscillator/LFO\";\nimport { Delay } from \"../core/context/Delay\";\nimport { CrossFade } from \"../component/channel/CrossFade\";\nimport { Signal } from \"../signal/Signal\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { intervalToFrequencyRatio } from \"../core/type/Conversions\";\n/**\n * PitchShift does near-realtime pitch shifting to the incoming signal.\n * The effect is achieved by speeding up or slowing down the delayTime\n * of a DelayNode using a sawtooth wave.\n * Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).\n * Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).\n * @category Effect\n */\nexport class PitchShift extends FeedbackEffect {\n    constructor() {\n        super(optionsFromArguments(PitchShift.getDefaults(), arguments, [\"pitch\"]));\n        this.name = \"PitchShift\";\n        const options = optionsFromArguments(PitchShift.getDefaults(), arguments, [\"pitch\"]);\n        this._frequency = new Signal({ context: this.context });\n        this._delayA = new Delay({\n            maxDelay: 1,\n            context: this.context\n        });\n        this._lfoA = new LFO({\n            context: this.context,\n            min: 0,\n            max: 0.1,\n            type: \"sawtooth\"\n        }).connect(this._delayA.delayTime);\n        this._delayB = new Delay({\n            maxDelay: 1,\n            context: this.context\n        });\n        this._lfoB = new LFO({\n            context: this.context,\n            min: 0,\n            max: 0.1,\n            type: \"sawtooth\",\n            phase: 180\n        }).connect(this._delayB.delayTime);\n        this._crossFade = new CrossFade({ context: this.context });\n        this._crossFadeLFO = new LFO({\n            context: this.context,\n            min: 0,\n            max: 1,\n            type: \"triangle\",\n            phase: 90\n        }).connect(this._crossFade.fade);\n        this._feedbackDelay = new Delay({\n            delayTime: options.delayTime,\n            context: this.context,\n        });\n        this.delayTime = this._feedbackDelay.delayTime;\n        readOnly(this, \"delayTime\");\n        this._pitch = options.pitch;\n        this._windowSize = options.windowSize;\n        // connect the two delay lines up\n        this._delayA.connect(this._crossFade.a);\n        this._delayB.connect(this._crossFade.b);\n        // connect the frequency\n        this._frequency.fan(this._lfoA.frequency, this._lfoB.frequency, this._crossFadeLFO.frequency);\n        // route the input\n        this.effectSend.fan(this._delayA, this._delayB);\n        this._crossFade.chain(this._feedbackDelay, this.effectReturn);\n        // start the LFOs at the same time\n        const now = this.now();\n        this._lfoA.start(now);\n        this._lfoB.start(now);\n        this._crossFadeLFO.start(now);\n        // set the initial value\n        this.windowSize = this._windowSize;\n    }\n    static getDefaults() {\n        return Object.assign(FeedbackEffect.getDefaults(), {\n            pitch: 0,\n            windowSize: 0.1,\n            delayTime: 0,\n            feedback: 0\n        });\n    }\n    /**\n     * Repitch the incoming signal by some interval (measured in semi-tones).\n     * @example\n     * const pitchShift = new Tone.PitchShift().toDestination();\n     * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();\n     * pitchShift.pitch = -12; // down one octave\n     * pitchShift.pitch = 7; // up a fifth\n     */\n    get pitch() {\n        return this._pitch;\n    }\n    set pitch(interval) {\n        this._pitch = interval;\n        let factor = 0;\n        if (interval < 0) {\n            this._lfoA.min = 0;\n            this._lfoA.max = this._windowSize;\n            this._lfoB.min = 0;\n            this._lfoB.max = this._windowSize;\n            factor = intervalToFrequencyRatio(interval - 1) + 1;\n        }\n        else {\n            this._lfoA.min = this._windowSize;\n            this._lfoA.max = 0;\n            this._lfoB.min = this._windowSize;\n            this._lfoB.max = 0;\n            factor = intervalToFrequencyRatio(interval) - 1;\n        }\n        this._frequency.value = factor * (1.2 / this._windowSize);\n    }\n    /**\n     * The window size corresponds roughly to the sample length in a looping sampler.\n     * Smaller values are desirable for a less noticeable delay time of the pitch shifted\n     * signal, but larger values will result in smoother pitch shifting for larger intervals.\n     * A nominal range of 0.03 to 0.1 is recommended.\n     */\n    get windowSize() {\n        return this._windowSize;\n    }\n    set windowSize(size) {\n        this._windowSize = this.toSeconds(size);\n        this.pitch = this._pitch;\n    }\n    dispose() {\n        super.dispose();\n        this._frequency.dispose();\n        this._delayA.dispose();\n        this._delayB.dispose();\n        this._lfoA.dispose();\n        this._lfoB.dispose();\n        this._crossFade.dispose();\n        this._crossFadeLFO.dispose();\n        this._feedbackDelay.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PitchShift.js.map","import { __awaiter } from \"tslib\";\nimport { Merge } from \"../component/channel/Merge\";\nimport { Gain } from \"../core/context/Gain\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Noise } from \"../source/Noise\";\nimport { Effect } from \"./Effect\";\nimport { OfflineContext } from \"../core/context/OfflineContext\";\nimport { noOp } from \"../core/util/Interface\";\nimport { assertRange } from \"../core/util/Debug\";\n/**\n * Simple convolution created with decaying noise.\n * Generates an Impulse Response Buffer\n * with Tone.Offline then feeds the IR into ConvolverNode.\n * The impulse response generation is async, so you have\n * to wait until [[ready]] resolves before it will make a sound.\n *\n * Inspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).\n * Copyright (c) 2014 Alan deLespinasse Apache 2.0 License.\n *\n * @category Effect\n */\nexport class Reverb extends Effect {\n    constructor() {\n        super(optionsFromArguments(Reverb.getDefaults(), arguments, [\"decay\"]));\n        this.name = \"Reverb\";\n        /**\n         * Convolver node\n         */\n        this._convolver = this.context.createConvolver();\n        /**\n         * Resolves when the reverb buffer is generated. Whenever either [[decay]]\n         * or [[preDelay]] are set, you have to wait until [[ready]] resolves\n         * before the IR is generated with the latest values.\n         */\n        this.ready = Promise.resolve();\n        const options = optionsFromArguments(Reverb.getDefaults(), arguments, [\"decay\"]);\n        this._decay = options.decay;\n        this._preDelay = options.preDelay;\n        this.generate();\n        this.connectEffect(this._convolver);\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            decay: 1.5,\n            preDelay: 0.01,\n        });\n    }\n    /**\n     * The duration of the reverb.\n     */\n    get decay() {\n        return this._decay;\n    }\n    set decay(time) {\n        time = this.toSeconds(time);\n        assertRange(time, 0.001);\n        this._decay = time;\n        this.generate();\n    }\n    /**\n     * The amount of time before the reverb is fully ramped in.\n     */\n    get preDelay() {\n        return this._preDelay;\n    }\n    set preDelay(time) {\n        time = this.toSeconds(time);\n        assertRange(time, 0);\n        this._preDelay = time;\n        this.generate();\n    }\n    /**\n     * Generate the Impulse Response. Returns a promise while the IR is being generated.\n     * @return Promise which returns this object.\n     */\n    generate() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const previousReady = this.ready;\n            // create a noise burst which decays over the duration in each channel\n            const context = new OfflineContext(2, this._decay + this._preDelay, this.context.sampleRate);\n            const noiseL = new Noise({ context });\n            const noiseR = new Noise({ context });\n            const merge = new Merge({ context });\n            noiseL.connect(merge, 0, 0);\n            noiseR.connect(merge, 0, 1);\n            const gainNode = new Gain({ context }).toDestination();\n            merge.connect(gainNode);\n            noiseL.start(0);\n            noiseR.start(0);\n            // predelay\n            gainNode.gain.setValueAtTime(0, 0);\n            gainNode.gain.setValueAtTime(1, this._preDelay);\n            // decay\n            gainNode.gain.exponentialApproachValueAtTime(0, this._preDelay, this.decay);\n            // render the buffer\n            const renderPromise = context.render();\n            this.ready = renderPromise.then(noOp);\n            // wait for the previous `ready` to resolve\n            yield previousReady;\n            // set the buffer\n            this._convolver.buffer = (yield renderPromise).get();\n            return this;\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._convolver.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Reverb.js.map","import { connect, connectSeries, ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { CrossFade } from \"../component/channel/CrossFade\";\nimport { Split } from \"../component/channel/Split\";\nimport { Gain } from \"../core/context/Gain\";\nimport { Merge } from \"../component/channel/Merge\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Base class for Stereo effects.\n */\nexport class StereoEffect extends ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"StereoEffect\";\n        this.input = new Gain({ context: this.context });\n        // force mono sources to be stereo\n        this.input.channelCount = 2;\n        this.input.channelCountMode = \"explicit\";\n        this._dryWet = this.output = new CrossFade({\n            context: this.context,\n            fade: options.wet\n        });\n        this.wet = this._dryWet.fade;\n        this._split = new Split({ context: this.context, channels: 2 });\n        this._merge = new Merge({ context: this.context, channels: 2 });\n        // connections\n        this.input.connect(this._split);\n        // dry wet connections\n        this.input.connect(this._dryWet.a);\n        this._merge.connect(this._dryWet.b);\n        readOnly(this, [\"wet\"]);\n    }\n    /**\n     * Connect the left part of the effect\n     */\n    connectEffectLeft(...nodes) {\n        this._split.connect(nodes[0], 0, 0);\n        connectSeries(...nodes);\n        connect(nodes[nodes.length - 1], this._merge, 0, 0);\n    }\n    /**\n     * Connect the right part of the effect\n     */\n    connectEffectRight(...nodes) {\n        this._split.connect(nodes[0], 1, 0);\n        connectSeries(...nodes);\n        connect(nodes[nodes.length - 1], this._merge, 0, 1);\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            wet: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._dryWet.dispose();\n        this._split.dispose();\n        this._merge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoEffect.js.map","import { StereoEffect } from \"./StereoEffect\";\nimport { Signal } from \"../signal/Signal\";\nimport { Gain } from \"../core/context/Gain\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { Split } from \"../component/channel/Split\";\nimport { Merge } from \"../component/channel/Merge\";\n/**\n * Just like a stereo feedback effect, but the feedback is routed from left to right\n * and right to left instead of on the same channel.\n * ```\n * +--------------------------------+ feedbackL <-----------------------------------+\n * |                                                                                |\n * +-->                          +----->        +---->                          +---+\n *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit\n * +-->                          +----->        +---->                          +---+\n * |                                                                                |\n * +--------------------------------+ feedbackR <-----------------------------------+\n * ```\n */\nexport class StereoFeedbackEffect extends StereoEffect {\n    constructor(options) {\n        super(options);\n        this.feedback = new Signal({\n            context: this.context,\n            value: options.feedback,\n            units: \"normalRange\"\n        });\n        this._feedbackL = new Gain({ context: this.context });\n        this._feedbackR = new Gain({ context: this.context });\n        this._feedbackSplit = new Split({ context: this.context, channels: 2 });\n        this._feedbackMerge = new Merge({ context: this.context, channels: 2 });\n        this._merge.connect(this._feedbackSplit);\n        this._feedbackMerge.connect(this._split);\n        // the left output connected to the left input\n        this._feedbackSplit.connect(this._feedbackL, 0, 0);\n        this._feedbackL.connect(this._feedbackMerge, 0, 0);\n        // the right output connected to the right input\n        this._feedbackSplit.connect(this._feedbackR, 1, 0);\n        this._feedbackR.connect(this._feedbackMerge, 0, 1);\n        // the feedback control\n        this.feedback.fan(this._feedbackL.gain, this._feedbackR.gain);\n        readOnly(this, [\"feedback\"]);\n    }\n    static getDefaults() {\n        return Object.assign(StereoEffect.getDefaults(), {\n            feedback: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.feedback.dispose();\n        this._feedbackL.dispose();\n        this._feedbackR.dispose();\n        this._feedbackSplit.dispose();\n        this._feedbackMerge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoFeedbackEffect.js.map","import { MidSideEffect } from \"../effect/MidSideEffect\";\nimport { Signal } from \"../signal/Signal\";\nimport { Multiply } from \"../signal/Multiply\";\nimport { Subtract } from \"../signal/Subtract\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { connect } from \"../core/context/ToneAudioNode\";\n/**\n * Applies a width factor to the mid/side seperation.\n * 0 is all mid and 1 is all side.\n * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n * ```\n * Mid *= 2*(1-width)<br>\n * Side *= 2*width\n * ```\n * @category Effect\n */\nexport class StereoWidener extends MidSideEffect {\n    constructor() {\n        super(optionsFromArguments(StereoWidener.getDefaults(), arguments, [\"width\"]));\n        this.name = \"StereoWidener\";\n        const options = optionsFromArguments(StereoWidener.getDefaults(), arguments, [\"width\"]);\n        this.width = new Signal({\n            context: this.context,\n            value: options.width,\n            units: \"normalRange\",\n        });\n        readOnly(this, [\"width\"]);\n        this._twoTimesWidthMid = new Multiply({\n            context: this.context,\n            value: 2,\n        });\n        this._twoTimesWidthSide = new Multiply({\n            context: this.context,\n            value: 2,\n        });\n        this._midMult = new Multiply({ context: this.context });\n        this._twoTimesWidthMid.connect(this._midMult.factor);\n        this.connectEffectMid(this._midMult);\n        this._oneMinusWidth = new Subtract({ context: this.context });\n        this._oneMinusWidth.connect(this._twoTimesWidthMid);\n        connect(this.context.getConstant(1), this._oneMinusWidth);\n        this.width.connect(this._oneMinusWidth.subtrahend);\n        this._sideMult = new Multiply({ context: this.context });\n        this.width.connect(this._twoTimesWidthSide);\n        this._twoTimesWidthSide.connect(this._sideMult.factor);\n        this.connectEffectSide(this._sideMult);\n    }\n    static getDefaults() {\n        return Object.assign(MidSideEffect.getDefaults(), {\n            width: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.width.dispose();\n        this._midMult.dispose();\n        this._sideMult.dispose();\n        this._twoTimesWidthMid.dispose();\n        this._twoTimesWidthSide.dispose();\n        this._oneMinusWidth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoWidener.js.map","import { StereoFeedbackEffect } from \"./StereoFeedbackEffect\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Just like a [[StereoFeedbackEffect]], but the feedback is routed from left to right\n * and right to left instead of on the same channel.\n * ```\n * +--------------------------------+ feedbackL <-----------------------------------+\n * |                                                                                |\n * +-->                          +----->        +---->                          +-----+\n *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit     | |\n * +-->                          +----->        +---->                          +---+ |\n * |                                                                                  |\n * +--------------------------------+ feedbackR <-------------------------------------+\n * ```\n */\nexport class StereoXFeedbackEffect extends StereoFeedbackEffect {\n    constructor(options) {\n        super(options);\n        // the left output connected to the right input\n        this._feedbackL.disconnect();\n        this._feedbackL.connect(this._feedbackMerge, 0, 1);\n        // the left output connected to the right input\n        this._feedbackR.disconnect();\n        this._feedbackR.connect(this._feedbackMerge, 0, 0);\n        readOnly(this, [\"feedback\"]);\n    }\n}\n//# sourceMappingURL=StereoXFeedbackEffect.js.map","import { StereoEffect } from \"./StereoEffect\";\nimport { LFO } from \"../source/oscillator/LFO\";\nimport { Gain } from \"../core/context/Gain\";\nimport { Signal } from \"../signal/Signal\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Tremolo modulates the amplitude of an incoming signal using an [[LFO]].\n * The effect is a stereo effect where the modulation phase is inverted in each channel.\n *\n * @example\n * // create a tremolo and start it's LFO\n * const tremolo = new Tone.Tremolo(9, 0.75).toDestination().start();\n * // route an oscillator through the tremolo and start it\n * const oscillator = new Tone.Oscillator().connect(tremolo).start();\n *\n * @category Effect\n */\nexport class Tremolo extends StereoEffect {\n    constructor() {\n        super(optionsFromArguments(Tremolo.getDefaults(), arguments, [\"frequency\", \"depth\"]));\n        this.name = \"Tremolo\";\n        const options = optionsFromArguments(Tremolo.getDefaults(), arguments, [\"frequency\", \"depth\"]);\n        this._lfoL = new LFO({\n            context: this.context,\n            type: options.type,\n            min: 1,\n            max: 0,\n        });\n        this._lfoR = new LFO({\n            context: this.context,\n            type: options.type,\n            min: 1,\n            max: 0,\n        });\n        this._amplitudeL = new Gain({ context: this.context });\n        this._amplitudeR = new Gain({ context: this.context });\n        this.frequency = new Signal({\n            context: this.context,\n            value: options.frequency,\n            units: \"frequency\",\n        });\n        this.depth = new Signal({\n            context: this.context,\n            value: options.depth,\n            units: \"normalRange\",\n        });\n        readOnly(this, [\"frequency\", \"depth\"]);\n        this.connectEffectLeft(this._amplitudeL);\n        this.connectEffectRight(this._amplitudeR);\n        this._lfoL.connect(this._amplitudeL.gain);\n        this._lfoR.connect(this._amplitudeR.gain);\n        this.frequency.fan(this._lfoL.frequency, this._lfoR.frequency);\n        this.depth.fan(this._lfoR.amplitude, this._lfoL.amplitude);\n        this.spread = options.spread;\n    }\n    static getDefaults() {\n        return Object.assign(StereoEffect.getDefaults(), {\n            frequency: 10,\n            type: \"sine\",\n            depth: 0.5,\n            spread: 180,\n        });\n    }\n    /**\n     * Start the tremolo.\n     */\n    start(time) {\n        this._lfoL.start(time);\n        this._lfoR.start(time);\n        return this;\n    }\n    /**\n     * Stop the tremolo.\n     */\n    stop(time) {\n        this._lfoL.stop(time);\n        this._lfoR.stop(time);\n        return this;\n    }\n    /**\n     * Sync the effect to the transport.\n     */\n    sync() {\n        this._lfoL.sync();\n        this._lfoR.sync();\n        this.context.transport.syncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport\n     */\n    unsync() {\n        this._lfoL.unsync();\n        this._lfoR.unsync();\n        this.context.transport.unsyncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * The oscillator type.\n     */\n    get type() {\n        return this._lfoL.type;\n    }\n    set type(type) {\n        this._lfoL.type = type;\n        this._lfoR.type = type;\n    }\n    /**\n     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n     * When set to 180, LFO's will be panned hard left and right respectively.\n     */\n    get spread() {\n        return this._lfoR.phase - this._lfoL.phase; // 180\n    }\n    set spread(spread) {\n        this._lfoL.phase = 90 - (spread / 2);\n        this._lfoR.phase = (spread / 2) + 90;\n    }\n    dispose() {\n        super.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._amplitudeL.dispose();\n        this._amplitudeR.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Tremolo.js.map","import { Effect } from \"./Effect\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { LFO } from \"../source/oscillator/LFO\";\nimport { Delay } from \"../core/context/Delay\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO\n * modulates the delayTime of the delay, causing the pitch to rise and fall.\n * @category Effect\n */\nexport class Vibrato extends Effect {\n    constructor() {\n        super(optionsFromArguments(Vibrato.getDefaults(), arguments, [\"frequency\", \"depth\"]));\n        this.name = \"Vibrato\";\n        const options = optionsFromArguments(Vibrato.getDefaults(), arguments, [\"frequency\", \"depth\"]);\n        this._delayNode = new Delay({\n            context: this.context,\n            delayTime: 0,\n            maxDelay: options.maxDelay,\n        });\n        this._lfo = new LFO({\n            context: this.context,\n            type: options.type,\n            min: 0,\n            max: options.maxDelay,\n            frequency: options.frequency,\n            phase: -90 // offse the phase so the resting position is in the center\n        }).start().connect(this._delayNode.delayTime);\n        this.frequency = this._lfo.frequency;\n        this.depth = this._lfo.amplitude;\n        this.depth.value = options.depth;\n        readOnly(this, [\"frequency\", \"depth\"]);\n        this.effectSend.chain(this._delayNode, this.effectReturn);\n    }\n    static getDefaults() {\n        return Object.assign(Effect.getDefaults(), {\n            maxDelay: 0.005,\n            frequency: 5,\n            depth: 0.1,\n            type: \"sine\"\n        });\n    }\n    /**\n     * Type of oscillator attached to the Vibrato.\n     */\n    get type() {\n        return this._lfo.type;\n    }\n    set type(type) {\n        this._lfo.type = type;\n    }\n    dispose() {\n        super.dispose();\n        this._delayNode.dispose();\n        this._lfo.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Vibrato.js.map","export * from \"./AutoFilter\";\nexport * from \"./AutoPanner\";\nexport * from \"./AutoWah\";\nexport * from \"./BitCrusher\";\nexport * from \"./Chebyshev\";\nexport * from \"./Chorus\";\nexport * from \"./Distortion\";\nexport * from \"./FeedbackDelay\";\nexport * from \"./FrequencyShifter\";\nexport * from \"./Freeverb\";\nexport * from \"./JCReverb\";\nexport * from \"./PingPongDelay\";\nexport * from \"./PitchShift\";\nexport * from \"./Phaser\";\nexport * from \"./Reverb\";\nexport * from \"./StereoWidener\";\nexport * from \"./Tremolo\";\nexport * from \"./Vibrato\";\n//# sourceMappingURL=index.js.map","import { ToneEvent } from \"./ToneEvent\";\nimport { ToneWithContext } from \"../core/context/ToneWithContext\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { noOp } from \"../core/util/Interface\";\n/**\n * Loop creates a looped callback at the\n * specified interval. The callback can be\n * started, stopped and scheduled along\n * the Transport's timeline.\n * @example\n * const loop = new Tone.Loop((time) => {\n * \t// triggered every eighth note.\n * \tconsole.log(time);\n * }, \"8n\").start(0);\n * Tone.Transport.start();\n * @category Event\n */\nexport class Loop extends ToneWithContext {\n    constructor() {\n        super(optionsFromArguments(Loop.getDefaults(), arguments, [\"callback\", \"interval\"]));\n        this.name = \"Loop\";\n        const options = optionsFromArguments(Loop.getDefaults(), arguments, [\"callback\", \"interval\"]);\n        this._event = new ToneEvent({\n            context: this.context,\n            callback: this._tick.bind(this),\n            loop: true,\n            loopEnd: options.interval,\n            playbackRate: options.playbackRate,\n            probability: options.probability\n        });\n        this.callback = options.callback;\n        // set the iterations\n        this.iterations = options.iterations;\n    }\n    static getDefaults() {\n        return Object.assign(ToneWithContext.getDefaults(), {\n            interval: \"4n\",\n            callback: noOp,\n            playbackRate: 1,\n            iterations: Infinity,\n            probability: 1,\n            mute: false,\n            humanize: false\n        });\n    }\n    /**\n     * Start the loop at the specified time along the Transport's timeline.\n     * @param  time  When to start the Loop.\n     */\n    start(time) {\n        this._event.start(time);\n        return this;\n    }\n    /**\n     * Stop the loop at the given time.\n     * @param  time  When to stop the Loop.\n     */\n    stop(time) {\n        this._event.stop(time);\n        return this;\n    }\n    /**\n     * Cancel all scheduled events greater than or equal to the given time\n     * @param  time  The time after which events will be cancel.\n     */\n    cancel(time) {\n        this._event.cancel(time);\n        return this;\n    }\n    /**\n     * Internal function called when the notes should be called\n     * @param time  The time the event occurs\n     */\n    _tick(time) {\n        this.callback(time);\n    }\n    /**\n     * The state of the Loop, either started or stopped.\n     */\n    get state() {\n        return this._event.state;\n    }\n    /**\n     * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.\n     */\n    get progress() {\n        return this._event.progress;\n    }\n    /**\n     * The time between successive callbacks.\n     * @example\n     * const loop = new Tone.Loop();\n     * loop.interval = \"8n\"; // loop every 8n\n     */\n    get interval() {\n        return this._event.loopEnd;\n    }\n    set interval(interval) {\n        this._event.loopEnd = interval;\n    }\n    /**\n     * The playback rate of the loop. The normal playback rate is 1 (no change).\n     * A `playbackRate` of 2 would be twice as fast.\n     */\n    get playbackRate() {\n        return this._event.playbackRate;\n    }\n    set playbackRate(rate) {\n        this._event.playbackRate = rate;\n    }\n    /**\n     * Random variation +/-0.01s to the scheduled time.\n     * Or give it a time value which it will randomize by.\n     */\n    get humanize() {\n        return this._event.humanize;\n    }\n    set humanize(variation) {\n        this._event.humanize = variation;\n    }\n    /**\n     * The probably of the callback being invoked.\n     */\n    get probability() {\n        return this._event.probability;\n    }\n    set probability(prob) {\n        this._event.probability = prob;\n    }\n    /**\n     * Muting the Loop means that no callbacks are invoked.\n     */\n    get mute() {\n        return this._event.mute;\n    }\n    set mute(mute) {\n        this._event.mute = mute;\n    }\n    /**\n     * The number of iterations of the loop. The default value is `Infinity` (loop forever).\n     */\n    get iterations() {\n        if (this._event.loop === true) {\n            return Infinity;\n        }\n        else {\n            return this._event.loop;\n        }\n    }\n    set iterations(iters) {\n        if (iters === Infinity) {\n            this._event.loop = true;\n        }\n        else {\n            this._event.loop = iters;\n        }\n    }\n    dispose() {\n        super.dispose();\n        this._event.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Loop.js.map","import { TicksClass } from \"../core/type/Ticks\";\nimport { TransportTimeClass } from \"../core/type/TransportTime\";\nimport { defaultArg, optionsFromArguments } from \"../core/util/Defaults\";\nimport { StateTimeline } from \"../core/util/StateTimeline\";\nimport { isArray, isDefined, isObject, isUndef } from \"../core/util/TypeCheck\";\nimport { ToneEvent } from \"./ToneEvent\";\n/**\n * Part is a collection ToneEvents which can be started/stopped and looped as a single unit.\n *\n * @example\n * const synth = new Tone.Synth().toDestination();\n * const part = new Tone.Part(((time, note) => {\n * \t// the notes given as the second element in the array\n * \t// will be passed in as the second argument\n * \tsynth.triggerAttackRelease(note, \"8n\", time);\n * }), [[0, \"C2\"], [\"0:2\", \"C3\"], [\"0:3:2\", \"G2\"]]);\n * @example\n * const synth = new Tone.Synth().toDestination();\n * // use an array of objects as long as the object has a \"time\" attribute\n * const part = new Tone.Part(((time, value) => {\n * \t// the value is an object which contains both the note and the velocity\n * \tsynth.triggerAttackRelease(value.note, \"8n\", time, value.velocity);\n * }), [{ time: 0, note: \"C3\", velocity: 0.9 },\n * \t{ time: \"0:2\", note: \"C4\", velocity: 0.5 }\n * ]).start(0);\n * @category Event\n */\nexport class Part extends ToneEvent {\n    constructor() {\n        super(optionsFromArguments(Part.getDefaults(), arguments, [\"callback\", \"events\"]));\n        this.name = \"Part\";\n        /**\n         * Tracks the scheduled events\n         */\n        this._state = new StateTimeline(\"stopped\");\n        /**\n         * The events that belong to this part\n         */\n        this._events = new Set();\n        const options = optionsFromArguments(Part.getDefaults(), arguments, [\"callback\", \"events\"]);\n        // make sure things are assigned in the right order\n        this._state.increasing = true;\n        // add the events\n        options.events.forEach(event => {\n            if (isArray(event)) {\n                this.add(event[0], event[1]);\n            }\n            else {\n                this.add(event);\n            }\n        });\n    }\n    static getDefaults() {\n        return Object.assign(ToneEvent.getDefaults(), {\n            events: [],\n        });\n    }\n    /**\n     * Start the part at the given time.\n     * @param  time    When to start the part.\n     * @param  offset  The offset from the start of the part to begin playing at.\n     */\n    start(time, offset) {\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) !== \"started\") {\n            offset = defaultArg(offset, this._loop ? this._loopStart : 0);\n            if (this._loop) {\n                offset = defaultArg(offset, this._loopStart);\n            }\n            else {\n                offset = defaultArg(offset, 0);\n            }\n            const computedOffset = this.toTicks(offset);\n            this._state.add({\n                id: -1,\n                offset: computedOffset,\n                state: \"started\",\n                time: ticks,\n            });\n            this._forEach(event => {\n                this._startNote(event, ticks, computedOffset);\n            });\n        }\n        return this;\n    }\n    /**\n     * Start the event in the given event at the correct time given\n     * the ticks and offset and looping.\n     * @param  event\n     * @param  ticks\n     * @param  offset\n     */\n    _startNote(event, ticks, offset) {\n        ticks -= offset;\n        if (this._loop) {\n            if (event.startOffset >= this._loopStart && event.startOffset < this._loopEnd) {\n                if (event.startOffset < offset) {\n                    // start it on the next loop\n                    ticks += this._getLoopDuration();\n                }\n                event.start(new TicksClass(this.context, ticks));\n            }\n            else if (event.startOffset < this._loopStart && event.startOffset >= offset) {\n                event.loop = false;\n                event.start(new TicksClass(this.context, ticks));\n            }\n        }\n        else if (event.startOffset >= offset) {\n            event.start(new TicksClass(this.context, ticks));\n        }\n    }\n    get startOffset() {\n        return this._startOffset;\n    }\n    set startOffset(offset) {\n        this._startOffset = offset;\n        this._forEach(event => {\n            event.startOffset += this._startOffset;\n        });\n    }\n    /**\n     * Stop the part at the given time.\n     * @param  time  When to stop the part.\n     */\n    stop(time) {\n        const ticks = this.toTicks(time);\n        this._state.cancel(ticks);\n        this._state.setStateAtTime(\"stopped\", ticks);\n        this._forEach(event => {\n            event.stop(time);\n        });\n        return this;\n    }\n    /**\n     * Get/Set an Event's value at the given time.\n     * If a value is passed in and no event exists at\n     * the given time, one will be created with that value.\n     * If two events are at the same time, the first one will\n     * be returned.\n     * @example\n     * const part = new Tone.Part();\n     * part.at(\"1m\"); // returns the part at the first measure\n     * part.at(\"2m\", \"C2\"); // set the value at \"2m\" to C2.\n     * // if an event didn't exist at that time, it will be created.\n     * @param time The time of the event to get or set.\n     * @param value If a value is passed in, the value of the event at the given time will be set to it.\n     */\n    at(time, value) {\n        const timeInTicks = new TransportTimeClass(this.context, time).toTicks();\n        const tickTime = new TicksClass(this.context, 1).toSeconds();\n        const iterator = this._events.values();\n        let result = iterator.next();\n        while (!result.done) {\n            const event = result.value;\n            if (Math.abs(timeInTicks - event.startOffset) < tickTime) {\n                if (isDefined(value)) {\n                    event.value = value;\n                }\n                return event;\n            }\n            result = iterator.next();\n        }\n        // if there was no event at that time, create one\n        if (isDefined(value)) {\n            this.add(time, value);\n            // return the new event\n            return this.at(time);\n        }\n        else {\n            return null;\n        }\n    }\n    add(time, value) {\n        // extract the parameters\n        if (time instanceof Object && Reflect.has(time, \"time\")) {\n            value = time;\n            time = value.time;\n        }\n        const ticks = this.toTicks(time);\n        let event;\n        if (value instanceof ToneEvent) {\n            event = value;\n            event.callback = this._tick.bind(this);\n        }\n        else {\n            event = new ToneEvent({\n                callback: this._tick.bind(this),\n                context: this.context,\n                value,\n            });\n        }\n        // the start offset\n        event.startOffset = ticks;\n        // initialize the values\n        event.set({\n            humanize: this.humanize,\n            loop: this.loop,\n            loopEnd: this.loopEnd,\n            loopStart: this.loopStart,\n            playbackRate: this.playbackRate,\n            probability: this.probability,\n        });\n        this._events.add(event);\n        // start the note if it should be played right now\n        this._restartEvent(event);\n        return this;\n    }\n    /**\n     * Restart the given event\n     */\n    _restartEvent(event) {\n        this._state.forEach((stateEvent) => {\n            if (stateEvent.state === \"started\") {\n                this._startNote(event, stateEvent.time, stateEvent.offset);\n            }\n            else {\n                // stop the note\n                event.stop(new TicksClass(this.context, stateEvent.time));\n            }\n        });\n    }\n    remove(time, value) {\n        // extract the parameters\n        if (isObject(time) && time.hasOwnProperty(\"time\")) {\n            value = time;\n            time = value.time;\n        }\n        time = this.toTicks(time);\n        this._events.forEach(event => {\n            if (event.startOffset === time) {\n                if (isUndef(value) || (isDefined(value) && event.value === value)) {\n                    this._events.delete(event);\n                    event.dispose();\n                }\n            }\n        });\n        return this;\n    }\n    /**\n     * Remove all of the notes from the group.\n     */\n    clear() {\n        this._forEach(event => event.dispose());\n        this._events.clear();\n        return this;\n    }\n    /**\n     * Cancel scheduled state change events: i.e. \"start\" and \"stop\".\n     * @param after The time after which to cancel the scheduled events.\n     */\n    cancel(after) {\n        this._forEach(event => event.cancel(after));\n        this._state.cancel(this.toTicks(after));\n        return this;\n    }\n    /**\n     * Iterate over all of the events\n     */\n    _forEach(callback) {\n        if (this._events) {\n            this._events.forEach(event => {\n                if (event instanceof Part) {\n                    event._forEach(callback);\n                }\n                else {\n                    callback(event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Set the attribute of all of the events\n     * @param  attr  the attribute to set\n     * @param  value      The value to set it to\n     */\n    _setAll(attr, value) {\n        this._forEach(event => {\n            event[attr] = value;\n        });\n    }\n    /**\n     * Internal tick method\n     * @param  time  The time of the event in seconds\n     */\n    _tick(time, value) {\n        if (!this.mute) {\n            this.callback(time, value);\n        }\n    }\n    /**\n     * Determine if the event should be currently looping\n     * given the loop boundries of this Part.\n     * @param  event  The event to test\n     */\n    _testLoopBoundries(event) {\n        if (this._loop && (event.startOffset < this._loopStart || event.startOffset >= this._loopEnd)) {\n            event.cancel(0);\n        }\n        else if (event.state === \"stopped\") {\n            // reschedule it if it's stopped\n            this._restartEvent(event);\n        }\n    }\n    get probability() {\n        return this._probability;\n    }\n    set probability(prob) {\n        this._probability = prob;\n        this._setAll(\"probability\", prob);\n    }\n    get humanize() {\n        return this._humanize;\n    }\n    set humanize(variation) {\n        this._humanize = variation;\n        this._setAll(\"humanize\", variation);\n    }\n    /**\n     * If the part should loop or not\n     * between Part.loopStart and\n     * Part.loopEnd. If set to true,\n     * the part will loop indefinitely,\n     * if set to a number greater than 1\n     * it will play a specific number of\n     * times, if set to false, 0 or 1, the\n     * part will only play once.\n     * @example\n     * const part = new Tone.Part();\n     * // loop the part 8 times\n     * part.loop = 8;\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        this._loop = loop;\n        this._forEach(event => {\n            event.loopStart = this.loopStart;\n            event.loopEnd = this.loopEnd;\n            event.loop = loop;\n            this._testLoopBoundries(event);\n        });\n    }\n    /**\n     * The loopEnd point determines when it will\n     * loop if Part.loop is true.\n     */\n    get loopEnd() {\n        return new TicksClass(this.context, this._loopEnd).toSeconds();\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = this.toTicks(loopEnd);\n        if (this._loop) {\n            this._forEach(event => {\n                event.loopEnd = loopEnd;\n                this._testLoopBoundries(event);\n            });\n        }\n    }\n    /**\n     * The loopStart point determines when it will\n     * loop if Part.loop is true.\n     */\n    get loopStart() {\n        return new TicksClass(this.context, this._loopStart).toSeconds();\n    }\n    set loopStart(loopStart) {\n        this._loopStart = this.toTicks(loopStart);\n        if (this._loop) {\n            this._forEach(event => {\n                event.loopStart = this.loopStart;\n                this._testLoopBoundries(event);\n            });\n        }\n    }\n    /**\n     * The playback rate of the part\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        this._setAll(\"playbackRate\", rate);\n    }\n    /**\n     * The number of scheduled notes in the part.\n     */\n    get length() {\n        return this._events.size;\n    }\n    dispose() {\n        super.dispose();\n        this.clear();\n        return this;\n    }\n}\n//# sourceMappingURL=Part.js.map","import { Loop } from \"./Loop\";\nimport { PatternGenerator } from \"./PatternGenerator\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { noOp } from \"../core/util/Interface\";\n/**\n * Pattern arpeggiates between the given notes\n * in a number of patterns.\n * @example\n * const pattern = new Tone.Pattern((time, note) => {\n * \t// the order of the notes passed in depends on the pattern\n * }, [\"C2\", \"D4\", \"E5\", \"A6\"], \"upDown\");\n * @category Event\n */\nexport class Pattern extends Loop {\n    constructor() {\n        super(optionsFromArguments(Pattern.getDefaults(), arguments, [\"callback\", \"values\", \"pattern\"]));\n        this.name = \"Pattern\";\n        const options = optionsFromArguments(Pattern.getDefaults(), arguments, [\"callback\", \"values\", \"pattern\"]);\n        this.callback = options.callback;\n        this._values = options.values;\n        this._pattern = PatternGenerator(options.values, options.pattern);\n        this._type = options.pattern;\n    }\n    static getDefaults() {\n        return Object.assign(Loop.getDefaults(), {\n            pattern: \"up\",\n            values: [],\n            callback: noOp,\n        });\n    }\n    /**\n     * Internal function called when the notes should be called\n     */\n    _tick(time) {\n        const value = this._pattern.next();\n        this._value = value.value;\n        this.callback(time, this._value);\n    }\n    /**\n     * The array of events.\n     */\n    get values() {\n        return this._values;\n    }\n    set values(val) {\n        this._values = val;\n        // reset the pattern\n        this.pattern = this._type;\n    }\n    /**\n     * The current value of the pattern.\n     */\n    get value() {\n        return this._value;\n    }\n    /**\n     * The pattern type. See Tone.CtrlPattern for the full list of patterns.\n     */\n    get pattern() {\n        return this._type;\n    }\n    set pattern(pattern) {\n        this._type = pattern;\n        this._pattern = PatternGenerator(this._values, this._type);\n    }\n}\n//# sourceMappingURL=Pattern.js.map","import { assert } from \"../core/util/Debug\";\nimport { clamp } from \"../core/util/Math\";\n/**\n * Start at the first value and go up to the last\n */\nfunction* upPatternGen(values) {\n    let index = 0;\n    while (index < values.length) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        index++;\n    }\n}\n/**\n * Start at the last value and go down to 0\n */\nfunction* downPatternGen(values) {\n    let index = values.length - 1;\n    while (index >= 0) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        index--;\n    }\n}\n/**\n * Infinitely yield the generator\n */\nfunction* infiniteGen(values, gen) {\n    while (true) {\n        yield* gen(values);\n    }\n}\n/**\n * Make sure that the index is in the given range\n */\nfunction clampToArraySize(index, values) {\n    return clamp(index, 0, values.length - 1);\n}\n/**\n * Alternate between two generators\n */\nfunction* alternatingGenerator(values, directionUp) {\n    let index = directionUp ? 0 : values.length - 1;\n    while (true) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        if (directionUp) {\n            index++;\n            if (index >= values.length - 1) {\n                directionUp = false;\n            }\n        }\n        else {\n            index--;\n            if (index <= 0) {\n                directionUp = true;\n            }\n        }\n    }\n}\n/**\n * Starting from the bottom move up 2, down 1\n */\nfunction* jumpUp(values) {\n    let index = 0;\n    let stepIndex = 0;\n    while (index < values.length) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        stepIndex++;\n        index += (stepIndex % 2 ? 2 : -1);\n    }\n}\n/**\n * Starting from the top move down 2, up 1\n */\nfunction* jumpDown(values) {\n    let index = values.length - 1;\n    let stepIndex = 0;\n    while (index >= 0) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        stepIndex++;\n        index += (stepIndex % 2 ? -2 : 1);\n    }\n}\n/**\n * Choose a random index each time\n */\nfunction* randomGen(values) {\n    while (true) {\n        const randomIndex = Math.floor(Math.random() * values.length);\n        yield values[randomIndex];\n    }\n}\n/**\n * Randomly go through all of the values once before choosing a new random order\n */\nfunction* randomOnce(values) {\n    // create an array of indices\n    const copy = [];\n    for (let i = 0; i < values.length; i++) {\n        copy.push(i);\n    }\n    while (copy.length > 0) {\n        // random choose an index, and then remove it so it's not chosen again\n        const randVal = copy.splice(Math.floor(copy.length * Math.random()), 1);\n        const index = clampToArraySize(randVal[0], values);\n        yield values[index];\n    }\n}\n/**\n * Randomly choose to walk up or down 1 index in the values array\n */\nfunction* randomWalk(values) {\n    // randomly choose a starting index in the values array\n    let index = Math.floor(Math.random() * values.length);\n    while (true) {\n        if (index === 0) {\n            index++; // at bottom of array, so force upward step\n        }\n        else if (index === values.length - 1) {\n            index--; // at top of array, so force downward step\n        }\n        else if (Math.random() < 0.5) { // else choose random downward or upward step\n            index--;\n        }\n        else {\n            index++;\n        }\n        yield values[index];\n    }\n}\n/**\n * PatternGenerator returns a generator which will iterate over the given array\n * of values and yield the items according to the passed in pattern\n * @param values An array of values to iterate over\n * @param pattern The name of the pattern use when iterating over\n * @param index Where to start in the offset of the values array\n */\nexport function* PatternGenerator(values, pattern = \"up\", index = 0) {\n    // safeguards\n    assert(values.length > 0, \"The array must have more than one value in it\");\n    switch (pattern) {\n        case \"up\":\n            yield* infiniteGen(values, upPatternGen);\n        case \"down\":\n            yield* infiniteGen(values, downPatternGen);\n        case \"upDown\":\n            yield* alternatingGenerator(values, true);\n        case \"downUp\":\n            yield* alternatingGenerator(values, false);\n        case \"alternateUp\":\n            yield* infiniteGen(values, jumpUp);\n        case \"alternateDown\":\n            yield* infiniteGen(values, jumpDown);\n        case \"random\":\n            yield* randomGen(values);\n        case \"randomOnce\":\n            yield* infiniteGen(values, randomOnce);\n        case \"randomWalk\":\n            yield* randomWalk(values);\n    }\n}\n//# sourceMappingURL=PatternGenerator.js.map","import { TicksClass } from \"../core/type/Ticks\";\nimport { omitFromObject, optionsFromArguments } from \"../core/util/Defaults\";\nimport { isArray, isString } from \"../core/util/TypeCheck\";\nimport { Part } from \"./Part\";\nimport { ToneEvent } from \"./ToneEvent\";\n/**\n * A sequence is an alternate notation of a part. Instead\n * of passing in an array of [time, event] pairs, pass\n * in an array of events which will be spaced at the\n * given subdivision. Sub-arrays will subdivide that beat\n * by the number of items are in the array.\n * Sequence notation inspiration from [Tidal](http://yaxu.org/tidal/)\n * @example\n * const synth = new Tone.Synth().toDestination();\n * const seq = new Tone.Sequence((time, note) => {\n * \tsynth.triggerAttackRelease(note, 0.1, time);\n * \t// subdivisions are given as subarrays\n * }, [\"C4\", [\"E4\", \"D4\", \"E4\"], \"G4\", [\"A4\", \"G4\"]]).start(0);\n * Tone.Transport.start();\n * @category Event\n */\nexport class Sequence extends ToneEvent {\n    constructor() {\n        super(optionsFromArguments(Sequence.getDefaults(), arguments, [\"callback\", \"events\", \"subdivision\"]));\n        this.name = \"Sequence\";\n        /**\n         * The object responsible for scheduling all of the events\n         */\n        this._part = new Part({\n            callback: this._seqCallback.bind(this),\n            context: this.context,\n        });\n        /**\n         * private reference to all of the sequence proxies\n         */\n        this._events = [];\n        /**\n         * The proxied array\n         */\n        this._eventsArray = [];\n        const options = optionsFromArguments(Sequence.getDefaults(), arguments, [\"callback\", \"events\", \"subdivision\"]);\n        this._subdivision = this.toTicks(options.subdivision);\n        this.events = options.events;\n        // set all of the values\n        this.loop = options.loop;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this.playbackRate = options.playbackRate;\n        this.probability = options.probability;\n        this.humanize = options.humanize;\n        this.mute = options.mute;\n        this.playbackRate = options.playbackRate;\n    }\n    static getDefaults() {\n        return Object.assign(omitFromObject(ToneEvent.getDefaults(), [\"value\"]), {\n            events: [],\n            loop: true,\n            loopEnd: 0,\n            loopStart: 0,\n            subdivision: \"8n\",\n        });\n    }\n    /**\n     * The internal callback for when an event is invoked\n     */\n    _seqCallback(time, value) {\n        if (value !== null) {\n            this.callback(time, value);\n        }\n    }\n    /**\n     * The sequence\n     */\n    get events() {\n        return this._events;\n    }\n    set events(s) {\n        this.clear();\n        this._eventsArray = s;\n        this._events = this._createSequence(this._eventsArray);\n        this._eventsUpdated();\n    }\n    /**\n     * Start the part at the given time.\n     * @param  time    When to start the part.\n     * @param  offset  The offset index to start at\n     */\n    start(time, offset) {\n        this._part.start(time, offset ? this._indexTime(offset) : offset);\n        return this;\n    }\n    /**\n     * Stop the part at the given time.\n     * @param  time  When to stop the part.\n     */\n    stop(time) {\n        this._part.stop(time);\n        return this;\n    }\n    /**\n     * The subdivision of the sequence. This can only be\n     * set in the constructor. The subdivision is the\n     * interval between successive steps.\n     */\n    get subdivision() {\n        return new TicksClass(this.context, this._subdivision).toSeconds();\n    }\n    /**\n     * Create a sequence proxy which can be monitored to create subsequences\n     */\n    _createSequence(array) {\n        return new Proxy(array, {\n            get: (target, property) => {\n                // property is index in this case\n                return target[property];\n            },\n            set: (target, property, value) => {\n                if (isString(property) && isFinite(parseInt(property, 10))) {\n                    if (isArray(value)) {\n                        target[property] = this._createSequence(value);\n                    }\n                    else {\n                        target[property] = value;\n                    }\n                }\n                else {\n                    target[property] = value;\n                }\n                this._eventsUpdated();\n                // return true to accept the changes\n                return true;\n            },\n        });\n    }\n    /**\n     * When the sequence has changed, all of the events need to be recreated\n     */\n    _eventsUpdated() {\n        this._part.clear();\n        this._rescheduleSequence(this._eventsArray, this._subdivision, this.startOffset);\n        // update the loopEnd\n        this.loopEnd = this.loopEnd;\n    }\n    /**\n     * reschedule all of the events that need to be rescheduled\n     */\n    _rescheduleSequence(sequence, subdivision, startOffset) {\n        sequence.forEach((value, index) => {\n            const eventOffset = index * (subdivision) + startOffset;\n            if (isArray(value)) {\n                this._rescheduleSequence(value, subdivision / value.length, eventOffset);\n            }\n            else {\n                const startTime = new TicksClass(this.context, eventOffset, \"i\").toSeconds();\n                this._part.add(startTime, value);\n            }\n        });\n    }\n    /**\n     * Get the time of the index given the Sequence's subdivision\n     * @param  index\n     * @return The time of that index\n     */\n    _indexTime(index) {\n        return new TicksClass(this.context, index * (this._subdivision) + this.startOffset).toSeconds();\n    }\n    /**\n     * Clear all of the events\n     */\n    clear() {\n        this._part.clear();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._part.dispose();\n        return this;\n    }\n    //-------------------------------------\n    // PROXY CALLS\n    //-------------------------------------\n    get loop() {\n        return this._part.loop;\n    }\n    set loop(l) {\n        this._part.loop = l;\n    }\n    /**\n     * The index at which the sequence should start looping\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(index) {\n        this._loopStart = index;\n        this._part.loopStart = this._indexTime(index);\n    }\n    /**\n     * The index at which the sequence should end looping\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(index) {\n        this._loopEnd = index;\n        if (index === 0) {\n            this._part.loopEnd = this._indexTime(this._eventsArray.length);\n        }\n        else {\n            this._part.loopEnd = this._indexTime(index);\n        }\n    }\n    get startOffset() {\n        return this._part.startOffset;\n    }\n    set startOffset(start) {\n        this._part.startOffset = start;\n    }\n    get playbackRate() {\n        return this._part.playbackRate;\n    }\n    set playbackRate(rate) {\n        this._part.playbackRate = rate;\n    }\n    get probability() {\n        return this._part.probability;\n    }\n    set probability(prob) {\n        this._part.probability = prob;\n    }\n    get progress() {\n        return this._part.progress;\n    }\n    get humanize() {\n        return this._part.humanize;\n    }\n    set humanize(variation) {\n        this._part.humanize = variation;\n    }\n    /**\n     * The number of scheduled events\n     */\n    get length() {\n        return this._part.length;\n    }\n}\n//# sourceMappingURL=Sequence.js.map","import \"../core/clock/Transport\";\nimport { ToneWithContext } from \"../core/context/ToneWithContext\";\nimport { TicksClass } from \"../core/type/Ticks\";\nimport { defaultArg, optionsFromArguments } from \"../core/util/Defaults\";\nimport { noOp } from \"../core/util/Interface\";\nimport { StateTimeline } from \"../core/util/StateTimeline\";\nimport { isBoolean, isNumber } from \"../core/util/TypeCheck\";\n/**\n * ToneEvent abstracts away this.context.transport.schedule and provides a schedulable\n * callback for a single or repeatable events along the timeline.\n *\n * @example\n * const synth = new Tone.PolySynth().toDestination();\n * const chordEvent = new Tone.ToneEvent(((time, chord) => {\n * \t// the chord as well as the exact time of the event\n * \t// are passed in as arguments to the callback function\n * \tsynth.triggerAttackRelease(chord, 0.5, time);\n * }), [\"D4\", \"E4\", \"F4\"]);\n * // start the chord at the beginning of the transport timeline\n * chordEvent.start();\n * // loop it every measure for 8 measures\n * chordEvent.loop = 8;\n * chordEvent.loopEnd = \"1m\";\n * @category Event\n */\nexport class ToneEvent extends ToneWithContext {\n    constructor() {\n        super(optionsFromArguments(ToneEvent.getDefaults(), arguments, [\"callback\", \"value\"]));\n        this.name = \"ToneEvent\";\n        /**\n         * Tracks the scheduled events\n         */\n        this._state = new StateTimeline(\"stopped\");\n        /**\n         * A delay time from when the event is scheduled to start\n         */\n        this._startOffset = 0;\n        const options = optionsFromArguments(ToneEvent.getDefaults(), arguments, [\"callback\", \"value\"]);\n        this._loop = options.loop;\n        this.callback = options.callback;\n        this.value = options.value;\n        this._loopStart = this.toTicks(options.loopStart);\n        this._loopEnd = this.toTicks(options.loopEnd);\n        this._playbackRate = options.playbackRate;\n        this._probability = options.probability;\n        this._humanize = options.humanize;\n        this.mute = options.mute;\n        this._playbackRate = options.playbackRate;\n        this._state.increasing = true;\n        // schedule the events for the first time\n        this._rescheduleEvents();\n    }\n    static getDefaults() {\n        return Object.assign(ToneWithContext.getDefaults(), {\n            callback: noOp,\n            humanize: false,\n            loop: false,\n            loopEnd: \"1m\",\n            loopStart: 0,\n            mute: false,\n            playbackRate: 1,\n            probability: 1,\n            value: null,\n        });\n    }\n    /**\n     * Reschedule all of the events along the timeline\n     * with the updated values.\n     * @param after Only reschedules events after the given time.\n     */\n    _rescheduleEvents(after = -1) {\n        // if no argument is given, schedules all of the events\n        this._state.forEachFrom(after, event => {\n            let duration;\n            if (event.state === \"started\") {\n                if (event.id !== -1) {\n                    this.context.transport.clear(event.id);\n                }\n                const startTick = event.time + Math.round(this.startOffset / this._playbackRate);\n                if (this._loop === true || isNumber(this._loop) && this._loop > 1) {\n                    duration = Infinity;\n                    if (isNumber(this._loop)) {\n                        duration = (this._loop) * this._getLoopDuration();\n                    }\n                    const nextEvent = this._state.getAfter(startTick);\n                    if (nextEvent !== null) {\n                        duration = Math.min(duration, nextEvent.time - startTick);\n                    }\n                    if (duration !== Infinity) {\n                        // schedule a stop since it's finite duration\n                        this._state.setStateAtTime(\"stopped\", startTick + duration + 1, { id: -1 });\n                        duration = new TicksClass(this.context, duration);\n                    }\n                    const interval = new TicksClass(this.context, this._getLoopDuration());\n                    event.id = this.context.transport.scheduleRepeat(this._tick.bind(this), interval, new TicksClass(this.context, startTick), duration);\n                }\n                else {\n                    event.id = this.context.transport.schedule(this._tick.bind(this), new TicksClass(this.context, startTick));\n                }\n            }\n        });\n    }\n    /**\n     * Returns the playback state of the note, either \"started\" or \"stopped\".\n     */\n    get state() {\n        return this._state.getValueAtTime(this.context.transport.ticks);\n    }\n    /**\n     * The start from the scheduled start time.\n     */\n    get startOffset() {\n        return this._startOffset;\n    }\n    set startOffset(offset) {\n        this._startOffset = offset;\n    }\n    /**\n     * The probability of the notes being triggered.\n     */\n    get probability() {\n        return this._probability;\n    }\n    set probability(prob) {\n        this._probability = prob;\n    }\n    /**\n     * If set to true, will apply small random variation\n     * to the callback time. If the value is given as a time, it will randomize\n     * by that amount.\n     * @example\n     * const event = new Tone.ToneEvent();\n     * event.humanize = true;\n     */\n    get humanize() {\n        return this._humanize;\n    }\n    set humanize(variation) {\n        this._humanize = variation;\n    }\n    /**\n     * Start the note at the given time.\n     * @param  time  When the event should start.\n     */\n    start(time) {\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) === \"stopped\") {\n            this._state.add({\n                id: -1,\n                state: \"started\",\n                time: ticks,\n            });\n            this._rescheduleEvents(ticks);\n        }\n        return this;\n    }\n    /**\n     * Stop the Event at the given time.\n     * @param  time  When the event should stop.\n     */\n    stop(time) {\n        this.cancel(time);\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) === \"started\") {\n            this._state.setStateAtTime(\"stopped\", ticks, { id: -1 });\n            const previousEvent = this._state.getBefore(ticks);\n            let reschedulTime = ticks;\n            if (previousEvent !== null) {\n                reschedulTime = previousEvent.time;\n            }\n            this._rescheduleEvents(reschedulTime);\n        }\n        return this;\n    }\n    /**\n     * Cancel all scheduled events greater than or equal to the given time\n     * @param  time  The time after which events will be cancel.\n     */\n    cancel(time) {\n        time = defaultArg(time, -Infinity);\n        const ticks = this.toTicks(time);\n        this._state.forEachFrom(ticks, event => {\n            this.context.transport.clear(event.id);\n        });\n        this._state.cancel(ticks);\n        return this;\n    }\n    /**\n     * The callback function invoker. Also\n     * checks if the Event is done playing\n     * @param  time  The time of the event in seconds\n     */\n    _tick(time) {\n        const ticks = this.context.transport.getTicksAtTime(time);\n        if (!this.mute && this._state.getValueAtTime(ticks) === \"started\") {\n            if (this.probability < 1 && Math.random() > this.probability) {\n                return;\n            }\n            if (this.humanize) {\n                let variation = 0.02;\n                if (!isBoolean(this.humanize)) {\n                    variation = this.toSeconds(this.humanize);\n                }\n                time += (Math.random() * 2 - 1) * variation;\n            }\n            this.callback(time, this.value);\n        }\n    }\n    /**\n     * Get the duration of the loop.\n     */\n    _getLoopDuration() {\n        return Math.round((this._loopEnd - this._loopStart) / this._playbackRate);\n    }\n    /**\n     * If the note should loop or not\n     * between ToneEvent.loopStart and\n     * ToneEvent.loopEnd. If set to true,\n     * the event will loop indefinitely,\n     * if set to a number greater than 1\n     * it will play a specific number of\n     * times, if set to false, 0 or 1, the\n     * part will only play once.\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        this._loop = loop;\n        this._rescheduleEvents();\n    }\n    /**\n     * The playback rate of the note. Defaults to 1.\n     * @example\n     * const note = new Tone.ToneEvent();\n     * note.loop = true;\n     * // repeat the note twice as fast\n     * note.playbackRate = 2;\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        this._rescheduleEvents();\n    }\n    /**\n     * The loopEnd point is the time the event will loop\n     * if ToneEvent.loop is true.\n     */\n    get loopEnd() {\n        return new TicksClass(this.context, this._loopEnd).toSeconds();\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = this.toTicks(loopEnd);\n        if (this._loop) {\n            this._rescheduleEvents();\n        }\n    }\n    /**\n     * The time when the loop should start.\n     */\n    get loopStart() {\n        return new TicksClass(this.context, this._loopStart).toSeconds();\n    }\n    set loopStart(loopStart) {\n        this._loopStart = this.toTicks(loopStart);\n        if (this._loop) {\n            this._rescheduleEvents();\n        }\n    }\n    /**\n     * The current progress of the loop interval.\n     * Returns 0 if the event is not started yet or\n     * it is not set to loop.\n     */\n    get progress() {\n        if (this._loop) {\n            const ticks = this.context.transport.ticks;\n            const lastEvent = this._state.get(ticks);\n            if (lastEvent !== null && lastEvent.state === \"started\") {\n                const loopDuration = this._getLoopDuration();\n                const progress = (ticks - lastEvent.time) % loopDuration;\n                return progress / loopDuration;\n            }\n            else {\n                return 0;\n            }\n        }\n        else {\n            return 0;\n        }\n    }\n    dispose() {\n        super.dispose();\n        this.cancel();\n        this._state.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneEvent.js.map","export * from \"./Loop\";\nexport * from \"./Part\";\nexport * from \"./Pattern\";\nexport * from \"./Sequence\";\nexport * from \"./ToneEvent\";\n//# sourceMappingURL=index.js.map","export { getContext, setContext } from \"./core/Global\";\nexport * from \"./classes\";\nexport * from \"./version\";\nimport { getContext } from \"./core/Global\";\nimport { ToneAudioBuffer } from \"./core/context/ToneAudioBuffer\";\nexport { start } from \"./core/Global\";\nexport { supported } from \"./core/context/AudioContext\";\n/**\n * The current audio context time of the global [[Context]].\n * See [[Context.now]]\n * @category Core\n */\nexport const now = getContext().now.bind(getContext());\n/**\n * The current audio context time of the global [[Context]] without the [[Context.lookAhead]]\n * See [[Context.immediate]]\n * @category Core\n */\nexport const immediate = getContext().immediate.bind(getContext());\n/**\n * The Transport object belonging to the global Tone.js Context.\n * See [[Transport]]\n * @category Core\n */\nexport const Transport = getContext().transport;\n/**\n * The Destination (output) belonging to the global Tone.js Context.\n * See [[Destination]]\n * @category Core\n */\nexport const Destination = getContext().destination;\n/**\n * The [[Listener]] belonging to the global Tone.js Context.\n * @category Core\n */\nexport const Listener = getContext().listener;\n/**\n * Draw is used to synchronize the draw frame with the Transport's callbacks.\n * See [[Draw]]\n * @category Core\n */\nexport const Draw = getContext().draw;\n/**\n * A reference to the global context\n * See [[Context]]\n * @category Core\n */\nexport const context = getContext();\n/**\n * Promise which resolves when all of the loading promises are resolved.\n * Alias for static [[ToneAudioBuffer.loaded]] method.\n * @category Core\n */\nexport const loaded = ToneAudioBuffer.loaded.bind(ToneAudioBuffer);\n// this fills in name changes from 13.x to 14.x\nimport { ToneAudioBuffers } from \"./core/context/ToneAudioBuffers\";\nimport { ToneBufferSource } from \"./source/buffer/ToneBufferSource\";\nexport const Buffer = ToneAudioBuffer;\nexport const Buffers = ToneAudioBuffers;\nexport const BufferSource = ToneBufferSource;\n//# sourceMappingURL=index.js.map","import { AudioToGain } from \"../signal/AudioToGain\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { ModulationSynth } from \"./ModulationSynth\";\n/**\n * AMSynth uses the output of one Tone.Synth to modulate the\n * amplitude of another Tone.Synth. The harmonicity (the ratio between\n * the two signals) affects the timbre of the output signal greatly.\n * Read more about Amplitude Modulation Synthesis on\n * [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).\n *\n * @example\n * const synth = new Tone.AMSynth().toDestination();\n * synth.triggerAttackRelease(\"C4\", \"4n\");\n *\n * @category Instrument\n */\nexport class AMSynth extends ModulationSynth {\n    constructor() {\n        super(optionsFromArguments(AMSynth.getDefaults(), arguments));\n        this.name = \"AMSynth\";\n        this._modulationScale = new AudioToGain({\n            context: this.context,\n        });\n        // control the two voices frequency\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.detune.fan(this._carrier.detune, this._modulator.detune);\n        this._modulator.chain(this._modulationScale, this._modulationNode.gain);\n        this._carrier.chain(this._modulationNode, this.output);\n    }\n    dispose() {\n        super.dispose();\n        this._modulationScale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AMSynth.js.map","import { Monophonic } from \"./Monophonic\";\nimport { MonoSynth } from \"./MonoSynth\";\nimport { Signal } from \"../signal/Signal\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { LFO } from \"../source/oscillator/LFO\";\nimport { Gain, } from \"../core/context/Gain\";\nimport { Multiply } from \"../signal/Multiply\";\nimport { deepMerge, omitFromObject, optionsFromArguments } from \"../core/util/Defaults\";\n/**\n * DuoSynth is a monophonic synth composed of two [[MonoSynths]] run in parallel with control over the\n * frequency ratio between the two voices and vibrato effect.\n * @example\n * const duoSynth = new Tone.DuoSynth().toDestination();\n * duoSynth.triggerAttackRelease(\"C4\", \"2n\");\n * @category Instrument\n */\nexport class DuoSynth extends Monophonic {\n    constructor() {\n        super(optionsFromArguments(DuoSynth.getDefaults(), arguments));\n        this.name = \"DuoSynth\";\n        const options = optionsFromArguments(DuoSynth.getDefaults(), arguments);\n        this.voice0 = new MonoSynth(Object.assign(options.voice0, {\n            context: this.context,\n            onsilence: () => this.onsilence(this)\n        }));\n        this.voice1 = new MonoSynth(Object.assign(options.voice1, {\n            context: this.context,\n        }));\n        this.harmonicity = new Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        this._vibrato = new LFO({\n            frequency: options.vibratoRate,\n            context: this.context,\n            min: -50,\n            max: 50\n        });\n        // start the vibrato immediately\n        this._vibrato.start();\n        this.vibratoRate = this._vibrato.frequency;\n        this._vibratoGain = new Gain({\n            context: this.context,\n            units: \"normalRange\",\n            gain: options.vibratoAmount\n        });\n        this.vibratoAmount = this._vibratoGain.gain;\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: 440\n        });\n        this.detune = new Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune\n        });\n        // control the two voices frequency\n        this.frequency.connect(this.voice0.frequency);\n        this.frequency.chain(this.harmonicity, this.voice1.frequency);\n        this._vibrato.connect(this._vibratoGain);\n        this._vibratoGain.fan(this.voice0.detune, this.voice1.detune);\n        this.detune.fan(this.voice0.detune, this.voice1.detune);\n        this.voice0.connect(this.output);\n        this.voice1.connect(this.output);\n        readOnly(this, [\"voice0\", \"voice1\", \"frequency\", \"vibratoAmount\", \"vibratoRate\"]);\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.voice0.envelope.getValueAtTime(time) + this.voice1.envelope.getValueAtTime(time);\n    }\n    static getDefaults() {\n        return deepMerge(Monophonic.getDefaults(), {\n            vibratoAmount: 0.5,\n            vibratoRate: 5,\n            harmonicity: 1.5,\n            voice0: deepMerge(omitFromObject(MonoSynth.getDefaults(), Object.keys(Monophonic.getDefaults())), {\n                filterEnvelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                },\n                envelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                }\n            }),\n            voice1: deepMerge(omitFromObject(MonoSynth.getDefaults(), Object.keys(Monophonic.getDefaults())), {\n                filterEnvelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                },\n                envelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                }\n            }),\n        });\n    }\n    /**\n     * Trigger the attack portion of the note\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // @ts-ignore\n        this.voice0._triggerEnvelopeAttack(time, velocity);\n        // @ts-ignore\n        this.voice1._triggerEnvelopeAttack(time, velocity);\n    }\n    /**\n     * Trigger the release portion of the note\n     */\n    _triggerEnvelopeRelease(time) {\n        // @ts-ignore\n        this.voice0._triggerEnvelopeRelease(time);\n        // @ts-ignore\n        this.voice1._triggerEnvelopeRelease(time);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.voice0.dispose();\n        this.voice1.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._vibrato.dispose();\n        this.vibratoRate.dispose();\n        this._vibratoGain.dispose();\n        this.harmonicity.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=DuoSynth.js.map","import { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Multiply } from \"../signal/Multiply\";\nimport { ModulationSynth } from \"./ModulationSynth\";\n/**\n * FMSynth is composed of two Tone.Synths where one Tone.Synth modulates\n * the frequency of a second Tone.Synth. A lot of spectral content\n * can be explored using the modulationIndex parameter. Read more about\n * frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).\n *\n * @example\n * const fmSynth = new Tone.FMSynth().toDestination();\n * fmSynth.triggerAttackRelease(\"C5\", \"4n\");\n *\n * @category Instrument\n */\nexport class FMSynth extends ModulationSynth {\n    constructor() {\n        super(optionsFromArguments(FMSynth.getDefaults(), arguments));\n        this.name = \"FMSynth\";\n        const options = optionsFromArguments(FMSynth.getDefaults(), arguments);\n        this.modulationIndex = new Multiply({\n            context: this.context,\n            value: options.modulationIndex,\n        });\n        // control the two voices frequency\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.frequency.chain(this.modulationIndex, this._modulationNode);\n        this.detune.fan(this._carrier.detune, this._modulator.detune);\n        this._modulator.connect(this._modulationNode.gain);\n        this._modulationNode.connect(this._carrier.frequency);\n        this._carrier.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(ModulationSynth.getDefaults(), {\n            modulationIndex: 10,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.modulationIndex.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FMSynth.js.map","import { Volume } from \"../component/channel/Volume\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Base-class for all instruments\n */\nexport class Instrument extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Instrument.getDefaults(), arguments));\n        /**\n         * Keep track of all events scheduled to the transport\n         * when the instrument is 'synced'\n         */\n        this._scheduledEvents = [];\n        /**\n         * If the instrument is currently synced\n         */\n        this._synced = false;\n        this._original_triggerAttack = this.triggerAttack;\n        this._original_triggerRelease = this.triggerRelease;\n        const options = optionsFromArguments(Instrument.getDefaults(), arguments);\n        this._volume = this.output = new Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        readOnly(this, \"volume\");\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            volume: 0,\n        });\n    }\n    /**\n     * Sync the instrument to the Transport. All subsequent calls of\n     * [[triggerAttack]] and [[triggerRelease]] will be scheduled along the transport.\n     * @example\n     * const fmSynth = new Tone.FMSynth().toDestination();\n     * fmSynth.volume.value = -6;\n     * fmSynth.sync();\n     * // schedule 3 notes when the transport first starts\n     * fmSynth.triggerAttackRelease(\"C4\", \"8n\", 0);\n     * fmSynth.triggerAttackRelease(\"E4\", \"8n\", \"8n\");\n     * fmSynth.triggerAttackRelease(\"G4\", \"8n\", \"4n\");\n     * // start the transport to hear the notes\n     * Tone.Transport.start();\n     */\n    sync() {\n        if (!this._synced) {\n            this._synced = true;\n            this._syncMethod(\"triggerAttack\", 1);\n            this._syncMethod(\"triggerRelease\", 0);\n        }\n        return this;\n    }\n    /**\n     * Wrap the given method so that it can be synchronized\n     * @param method Which method to wrap and sync\n     * @param  timePosition What position the time argument appears in\n     */\n    _syncMethod(method, timePosition) {\n        const originalMethod = this[\"_original_\" + method] = this[method];\n        this[method] = (...args) => {\n            const time = args[timePosition];\n            const id = this.context.transport.schedule((t) => {\n                args[timePosition] = t;\n                originalMethod.apply(this, args);\n            }, time);\n            this._scheduledEvents.push(id);\n        };\n    }\n    /**\n     * Unsync the instrument from the Transport\n     */\n    unsync() {\n        this._scheduledEvents.forEach(id => this.context.transport.clear(id));\n        this._scheduledEvents = [];\n        if (this._synced) {\n            this._synced = false;\n            this.triggerAttack = this._original_triggerAttack;\n            this.triggerRelease = this._original_triggerRelease;\n        }\n        return this;\n    }\n    /**\n     * Trigger the attack and then the release after the duration.\n     * @param  note     The note to trigger.\n     * @param  duration How long the note should be held for before\n     *                         triggering the release. This value must be greater than 0.\n     * @param time  When the note should be triggered.\n     * @param  velocity The velocity the note should be triggered at.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * // trigger \"C4\" for the duration of an 8th note\n     * synth.triggerAttackRelease(\"C4\", \"8n\");\n     */\n    triggerAttackRelease(note, duration, time, velocity) {\n        const computedTime = this.toSeconds(time);\n        const computedDuration = this.toSeconds(duration);\n        this.triggerAttack(note, computedTime, velocity);\n        this.triggerRelease(computedTime + computedDuration);\n        return this;\n    }\n    /**\n     * clean up\n     * @returns {Instrument} this\n     */\n    dispose() {\n        super.dispose();\n        this._volume.dispose();\n        this.unsync();\n        this._scheduledEvents = [];\n        return this;\n    }\n}\n//# sourceMappingURL=Instrument.js.map","import { __decorate } from \"tslib\";\nimport { FrequencyClass } from \"../core/type/Frequency\";\nimport { deepMerge, optionsFromArguments } from \"../core/util/Defaults\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { Monophonic } from \"./Monophonic\";\nimport { Synth } from \"./Synth\";\nimport { range, timeRange } from \"../core/util/Decorator\";\n/**\n * MembraneSynth makes kick and tom sounds using a single oscillator\n * with an amplitude envelope and frequency ramp. A Tone.OmniOscillator\n * is routed through a Tone.AmplitudeEnvelope to the output. The drum\n * quality of the sound comes from the frequency envelope applied\n * during MembraneSynth.triggerAttack(note). The frequency envelope\n * starts at <code>note * .octaves</code> and ramps to <code>note</code>\n * over the duration of <code>.pitchDecay</code>.\n * @example\n * const synth = new Tone.MembraneSynth().toDestination();\n * synth.triggerAttackRelease(\"C2\", \"8n\");\n * @category Instrument\n */\nexport class MembraneSynth extends Synth {\n    constructor() {\n        super(optionsFromArguments(MembraneSynth.getDefaults(), arguments));\n        this.name = \"MembraneSynth\";\n        /**\n         * Portamento is ignored in this synth. use pitch decay instead.\n         */\n        this.portamento = 0;\n        const options = optionsFromArguments(MembraneSynth.getDefaults(), arguments);\n        this.pitchDecay = options.pitchDecay;\n        this.octaves = options.octaves;\n        readOnly(this, [\"oscillator\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return deepMerge(Monophonic.getDefaults(), Synth.getDefaults(), {\n            envelope: {\n                attack: 0.001,\n                attackCurve: \"exponential\",\n                decay: 0.4,\n                release: 1.4,\n                sustain: 0.01,\n            },\n            octaves: 10,\n            oscillator: {\n                type: \"sine\",\n            },\n            pitchDecay: 0.05,\n        });\n    }\n    setNote(note, time) {\n        const seconds = this.toSeconds(time);\n        const hertz = this.toFrequency(note instanceof FrequencyClass ? note.toFrequency() : note);\n        const maxNote = hertz * this.octaves;\n        this.oscillator.frequency.setValueAtTime(maxNote, seconds);\n        this.oscillator.frequency.exponentialRampToValueAtTime(hertz, seconds + this.toSeconds(this.pitchDecay));\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        return this;\n    }\n}\n__decorate([\n    range(0)\n], MembraneSynth.prototype, \"octaves\", void 0);\n__decorate([\n    timeRange(0)\n], MembraneSynth.prototype, \"pitchDecay\", void 0);\n//# sourceMappingURL=MembraneSynth.js.map","import { Envelope } from \"../component/envelope/Envelope\";\nimport { Filter } from \"../component/filter/Filter\";\nimport { Gain } from \"../core/context/Gain\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { deepMerge, omitFromObject, optionsFromArguments } from \"../core/util/Defaults\";\nimport { noOp } from \"../core/util/Interface\";\nimport { Multiply } from \"../signal/Multiply\";\nimport { Scale } from \"../signal/Scale\";\nimport { Signal } from \"../signal/Signal\";\nimport { FMOscillator } from \"../source/oscillator/FMOscillator\";\nimport { Monophonic } from \"./Monophonic\";\n/**\n * Inharmonic ratio of frequencies based on the Roland TR-808\n * Taken from https://ccrma.stanford.edu/papers/tr-808-cymbal-physically-informed-circuit-bendable-digital-model\n */\nconst inharmRatios = [1.0, 1.483, 1.932, 2.546, 2.630, 3.897];\n/**\n * A highly inharmonic and spectrally complex source with a highpass filter\n * and amplitude envelope which is good for making metallophone sounds.\n * Based on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).\n * Inspiration from [Sound on Sound](https://shorturl.at/rSZ12).\n * @category Instrument\n */\nexport class MetalSynth extends Monophonic {\n    constructor() {\n        super(optionsFromArguments(MetalSynth.getDefaults(), arguments));\n        this.name = \"MetalSynth\";\n        /**\n         * The array of FMOscillators\n         */\n        this._oscillators = [];\n        /**\n         * The frequency multipliers\n         */\n        this._freqMultipliers = [];\n        const options = optionsFromArguments(MetalSynth.getDefaults(), arguments);\n        this.detune = new Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n        });\n        this._amplitude = new Gain({\n            context: this.context,\n            gain: 0,\n        }).connect(this.output);\n        this._highpass = new Filter({\n            // Q: -3.0102999566398125,\n            Q: 0,\n            context: this.context,\n            type: \"highpass\",\n        }).connect(this._amplitude);\n        for (let i = 0; i < inharmRatios.length; i++) {\n            const osc = new FMOscillator({\n                context: this.context,\n                harmonicity: options.harmonicity,\n                modulationIndex: options.modulationIndex,\n                modulationType: \"square\",\n                onstop: i === 0 ? () => this.onsilence(this) : noOp,\n                type: \"square\",\n            });\n            osc.connect(this._highpass);\n            this._oscillators[i] = osc;\n            const mult = new Multiply({\n                context: this.context,\n                value: inharmRatios[i],\n            });\n            this._freqMultipliers[i] = mult;\n            this.frequency.chain(mult, osc.frequency);\n            this.detune.connect(osc.detune);\n        }\n        this._filterFreqScaler = new Scale({\n            context: this.context,\n            max: 7000,\n            min: this.toFrequency(options.resonance),\n        });\n        this.envelope = new Envelope({\n            attack: options.envelope.attack,\n            attackCurve: \"linear\",\n            context: this.context,\n            decay: options.envelope.decay,\n            release: options.envelope.release,\n            sustain: 0,\n        });\n        this.envelope.chain(this._filterFreqScaler, this._highpass.frequency);\n        this.envelope.connect(this._amplitude.gain);\n        // set the octaves\n        this._octaves = options.octaves;\n        this.octaves = options.octaves;\n    }\n    static getDefaults() {\n        return deepMerge(Monophonic.getDefaults(), {\n            envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {\n                attack: 0.001,\n                decay: 1.4,\n                release: 0.2,\n            }),\n            harmonicity: 5.1,\n            modulationIndex: 32,\n            octaves: 1.5,\n            resonance: 4000,\n        });\n    }\n    /**\n     * Trigger the attack.\n     * @param time When the attack should be triggered.\n     * @param velocity The velocity that the envelope should be triggered at.\n     */\n    _triggerEnvelopeAttack(time, velocity = 1) {\n        this.envelope.triggerAttack(time, velocity);\n        this._oscillators.forEach(osc => osc.start(time));\n        if (this.envelope.sustain === 0) {\n            this._oscillators.forEach(osc => {\n                osc.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));\n            });\n        }\n        return this;\n    }\n    /**\n     * Trigger the release of the envelope.\n     * @param time When the release should be triggered.\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this._oscillators.forEach(osc => osc.stop(time + this.toSeconds(this.envelope.release)));\n        return this;\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    /**\n     * The modulationIndex of the oscillators which make up the source.\n     * see [[FMOscillator.modulationIndex]]\n     * @min 1\n     * @max 100\n     */\n    get modulationIndex() {\n        return this._oscillators[0].modulationIndex.value;\n    }\n    set modulationIndex(val) {\n        this._oscillators.forEach(osc => (osc.modulationIndex.value = val));\n    }\n    /**\n     * The harmonicity of the oscillators which make up the source.\n     * see Tone.FMOscillator.harmonicity\n     * @min 0.1\n     * @max 10\n     */\n    get harmonicity() {\n        return this._oscillators[0].harmonicity.value;\n    }\n    set harmonicity(val) {\n        this._oscillators.forEach(osc => (osc.harmonicity.value = val));\n    }\n    /**\n     * The lower level of the highpass filter which is attached to the envelope.\n     * This value should be between [0, 7000]\n     * @min 0\n     * @max 7000\n     */\n    get resonance() {\n        return this._filterFreqScaler.min;\n    }\n    set resonance(val) {\n        this._filterFreqScaler.min = this.toFrequency(val);\n        this.octaves = this._octaves;\n    }\n    /**\n     * The number of octaves above the \"resonance\" frequency\n     * that the filter ramps during the attack/decay envelope\n     * @min 0\n     * @max 8\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(val) {\n        this._octaves = val;\n        this._filterFreqScaler.max = this._filterFreqScaler.min * Math.pow(2, val);\n    }\n    dispose() {\n        super.dispose();\n        this._oscillators.forEach(osc => osc.dispose());\n        this._freqMultipliers.forEach(freqMult => freqMult.dispose());\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._filterFreqScaler.dispose();\n        this._amplitude.dispose();\n        this.envelope.dispose();\n        this._highpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MetalSynth.js.map","import { Signal } from \"../signal/Signal\";\nimport { Multiply } from \"../signal/Multiply\";\nimport { Gain } from \"../core/context/Gain\";\nimport { Envelope } from \"../component/envelope/Envelope\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { Monophonic } from \"./Monophonic\";\nimport { OmniOscillator } from \"../source/oscillator/OmniOscillator\";\nimport { Source } from \"../source/Source\";\nimport { Synth } from \"./Synth\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { omitFromObject, optionsFromArguments } from \"../core/util/Defaults\";\n/**\n * Base class for both AM and FM synths\n */\nexport class ModulationSynth extends Monophonic {\n    constructor() {\n        super(optionsFromArguments(ModulationSynth.getDefaults(), arguments));\n        this.name = \"ModulationSynth\";\n        const options = optionsFromArguments(ModulationSynth.getDefaults(), arguments);\n        this._carrier = new Synth({\n            context: this.context,\n            oscillator: options.oscillator,\n            envelope: options.envelope,\n            onsilence: () => this.onsilence(this),\n            volume: -10,\n        });\n        this._modulator = new Synth({\n            context: this.context,\n            oscillator: options.modulation,\n            envelope: options.modulationEnvelope,\n            volume: -10,\n        });\n        this.oscillator = this._carrier.oscillator;\n        this.envelope = this._carrier.envelope;\n        this.modulation = this._modulator.oscillator;\n        this.modulationEnvelope = this._modulator.envelope;\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n        });\n        this.detune = new Signal({\n            context: this.context,\n            value: options.detune,\n            units: \"cents\"\n        });\n        this.harmonicity = new Multiply({\n            context: this.context,\n            value: options.harmonicity,\n            minValue: 0,\n        });\n        this._modulationNode = new Gain({\n            context: this.context,\n            gain: 0,\n        });\n        readOnly(this, [\"frequency\", \"harmonicity\", \"oscillator\", \"envelope\", \"modulation\", \"modulationEnvelope\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Monophonic.getDefaults(), {\n            harmonicity: 3,\n            oscillator: Object.assign(omitFromObject(OmniOscillator.getDefaults(), [\n                ...Object.keys(Source.getDefaults()),\n                \"frequency\",\n                \"detune\"\n            ]), {\n                type: \"sine\"\n            }),\n            envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {\n                attack: 0.01,\n                decay: 0.01,\n                sustain: 1,\n                release: 0.5\n            }),\n            modulation: Object.assign(omitFromObject(OmniOscillator.getDefaults(), [\n                ...Object.keys(Source.getDefaults()),\n                \"frequency\",\n                \"detune\"\n            ]), {\n                type: \"square\"\n            }),\n            modulationEnvelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {\n                attack: 0.5,\n                decay: 0.0,\n                sustain: 1,\n                release: 0.5\n            })\n        });\n    }\n    /**\n     * Trigger the attack portion of the note\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // @ts-ignore\n        this._carrier._triggerEnvelopeAttack(time, velocity);\n        // @ts-ignore\n        this._modulator._triggerEnvelopeAttack(time, velocity);\n    }\n    /**\n     * Trigger the release portion of the note\n     */\n    _triggerEnvelopeRelease(time) {\n        // @ts-ignore\n        this._carrier._triggerEnvelopeRelease(time);\n        // @ts-ignore\n        this._modulator._triggerEnvelopeRelease(time);\n        return this;\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    dispose() {\n        super.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this.harmonicity.dispose();\n        this._modulationNode.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ModulationSynth.js.map","import { AmplitudeEnvelope } from \"../component/envelope/AmplitudeEnvelope\";\nimport { Envelope } from \"../component/envelope/Envelope\";\nimport { Filter } from \"../component/filter/Filter\";\nimport { omitFromObject, optionsFromArguments } from \"../core/util/Defaults\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { Monophonic } from \"../instrument/Monophonic\";\nimport { OmniOscillator } from \"../source/oscillator/OmniOscillator\";\nimport { Source } from \"../source/Source\";\nimport { FrequencyEnvelope } from \"../component/envelope/FrequencyEnvelope\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\n/**\n * MonoSynth is composed of one `oscillator`, one `filter`, and two `envelopes`.\n * The amplitude of the Oscillator and the cutoff frequency of the\n * Filter are controlled by Envelopes.\n * <img src=\"https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240\">\n * @example\n * const synth = new Tone.MonoSynth({\n * \toscillator: {\n * \t\ttype: \"square\"\n * \t},\n * \tenvelope: {\n * \t\tattack: 0.1\n * \t}\n * }).toDestination();\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Instrument\n */\nexport class MonoSynth extends Monophonic {\n    constructor() {\n        super(optionsFromArguments(MonoSynth.getDefaults(), arguments));\n        this.name = \"MonoSynth\";\n        const options = optionsFromArguments(MonoSynth.getDefaults(), arguments);\n        this.oscillator = new OmniOscillator(Object.assign(options.oscillator, {\n            context: this.context,\n            detune: options.detune,\n            onstop: () => this.onsilence(this),\n        }));\n        this.frequency = this.oscillator.frequency;\n        this.detune = this.oscillator.detune;\n        this.filter = new Filter(Object.assign(options.filter, { context: this.context }));\n        this.filterEnvelope = new FrequencyEnvelope(Object.assign(options.filterEnvelope, { context: this.context }));\n        this.envelope = new AmplitudeEnvelope(Object.assign(options.envelope, { context: this.context }));\n        // connect the oscillators to the output\n        this.oscillator.chain(this.filter, this.envelope, this.output);\n        // connect the filter envelope\n        this.filterEnvelope.connect(this.filter.frequency);\n        readOnly(this, [\"oscillator\", \"frequency\", \"detune\", \"filter\", \"filterEnvelope\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Monophonic.getDefaults(), {\n            envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {\n                attack: 0.005,\n                decay: 0.1,\n                release: 1,\n                sustain: 0.9,\n            }),\n            filter: Object.assign(omitFromObject(Filter.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {\n                Q: 1,\n                rolloff: -12,\n                type: \"lowpass\",\n            }),\n            filterEnvelope: Object.assign(omitFromObject(FrequencyEnvelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {\n                attack: 0.6,\n                baseFrequency: 200,\n                decay: 0.2,\n                exponent: 2,\n                octaves: 3,\n                release: 2,\n                sustain: 0.5,\n            }),\n            oscillator: Object.assign(omitFromObject(OmniOscillator.getDefaults(), Object.keys(Source.getDefaults())), {\n                type: \"sawtooth\",\n            }),\n        });\n    }\n    /**\n     * start the attack portion of the envelope\n     * @param time the time the attack should start\n     * @param velocity the velocity of the note (0-1)\n     */\n    _triggerEnvelopeAttack(time, velocity = 1) {\n        this.envelope.triggerAttack(time, velocity);\n        this.filterEnvelope.triggerAttack(time);\n        this.oscillator.start(time);\n        if (this.envelope.sustain === 0) {\n            const computedAttack = this.toSeconds(this.envelope.attack);\n            const computedDecay = this.toSeconds(this.envelope.decay);\n            this.oscillator.stop(time + computedAttack + computedDecay);\n        }\n    }\n    /**\n     * start the release portion of the envelope\n     * @param time the time the release should start\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this.filterEnvelope.triggerRelease(time);\n        this.oscillator.stop(time + this.toSeconds(this.envelope.release));\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    dispose() {\n        super.dispose();\n        this.oscillator.dispose();\n        this.envelope.dispose();\n        this.filterEnvelope.dispose();\n        this.filter.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MonoSynth.js.map","import { __decorate } from \"tslib\";\nimport { FrequencyClass } from \"../core/type/Frequency\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { noOp } from \"../core/util/Interface\";\nimport { Instrument } from \"../instrument/Instrument\";\nimport { timeRange } from \"../core/util/Decorator\";\n/**\n * Abstract base class for other monophonic instruments to extend.\n */\nexport class Monophonic extends Instrument {\n    constructor() {\n        super(optionsFromArguments(Monophonic.getDefaults(), arguments));\n        const options = optionsFromArguments(Monophonic.getDefaults(), arguments);\n        this.portamento = options.portamento;\n        this.onsilence = options.onsilence;\n    }\n    static getDefaults() {\n        return Object.assign(Instrument.getDefaults(), {\n            detune: 0,\n            onsilence: noOp,\n            portamento: 0,\n        });\n    }\n    /**\n     * Trigger the attack of the note optionally with a given velocity.\n     * @param  note The note to trigger.\n     * @param  time When the note should start.\n     * @param  velocity The velocity scaler determines how \"loud\" the note will be triggered.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * // trigger the note a half second from now at half velocity\n     * synth.triggerAttack(\"C4\", \"+0.5\", 0.5);\n     */\n    triggerAttack(note, time, velocity = 1) {\n        this.log(\"triggerAttack\", note, time, velocity);\n        const seconds = this.toSeconds(time);\n        this._triggerEnvelopeAttack(seconds, velocity);\n        this.setNote(note, seconds);\n        return this;\n    }\n    /**\n     * Trigger the release portion of the envelope\n     * @param  time If no time is given, the release happens immediatly\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * synth.triggerAttack(\"C4\");\n     * // trigger the release a second from now\n     * synth.triggerRelease(\"+1\");\n     */\n    triggerRelease(time) {\n        this.log(\"triggerRelease\", time);\n        const seconds = this.toSeconds(time);\n        this._triggerEnvelopeRelease(seconds);\n        return this;\n    }\n    /**\n     * Set the note at the given time. If no time is given, the note\n     * will set immediately.\n     * @param note The note to change to.\n     * @param  time The time when the note should be set.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * synth.triggerAttack(\"C4\");\n     * // change to F#6 in one quarter note from now.\n     * synth.setNote(\"F#6\", \"+4n\");\n     */\n    setNote(note, time) {\n        const computedTime = this.toSeconds(time);\n        const computedFrequency = note instanceof FrequencyClass ? note.toFrequency() : note;\n        if (this.portamento > 0 && this.getLevelAtTime(computedTime) > 0.05) {\n            const portTime = this.toSeconds(this.portamento);\n            this.frequency.exponentialRampTo(computedFrequency, portTime, computedTime);\n        }\n        else {\n            this.frequency.setValueAtTime(computedFrequency, computedTime);\n        }\n        return this;\n    }\n}\n__decorate([\n    timeRange(0)\n], Monophonic.prototype, \"portamento\", void 0);\n//# sourceMappingURL=Monophonic.js.map","import { AmplitudeEnvelope } from \"../component/envelope/AmplitudeEnvelope\";\nimport { omitFromObject, optionsFromArguments } from \"../core/util/Defaults\";\nimport { Noise } from \"../source/Noise\";\nimport { Instrument } from \"./Instrument\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { Envelope } from \"../component/envelope/Envelope\";\nimport { Source } from \"../source/Source\";\n/**\n * Tone.NoiseSynth is composed of [[Noise]] through an [[AmplitudeEnvelope]].\n * ```\n * +-------+   +-------------------+\n * | Noise +>--> AmplitudeEnvelope +>--> Output\n * +-------+   +-------------------+\n * ```\n * @example\n * const noiseSynth = new Tone.NoiseSynth().toDestination();\n * noiseSynth.triggerAttackRelease(\"8n\", 0.05);\n * @category Instrument\n */\nexport class NoiseSynth extends Instrument {\n    constructor() {\n        super(optionsFromArguments(NoiseSynth.getDefaults(), arguments));\n        this.name = \"NoiseSynth\";\n        const options = optionsFromArguments(NoiseSynth.getDefaults(), arguments);\n        this.noise = new Noise(Object.assign({\n            context: this.context,\n        }, options.noise));\n        this.envelope = new AmplitudeEnvelope(Object.assign({\n            context: this.context,\n        }, options.envelope));\n        // connect the noise to the output\n        this.noise.chain(this.envelope, this.output);\n    }\n    static getDefaults() {\n        return Object.assign(Instrument.getDefaults(), {\n            envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {\n                decay: 0.1,\n                sustain: 0.0,\n            }),\n            noise: Object.assign(omitFromObject(Noise.getDefaults(), Object.keys(Source.getDefaults())), {\n                type: \"white\",\n            }),\n        });\n    }\n    /**\n     * Start the attack portion of the envelopes. Unlike other\n     * instruments, Tone.NoiseSynth doesn't have a note.\n     * @example\n     * const noiseSynth = new Tone.NoiseSynth().toDestination();\n     * noiseSynth.triggerAttack();\n     */\n    triggerAttack(time, velocity = 1) {\n        time = this.toSeconds(time);\n        // the envelopes\n        this.envelope.triggerAttack(time, velocity);\n        // start the noise\n        this.noise.start(time);\n        if (this.envelope.sustain === 0) {\n            this.noise.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));\n        }\n        return this;\n    }\n    /**\n     * Start the release portion of the envelopes.\n     */\n    triggerRelease(time) {\n        time = this.toSeconds(time);\n        this.envelope.triggerRelease(time);\n        this.noise.stop(time + this.toSeconds(this.envelope.release));\n        return this;\n    }\n    sync() {\n        this._syncMethod(\"triggerAttack\", 0);\n        this._syncMethod(\"triggerRelease\", 0);\n        return this;\n    }\n    triggerAttackRelease(duration, time, velocity = 1) {\n        time = this.toSeconds(time);\n        duration = this.toSeconds(duration);\n        this.triggerAttack(time, velocity);\n        this.triggerRelease(time + duration);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.noise.dispose();\n        this.envelope.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=NoiseSynth.js.map","import { LowpassCombFilter } from \"../component/filter/LowpassCombFilter\";\nimport { deepMerge } from \"../core/util/Defaults\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Noise } from \"../source/Noise\";\nimport { Instrument } from \"./Instrument\";\n/**\n * Karplus-String string synthesis.\n * @example\n * const plucky = new Tone.PluckSynth().toDestination();\n * plucky.triggerAttack(\"C4\", \"+0.5\");\n * plucky.triggerAttack(\"C3\", \"+1\");\n * plucky.triggerAttack(\"C2\", \"+1.5\");\n * plucky.triggerAttack(\"C1\", \"+2\");\n * @category Instrument\n */\nexport class PluckSynth extends Instrument {\n    constructor() {\n        super(optionsFromArguments(PluckSynth.getDefaults(), arguments));\n        this.name = \"PluckSynth\";\n        const options = optionsFromArguments(PluckSynth.getDefaults(), arguments);\n        this._noise = new Noise({\n            context: this.context,\n            type: \"pink\"\n        });\n        this.attackNoise = options.attackNoise;\n        this._lfcf = new LowpassCombFilter({\n            context: this.context,\n            dampening: options.dampening,\n            resonance: options.resonance,\n        });\n        this.resonance = options.resonance;\n        this.release = options.release;\n        this._noise.connect(this._lfcf);\n        this._lfcf.connect(this.output);\n    }\n    static getDefaults() {\n        return deepMerge(Instrument.getDefaults(), {\n            attackNoise: 1,\n            dampening: 4000,\n            resonance: 0.7,\n            release: 1,\n        });\n    }\n    /**\n     * The dampening control. i.e. the lowpass filter frequency of the comb filter\n     * @min 0\n     * @max 7000\n     */\n    get dampening() {\n        return this._lfcf.dampening;\n    }\n    set dampening(fq) {\n        this._lfcf.dampening = fq;\n    }\n    triggerAttack(note, time) {\n        const freq = this.toFrequency(note);\n        time = this.toSeconds(time);\n        const delayAmount = 1 / freq;\n        this._lfcf.delayTime.setValueAtTime(delayAmount, time);\n        this._noise.start(time);\n        this._noise.stop(time + delayAmount * this.attackNoise);\n        this._lfcf.resonance.cancelScheduledValues(time);\n        this._lfcf.resonance.setValueAtTime(this.resonance, time);\n        return this;\n    }\n    /**\n     * Ramp down the [[resonance]] to 0 over the duration of the release time.\n     */\n    triggerRelease(time) {\n        this._lfcf.resonance.linearRampTo(0, this.release, time);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._noise.dispose();\n        this._lfcf.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PluckSynth.js.map","import { MidiClass } from \"../core/type/Midi\";\nimport { deepMerge, omitFromObject, optionsFromArguments } from \"../core/util/Defaults\";\nimport { isArray, isNumber } from \"../core/util/TypeCheck\";\nimport { Instrument } from \"./Instrument\";\nimport { Synth } from \"./Synth\";\nimport { assert, warn } from \"../core/util/Debug\";\n/**\n * PolySynth handles voice creation and allocation for any\n * instruments passed in as the second paramter. PolySynth is\n * not a synthesizer by itself, it merely manages voices of\n * one of the other types of synths, allowing any of the\n * monophonic synthesizers to be polyphonic.\n *\n * @example\n * const synth = new Tone.PolySynth().toDestination();\n * // set the attributes across all the voices using 'set'\n * synth.set({ detune: -1200 });\n * // play a chord\n * synth.triggerAttackRelease([\"C4\", \"E4\", \"A4\"], 1);\n * @category Instrument\n */\nexport class PolySynth extends Instrument {\n    constructor() {\n        super(optionsFromArguments(PolySynth.getDefaults(), arguments, [\"voice\", \"options\"]));\n        this.name = \"PolySynth\";\n        /**\n         * The voices which are not currently in use\n         */\n        this._availableVoices = [];\n        /**\n         * The currently active voices\n         */\n        this._activeVoices = [];\n        /**\n         * All of the allocated voices for this synth.\n         */\n        this._voices = [];\n        /**\n         * The GC timeout. Held so that it could be cancelled when the node is disposed.\n         */\n        this._gcTimeout = -1;\n        /**\n         * A moving average of the number of active voices\n         */\n        this._averageActiveVoices = 0;\n        const options = optionsFromArguments(PolySynth.getDefaults(), arguments, [\"voice\", \"options\"]);\n        // check against the old API (pre 14.3.0)\n        assert(!isNumber(options.voice), \"DEPRECATED: The polyphony count is no longer the first argument.\");\n        const defaults = options.voice.getDefaults();\n        this.options = Object.assign(defaults, options.options);\n        this.voice = options.voice;\n        this.maxPolyphony = options.maxPolyphony;\n        // create the first voice\n        this._dummyVoice = this._getNextAvailableVoice();\n        // remove it from the voices list\n        const index = this._voices.indexOf(this._dummyVoice);\n        this._voices.splice(index, 1);\n        // kick off the GC interval\n        this._gcTimeout = this.context.setInterval(this._collectGarbage.bind(this), 1);\n    }\n    static getDefaults() {\n        return Object.assign(Instrument.getDefaults(), {\n            maxPolyphony: 32,\n            options: {},\n            voice: Synth,\n        });\n    }\n    /**\n     * The number of active voices.\n     */\n    get activeVoices() {\n        return this._activeVoices.length;\n    }\n    /**\n     * Invoked when the source is done making sound, so that it can be\n     * readded to the pool of available voices\n     */\n    _makeVoiceAvailable(voice) {\n        this._availableVoices.push(voice);\n        // remove the midi note from 'active voices'\n        const activeVoiceIndex = this._activeVoices.findIndex((e) => e.voice === voice);\n        this._activeVoices.splice(activeVoiceIndex, 1);\n    }\n    /**\n     * Get an available voice from the pool of available voices.\n     * If one is not available and the maxPolyphony limit is reached,\n     * steal a voice, otherwise return null.\n     */\n    _getNextAvailableVoice() {\n        // if there are available voices, return the first one\n        if (this._availableVoices.length) {\n            return this._availableVoices.shift();\n        }\n        else if (this._voices.length < this.maxPolyphony) {\n            // otherwise if there is still more maxPolyphony, make a new voice\n            const voice = new this.voice(Object.assign(this.options, {\n                context: this.context,\n                onsilence: this._makeVoiceAvailable.bind(this),\n            }));\n            voice.connect(this.output);\n            this._voices.push(voice);\n            return voice;\n        }\n        else {\n            warn(\"Max polyphony exceeded. Note dropped.\");\n        }\n    }\n    /**\n     * Occasionally check if there are any allocated voices which can be cleaned up.\n     */\n    _collectGarbage() {\n        this._averageActiveVoices = Math.max(this._averageActiveVoices * 0.95, this.activeVoices);\n        if (this._availableVoices.length && this._voices.length > Math.ceil(this._averageActiveVoices + 1)) {\n            // take off an available note\n            const firstAvail = this._availableVoices.shift();\n            const index = this._voices.indexOf(firstAvail);\n            this._voices.splice(index, 1);\n            if (!this.context.isOffline) {\n                firstAvail.dispose();\n            }\n        }\n    }\n    /**\n     * Internal method which triggers the attack\n     */\n    _triggerAttack(notes, time, velocity) {\n        notes.forEach(note => {\n            const midiNote = new MidiClass(this.context, note).toMidi();\n            const voice = this._getNextAvailableVoice();\n            if (voice) {\n                voice.triggerAttack(note, time, velocity);\n                this._activeVoices.push({\n                    midi: midiNote, voice, released: false,\n                });\n                this.log(\"triggerAttack\", note, time);\n            }\n        });\n    }\n    /**\n     * Internal method which triggers the release\n     */\n    _triggerRelease(notes, time) {\n        notes.forEach(note => {\n            const midiNote = new MidiClass(this.context, note).toMidi();\n            const event = this._activeVoices.find(({ midi, released }) => midi === midiNote && !released);\n            if (event) {\n                // trigger release on that note\n                event.voice.triggerRelease(time);\n                // mark it as released\n                event.released = true;\n                this.log(\"triggerRelease\", note, time);\n            }\n        });\n    }\n    /**\n     * Schedule the attack/release events. If the time is in the future, then it should set a timeout\n     * to wait for just-in-time scheduling\n     */\n    _scheduleEvent(type, notes, time, velocity) {\n        assert(!this.disposed, \"Synth was already disposed\");\n        // if the notes are greater than this amount of time in the future, they should be scheduled with setTimeout\n        if (time <= this.now()) {\n            // do it immediately\n            if (type === \"attack\") {\n                this._triggerAttack(notes, time, velocity);\n            }\n            else {\n                this._triggerRelease(notes, time);\n            }\n        }\n        else {\n            // schedule it to start in the future\n            this.context.setTimeout(() => {\n                this._scheduleEvent(type, notes, time, velocity);\n            }, time - this.now());\n        }\n    }\n    /**\n     * Trigger the attack portion of the note\n     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.\n     * @param  time  The start time of the note.\n     * @param velocity The velocity of the note.\n     * @example\n     * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();\n     * // trigger a chord immediately with a velocity of 0.2\n     * synth.triggerAttack([\"Ab3\", \"C4\", \"F5\"], Tone.now(), 0.2);\n     */\n    triggerAttack(notes, time, velocity) {\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        const computedTime = this.toSeconds(time);\n        this._scheduleEvent(\"attack\", notes, computedTime, velocity);\n        return this;\n    }\n    /**\n     * Trigger the release of the note. Unlike monophonic instruments,\n     * a note (or array of notes) needs to be passed in as the first argument.\n     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.\n     * @param  time  When the release will be triggered.\n     * @example\n     * @example\n     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();\n     * poly.triggerAttack([\"Ab3\", \"C4\", \"F5\"]);\n     * // trigger the release of the given notes.\n     * poly.triggerRelease([\"Ab3\", \"C4\"], \"+1\");\n     * poly.triggerRelease(\"F5\", \"+3\");\n     */\n    triggerRelease(notes, time) {\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        const computedTime = this.toSeconds(time);\n        this._scheduleEvent(\"release\", notes, computedTime);\n        return this;\n    }\n    /**\n     * Trigger the attack and release after the specified duration\n     * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.\n     * @param  duration the duration of the note\n     * @param  time  if no time is given, defaults to now\n     * @param  velocity the velocity of the attack (0-1)\n     * @example\n     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();\n     * // can pass in an array of durations as well\n     * poly.triggerAttackRelease([\"Eb3\", \"G4\", \"Bb4\", \"D5\"], [4, 3, 2, 1]);\n     */\n    triggerAttackRelease(notes, duration, time, velocity) {\n        const computedTime = this.toSeconds(time);\n        this.triggerAttack(notes, computedTime, velocity);\n        if (isArray(duration)) {\n            assert(isArray(notes), \"If the duration is an array, the notes must also be an array\");\n            notes = notes;\n            for (let i = 0; i < notes.length; i++) {\n                const d = duration[Math.min(i, duration.length - 1)];\n                const durationSeconds = this.toSeconds(d);\n                assert(durationSeconds > 0, \"The duration must be greater than 0\");\n                this.triggerRelease(notes[i], computedTime + durationSeconds);\n            }\n        }\n        else {\n            const durationSeconds = this.toSeconds(duration);\n            assert(durationSeconds > 0, \"The duration must be greater than 0\");\n            this.triggerRelease(notes, computedTime + durationSeconds);\n        }\n        return this;\n    }\n    sync() {\n        this._syncMethod(\"triggerAttack\", 1);\n        this._syncMethod(\"triggerRelease\", 1);\n        return this;\n    }\n    /**\n     * Set a member/attribute of the voices\n     * @example\n     * const poly = new Tone.PolySynth().toDestination();\n     * // set all of the voices using an options object for the synth type\n     * poly.set({\n     * \tenvelope: {\n     * \t\tattack: 0.25\n     * \t}\n     * });\n     * poly.triggerAttackRelease(\"Bb3\", 0.2);\n     */\n    set(options) {\n        // remove options which are controlled by the PolySynth\n        const sanitizedOptions = omitFromObject(options, [\"onsilence\", \"context\"]);\n        // store all of the options\n        this.options = deepMerge(this.options, sanitizedOptions);\n        this._voices.forEach(voice => voice.set(sanitizedOptions));\n        this._dummyVoice.set(sanitizedOptions);\n        return this;\n    }\n    get() {\n        return this._dummyVoice.get();\n    }\n    /**\n     * Trigger the release portion of all the currently active voices immediately.\n     * Useful for silencing the synth.\n     */\n    releaseAll() {\n        const now = this.now();\n        this._activeVoices.forEach(({ voice }) => {\n            voice.triggerRelease(now);\n        });\n        this._activeVoices = [];\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._dummyVoice.dispose();\n        this._voices.forEach(v => v.dispose());\n        this._activeVoices = [];\n        this._availableVoices = [];\n        this.context.clearInterval(this._gcTimeout);\n        return this;\n    }\n}\n//# sourceMappingURL=PolySynth.js.map","import { __decorate } from \"tslib\";\nimport { ToneAudioBuffers } from \"../core/context/ToneAudioBuffers\";\nimport { intervalToFrequencyRatio } from \"../core/type/Conversions\";\nimport { FrequencyClass } from \"../core/type/Frequency\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { noOp } from \"../core/util/Interface\";\nimport { isArray, isNote, isNumber } from \"../core/util/TypeCheck\";\nimport { Instrument } from \"../instrument/Instrument\";\nimport { ToneBufferSource } from \"../source/buffer/ToneBufferSource\";\nimport { timeRange } from \"../core/util/Decorator\";\nimport { assert } from \"../core/util/Debug\";\n/**\n * Pass in an object which maps the note's pitch or midi value to the url,\n * then you can trigger the attack and release of that note like other instruments.\n * By automatically repitching the samples, it is possible to play pitches which\n * were not explicitly included which can save loading time.\n *\n * For sample or buffer playback where repitching is not necessary,\n * use [[Player]].\n * @example\n * const sampler = new Tone.Sampler({\n * \turls: {\n * \t\tC1: \"C1.mp3\",\n * \t\tC2: \"C2.mp3\",\n * \t},\n * \tbaseUrl: \"https://tonejs.github.io/examples/audio/casio/\",\n * \tonload: () => {\n * \t\tsampler.triggerAttackRelease([\"C1\", \"E1\", \"G1\", \"B1\"], 0.5);\n * \t},\n * });\n * @category Instrument\n */\nexport class Sampler extends Instrument {\n    constructor() {\n        super(optionsFromArguments(Sampler.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\"));\n        this.name = \"Sampler\";\n        /**\n         * The object of all currently playing BufferSources\n         */\n        this._activeSources = new Map();\n        const options = optionsFromArguments(Sampler.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\");\n        const urlMap = {};\n        Object.keys(options.urls).forEach((note) => {\n            const noteNumber = parseInt(note, 10);\n            assert(isNote(note)\n                || (isNumber(noteNumber) && isFinite(noteNumber)), `url key is neither a note or midi pitch: ${note}`);\n            if (isNote(note)) {\n                // convert the note name to MIDI\n                const mid = new FrequencyClass(this.context, note).toMidi();\n                urlMap[mid] = options.urls[note];\n            }\n            else if (isNumber(noteNumber) && isFinite(noteNumber)) {\n                // otherwise if it's numbers assume it's midi\n                urlMap[noteNumber] = options.urls[noteNumber];\n            }\n        });\n        this._buffers = new ToneAudioBuffers({\n            urls: urlMap,\n            onload: options.onload,\n            baseUrl: options.baseUrl,\n            onerror: options.onerror,\n        });\n        this.attack = options.attack;\n        this.release = options.release;\n        this.curve = options.curve;\n        // invoke the callback if it's already loaded\n        if (this._buffers.loaded) {\n            // invoke onload deferred\n            Promise.resolve().then(options.onload);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(Instrument.getDefaults(), {\n            attack: 0,\n            baseUrl: \"\",\n            curve: \"exponential\",\n            onload: noOp,\n            onerror: noOp,\n            release: 0.1,\n            urls: {},\n        });\n    }\n    /**\n     * Returns the difference in steps between the given midi note at the closets sample.\n     */\n    _findClosest(midi) {\n        // searches within 8 octaves of the given midi note\n        const MAX_INTERVAL = 96;\n        let interval = 0;\n        while (interval < MAX_INTERVAL) {\n            // check above and below\n            if (this._buffers.has(midi + interval)) {\n                return -interval;\n            }\n            else if (this._buffers.has(midi - interval)) {\n                return interval;\n            }\n            interval++;\n        }\n        throw new Error(`No available buffers for note: ${midi}`);\n    }\n    /**\n     * @param  notes\tThe note to play, or an array of notes.\n     * @param  time     When to play the note\n     * @param  velocity The velocity to play the sample back.\n     */\n    triggerAttack(notes, time, velocity = 1) {\n        this.log(\"triggerAttack\", notes, time, velocity);\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        notes.forEach(note => {\n            const midi = new FrequencyClass(this.context, note).toMidi();\n            // find the closest note pitch\n            const difference = this._findClosest(midi);\n            const closestNote = midi - difference;\n            const buffer = this._buffers.get(closestNote);\n            const playbackRate = intervalToFrequencyRatio(difference);\n            // play that note\n            const source = new ToneBufferSource({\n                url: buffer,\n                context: this.context,\n                curve: this.curve,\n                fadeIn: this.attack,\n                fadeOut: this.release,\n                playbackRate,\n            }).connect(this.output);\n            source.start(time, 0, buffer.duration / playbackRate, velocity);\n            // add it to the active sources\n            if (!isArray(this._activeSources.get(midi))) {\n                this._activeSources.set(midi, []);\n            }\n            this._activeSources.get(midi).push(source);\n            // remove it when it's done\n            source.onended = () => {\n                if (this._activeSources && this._activeSources.has(midi)) {\n                    const sources = this._activeSources.get(midi);\n                    const index = sources.indexOf(source);\n                    if (index !== -1) {\n                        sources.splice(index, 1);\n                    }\n                }\n            };\n        });\n        return this;\n    }\n    /**\n     * @param  notes\tThe note to release, or an array of notes.\n     * @param  time     \tWhen to release the note.\n     */\n    triggerRelease(notes, time) {\n        this.log(\"triggerRelease\", notes, time);\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        notes.forEach(note => {\n            const midi = new FrequencyClass(this.context, note).toMidi();\n            // find the note\n            if (this._activeSources.has(midi) && this._activeSources.get(midi).length) {\n                const sources = this._activeSources.get(midi);\n                time = this.toSeconds(time);\n                sources.forEach(source => {\n                    source.stop(time);\n                });\n                this._activeSources.set(midi, []);\n            }\n        });\n        return this;\n    }\n    /**\n     * Release all currently active notes.\n     * @param  time     \tWhen to release the notes.\n     */\n    releaseAll(time) {\n        const computedTime = this.toSeconds(time);\n        this._activeSources.forEach(sources => {\n            while (sources.length) {\n                const source = sources.shift();\n                source.stop(computedTime);\n            }\n        });\n        return this;\n    }\n    sync() {\n        this._syncMethod(\"triggerAttack\", 1);\n        this._syncMethod(\"triggerRelease\", 1);\n        return this;\n    }\n    /**\n     * Invoke the attack phase, then after the duration, invoke the release.\n     * @param  notes\tThe note to play and release, or an array of notes.\n     * @param  duration The time the note should be held\n     * @param  time     When to start the attack\n     * @param  velocity The velocity of the attack\n     */\n    triggerAttackRelease(notes, duration, time, velocity = 1) {\n        const computedTime = this.toSeconds(time);\n        this.triggerAttack(notes, computedTime, velocity);\n        if (isArray(duration)) {\n            assert(isArray(notes), \"notes must be an array when duration is array\");\n            notes.forEach((note, index) => {\n                const d = duration[Math.min(index, duration.length - 1)];\n                this.triggerRelease(note, computedTime + this.toSeconds(d));\n            });\n        }\n        else {\n            this.triggerRelease(notes, computedTime + this.toSeconds(duration));\n        }\n        return this;\n    }\n    /**\n     * Add a note to the sampler.\n     * @param  note      The buffer's pitch.\n     * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.\n     * @param  callback  The callback to invoke when the url is loaded.\n     */\n    add(note, url, callback) {\n        assert(isNote(note) || isFinite(note), `note must be a pitch or midi: ${note}`);\n        if (isNote(note)) {\n            // convert the note name to MIDI\n            const mid = new FrequencyClass(this.context, note).toMidi();\n            this._buffers.add(mid, url, callback);\n        }\n        else {\n            // otherwise if it's numbers assume it's midi\n            this._buffers.add(note, url, callback);\n        }\n        return this;\n    }\n    /**\n     * If the buffers are loaded or not\n     */\n    get loaded() {\n        return this._buffers.loaded;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._buffers.dispose();\n        this._activeSources.forEach(sources => {\n            sources.forEach(source => source.dispose());\n        });\n        this._activeSources.clear();\n        return this;\n    }\n}\n__decorate([\n    timeRange(0)\n], Sampler.prototype, \"attack\", void 0);\n__decorate([\n    timeRange(0)\n], Sampler.prototype, \"release\", void 0);\n//# sourceMappingURL=Sampler.js.map","import { AmplitudeEnvelope } from \"../component/envelope/AmplitudeEnvelope\";\nimport { Envelope } from \"../component/envelope/Envelope\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { omitFromObject, optionsFromArguments } from \"../core/util/Defaults\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { OmniOscillator } from \"../source/oscillator/OmniOscillator\";\nimport { Source } from \"../source/Source\";\nimport { Monophonic } from \"./Monophonic\";\n/**\n * Synth is composed simply of a [[OmniOscillator]] routed through an [[AmplitudeEnvelope]].\n * ```\n * +----------------+   +-------------------+\n * | OmniOscillator +>--> AmplitudeEnvelope +>--> Output\n * +----------------+   +-------------------+\n * ```\n * @example\n * const synth = new Tone.Synth().toDestination();\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Instrument\n */\nexport class Synth extends Monophonic {\n    constructor() {\n        super(optionsFromArguments(Synth.getDefaults(), arguments));\n        this.name = \"Synth\";\n        const options = optionsFromArguments(Synth.getDefaults(), arguments);\n        this.oscillator = new OmniOscillator(Object.assign({\n            context: this.context,\n            detune: options.detune,\n            onstop: () => this.onsilence(this),\n        }, options.oscillator));\n        this.frequency = this.oscillator.frequency;\n        this.detune = this.oscillator.detune;\n        this.envelope = new AmplitudeEnvelope(Object.assign({\n            context: this.context,\n        }, options.envelope));\n        // connect the oscillators to the output\n        this.oscillator.chain(this.envelope, this.output);\n        readOnly(this, [\"oscillator\", \"frequency\", \"detune\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Monophonic.getDefaults(), {\n            envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {\n                attack: 0.005,\n                decay: 0.1,\n                release: 1,\n                sustain: 0.3,\n            }),\n            oscillator: Object.assign(omitFromObject(OmniOscillator.getDefaults(), [...Object.keys(Source.getDefaults()), \"frequency\", \"detune\"]), {\n                type: \"triangle\",\n            }),\n        });\n    }\n    /**\n     * start the attack portion of the envelope\n     * @param time the time the attack should start\n     * @param velocity the velocity of the note (0-1)\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // the envelopes\n        this.envelope.triggerAttack(time, velocity);\n        this.oscillator.start(time);\n        // if there is no release portion, stop the oscillator\n        if (this.envelope.sustain === 0) {\n            const computedAttack = this.toSeconds(this.envelope.attack);\n            const computedDecay = this.toSeconds(this.envelope.decay);\n            this.oscillator.stop(time + computedAttack + computedDecay);\n        }\n    }\n    /**\n     * start the release portion of the envelope\n     * @param time the time the release should start\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this.oscillator.stop(time + this.toSeconds(this.envelope.release));\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this.oscillator.dispose();\n        this.envelope.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Synth.js.map","export * from \"./AMSynth\";\nexport * from \"./DuoSynth\";\nexport * from \"./FMSynth\";\nexport * from \"./MetalSynth\";\nexport * from \"./MembraneSynth\";\nexport * from \"./MonoSynth\";\nexport * from \"./NoiseSynth\";\nexport * from \"./PluckSynth\";\nexport * from \"./PolySynth\";\nexport * from \"./Sampler\";\nexport * from \"./Synth\";\n//# sourceMappingURL=index.js.map","import { SignalOperator } from \"./SignalOperator\";\nimport { WaveShaper } from \"./WaveShaper\";\n/**\n * Return the absolute value of an incoming signal.\n *\n * @offline 0.5 1\n * @example\n * const abs = new Tone.Abs().toDestination();\n * const signal = new Tone.Signal(1);\n * signal.rampTo(-1, 0.5);\n * signal.connect(abs);\n * @category Signal\n */\nexport class Abs extends SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"Abs\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._abs = new WaveShaper({\n            context: this.context,\n            mapping: val => {\n                if (Math.abs(val) < 0.001) {\n                    return 0;\n                }\n                else {\n                    return Math.abs(val);\n                }\n            },\n        });\n        /**\n         * The AudioRange input [-1, 1]\n         */\n        this.input = this._abs;\n        /**\n         * The output range [0, 1]\n         */\n        this.output = this._abs;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._abs.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Abs.js.map","import { connectSeries } from \"../core/context/ToneAudioNode\";\nimport { Gain } from \"../core/context/Gain\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Signal } from \"./Signal\";\n/**\n * Add a signal and a number or two signals. When no value is\n * passed into the constructor, Tone.Add will sum input and `addend`\n * If a value is passed into the constructor, the it will be added to the input.\n *\n * @offline 0.5 1\n * @example\n * const add = new Tone.Add(2).toDestination();\n * add.addend.setValueAtTime(1, 0.2);\n * const signal = new Tone.Signal(2);\n * // add a signal and a scalar\n * signal.connect(add);\n * signal.setValueAtTime(1, 0.1);\n * @category Signal\n */\nexport class Add extends Signal {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Add.getDefaults(), arguments, [\"value\"])));\n        this.override = false;\n        this.name = \"Add\";\n        /**\n         * the summing node\n         */\n        this._sum = new Gain({ context: this.context });\n        this.input = this._sum;\n        this.output = this._sum;\n        /**\n         * The value which is added to the input signal\n         */\n        this.addend = this._param;\n        connectSeries(this._constantSource, this._sum);\n    }\n    static getDefaults() {\n        return Object.assign(Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._sum.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Add.js.map","import { SignalOperator } from \"./SignalOperator\";\nimport { WaveShaper } from \"./WaveShaper\";\n/**\n * AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1].\n * See [[GainToAudio]].\n * @category Signal\n */\nexport class AudioToGain extends SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"AudioToGain\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._norm = new WaveShaper({\n            context: this.context,\n            mapping: x => (x + 1) / 2,\n        });\n        /**\n         * The AudioRange input [-1, 1]\n         */\n        this.input = this._norm;\n        /**\n         * The GainRange output [0, 1]\n         */\n        this.output = this._norm;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._norm.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AudioToGain.js.map","import { SignalOperator } from \"./SignalOperator\";\nimport { WaveShaper } from \"./WaveShaper\";\n/**\n * GainToAudio converts an input in NormalRange [0,1] to AudioRange [-1,1].\n * See [[AudioToGain]].\n * @category Signal\n */\nexport class GainToAudio extends SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"GainToAudio\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._norm = new WaveShaper({\n            context: this.context,\n            mapping: x => Math.abs(x) * 2 - 1,\n        });\n        /**\n         * The NormalRange input [0, 1]\n         */\n        this.input = this._norm;\n        /**\n         * The AudioRange output [-1, 1]\n         */\n        this.output = this._norm;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._norm.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GainToAudio.js.map","import { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Subtract } from \"./Subtract\";\nimport { Signal } from \"./Signal\";\nimport { GreaterThanZero } from \"./GreaterThanZero\";\nimport { readOnly } from \"../core/util/Interface\";\n/**\n * Output 1 if the signal is greater than the value, otherwise outputs 0.\n * can compare two signals or a signal and a number.\n *\n * @offline 0.1 1\n * @example\n * const gt = new Tone.GreaterThan(2).toDestination();\n * const sig = new Tone.Signal(4).connect(gt);\n */\nexport class GreaterThan extends Signal {\n    constructor() {\n        super(Object.assign(optionsFromArguments(GreaterThan.getDefaults(), arguments, [\"value\"])));\n        this.name = \"GreaterThan\";\n        this.override = false;\n        const options = optionsFromArguments(GreaterThan.getDefaults(), arguments, [\"value\"]);\n        this._subtract = this.input = new Subtract({\n            context: this.context,\n            value: options.value\n        });\n        this._gtz = this.output = new GreaterThanZero({ context: this.context });\n        this.comparator = this._param = this._subtract.subtrahend;\n        readOnly(this, \"comparator\");\n        // connect\n        this._subtract.connect(this._gtz);\n    }\n    static getDefaults() {\n        return Object.assign(Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._gtz.dispose();\n        this._subtract.dispose();\n        this.comparator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GreaterThan.js.map","import { SignalOperator } from \"./SignalOperator\";\nimport { Multiply } from \"./Multiply\";\nimport { WaveShaper } from \"./WaveShaper\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\n/**\n * GreaterThanZero outputs 1 when the input is strictly greater than zero\n * @offline 0.1 1\n * @example\n * const gt0 = new Tone.GreaterThanZero().toDestination();\n * const sig = new Tone.Signal(0.5).connect(gt0);\n * sig.setValueAtTime(-1, 0.05);\n */\nexport class GreaterThanZero extends SignalOperator {\n    constructor() {\n        super(Object.assign(optionsFromArguments(GreaterThanZero.getDefaults(), arguments)));\n        this.name = \"GreaterThanZero\";\n        this._thresh = this.output = new WaveShaper({\n            context: this.context,\n            length: 127,\n            mapping: (val) => {\n                if (val <= 0) {\n                    return 0;\n                }\n                else {\n                    return 1;\n                }\n            },\n        });\n        this._scale = this.input = new Multiply({\n            context: this.context,\n            value: 10000\n        });\n        // connections\n        this._scale.connect(this._thresh);\n    }\n    dispose() {\n        super.dispose();\n        this._scale.dispose();\n        this._thresh.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GreaterThanZero.js.map","import { Gain } from \"../core/context/Gain\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Signal } from \"./Signal\";\n/**\n * Multiply two incoming signals. Or, if a number is given in the constructor,\n * multiplies the incoming signal by that value.\n *\n * @example\n * // multiply two signals\n * const mult = new Tone.Multiply();\n * const sigA = new Tone.Signal(3);\n * const sigB = new Tone.Signal(4);\n * sigA.connect(mult);\n * sigB.connect(mult.factor);\n * // output of mult is 12.\n * @example\n * // multiply a signal and a number\n * const mult = new Tone.Multiply(10);\n * const sig = new Tone.Signal(2).connect(mult);\n * // the output of mult is 20.\n * @category Signal\n */\nexport class Multiply extends Signal {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Multiply.getDefaults(), arguments, [\"value\"])));\n        this.name = \"Multiply\";\n        /**\n         * Indicates if the value should be overridden on connection\n         */\n        this.override = false;\n        const options = optionsFromArguments(Multiply.getDefaults(), arguments, [\"value\"]);\n        this._mult = this.input = this.output = new Gain({\n            context: this.context,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        this.factor = this._param = this._mult.gain;\n        this.factor.setValueAtTime(options.value, 0);\n    }\n    static getDefaults() {\n        return Object.assign(Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._mult.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Multiply.js.map","import { Multiply } from \"./Multiply\";\nimport { SignalOperator } from \"./SignalOperator\";\n/**\n * Negate the incoming signal. i.e. an input signal of 10 will output -10\n *\n * @example\n * const neg = new Tone.Negate();\n * const sig = new Tone.Signal(-2).connect(neg);\n * // output of neg is positive 2.\n * @category Signal\n */\nexport class Negate extends SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"Negate\";\n        /**\n         * negation is done by multiplying by -1\n         */\n        this._multiply = new Multiply({\n            context: this.context,\n            value: -1,\n        });\n        /**\n         * The input and output are equal to the multiply node\n         */\n        this.input = this._multiply;\n        this.output = this._multiply;\n    }\n    /**\n     * clean up\n     * @returns {Negate} this\n     */\n    dispose() {\n        super.dispose();\n        this._multiply.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Negate.js.map","import { WaveShaper } from \"./WaveShaper\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { SignalOperator } from \"./SignalOperator\";\n/**\n * Pow applies an exponent to the incoming signal. The incoming signal must be AudioRange [-1, 1]\n *\n * @example\n * const pow = new Tone.Pow(2);\n * const sig = new Tone.Signal(0.5).connect(pow);\n * // output of pow is 0.25.\n * @category Signal\n */\nexport class Pow extends SignalOperator {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Pow.getDefaults(), arguments, [\"value\"])));\n        this.name = \"Pow\";\n        const options = optionsFromArguments(Pow.getDefaults(), arguments, [\"value\"]);\n        this._exponentScaler = this.input = this.output = new WaveShaper({\n            context: this.context,\n            mapping: this._expFunc(options.value),\n            length: 8192,\n        });\n        this._exponent = options.value;\n    }\n    static getDefaults() {\n        return Object.assign(SignalOperator.getDefaults(), {\n            value: 1,\n        });\n    }\n    /**\n     * the function which maps the waveshaper\n     * @param exponent exponent value\n     */\n    _expFunc(exponent) {\n        return (val) => {\n            return Math.pow(Math.abs(val), exponent);\n        };\n    }\n    /**\n     * The value of the exponent.\n     */\n    get value() {\n        return this._exponent;\n    }\n    set value(exponent) {\n        this._exponent = exponent;\n        this._exponentScaler.setMap(this._expFunc(this._exponent));\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._exponentScaler.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Pow.js.map","import { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Add } from \"./Add\";\nimport { Multiply } from \"./Multiply\";\nimport { SignalOperator } from \"./SignalOperator\";\n/**\n * Performs a linear scaling on an input signal.\n * Scales a NormalRange input to between\n * outputMin and outputMax.\n *\n * @example\n * const scale = new Tone.Scale(50, 100);\n * const signal = new Tone.Signal(0.5).connect(scale);\n * // the output of scale equals 75\n * @category Signal\n */\nexport class Scale extends SignalOperator {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Scale.getDefaults(), arguments, [\"min\", \"max\"])));\n        this.name = \"Scale\";\n        const options = optionsFromArguments(Scale.getDefaults(), arguments, [\"min\", \"max\"]);\n        this._mult = this.input = new Multiply({\n            context: this.context,\n            value: options.max - options.min,\n        });\n        this._add = this.output = new Add({\n            context: this.context,\n            value: options.min,\n        });\n        this._min = options.min;\n        this._max = options.max;\n        this.input.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(SignalOperator.getDefaults(), {\n            max: 1,\n            min: 0,\n        });\n    }\n    /**\n     * The minimum output value. This number is output when the value input value is 0.\n     */\n    get min() {\n        return this._min;\n    }\n    set min(min) {\n        this._min = min;\n        this._setRange();\n    }\n    /**\n     * The maximum output value. This number is output when the value input value is 1.\n     */\n    get max() {\n        return this._max;\n    }\n    set max(max) {\n        this._max = max;\n        this._setRange();\n    }\n    /**\n     * set the values\n     */\n    _setRange() {\n        this._add.value = this._min;\n        this._mult.value = this._max - this._min;\n    }\n    dispose() {\n        super.dispose();\n        this._add.dispose();\n        this._mult.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Scale.js.map","import { Scale } from \"./Scale\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Pow } from \"./Pow\";\n/**\n * Performs an exponential scaling on an input signal.\n * Scales a NormalRange value [0,1] exponentially\n * to the output range of outputMin to outputMax.\n * @example\n * const scaleExp = new Tone.ScaleExp(0, 100, 2);\n * const signal = new Tone.Signal(0.5).connect(scaleExp);\n */\nexport class ScaleExp extends Scale {\n    constructor() {\n        super(Object.assign(optionsFromArguments(ScaleExp.getDefaults(), arguments, [\"min\", \"max\", \"exponent\"])));\n        this.name = \"ScaleExp\";\n        const options = optionsFromArguments(ScaleExp.getDefaults(), arguments, [\"min\", \"max\", \"exponent\"]);\n        this.input = this._exp = new Pow({\n            context: this.context,\n            value: options.exponent,\n        });\n        this._exp.connect(this._mult);\n    }\n    static getDefaults() {\n        return Object.assign(Scale.getDefaults(), {\n            exponent: 1,\n        });\n    }\n    /**\n     * Instead of interpolating linearly between the [[min]] and\n     * [[max]] values, setting the exponent will interpolate between\n     * the two values with an exponential curve.\n     */\n    get exponent() {\n        return this._exp.value;\n    }\n    set exponent(exp) {\n        this._exp.value = exp;\n    }\n    dispose() {\n        super.dispose();\n        this._exp.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ScaleExp.js.map","import { Param } from \"../core/context/Param\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { connect } from \"../core/context/ToneAudioNode\";\nimport { isAudioParam } from \"../core/util/AdvancedTypeCheck\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { ToneConstantSource } from \"./ToneConstantSource\";\n/**\n * A signal is an audio-rate value. Tone.Signal is a core component of the library.\n * Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal\n * has all of the methods available to native Web Audio\n * [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)\n * as well as additional conveniences. Read more about working with signals\n * [here](https://github.com/Tonejs/Tone.js/wiki/Signals).\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination().start();\n * // a scheduleable signal which can be connected to control an AudioParam or another Signal\n * const signal = new Tone.Signal({\n * \tvalue: \"C4\",\n * \tunits: \"frequency\"\n * }).connect(osc.frequency);\n * // the scheduled ramp controls the connected signal\n * signal.rampTo(\"C2\", 4, \"+0.5\");\n * @category Signal\n */\nexport class Signal extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Signal.getDefaults(), arguments, [\"value\", \"units\"]));\n        this.name = \"Signal\";\n        /**\n         * Indicates if the value should be overridden on connection.\n         */\n        this.override = true;\n        const options = optionsFromArguments(Signal.getDefaults(), arguments, [\"value\", \"units\"]);\n        this.output = this._constantSource = new ToneConstantSource({\n            context: this.context,\n            convert: options.convert,\n            offset: options.value,\n            units: options.units,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        this._constantSource.start(0);\n        this.input = this._param = this._constantSource.offset;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            convert: true,\n            units: \"number\",\n            value: 0,\n        });\n    }\n    connect(destination, outputNum = 0, inputNum = 0) {\n        // start it only when connected to something\n        connectSignal(this, destination, outputNum, inputNum);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._param.dispose();\n        this._constantSource.dispose();\n        return this;\n    }\n    //-------------------------------------\n    // ABSTRACT PARAM INTERFACE\n    // just a proxy for the ConstantSourceNode's offset AudioParam\n    // all docs are generated from AbstractParam.ts\n    //-------------------------------------\n    setValueAtTime(value, time) {\n        this._param.setValueAtTime(value, time);\n        return this;\n    }\n    getValueAtTime(time) {\n        return this._param.getValueAtTime(time);\n    }\n    setRampPoint(time) {\n        this._param.setRampPoint(time);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        this._param.linearRampToValueAtTime(value, time);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        this._param.exponentialRampToValueAtTime(value, time);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        this._param.exponentialRampTo(value, rampTime, startTime);\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        this._param.linearRampTo(value, rampTime, startTime);\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        this._param.targetRampTo(value, rampTime, startTime);\n        return this;\n    }\n    exponentialApproachValueAtTime(value, time, rampTime) {\n        this._param.exponentialApproachValueAtTime(value, time, rampTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        this._param.setTargetAtTime(value, startTime, timeConstant);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling) {\n        this._param.setValueCurveAtTime(values, startTime, duration, scaling);\n        return this;\n    }\n    cancelScheduledValues(time) {\n        this._param.cancelScheduledValues(time);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        this._param.cancelAndHoldAtTime(time);\n        return this;\n    }\n    rampTo(value, rampTime, startTime) {\n        this._param.rampTo(value, rampTime, startTime);\n        return this;\n    }\n    get value() {\n        return this._param.value;\n    }\n    set value(value) {\n        this._param.value = value;\n    }\n    get convert() {\n        return this._param.convert;\n    }\n    set convert(convert) {\n        this._param.convert = convert;\n    }\n    get units() {\n        return this._param.units;\n    }\n    get overridden() {\n        return this._param.overridden;\n    }\n    set overridden(overridden) {\n        this._param.overridden = overridden;\n    }\n    get maxValue() {\n        return this._param.maxValue;\n    }\n    get minValue() {\n        return this._param.minValue;\n    }\n    /**\n     * See [[Param.apply]].\n     */\n    apply(param) {\n        this._param.apply(param);\n        return this;\n    }\n}\n/**\n * When connecting from a signal, it's necessary to zero out the node destination\n * node if that node is also a signal. If the destination is not 0, then the values\n * will be summed. This method insures that the output of the destination signal will\n * be the same as the source signal, making the destination signal a pass through node.\n * @param signal The output signal to connect from\n * @param destination the destination to connect to\n * @param outputNum the optional output number\n * @param inputNum the input number\n */\nexport function connectSignal(signal, destination, outputNum, inputNum) {\n    if (destination instanceof Param || isAudioParam(destination) ||\n        (destination instanceof Signal && destination.override)) {\n        // cancel changes\n        destination.cancelScheduledValues(0);\n        // reset the value\n        destination.setValueAtTime(0, 0);\n        // mark the value as overridden\n        if (destination instanceof Signal) {\n            destination.overridden = true;\n        }\n    }\n    connect(signal, destination, outputNum, inputNum);\n}\n//# sourceMappingURL=Signal.js.map","import { optionsFromArguments } from \"../core/util/Defaults\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { connectSignal } from \"./Signal\";\n/**\n * A signal operator has an input and output and modifies the signal.\n */\nexport class SignalOperator extends ToneAudioNode {\n    constructor() {\n        super(Object.assign(optionsFromArguments(SignalOperator.getDefaults(), arguments, [\"context\"])));\n    }\n    connect(destination, outputNum = 0, inputNum = 0) {\n        connectSignal(this, destination, outputNum, inputNum);\n        return this;\n    }\n}\n//# sourceMappingURL=SignalOperator.js.map","import { connectSeries } from \"../core/context/ToneAudioNode\";\nimport { Gain } from \"../core/context/Gain\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { Negate } from \"../signal/Negate\";\nimport { Signal } from \"../signal/Signal\";\n/**\n * Subtract the signal connected to the input is subtracted from the signal connected\n * The subtrahend.\n *\n * @example\n * // subtract a scalar from a signal\n * const sub = new Tone.Subtract(1);\n * const sig = new Tone.Signal(4).connect(sub);\n * // the output of sub is 3.\n * @example\n * // subtract two signals\n * const sub = new Tone.Subtract();\n * const sigA = new Tone.Signal(10);\n * const sigB = new Tone.Signal(2.5);\n * sigA.connect(sub);\n * sigB.connect(sub.subtrahend);\n * // output of sub is 7.5\n * @category Signal\n */\nexport class Subtract extends Signal {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Subtract.getDefaults(), arguments, [\"value\"])));\n        this.override = false;\n        this.name = \"Subtract\";\n        /**\n         * the summing node\n         */\n        this._sum = new Gain({ context: this.context });\n        this.input = this._sum;\n        this.output = this._sum;\n        /**\n         * Negate the input of the second input before connecting it to the summing node.\n         */\n        this._neg = new Negate({ context: this.context });\n        /**\n         * The value which is subtracted from the main signal\n         */\n        this.subtrahend = this._param;\n        connectSeries(this._constantSource, this._neg, this._sum);\n    }\n    static getDefaults() {\n        return Object.assign(Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._neg.dispose();\n        this._sum.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Subtract.js.map","import { Signal } from \"./Signal\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { TransportTimeClass } from \"../core/type/TransportTime\";\nimport { ToneConstantSource } from \"./ToneConstantSource\";\n/**\n * Adds the ability to synchronize the signal to the [[Transport]]\n */\nexport class SyncedSignal extends Signal {\n    constructor() {\n        super(optionsFromArguments(Signal.getDefaults(), arguments, [\"value\", \"units\"]));\n        this.name = \"SyncedSignal\";\n        /**\n         * Don't override when something is connected to the input\n         */\n        this.override = false;\n        const options = optionsFromArguments(Signal.getDefaults(), arguments, [\"value\", \"units\"]);\n        this._lastVal = options.value;\n        this._synced = this.context.transport.scheduleRepeat(this._onTick.bind(this), \"1i\");\n        this._syncedCallback = this._anchorValue.bind(this);\n        this.context.transport.on(\"start\", this._syncedCallback);\n        this.context.transport.on(\"pause\", this._syncedCallback);\n        this.context.transport.on(\"stop\", this._syncedCallback);\n        // disconnect the constant source from the output and replace it with another one\n        this._constantSource.disconnect();\n        this._constantSource.stop(0);\n        // create a new one\n        this._constantSource = this.output = new ToneConstantSource({\n            context: this.context,\n            offset: options.value,\n            units: options.units,\n        }).start(0);\n        this.setValueAtTime(options.value, 0);\n    }\n    /**\n     * Callback which is invoked every tick.\n     */\n    _onTick(time) {\n        const val = super.getValueAtTime(this.context.transport.seconds);\n        // approximate ramp curves with linear ramps\n        if (this._lastVal !== val) {\n            this._lastVal = val;\n            this._constantSource.offset.setValueAtTime(val, time);\n        }\n    }\n    /**\n     * Anchor the value at the start and stop of the Transport\n     */\n    _anchorValue(time) {\n        const val = super.getValueAtTime(this.context.transport.seconds);\n        this._lastVal = val;\n        this._constantSource.offset.cancelAndHoldAtTime(time);\n        this._constantSource.offset.setValueAtTime(val, time);\n    }\n    getValueAtTime(time) {\n        const computedTime = new TransportTimeClass(this.context, time).toSeconds();\n        return super.getValueAtTime(computedTime);\n    }\n    setValueAtTime(value, time) {\n        const computedTime = new TransportTimeClass(this.context, time).toSeconds();\n        super.setValueAtTime(value, computedTime);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        const computedTime = new TransportTimeClass(this.context, time).toSeconds();\n        super.linearRampToValueAtTime(value, computedTime);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        const computedTime = new TransportTimeClass(this.context, time).toSeconds();\n        super.exponentialRampToValueAtTime(value, computedTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();\n        super.setTargetAtTime(value, computedTime, timeConstant);\n        return this;\n    }\n    cancelScheduledValues(startTime) {\n        const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();\n        super.cancelScheduledValues(computedTime);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling) {\n        const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();\n        duration = this.toSeconds(duration);\n        super.setValueCurveAtTime(values, computedTime, duration, scaling);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        const computedTime = new TransportTimeClass(this.context, time).toSeconds();\n        super.cancelAndHoldAtTime(computedTime);\n        return this;\n    }\n    setRampPoint(time) {\n        const computedTime = new TransportTimeClass(this.context, time).toSeconds();\n        super.setRampPoint(computedTime);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();\n        super.exponentialRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();\n        super.linearRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();\n        super.targetRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.context.transport.clear(this._synced);\n        this.context.transport.off(\"start\", this._syncedCallback);\n        this.context.transport.off(\"pause\", this._syncedCallback);\n        this.context.transport.off(\"stop\", this._syncedCallback);\n        this._constantSource.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=SyncedSignal.js.map","import { connect } from \"../core/context/ToneAudioNode\";\nimport { Param } from \"../core/context/Param\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { OneShotSource } from \"../source/OneShotSource\";\n/**\n * Wrapper around the native fire-and-forget ConstantSource.\n * Adds the ability to reschedule the stop method.\n * @category Signal\n */\nexport class ToneConstantSource extends OneShotSource {\n    constructor() {\n        super(optionsFromArguments(ToneConstantSource.getDefaults(), arguments, [\"offset\"]));\n        this.name = \"ToneConstantSource\";\n        /**\n         * The signal generator\n         */\n        this._source = this.context.createConstantSource();\n        const options = optionsFromArguments(ToneConstantSource.getDefaults(), arguments, [\"offset\"]);\n        connect(this._source, this._gainNode);\n        this.offset = new Param({\n            context: this.context,\n            convert: options.convert,\n            param: this._source.offset,\n            units: options.units,\n            value: options.offset,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(OneShotSource.getDefaults(), {\n            convert: true,\n            offset: 1,\n            units: \"number\",\n        });\n    }\n    /**\n     * Start the source node at the given time\n     * @param  time When to start the source\n     */\n    start(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        this._startGain(computedTime);\n        this._source.start(computedTime);\n        return this;\n    }\n    _stopSource(time) {\n        this._source.stop(time);\n    }\n    dispose() {\n        super.dispose();\n        if (this.state === \"started\") {\n            this.stop();\n        }\n        this._source.disconnect();\n        this.offset.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneConstantSource.js.map","import { optionsFromArguments } from \"../core/util/Defaults\";\nimport { isArray, isFunction } from \"../core/util/TypeCheck\";\nimport { assert } from \"../core/util/Debug\";\nimport { Signal } from \"./Signal\";\nimport { SignalOperator } from \"./SignalOperator\";\n/**\n * Wraps the native Web Audio API\n * [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination().start();\n * // multiply the output of the signal by 2 using the waveshaper's function\n * const timesTwo = new Tone.WaveShaper((val) => val * 2, 2048).connect(osc.frequency);\n * const signal = new Tone.Signal(440).connect(timesTwo);\n * @category Signal\n */\nexport class WaveShaper extends SignalOperator {\n    constructor() {\n        super(Object.assign(optionsFromArguments(WaveShaper.getDefaults(), arguments, [\"mapping\", \"length\"])));\n        this.name = \"WaveShaper\";\n        /**\n         * the waveshaper node\n         */\n        this._shaper = this.context.createWaveShaper();\n        /**\n         * The input to the waveshaper node.\n         */\n        this.input = this._shaper;\n        /**\n         * The output from the waveshaper node\n         */\n        this.output = this._shaper;\n        const options = optionsFromArguments(WaveShaper.getDefaults(), arguments, [\"mapping\", \"length\"]);\n        if (isArray(options.mapping) || options.mapping instanceof Float32Array) {\n            this.curve = Float32Array.from(options.mapping);\n        }\n        else if (isFunction(options.mapping)) {\n            this.setMap(options.mapping, options.length);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(Signal.getDefaults(), {\n            length: 1024,\n        });\n    }\n    /**\n     * Uses a mapping function to set the value of the curve.\n     * @param mapping The function used to define the values.\n     *                The mapping function take two arguments:\n     *                the first is the value at the current position\n     *                which goes from -1 to 1 over the number of elements\n     *                in the curve array. The second argument is the array position.\n     * @example\n     * const shaper = new Tone.WaveShaper();\n     * // map the input signal from [-1, 1] to [0, 10]\n     * shaper.setMap((val, index) => (val + 1) * 5);\n     */\n    setMap(mapping, length = 1024) {\n        const array = new Float32Array(length);\n        for (let i = 0, len = length; i < len; i++) {\n            const normalized = (i / (len - 1)) * 2 - 1;\n            array[i] = mapping(normalized, i);\n        }\n        this.curve = array;\n        return this;\n    }\n    /**\n     * The array to set as the waveshaper curve. For linear curves\n     * array length does not make much difference, but for complex curves\n     * longer arrays will provide smoother interpolation.\n     */\n    get curve() {\n        return this._shaper.curve;\n    }\n    set curve(mapping) {\n        this._shaper.curve = mapping;\n    }\n    /**\n     * Specifies what type of oversampling (if any) should be used when\n     * applying the shaping curve. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        const isOverSampleType = [\"none\", \"2x\", \"4x\"].some(str => str.includes(oversampling));\n        assert(isOverSampleType, \"oversampling must be either 'none', '2x', or '4x'\");\n        this._shaper.oversample = oversampling;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._shaper.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=WaveShaper.js.map","import { Gain } from \"../core/context/Gain\";\nimport { connect, disconnect } from \"../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { SignalOperator } from \"./SignalOperator\";\n/**\n * Tone.Zero outputs 0's at audio-rate. The reason this has to be\n * it's own class is that many browsers optimize out Tone.Signal\n * with a value of 0 and will not process nodes further down the graph.\n * @category Signal\n */\nexport class Zero extends SignalOperator {\n    constructor() {\n        super(Object.assign(optionsFromArguments(Zero.getDefaults(), arguments)));\n        this.name = \"Zero\";\n        /**\n         * The gain node which connects the constant source to the output\n         */\n        this._gain = new Gain({ context: this.context });\n        /**\n         * Only outputs 0\n         */\n        this.output = this._gain;\n        /**\n         * no input node\n         */\n        this.input = undefined;\n        connect(this.context.getConstant(0), this._gain);\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        disconnect(this.context.getConstant(0), this._gain);\n        return this;\n    }\n}\n//# sourceMappingURL=Zero.js.map","export * from \"./Add\";\nexport * from \"./Abs\";\nexport * from \"./AudioToGain\";\nexport * from \"./GainToAudio\";\nexport * from \"./GreaterThan\";\nexport * from \"./GreaterThanZero\";\nexport * from \"./Multiply\";\nexport * from \"./Negate\";\nexport * from \"./Pow\";\nexport * from \"./Signal\";\nexport * from \"./Scale\";\nexport * from \"./ScaleExp\";\nexport * from \"./Subtract\";\nexport * from \"./SyncedSignal\";\nexport * from \"./WaveShaper\";\nexport * from \"./Zero\";\n//# sourceMappingURL=index.js.map","import { ToneAudioBuffer } from \"../core/context/ToneAudioBuffer\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { assert } from \"../core/util/Debug\";\nimport { Source } from \"../source/Source\";\nimport { ToneBufferSource } from \"./buffer/ToneBufferSource\";\n/**\n * Noise is a noise generator. It uses looped noise buffers to save on performance.\n * Noise supports the noise types: \"pink\", \"white\", and \"brown\". Read more about\n * colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).\n *\n * @example\n * // initialize the noise and start\n * const noise = new Tone.Noise(\"pink\").start();\n * // make an autofilter to shape the noise\n * const autoFilter = new Tone.AutoFilter({\n * \tfrequency: \"8n\",\n * \tbaseFrequency: 200,\n * \toctaves: 8\n * }).toDestination().start();\n * // connect the noise\n * noise.connect(autoFilter);\n * // start the autofilter LFO\n * autoFilter.start();\n * @category Source\n */\nexport class Noise extends Source {\n    constructor() {\n        super(optionsFromArguments(Noise.getDefaults(), arguments, [\"type\"]));\n        this.name = \"Noise\";\n        /**\n         * Private reference to the source\n         */\n        this._source = null;\n        const options = optionsFromArguments(Noise.getDefaults(), arguments, [\"type\"]);\n        this._playbackRate = options.playbackRate;\n        this.type = options.type;\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(Source.getDefaults(), {\n            fadeIn: 0,\n            fadeOut: 0,\n            playbackRate: 1,\n            type: \"white\",\n        });\n    }\n    /**\n     * The type of the noise. Can be \"white\", \"brown\", or \"pink\".\n     * @example\n     * const noise = new Tone.Noise().toDestination().start();\n     * noise.type = \"brown\";\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        assert(type in _noiseBuffers, \"Noise: invalid type: \" + type);\n        if (this._type !== type) {\n            this._type = type;\n            // if it's playing, stop and restart it\n            if (this.state === \"started\") {\n                const now = this.now();\n                this._stop(now);\n                this._start(now);\n            }\n        }\n    }\n    /**\n     * The playback rate of the noise. Affects\n     * the \"frequency\" of the noise.\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        if (this._source) {\n            this._source.playbackRate.value = rate;\n        }\n    }\n    /**\n     * internal start method\n     */\n    _start(time) {\n        const buffer = _noiseBuffers[this._type];\n        this._source = new ToneBufferSource({\n            url: buffer,\n            context: this.context,\n            fadeIn: this._fadeIn,\n            fadeOut: this._fadeOut,\n            loop: true,\n            onended: () => this.onstop(this),\n            playbackRate: this._playbackRate,\n        }).connect(this.output);\n        this._source.start(this.toSeconds(time), Math.random() * (buffer.duration - 0.001));\n    }\n    /**\n     * internal stop method\n     */\n    _stop(time) {\n        if (this._source) {\n            this._source.stop(this.toSeconds(time));\n            this._source = null;\n        }\n    }\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(time) {\n        this._fadeIn = time;\n        if (this._source) {\n            this._source.fadeIn = this._fadeIn;\n        }\n    }\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(time) {\n        this._fadeOut = time;\n        if (this._source) {\n            this._source.fadeOut = this._fadeOut;\n        }\n    }\n    _restart(time) {\n        // TODO could be optimized by cancelling the buffer source 'stop'\n        this._stop(time);\n        this._start(time);\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        if (this._source) {\n            this._source.disconnect();\n        }\n        return this;\n    }\n}\n//--------------------\n// THE NOISE BUFFERS\n//--------------------\n// Noise buffer stats\nconst BUFFER_LENGTH = 44100 * 5;\nconst NUM_CHANNELS = 2;\n/**\n * Cache the noise buffers\n */\nconst _noiseCache = {\n    brown: null,\n    pink: null,\n    white: null,\n};\n/**\n * The noise arrays. Generated on initialization.\n * borrowed heavily from https://github.com/zacharydenton/noise.js\n * (c) 2013 Zach Denton (MIT)\n */\nconst _noiseBuffers = {\n    get brown() {\n        if (!_noiseCache.brown) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                let lastOut = 0.0;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    const white = Math.random() * 2 - 1;\n                    channel[i] = (lastOut + (0.02 * white)) / 1.02;\n                    lastOut = channel[i];\n                    channel[i] *= 3.5; // (roughly) compensate for gain\n                }\n            }\n            _noiseCache.brown = new ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.brown;\n    },\n    get pink() {\n        if (!_noiseCache.pink) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                let b0, b1, b2, b3, b4, b5, b6;\n                b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0.0;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    const white = Math.random() * 2 - 1;\n                    b0 = 0.99886 * b0 + white * 0.0555179;\n                    b1 = 0.99332 * b1 + white * 0.0750759;\n                    b2 = 0.96900 * b2 + white * 0.1538520;\n                    b3 = 0.86650 * b3 + white * 0.3104856;\n                    b4 = 0.55000 * b4 + white * 0.5329522;\n                    b5 = -0.7616 * b5 - white * 0.0168980;\n                    channel[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;\n                    channel[i] *= 0.11; // (roughly) compensate for gain\n                    b6 = white * 0.115926;\n                }\n            }\n            _noiseCache.pink = new ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.pink;\n    },\n    get white() {\n        if (!_noiseCache.white) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    channel[i] = Math.random() * 2 - 1;\n                }\n            }\n            _noiseCache.white = new ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.white;\n    },\n};\n//# sourceMappingURL=Noise.js.map","import { Gain } from \"../core/context/Gain\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { noOp } from \"../core/util/Interface\";\nimport { assert } from \"../core/util/Debug\";\n/**\n * Base class for fire-and-forget nodes\n */\nexport class OneShotSource extends ToneAudioNode {\n    constructor(options) {\n        super(options);\n        /**\n         * The callback to invoke after the\n         * source is done playing.\n         */\n        this.onended = noOp;\n        /**\n         * The start time\n         */\n        this._startTime = -1;\n        /**\n         * The stop time\n         */\n        this._stopTime = -1;\n        /**\n         * The id of the timeout\n         */\n        this._timeout = -1;\n        /**\n         * The public output node\n         */\n        this.output = new Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The output gain node.\n         */\n        this._gainNode = this.output;\n        /**\n         * Get the playback state at the given time\n         */\n        this.getStateAtTime = function (time) {\n            const computedTime = this.toSeconds(time);\n            if (this._startTime !== -1 && computedTime >= this._startTime &&\n                (this._stopTime === -1 || computedTime <= this._stopTime)) {\n                return \"started\";\n            }\n            else {\n                return \"stopped\";\n            }\n        };\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n        this._curve = options.curve;\n        this.onended = options.onended;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            curve: \"linear\",\n            fadeIn: 0,\n            fadeOut: 0,\n            onended: noOp,\n        });\n    }\n    /**\n     * Start the source at the given time\n     * @param  time When to start the source\n     */\n    _startGain(time, gain = 1) {\n        assert(this._startTime === -1, \"Source cannot be started more than once\");\n        // apply a fade in envelope\n        const fadeInTime = this.toSeconds(this._fadeIn);\n        // record the start time\n        this._startTime = time + fadeInTime;\n        this._startTime = Math.max(this._startTime, this.context.currentTime);\n        // schedule the envelope\n        if (fadeInTime > 0) {\n            this._gainNode.gain.setValueAtTime(0, time);\n            if (this._curve === \"linear\") {\n                this._gainNode.gain.linearRampToValueAtTime(gain, time + fadeInTime);\n            }\n            else {\n                this._gainNode.gain.exponentialApproachValueAtTime(gain, time, fadeInTime);\n            }\n        }\n        else {\n            this._gainNode.gain.setValueAtTime(gain, time);\n        }\n        return this;\n    }\n    /**\n     * Stop the source node at the given time.\n     * @param time When to stop the source\n     */\n    stop(time) {\n        this.log(\"stop\", time);\n        this._stopGain(this.toSeconds(time));\n        return this;\n    }\n    /**\n     * Stop the source at the given time\n     * @param  time When to stop the source\n     */\n    _stopGain(time) {\n        assert(this._startTime !== -1, \"'start' must be called before 'stop'\");\n        // cancel the previous stop\n        this.cancelStop();\n        // the fadeOut time\n        const fadeOutTime = this.toSeconds(this._fadeOut);\n        // schedule the stop callback\n        this._stopTime = this.toSeconds(time) + fadeOutTime;\n        this._stopTime = Math.max(this._stopTime, this.context.currentTime);\n        if (fadeOutTime > 0) {\n            // start the fade out curve at the given time\n            if (this._curve === \"linear\") {\n                this._gainNode.gain.linearRampTo(0, fadeOutTime, time);\n            }\n            else {\n                this._gainNode.gain.targetRampTo(0, fadeOutTime, time);\n            }\n        }\n        else {\n            // stop any ongoing ramps, and set the value to 0\n            this._gainNode.gain.cancelAndHoldAtTime(time);\n            this._gainNode.gain.setValueAtTime(0, time);\n        }\n        this.context.clearTimeout(this._timeout);\n        this._timeout = this.context.setTimeout(() => {\n            // allow additional time for the exponential curve to fully decay\n            const additionalTail = this._curve === \"exponential\" ? fadeOutTime * 2 : 0;\n            this._stopSource(this.now() + additionalTail);\n            this._onended();\n        }, this._stopTime - this.context.currentTime);\n        return this;\n    }\n    /**\n     * Invoke the onended callback\n     */\n    _onended() {\n        if (this.onended !== noOp) {\n            this.onended(this);\n            // overwrite onended to make sure it only is called once\n            this.onended = noOp;\n            // dispose when it's ended to free up for garbage collection only in the online context\n            if (!this.context.isOffline) {\n                setTimeout(() => this.dispose(), 1000);\n            }\n        }\n    }\n    /**\n     * Get the playback state at the current time\n     */\n    get state() {\n        return this.getStateAtTime(this.now());\n    }\n    /**\n     * Cancel a scheduled stop event\n     */\n    cancelStop() {\n        this.log(\"cancelStop\");\n        assert(this._startTime !== -1, \"Source is not started\");\n        // cancel the stop envelope\n        this._gainNode.gain.cancelScheduledValues(this._startTime + this.sampleTime);\n        this.context.clearTimeout(this._timeout);\n        this._stopTime = -1;\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._gainNode.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=OneShotSource.js.map","import { Volume } from \"../component/channel/Volume\";\nimport \"../core/context/Destination\";\nimport \"../core/clock/Transport\";\nimport { ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { defaultArg } from \"../core/util/Defaults\";\nimport { noOp, readOnly } from \"../core/util/Interface\";\nimport { StateTimeline } from \"../core/util/StateTimeline\";\nimport { isDefined, isUndef } from \"../core/util/TypeCheck\";\nimport { assert, assertContextRunning } from \"../core/util/Debug\";\nimport { GT } from \"../core/util/Math\";\n/**\n * Base class for sources.\n * start/stop of this.context.transport.\n *\n * ```\n * // Multiple state change events can be chained together,\n * // but must be set in the correct order and with ascending times\n * // OK\n * state.start().stop(\"+0.2\");\n * // OK\n * state.start().stop(\"+0.2\").start(\"+0.4\").stop(\"+0.7\")\n * // BAD\n * state.stop(\"+0.2\").start();\n * // BAD\n * state.start(\"+0.3\").stop(\"+0.2\");\n * ```\n */\nexport class Source extends ToneAudioNode {\n    constructor(options) {\n        super(options);\n        /**\n         * Sources have no inputs\n         */\n        this.input = undefined;\n        /**\n         * Keep track of the scheduled state.\n         */\n        this._state = new StateTimeline(\"stopped\");\n        /**\n         * The synced `start` callback function from the transport\n         */\n        this._synced = false;\n        /**\n         * Keep track of all of the scheduled event ids\n         */\n        this._scheduled = [];\n        /**\n         * Placeholder functions for syncing/unsyncing to transport\n         */\n        this._syncedStart = noOp;\n        this._syncedStop = noOp;\n        this._state.memory = 100;\n        this._state.increasing = true;\n        this._volume = this.output = new Volume({\n            context: this.context,\n            mute: options.mute,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        readOnly(this, \"volume\");\n        this.onstop = options.onstop;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            mute: false,\n            onstop: noOp,\n            volume: 0,\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\" or \"stopped\".\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/examples/audio/FWDL.mp3\", () => {\n     * \tplayer.start();\n     * \tconsole.log(player.state);\n     * }).toDestination();\n     */\n    get state() {\n        if (this._synced) {\n            if (this.context.transport.state === \"started\") {\n                return this._state.getValueAtTime(this.context.transport.seconds);\n            }\n            else {\n                return \"stopped\";\n            }\n        }\n        else {\n            return this._state.getValueAtTime(this.now());\n        }\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // mute the output\n     * osc.mute = true;\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    /**\n     * Ensure that the scheduled time is not before the current time.\n     * Should only be used when scheduled unsynced.\n     */\n    _clampToCurrentTime(time) {\n        if (this._synced) {\n            return time;\n        }\n        else {\n            return Math.max(time, this.context.currentTime);\n        }\n    }\n    /**\n     * Start the source at the specified time. If no time is given,\n     * start the source now.\n     * @param  time When the source should be started.\n     * @example\n     * const source = new Tone.Oscillator().toDestination();\n     * source.start(\"+0.5\"); // starts the source 0.5 seconds from now\n     */\n    start(time, offset, duration) {\n        let computedTime = isUndef(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);\n        computedTime = this._clampToCurrentTime(computedTime);\n        // if it's started, stop it and restart it\n        if (!this._synced && this._state.getValueAtTime(computedTime) === \"started\") {\n            // time should be strictly greater than the previous start time\n            assert(GT(computedTime, this._state.get(computedTime).time), \"Start time must be strictly greater than previous start time\");\n            this._state.cancel(computedTime);\n            this._state.setStateAtTime(\"started\", computedTime);\n            this.log(\"restart\", computedTime);\n            this.restart(computedTime, offset, duration);\n        }\n        else {\n            this.log(\"start\", computedTime);\n            this._state.setStateAtTime(\"started\", computedTime);\n            if (this._synced) {\n                // add the offset time to the event\n                const event = this._state.get(computedTime);\n                if (event) {\n                    event.offset = this.toSeconds(defaultArg(offset, 0));\n                    event.duration = duration ? this.toSeconds(duration) : undefined;\n                }\n                const sched = this.context.transport.schedule(t => {\n                    this._start(t, offset, duration);\n                }, computedTime);\n                this._scheduled.push(sched);\n                // if it's already started\n                if (this.context.transport.state === \"started\") {\n                    this._syncedStart(this.now(), this.context.transport.seconds);\n                }\n            }\n            else {\n                assertContextRunning(this.context);\n                this._start(computedTime, offset, duration);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the source at the specified time. If no time is given,\n     * stop the source now.\n     * @param  time When the source should be stopped.\n     * @example\n     * const source = new Tone.Oscillator().toDestination();\n     * source.start();\n     * source.stop(\"+0.5\"); // stops the source 0.5 seconds from now\n     */\n    stop(time) {\n        let computedTime = isUndef(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);\n        computedTime = this._clampToCurrentTime(computedTime);\n        if (this._state.getValueAtTime(computedTime) === \"started\" || isDefined(this._state.getNextState(\"started\", computedTime))) {\n            this.log(\"stop\", computedTime);\n            if (!this._synced) {\n                this._stop(computedTime);\n            }\n            else {\n                const sched = this.context.transport.schedule(this._stop.bind(this), computedTime);\n                this._scheduled.push(sched);\n            }\n            this._state.cancel(computedTime);\n            this._state.setStateAtTime(\"stopped\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Restart the source.\n     */\n    restart(time, offset, duration) {\n        time = this.toSeconds(time);\n        if (this._state.getValueAtTime(time) === \"started\") {\n            this._state.cancel(time);\n            this._restart(time, offset, duration);\n        }\n        return this;\n    }\n    /**\n     * Sync the source to the Transport so that all subsequent\n     * calls to `start` and `stop` are synced to the TransportTime\n     * instead of the AudioContext time.\n     *\n     * @example\n     * const osc = new Tone.Oscillator().toDestination();\n     * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline\n     * osc.sync().start(0).stop(0.3);\n     * // start the transport.\n     * Tone.Transport.start();\n     * // set it to loop once a second\n     * Tone.Transport.loop = true;\n     * Tone.Transport.loopEnd = 1;\n     */\n    sync() {\n        if (!this._synced) {\n            this._synced = true;\n            this._syncedStart = (time, offset) => {\n                if (offset > 0) {\n                    // get the playback state at that time\n                    const stateEvent = this._state.get(offset);\n                    // listen for start events which may occur in the middle of the sync'ed time\n                    if (stateEvent && stateEvent.state === \"started\" && stateEvent.time !== offset) {\n                        // get the offset\n                        const startOffset = offset - this.toSeconds(stateEvent.time);\n                        let duration;\n                        if (stateEvent.duration) {\n                            duration = this.toSeconds(stateEvent.duration) - startOffset;\n                        }\n                        this._start(time, this.toSeconds(stateEvent.offset) + startOffset, duration);\n                    }\n                }\n            };\n            this._syncedStop = time => {\n                const seconds = this.context.transport.getSecondsAtTime(Math.max(time - this.sampleTime, 0));\n                if (this._state.getValueAtTime(seconds) === \"started\") {\n                    this._stop(time);\n                }\n            };\n            this.context.transport.on(\"start\", this._syncedStart);\n            this.context.transport.on(\"loopStart\", this._syncedStart);\n            this.context.transport.on(\"stop\", this._syncedStop);\n            this.context.transport.on(\"pause\", this._syncedStop);\n            this.context.transport.on(\"loopEnd\", this._syncedStop);\n        }\n        return this;\n    }\n    /**\n     * Unsync the source to the Transport. See Source.sync\n     */\n    unsync() {\n        if (this._synced) {\n            this.context.transport.off(\"stop\", this._syncedStop);\n            this.context.transport.off(\"pause\", this._syncedStop);\n            this.context.transport.off(\"loopEnd\", this._syncedStop);\n            this.context.transport.off(\"start\", this._syncedStart);\n            this.context.transport.off(\"loopStart\", this._syncedStart);\n        }\n        this._synced = false;\n        // clear all of the scheduled ids\n        this._scheduled.forEach(id => this.context.transport.clear(id));\n        this._scheduled = [];\n        this._state.cancel(0);\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.onstop = noOp;\n        this.unsync();\n        this._volume.dispose();\n        this._state.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Source.js.map","import { __awaiter } from \"tslib\";\nimport { connect, ToneAudioNode } from \"../core/context/ToneAudioNode\";\nimport { Volume } from \"../component/channel/Volume\";\nimport { optionsFromArguments } from \"../core/util/Defaults\";\nimport { assert } from \"../core/util/Debug\";\nimport { readOnly } from \"../core/util/Interface\";\nimport { isDefined, isNumber } from \"../core/util/TypeCheck\";\n/**\n * UserMedia uses MediaDevices.getUserMedia to open up and external microphone or audio input.\n * Check [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)\n * to see which browsers are supported. Access to an external input\n * is limited to secure (HTTPS) connections.\n * @example\n * const mic = new Tone.UserMedia();\n * mic.open().then(() => {\n * \t// promise resolves when input is available\n * });\n * @category Source\n */\nexport class UserMedia extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(UserMedia.getDefaults(), arguments, [\"volume\"]));\n        this.name = \"UserMedia\";\n        const options = optionsFromArguments(UserMedia.getDefaults(), arguments, [\"volume\"]);\n        this._volume = this.output = new Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        readOnly(this, \"volume\");\n        this.mute = options.mute;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0\n        });\n    }\n    /**\n     * Open the media stream. If a string is passed in, it is assumed\n     * to be the label or id of the stream, if a number is passed in,\n     * it is the input number of the stream.\n     * @param  labelOrId The label or id of the audio input media device.\n     *                   With no argument, the default stream is opened.\n     * @return The promise is resolved when the stream is open.\n     */\n    open(labelOrId) {\n        return __awaiter(this, void 0, void 0, function* () {\n            assert(UserMedia.supported, \"UserMedia is not supported\");\n            // close the previous stream\n            if (this.state === \"started\") {\n                this.close();\n            }\n            const devices = yield UserMedia.enumerateDevices();\n            if (isNumber(labelOrId)) {\n                this._device = devices[labelOrId];\n            }\n            else {\n                this._device = devices.find((device) => {\n                    return device.label === labelOrId || device.deviceId === labelOrId;\n                });\n                // didn't find a matching device\n                if (!this._device && devices.length > 0) {\n                    this._device = devices[0];\n                }\n                assert(isDefined(this._device), `No matching device ${labelOrId}`);\n            }\n            // do getUserMedia\n            const constraints = {\n                audio: {\n                    echoCancellation: false,\n                    sampleRate: this.context.sampleRate,\n                    noiseSuppression: false,\n                    mozNoiseSuppression: false,\n                }\n            };\n            if (this._device) {\n                // @ts-ignore\n                constraints.audio.deviceId = this._device.deviceId;\n            }\n            const stream = yield navigator.mediaDevices.getUserMedia(constraints);\n            // start a new source only if the previous one is closed\n            if (!this._stream) {\n                this._stream = stream;\n                // Wrap a MediaStreamSourceNode around the live input stream.\n                const mediaStreamNode = this.context.createMediaStreamSource(stream);\n                // Connect the MediaStreamSourceNode to a gate gain node\n                connect(mediaStreamNode, this.output);\n                this._mediaStream = mediaStreamNode;\n            }\n            return this;\n        });\n    }\n    /**\n     * Close the media stream\n     */\n    close() {\n        if (this._stream && this._mediaStream) {\n            this._stream.getAudioTracks().forEach((track) => {\n                track.stop();\n            });\n            this._stream = undefined;\n            // remove the old media stream\n            this._mediaStream.disconnect();\n            this._mediaStream = undefined;\n        }\n        this._device = undefined;\n        return this;\n    }\n    /**\n     * Returns a promise which resolves with the list of audio input devices available.\n     * @return The promise that is resolved with the devices\n     * @example\n     * Tone.UserMedia.enumerateDevices().then((devices) => {\n     * \t// print the device labels\n     * \tconsole.log(devices.map(device => device.label));\n     * });\n     */\n    static enumerateDevices() {\n        return __awaiter(this, void 0, void 0, function* () {\n            const allDevices = yield navigator.mediaDevices.enumerateDevices();\n            return allDevices.filter(device => {\n                return device.kind === \"audioinput\";\n            });\n        });\n    }\n    /**\n     * Returns the playback state of the source, \"started\" when the microphone is open\n     * and \"stopped\" when the mic is closed.\n     */\n    get state() {\n        return this._stream && this._stream.active ? \"started\" : \"stopped\";\n    }\n    /**\n     * Returns an identifier for the represented device that is\n     * persisted across sessions. It is un-guessable by other applications and\n     * unique to the origin of the calling application. It is reset when the\n     * user clears cookies (for Private Browsing, a different identifier is\n     * used that is not persisted across sessions). Returns undefined when the\n     * device is not open.\n     */\n    get deviceId() {\n        if (this._device) {\n            return this._device.deviceId;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Returns a group identifier. Two devices have the\n     * same group identifier if they belong to the same physical device.\n     * Returns null  when the device is not open.\n     */\n    get groupId() {\n        if (this._device) {\n            return this._device.groupId;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Returns a label describing this device (for example \"Built-in Microphone\").\n     * Returns undefined when the device is not open or label is not available\n     * because of permissions.\n     */\n    get label() {\n        if (this._device) {\n            return this._device.label;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const mic = new Tone.UserMedia();\n     * mic.open().then(() => {\n     * \t// promise resolves when input is available\n     * });\n     * // mute the output\n     * mic.mute = true;\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    dispose() {\n        super.dispose();\n        this.close();\n        this._volume.dispose();\n        this.volume.dispose();\n        return this;\n    }\n    /**\n     * If getUserMedia is supported by the browser.\n     */\n    static get supported() {\n        return isDefined(navigator.mediaDevices) &&\n            isDefined(navigator.mediaDevices.getUserMedia);\n    }\n}\n//# sourceMappingURL=UserMedia.js.map","import { Source } from \"../Source\";\nimport { noOp } from \"../../core/util/Interface\";\nimport { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { defaultArg, optionsFromArguments } from \"../../core/util/Defaults\";\nimport { Clock } from \"../../core/clock/Clock\";\nimport { ToneBufferSource } from \"./ToneBufferSource\";\nimport { intervalToFrequencyRatio } from \"../../core/type/Conversions\";\nimport { assertRange } from \"../../core/util/Debug\";\n/**\n * GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).\n * Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the\n * amount of time each small chunk of audio is played for and the overlap is the\n * amount of crossfading transition time between successive grains.\n * @category Source\n */\nexport class GrainPlayer extends Source {\n    constructor() {\n        super(optionsFromArguments(GrainPlayer.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"GrainPlayer\";\n        /**\n         * Internal loopStart value\n         */\n        this._loopStart = 0;\n        /**\n         * Internal loopStart value\n         */\n        this._loopEnd = 0;\n        /**\n         * All of the currently playing BufferSources\n         */\n        this._activeSources = [];\n        const options = optionsFromArguments(GrainPlayer.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this.buffer = new ToneAudioBuffer({\n            onload: options.onload,\n            onerror: options.onerror,\n            reverse: options.reverse,\n            url: options.url,\n        });\n        this._clock = new Clock({\n            context: this.context,\n            callback: this._tick.bind(this),\n            frequency: 1 / options.grainSize\n        });\n        this._playbackRate = options.playbackRate;\n        this._grainSize = options.grainSize;\n        this._overlap = options.overlap;\n        this.detune = options.detune;\n        // setup\n        this.overlap = options.overlap;\n        this.loop = options.loop;\n        this.playbackRate = options.playbackRate;\n        this.grainSize = options.grainSize;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this.reverse = options.reverse;\n        this._clock.on(\"stop\", this._onstop.bind(this));\n    }\n    static getDefaults() {\n        return Object.assign(Source.getDefaults(), {\n            onload: noOp,\n            onerror: noOp,\n            overlap: 0.1,\n            grainSize: 0.2,\n            playbackRate: 1,\n            detune: 0,\n            loop: false,\n            loopStart: 0,\n            loopEnd: 0,\n            reverse: false\n        });\n    }\n    /**\n     * Internal start method\n     */\n    _start(time, offset, duration) {\n        offset = defaultArg(offset, 0);\n        offset = this.toSeconds(offset);\n        time = this.toSeconds(time);\n        const grainSize = 1 / this._clock.frequency.getValueAtTime(time);\n        this._clock.start(time, offset / grainSize);\n        if (duration) {\n            this.stop(time + this.toSeconds(duration));\n        }\n    }\n    /**\n     * Stop and then restart the player from the beginning (or offset)\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given,\n     * \t\t\t\t\tit will default to the full length of the sample (minus any offset)\n     */\n    restart(time, offset, duration) {\n        super.restart(time, offset, duration);\n        return this;\n    }\n    _restart(time, offset, duration) {\n        this._stop(time);\n        this._start(time, offset, duration);\n    }\n    /**\n     * Internal stop method\n     */\n    _stop(time) {\n        this._clock.stop(time);\n    }\n    /**\n     * Invoked when the clock is stopped\n     */\n    _onstop(time) {\n        // stop the players\n        this._activeSources.forEach((source) => {\n            source.fadeOut = 0;\n            source.stop(time);\n        });\n        this.onstop(this);\n    }\n    /**\n     * Invoked on each clock tick. scheduled a new grain at this time.\n     */\n    _tick(time) {\n        // check if it should stop looping\n        const ticks = this._clock.getTicksAtTime(time);\n        const offset = ticks * this._grainSize;\n        this.log(\"offset\", offset);\n        if (!this.loop && offset > this.buffer.duration) {\n            this.stop(time);\n            return;\n        }\n        // at the beginning of the file, the fade in should be 0\n        const fadeIn = offset < this._overlap ? 0 : this._overlap;\n        // create a buffer source\n        const source = new ToneBufferSource({\n            context: this.context,\n            url: this.buffer,\n            fadeIn: fadeIn,\n            fadeOut: this._overlap,\n            loop: this.loop,\n            loopStart: this._loopStart,\n            loopEnd: this._loopEnd,\n            // compute the playbackRate based on the detune\n            playbackRate: intervalToFrequencyRatio(this.detune / 100)\n        }).connect(this.output);\n        source.start(time, this._grainSize * ticks);\n        source.stop(time + this._grainSize / this.playbackRate);\n        // add it to the active sources\n        this._activeSources.push(source);\n        // remove it when it's done\n        source.onended = () => {\n            const index = this._activeSources.indexOf(source);\n            if (index !== -1) {\n                this._activeSources.splice(index, 1);\n            }\n        };\n    }\n    /**\n     * The playback rate of the sample\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        assertRange(rate, 0.001);\n        this._playbackRate = rate;\n        this.grainSize = this._grainSize;\n    }\n    /**\n     * The loop start time.\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(time) {\n        if (this.buffer.loaded) {\n            assertRange(this.toSeconds(time), 0, this.buffer.duration);\n        }\n        this._loopStart = this.toSeconds(time);\n    }\n    /**\n     * The loop end time.\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(time) {\n        if (this.buffer.loaded) {\n            assertRange(this.toSeconds(time), 0, this.buffer.duration);\n        }\n        this._loopEnd = this.toSeconds(time);\n    }\n    /**\n     * The direction the buffer should play in\n     */\n    get reverse() {\n        return this.buffer.reverse;\n    }\n    set reverse(rev) {\n        this.buffer.reverse = rev;\n    }\n    /**\n     * The size of each chunk of audio that the\n     * buffer is chopped into and played back at.\n     */\n    get grainSize() {\n        return this._grainSize;\n    }\n    set grainSize(size) {\n        this._grainSize = this.toSeconds(size);\n        this._clock.frequency.setValueAtTime(this._playbackRate / this._grainSize, this.now());\n    }\n    /**\n     * The duration of the cross-fade between successive grains.\n     */\n    get overlap() {\n        return this._overlap;\n    }\n    set overlap(time) {\n        this._overlap = this.toSeconds(time);\n    }\n    /**\n     * If all the buffer is loaded\n     */\n    get loaded() {\n        return this.buffer.loaded;\n    }\n    dispose() {\n        super.dispose();\n        this.buffer.dispose();\n        this._clock.dispose();\n        this._activeSources.forEach((source) => source.dispose());\n        return this;\n    }\n}\n//# sourceMappingURL=GrainPlayer.js.map","import { __awaiter, __decorate } from \"tslib\";\nimport { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { defaultArg, optionsFromArguments } from \"../../core/util/Defaults\";\nimport { noOp } from \"../../core/util/Interface\";\nimport { isUndef } from \"../../core/util/TypeCheck\";\nimport { Source } from \"../Source\";\nimport { ToneBufferSource } from \"./ToneBufferSource\";\nimport { assertRange } from \"../../core/util/Debug\";\nimport { timeRange } from \"../../core/util/Decorator\";\n/**\n * Player is an audio file player with start, loop, and stop functions.\n * @example\n * const player = new Tone.Player(\"https://tonejs.github.io/examples/audio/FWDL.mp3\").toDestination();\n * // play as soon as the buffer is loaded\n * player.autostart = true;\n * @category Source\n */\nexport class Player extends Source {\n    constructor() {\n        super(optionsFromArguments(Player.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"Player\";\n        /**\n         * All of the active buffer source nodes\n         */\n        this._activeSources = new Set();\n        const options = optionsFromArguments(Player.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this._buffer = new ToneAudioBuffer({\n            onload: this._onload.bind(this, options.onload),\n            onerror: options.onerror,\n            reverse: options.reverse,\n            url: options.url,\n        });\n        this.autostart = options.autostart;\n        this._loop = options.loop;\n        this._loopStart = options.loopStart;\n        this._loopEnd = options.loopEnd;\n        this._playbackRate = options.playbackRate;\n        this.fadeIn = options.fadeIn;\n        this.fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(Source.getDefaults(), {\n            autostart: false,\n            fadeIn: 0,\n            fadeOut: 0,\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            onload: noOp,\n            onerror: noOp,\n            playbackRate: 1,\n            reverse: false,\n        });\n    }\n    /**\n     * Load the audio file as an audio buffer.\n     * Decodes the audio asynchronously and invokes\n     * the callback once the audio buffer loads.\n     * Note: this does not need to be called if a url\n     * was passed in to the constructor. Only use this\n     * if you want to manually load a new url.\n     * @param url The url of the buffer to load. Filetype support depends on the browser.\n     */\n    load(url) {\n        return __awaiter(this, void 0, void 0, function* () {\n            yield this._buffer.load(url);\n            this._onload();\n            return this;\n        });\n    }\n    /**\n     * Internal callback when the buffer is loaded.\n     */\n    _onload(callback = noOp) {\n        callback();\n        if (this.autostart) {\n            this.start();\n        }\n    }\n    /**\n     * Internal callback when the buffer is done playing.\n     */\n    _onSourceEnd(source) {\n        // invoke the onstop function\n        this.onstop(this);\n        // delete the source from the active sources\n        this._activeSources.delete(source);\n        if (this._activeSources.size === 0 && !this._synced &&\n            this._state.getValueAtTime(this.now()) === \"started\") {\n            this._state.setStateAtTime(\"stopped\", this.now());\n        }\n    }\n    /**\n     * Play the buffer at the given startTime. Optionally add an offset\n     * and/or duration which will play the buffer from a position\n     * within the buffer for the given duration.\n     *\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)\n     */\n    start(time, offset, duration) {\n        super.start(time, offset, duration);\n        return this;\n    }\n    /**\n     * Internal start method\n     */\n    _start(startTime, offset, duration) {\n        // if it's a loop the default offset is the loopStart point\n        if (this._loop) {\n            offset = defaultArg(offset, this._loopStart);\n        }\n        else {\n            // otherwise the default offset is 0\n            offset = defaultArg(offset, 0);\n        }\n        // compute the values in seconds\n        let computedOffset = this.toSeconds(offset);\n        // if it's synced, it should factor in the playback rate for computing the offset\n        if (this._synced) {\n            computedOffset *= this._playbackRate;\n        }\n        // compute the duration which is either the passed in duration of the buffer.duration - offset\n        const origDuration = duration;\n        duration = defaultArg(duration, Math.max(this._buffer.duration - computedOffset, 0));\n        let computedDuration = this.toSeconds(duration);\n        // scale it by the playback rate\n        computedDuration = computedDuration / this._playbackRate;\n        // get the start time\n        startTime = this.toSeconds(startTime);\n        // make the source\n        const source = new ToneBufferSource({\n            url: this._buffer,\n            context: this.context,\n            fadeIn: this.fadeIn,\n            fadeOut: this.fadeOut,\n            loop: this._loop,\n            loopEnd: this._loopEnd,\n            loopStart: this._loopStart,\n            onended: this._onSourceEnd.bind(this),\n            playbackRate: this._playbackRate,\n        }).connect(this.output);\n        // set the looping properties\n        if (!this._loop && !this._synced) {\n            // cancel the previous stop\n            this._state.cancel(startTime + computedDuration);\n            // if it's not looping, set the state change at the end of the sample\n            this._state.setStateAtTime(\"stopped\", startTime + computedDuration, {\n                implicitEnd: true,\n            });\n        }\n        // add it to the array of active sources\n        this._activeSources.add(source);\n        // start it\n        if (this._loop && isUndef(origDuration)) {\n            source.start(startTime, computedOffset);\n        }\n        else {\n            // subtract the fade out time\n            source.start(startTime, computedOffset, computedDuration - this.toSeconds(this.fadeOut));\n        }\n    }\n    /**\n     * Stop playback.\n     */\n    _stop(time) {\n        const computedTime = this.toSeconds(time);\n        this._activeSources.forEach(source => source.stop(computedTime));\n    }\n    /**\n     * Stop and then restart the player from the beginning (or offset)\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given,\n     * \t\t\t\t\tit will default to the full length of the sample (minus any offset)\n     */\n    restart(time, offset, duration) {\n        super.restart(time, offset, duration);\n        return this;\n    }\n    _restart(time, offset, duration) {\n        this._stop(time);\n        this._start(time, offset, duration);\n    }\n    /**\n     * Seek to a specific time in the player's buffer. If the\n     * source is no longer playing at that time, it will stop.\n     * @param offset The time to seek to.\n     * @param when The time for the seek event to occur.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/examples/audio/FWDL.mp3\", () => {\n     * \tplayer.start();\n     * \t// seek to the offset in 1 second from now\n     * \tplayer.seek(0.4, \"+1\");\n     * }).toDestination();\n     */\n    seek(offset, when) {\n        const computedTime = this.toSeconds(when);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            const computedOffset = this.toSeconds(offset);\n            // if it's currently playing, stop it\n            this._stop(computedTime);\n            // restart it at the given time\n            this._start(computedTime, computedOffset);\n        }\n        return this;\n    }\n    /**\n     * Set the loop start and end. Will only loop if loop is set to true.\n     * @param loopStart The loop start time\n     * @param loopEnd The loop end time\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/examples/audio/FWDL.mp3\").toDestination();\n     * // loop between the given points\n     * player.setLoopPoints(0.2, 0.3);\n     * player.loop = true;\n     * player.autostart = true;\n     */\n    setLoopPoints(loopStart, loopEnd) {\n        this.loopStart = loopStart;\n        this.loopEnd = loopEnd;\n        return this;\n    }\n    /**\n     * If loop is true, the loop will start at this position.\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(loopStart) {\n        this._loopStart = loopStart;\n        if (this.buffer.loaded) {\n            assertRange(this.toSeconds(loopStart), 0, this.buffer.duration);\n        }\n        // get the current source\n        this._activeSources.forEach(source => {\n            source.loopStart = loopStart;\n        });\n    }\n    /**\n     * If loop is true, the loop will end at this position.\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = loopEnd;\n        if (this.buffer.loaded) {\n            assertRange(this.toSeconds(loopEnd), 0, this.buffer.duration);\n        }\n        // get the current source\n        this._activeSources.forEach(source => {\n            source.loopEnd = loopEnd;\n        });\n    }\n    /**\n     * The audio buffer belonging to the player.\n     */\n    get buffer() {\n        return this._buffer;\n    }\n    set buffer(buffer) {\n        this._buffer.set(buffer);\n    }\n    /**\n     * If the buffer should loop once it's over.\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        // if no change, do nothing\n        if (this._loop === loop) {\n            return;\n        }\n        this._loop = loop;\n        // set the loop of all of the sources\n        this._activeSources.forEach(source => {\n            source.loop = loop;\n        });\n        if (loop) {\n            // remove the next stopEvent\n            const stopEvent = this._state.getNextState(\"stopped\", this.now());\n            if (stopEvent) {\n                this._state.cancel(stopEvent.time);\n            }\n        }\n    }\n    /**\n     * The playback speed. 1 is normal speed. This is not a signal because\n     * Safari and iOS currently don't support playbackRate as a signal.\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        const now = this.now();\n        // cancel the stop event since it's at a different time now\n        const stopEvent = this._state.getNextState(\"stopped\", now);\n        if (stopEvent && stopEvent.implicitEnd) {\n            this._state.cancel(stopEvent.time);\n            this._activeSources.forEach(source => source.cancelStop());\n        }\n        // set all the sources\n        this._activeSources.forEach(source => {\n            source.playbackRate.setValueAtTime(rate, now);\n        });\n    }\n    /**\n     * The direction the buffer should play in\n     */\n    get reverse() {\n        return this._buffer.reverse;\n    }\n    set reverse(rev) {\n        this._buffer.reverse = rev;\n    }\n    /**\n     * If the buffer is loaded\n     */\n    get loaded() {\n        return this._buffer.loaded;\n    }\n    dispose() {\n        super.dispose();\n        // disconnect all of the players\n        this._activeSources.forEach(source => source.dispose());\n        this._activeSources.clear();\n        this._buffer.dispose();\n        return this;\n    }\n}\n__decorate([\n    timeRange(0)\n], Player.prototype, \"fadeIn\", void 0);\n__decorate([\n    timeRange(0)\n], Player.prototype, \"fadeOut\", void 0);\n//# sourceMappingURL=Player.js.map","import { Volume } from \"../../component/channel/Volume\";\nimport { ToneAudioBuffers } from \"../../core/context/ToneAudioBuffers\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { assert } from \"../../core/util/Debug\";\nimport { noOp, readOnly } from \"../../core/util/Interface\";\nimport { Source } from \"../Source\";\nimport { Player } from \"./Player\";\n/**\n * Players combines multiple [[Player]] objects.\n * @category Source\n */\nexport class Players extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(Players.getDefaults(), arguments, [\"urls\", \"onload\"], \"urls\"));\n        this.name = \"Players\";\n        /**\n         * Players has no input.\n         */\n        this.input = undefined;\n        /**\n         * The container of all of the players\n         */\n        this._players = new Map();\n        const options = optionsFromArguments(Players.getDefaults(), arguments, [\"urls\", \"onload\"], \"urls\");\n        /**\n         * The output volume node\n         */\n        this._volume = this.output = new Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        readOnly(this, \"volume\");\n        this._buffers = new ToneAudioBuffers({\n            urls: options.urls,\n            onload: options.onload,\n            baseUrl: options.baseUrl,\n            onerror: options.onerror\n        });\n        // mute initially\n        this.mute = options.mute;\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(Source.getDefaults(), {\n            baseUrl: \"\",\n            fadeIn: 0,\n            fadeOut: 0,\n            mute: false,\n            onload: noOp,\n            onerror: noOp,\n            urls: {},\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    /**\n     * The fadeIn time of the envelope applied to the source.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(fadeIn) {\n        this._fadeIn = fadeIn;\n        this._players.forEach(player => {\n            player.fadeIn = fadeIn;\n        });\n    }\n    /**\n     * The fadeOut time of the each of the sources.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(fadeOut) {\n        this._fadeOut = fadeOut;\n        this._players.forEach(player => {\n            player.fadeOut = fadeOut;\n        });\n    }\n    /**\n     * The state of the players object. Returns \"started\" if any of the players are playing.\n     */\n    get state() {\n        const playing = Array.from(this._players).some(([_, player]) => player.state === \"started\");\n        return playing ? \"started\" : \"stopped\";\n    }\n    /**\n     * True if the buffers object has a buffer by that name.\n     * @param name  The key or index of the buffer.\n     */\n    has(name) {\n        return this._buffers.has(name);\n    }\n    /**\n     * Get a player by name.\n     * @param  name  The players name as defined in the constructor object or `add` method.\n     */\n    player(name) {\n        assert(this.has(name), `No Player with the name ${name} exists on this object`);\n        if (!this._players.has(name)) {\n            const player = new Player({\n                context: this.context,\n                fadeIn: this._fadeIn,\n                fadeOut: this._fadeOut,\n                url: this._buffers.get(name),\n            }).connect(this.output);\n            this._players.set(name, player);\n        }\n        return this._players.get(name);\n    }\n    /**\n     * If all the buffers are loaded or not\n     */\n    get loaded() {\n        return this._buffers.loaded;\n    }\n    /**\n     * Add a player by name and url to the Players\n     * @param  name A unique name to give the player\n     * @param  url  Either the url of the bufer or a buffer which will be added with the given name.\n     * @param callback  The callback to invoke when the url is loaded.\n     */\n    add(name, url, callback) {\n        assert(!this._buffers.has(name), \"A buffer with that name already exists on this object\");\n        this._buffers.add(name, url, callback);\n        return this;\n    }\n    /**\n     * Stop all of the players at the given time\n     * @param time The time to stop all of the players.\n     */\n    stopAll(time) {\n        this._players.forEach(player => player.stop(time));\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._volume.dispose();\n        this.volume.dispose();\n        this._players.forEach(player => player.dispose());\n        this._buffers.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Players.js.map","import { connect } from \"../../core/context/ToneAudioNode\";\nimport { Param } from \"../../core/context/Param\";\nimport { ToneAudioBuffer } from \"../../core/context/ToneAudioBuffer\";\nimport { defaultArg, optionsFromArguments } from \"../../core/util/Defaults\";\nimport { noOp } from \"../../core/util/Interface\";\nimport { isDefined } from \"../../core/util/TypeCheck\";\nimport { assert } from \"../../core/util/Debug\";\nimport { OneShotSource } from \"../OneShotSource\";\nimport { EQ, GTE, LT } from \"../../core/util/Math\";\n/**\n * Wrapper around the native BufferSourceNode.\n * @category Source\n */\nexport class ToneBufferSource extends OneShotSource {\n    constructor() {\n        super(optionsFromArguments(ToneBufferSource.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"ToneBufferSource\";\n        /**\n         * The oscillator\n         */\n        this._source = this.context.createBufferSource();\n        this._internalChannels = [this._source];\n        /**\n         * indicators if the source has started/stopped\n         */\n        this._sourceStarted = false;\n        this._sourceStopped = false;\n        const options = optionsFromArguments(ToneBufferSource.getDefaults(), arguments, [\"url\", \"onload\"]);\n        connect(this._source, this._gainNode);\n        this._source.onended = () => this._stopSource();\n        /**\n         * The playbackRate of the buffer\n         */\n        this.playbackRate = new Param({\n            context: this.context,\n            param: this._source.playbackRate,\n            units: \"positive\",\n            value: options.playbackRate,\n        });\n        // set some values initially\n        this.loop = options.loop;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this._buffer = new ToneAudioBuffer(options.url, options.onload, options.onerror);\n        this._internalChannels.push(this._source);\n    }\n    static getDefaults() {\n        return Object.assign(OneShotSource.getDefaults(), {\n            url: new ToneAudioBuffer(),\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            onload: noOp,\n            onerror: noOp,\n            playbackRate: 1,\n        });\n    }\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(t) {\n        this._fadeIn = t;\n    }\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(t) {\n        this._fadeOut = t;\n    }\n    /**\n     * The curve applied to the fades, either \"linear\" or \"exponential\"\n     */\n    get curve() {\n        return this._curve;\n    }\n    set curve(t) {\n        this._curve = t;\n    }\n    /**\n     * Start the buffer\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)\n     * @param  gain  The gain to play the buffer back at.\n     */\n    start(time, offset, duration, gain = 1) {\n        assert(this.buffer.loaded, \"buffer is either not set or not loaded\");\n        const computedTime = this.toSeconds(time);\n        // apply the gain envelope\n        this._startGain(computedTime, gain);\n        // if it's a loop the default offset is the loopstart point\n        if (this.loop) {\n            offset = defaultArg(offset, this.loopStart);\n        }\n        else {\n            // otherwise the default offset is 0\n            offset = defaultArg(offset, 0);\n        }\n        // make sure the offset is not less than 0\n        let computedOffset = Math.max(this.toSeconds(offset), 0);\n        // start the buffer source\n        if (this.loop) {\n            // modify the offset if it's greater than the loop time\n            const loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;\n            const loopStart = this.toSeconds(this.loopStart);\n            const loopDuration = loopEnd - loopStart;\n            // move the offset back\n            if (GTE(computedOffset, loopEnd)) {\n                computedOffset = ((computedOffset - loopStart) % loopDuration) + loopStart;\n            }\n            // when the offset is very close to the duration, set it to 0\n            if (EQ(computedOffset, this.buffer.duration)) {\n                computedOffset = 0;\n            }\n        }\n        // this.buffer.loaded would have return false if the AudioBuffer was undefined\n        this._source.buffer = this.buffer.get();\n        this._source.loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;\n        if (LT(computedOffset, this.buffer.duration)) {\n            this._sourceStarted = true;\n            this._source.start(computedTime, computedOffset);\n        }\n        // if a duration is given, schedule a stop\n        if (isDefined(duration)) {\n            let computedDur = this.toSeconds(duration);\n            // make sure it's never negative\n            computedDur = Math.max(computedDur, 0);\n            this.stop(computedTime + computedDur);\n        }\n        return this;\n    }\n    _stopSource(time) {\n        if (!this._sourceStopped && this._sourceStarted) {\n            this._sourceStopped = true;\n            this._source.stop(this.toSeconds(time));\n            this._onended();\n        }\n    }\n    /**\n     * If loop is true, the loop will start at this position.\n     */\n    get loopStart() {\n        return this._source.loopStart;\n    }\n    set loopStart(loopStart) {\n        this._source.loopStart = this.toSeconds(loopStart);\n    }\n    /**\n     * If loop is true, the loop will end at this position.\n     */\n    get loopEnd() {\n        return this._source.loopEnd;\n    }\n    set loopEnd(loopEnd) {\n        this._source.loopEnd = this.toSeconds(loopEnd);\n    }\n    /**\n     * The audio buffer belonging to the player.\n     */\n    get buffer() {\n        return this._buffer;\n    }\n    set buffer(buffer) {\n        this._buffer.set(buffer);\n    }\n    /**\n     * If the buffer should loop once it's over.\n     */\n    get loop() {\n        return this._source.loop;\n    }\n    set loop(loop) {\n        this._source.loop = loop;\n        if (this._sourceStarted) {\n            this.cancelStop();\n        }\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._source.onended = null;\n        this._source.disconnect();\n        this._buffer.dispose();\n        this.playbackRate.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneBufferSource.js.map","export * from \"./Noise\";\nexport * from \"./UserMedia\";\nexport * from \"./oscillator/Oscillator\";\nexport * from \"./oscillator/AMOscillator\";\nexport * from \"./oscillator/FMOscillator\";\nexport * from \"./oscillator/PulseOscillator\";\nexport * from \"./oscillator/FatOscillator\";\nexport * from \"./oscillator/PWMOscillator\";\nexport * from \"./oscillator/OmniOscillator\";\nexport * from \"./oscillator/ToneOscillatorNode\";\nexport * from \"./oscillator/LFO\";\nexport * from \"./buffer/ToneBufferSource\";\nexport * from \"./buffer/Player\";\nexport * from \"./buffer/Players\";\nexport * from \"./buffer/GrainPlayer\";\n//# sourceMappingURL=index.js.map","import { __awaiter } from \"tslib\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { AudioToGain } from \"../../signal/AudioToGain\";\nimport { Multiply } from \"../../signal/Multiply\";\nimport { Source } from \"../Source\";\nimport { Oscillator } from \"./Oscillator\";\nimport { generateWaveform } from \"./OscillatorInterface\";\n/**\n * An amplitude modulated oscillator node. It is implemented with\n * two oscillators, one which modulators the other's amplitude\n * through a gain node.\n * ```\n *    +-------------+       +----------+\n *    | Carrier Osc +>------> GainNode |\n *    +-------------+       |          +--->Output\n *                      +---> gain     |\n * +---------------+    |   +----------+\n * | Modulator Osc +>---+\n * +---------------+\n * ```\n * @offline 0.2 1\n * @example\n * const amOsc = new Tone.AMOscillator(30, \"sine\", \"square\").toDestination().start();\n * @category Source\n */\nexport class AMOscillator extends Source {\n    constructor() {\n        super(optionsFromArguments(AMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]));\n        this.name = \"AMOscillator\";\n        /**\n         * convert the -1,1 output to 0,1\n         */\n        this._modulationScale = new AudioToGain({ context: this.context });\n        /**\n         * the node where the modulation happens\n         */\n        this._modulationNode = new Gain({\n            context: this.context,\n        });\n        const options = optionsFromArguments(AMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]);\n        this._carrier = new Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: options.type,\n        });\n        this.frequency = this._carrier.frequency,\n            this.detune = this._carrier.detune;\n        this._modulator = new Oscillator({\n            context: this.context,\n            phase: options.phase,\n            type: options.modulationType,\n        });\n        this.harmonicity = new Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        // connections\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this._modulator.chain(this._modulationScale, this._modulationNode.gain);\n        this._carrier.chain(this._modulationNode, this.output);\n        readOnly(this, [\"frequency\", \"detune\", \"harmonicity\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Oscillator.getDefaults(), {\n            harmonicity: 1,\n            modulationType: \"square\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._modulator.start(time);\n        this._carrier.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        this._modulator.stop(time);\n        this._carrier.stop(time);\n    }\n    _restart(time) {\n        this._modulator.restart(time);\n        this._carrier.restart(time);\n    }\n    /**\n     * The type of the carrier oscillator\n     */\n    get type() {\n        return this._carrier.type;\n    }\n    set type(type) {\n        this._carrier.type = type;\n    }\n    get baseType() {\n        return this._carrier.baseType;\n    }\n    set baseType(baseType) {\n        this._carrier.baseType = baseType;\n    }\n    get partialCount() {\n        return this._carrier.partialCount;\n    }\n    set partialCount(partialCount) {\n        this._carrier.partialCount = partialCount;\n    }\n    /**\n     * The type of the modulator oscillator\n     */\n    get modulationType() {\n        return this._modulator.type;\n    }\n    set modulationType(type) {\n        this._modulator.type = type;\n    }\n    get phase() {\n        return this._carrier.phase;\n    }\n    set phase(phase) {\n        this._carrier.phase = phase;\n        this._modulator.phase = phase;\n    }\n    get partials() {\n        return this._carrier.partials;\n    }\n    set partials(partials) {\n        this._carrier.partials = partials;\n    }\n    asArray(length = 1024) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return generateWaveform(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this.harmonicity.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this._modulationNode.dispose();\n        this._modulationScale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AMOscillator.js.map","import { __awaiter } from \"tslib\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { Multiply } from \"../../signal/Multiply\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { Oscillator } from \"./Oscillator\";\nimport { generateWaveform } from \"./OscillatorInterface\";\n/**\n * FMOscillator implements a frequency modulation synthesis\n * ```\n *                                              +-------------+\n * +---------------+        +-------------+     | Carrier Osc |\n * | Modulator Osc +>-------> GainNode    |     |             +--->Output\n * +---------------+        |             +>----> frequency   |\n *                       +--> gain        |     +-------------+\n *                       |  +-------------+\n * +-----------------+   |\n * | modulationIndex +>--+\n * +-----------------+\n * ```\n *\n * @offline 0.1 1\n * @example\n * const fmOsc = new Tone.FMOscillator({\n * \tfrequency: 200,\n * \ttype: \"square\",\n * \tmodulationType: \"triangle\",\n * \tharmonicity: 0.2,\n * \tmodulationIndex: 3\n * }).toDestination().start();\n * @category Source\n */\nexport class FMOscillator extends Source {\n    constructor() {\n        super(optionsFromArguments(FMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]));\n        this.name = \"FMOscillator\";\n        /**\n         * the node where the modulation happens\n         */\n        this._modulationNode = new Gain({\n            context: this.context,\n            gain: 0,\n        });\n        const options = optionsFromArguments(FMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]);\n        this._carrier = new Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: 0,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: options.type,\n        });\n        this.detune = this._carrier.detune;\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this._modulator = new Oscillator({\n            context: this.context,\n            phase: options.phase,\n            type: options.modulationType,\n        });\n        this.harmonicity = new Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        this.modulationIndex = new Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.modulationIndex,\n        });\n        // connections\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.frequency.chain(this.modulationIndex, this._modulationNode);\n        this._modulator.connect(this._modulationNode.gain);\n        this._modulationNode.connect(this._carrier.frequency);\n        this._carrier.connect(this.output);\n        this.detune.connect(this._modulator.detune);\n        readOnly(this, [\"modulationIndex\", \"frequency\", \"detune\", \"harmonicity\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Oscillator.getDefaults(), {\n            harmonicity: 1,\n            modulationIndex: 2,\n            modulationType: \"square\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._modulator.start(time);\n        this._carrier.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        this._modulator.stop(time);\n        this._carrier.stop(time);\n    }\n    _restart(time) {\n        this._modulator.restart(time);\n        this._carrier.restart(time);\n        return this;\n    }\n    get type() {\n        return this._carrier.type;\n    }\n    set type(type) {\n        this._carrier.type = type;\n    }\n    get baseType() {\n        return this._carrier.baseType;\n    }\n    set baseType(baseType) {\n        this._carrier.baseType = baseType;\n    }\n    get partialCount() {\n        return this._carrier.partialCount;\n    }\n    set partialCount(partialCount) {\n        this._carrier.partialCount = partialCount;\n    }\n    /**\n     * The type of the modulator oscillator\n     */\n    get modulationType() {\n        return this._modulator.type;\n    }\n    set modulationType(type) {\n        this._modulator.type = type;\n    }\n    get phase() {\n        return this._carrier.phase;\n    }\n    set phase(phase) {\n        this._carrier.phase = phase;\n        this._modulator.phase = phase;\n    }\n    get partials() {\n        return this._carrier.partials;\n    }\n    set partials(partials) {\n        this._carrier.partials = partials;\n    }\n    asArray(length = 1024) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return generateWaveform(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.harmonicity.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this._modulationNode.dispose();\n        this.modulationIndex.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FMOscillator.js.map","import { __awaiter } from \"tslib\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { noOp, readOnly } from \"../../core/util/Interface\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { Oscillator } from \"./Oscillator\";\nimport { generateWaveform } from \"./OscillatorInterface\";\nimport { assertRange } from \"../../core/util/Debug\";\n/**\n * FatOscillator is an array of oscillators with detune spread between the oscillators\n * @example\n * const fatOsc = new Tone.FatOscillator(\"Ab3\", \"sawtooth\", 40).toDestination().start();\n * @category Source\n */\nexport class FatOscillator extends Source {\n    constructor() {\n        super(optionsFromArguments(FatOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"spread\"]));\n        this.name = \"FatOscillator\";\n        /**\n         * The array of oscillators\n         */\n        this._oscillators = [];\n        const options = optionsFromArguments(FatOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"spread\"]);\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this._spread = options.spread;\n        this._type = options.type;\n        this._phase = options.phase;\n        this._partials = options.partials;\n        this._partialCount = options.partialCount;\n        // set the count initially\n        this.count = options.count;\n        readOnly(this, [\"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Oscillator.getDefaults(), {\n            count: 3,\n            spread: 20,\n            type: \"sawtooth\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._forEach(osc => osc.start(time));\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._forEach(osc => osc.stop(time));\n    }\n    _restart(time) {\n        this._forEach(osc => osc.restart(time));\n    }\n    /**\n     * Iterate over all of the oscillators\n     */\n    _forEach(iterator) {\n        for (let i = 0; i < this._oscillators.length; i++) {\n            iterator(this._oscillators[i], i);\n        }\n    }\n    /**\n     * The type of the oscillator\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._type = type;\n        this._forEach(osc => osc.type = type);\n    }\n    /**\n     * The detune spread between the oscillators. If \"count\" is\n     * set to 3 oscillators and the \"spread\" is set to 40,\n     * the three oscillators would be detuned like this: [-20, 0, 20]\n     * for a total detune spread of 40 cents.\n     * @example\n     * const fatOsc = new Tone.FatOscillator().toDestination().start();\n     * fatOsc.spread = 70;\n     */\n    get spread() {\n        return this._spread;\n    }\n    set spread(spread) {\n        this._spread = spread;\n        if (this._oscillators.length > 1) {\n            const start = -spread / 2;\n            const step = spread / (this._oscillators.length - 1);\n            this._forEach((osc, i) => osc.detune.value = start + step * i);\n        }\n    }\n    /**\n     * The number of detuned oscillators. Must be an integer greater than 1.\n     * @example\n     * const fatOsc = new Tone.FatOscillator(\"C#3\", \"sawtooth\").toDestination().start();\n     * // use 4 sawtooth oscillators\n     * fatOsc.count = 4;\n     */\n    get count() {\n        return this._oscillators.length;\n    }\n    set count(count) {\n        assertRange(count, 1);\n        if (this._oscillators.length !== count) {\n            // dispose the previous oscillators\n            this._forEach(osc => osc.dispose());\n            this._oscillators = [];\n            for (let i = 0; i < count; i++) {\n                const osc = new Oscillator({\n                    context: this.context,\n                    volume: -6 - count * 1.1,\n                    type: this._type,\n                    phase: this._phase + (i / count) * 360,\n                    partialCount: this._partialCount,\n                    onstop: i === 0 ? () => this.onstop(this) : noOp,\n                });\n                if (this.type === \"custom\") {\n                    osc.partials = this._partials;\n                }\n                this.frequency.connect(osc.frequency);\n                this.detune.connect(osc.detune);\n                osc.detune.overridden = false;\n                osc.connect(this.output);\n                this._oscillators[i] = osc;\n            }\n            // set the spread\n            this.spread = this._spread;\n            if (this.state === \"started\") {\n                this._forEach(osc => osc.start());\n            }\n        }\n    }\n    get phase() {\n        return this._phase;\n    }\n    set phase(phase) {\n        this._phase = phase;\n        this._forEach(osc => osc.phase = phase);\n    }\n    get baseType() {\n        return this._oscillators[0].baseType;\n    }\n    set baseType(baseType) {\n        this._forEach(osc => osc.baseType = baseType);\n        this._type = this._oscillators[0].type;\n    }\n    get partials() {\n        return this._oscillators[0].partials;\n    }\n    set partials(partials) {\n        this._partials = partials;\n        this._partialCount = this._partials.length;\n        if (partials.length) {\n            this._type = \"custom\";\n            this._forEach(osc => osc.partials = partials);\n        }\n    }\n    get partialCount() {\n        return this._oscillators[0].partialCount;\n    }\n    set partialCount(partialCount) {\n        this._partialCount = partialCount;\n        this._forEach(osc => osc.partialCount = partialCount);\n        this._type = this._oscillators[0].type;\n    }\n    asArray(length = 1024) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return generateWaveform(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._forEach(osc => osc.dispose());\n        return this;\n    }\n}\n//# sourceMappingURL=FatOscillator.js.map","import { Gain } from \"../../core/context/Gain\";\nimport { Param } from \"../../core/context/Param\";\nimport { ToneAudioNode } from \"../../core/context/ToneAudioNode\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { AudioToGain } from \"../../signal/AudioToGain\";\nimport { Scale } from \"../../signal/Scale\";\nimport { connectSignal, Signal } from \"../../signal/Signal\";\nimport { Zero } from \"../../signal/Zero\";\nimport { Oscillator } from \"./Oscillator\";\n/**\n * LFO stands for low frequency oscillator. LFO produces an output signal\n * which can be attached to an AudioParam or Tone.Signal\n * in order to modulate that parameter with an oscillator. The LFO can\n * also be synced to the transport to start/stop and change when the tempo changes.\n * @offline 0.5 1\n * @example\n * const lfo = new Tone.LFO(\"4n\", 400, 4000).start().toDestination();\n * @category Source\n */\nexport class LFO extends ToneAudioNode {\n    constructor() {\n        super(optionsFromArguments(LFO.getDefaults(), arguments, [\"frequency\", \"min\", \"max\"]));\n        this.name = \"LFO\";\n        /**\n         * The value that the LFO outputs when it's stopped\n         */\n        this._stoppedValue = 0;\n        /**\n         * A private placeholder for the units\n         */\n        this._units = \"number\";\n        /**\n         * If the input value is converted using the [[units]]\n         */\n        this.convert = true;\n        /**\n         * Private methods borrowed from Param\n         */\n        // @ts-ignore\n        this._fromType = Param.prototype._fromType;\n        // @ts-ignore\n        this._toType = Param.prototype._toType;\n        // @ts-ignore\n        this._is = Param.prototype._is;\n        // @ts-ignore\n        this._clampValue = Param.prototype._clampValue;\n        const options = optionsFromArguments(LFO.getDefaults(), arguments, [\"frequency\", \"min\", \"max\"]);\n        // @ts-ignore\n        this._oscillator = new Oscillator({\n            context: this.context,\n            frequency: options.frequency,\n            type: options.type,\n        });\n        this.frequency = this._oscillator.frequency;\n        this._amplitudeGain = new Gain({\n            context: this.context,\n            gain: options.amplitude,\n            units: \"normalRange\",\n        });\n        this.amplitude = this._amplitudeGain.gain;\n        this._stoppedSignal = new Signal({\n            context: this.context,\n            units: \"audioRange\",\n            value: 0,\n        });\n        this._zeros = new Zero({ context: this.context });\n        this._a2g = new AudioToGain({ context: this.context });\n        this._scaler = this.output = new Scale({\n            context: this.context,\n            max: options.max,\n            min: options.min,\n        });\n        this.units = options.units;\n        this.min = options.min;\n        this.max = options.max;\n        // connect it up\n        this._oscillator.chain(this._a2g, this._amplitudeGain, this._scaler);\n        this._zeros.connect(this._a2g);\n        this._stoppedSignal.connect(this._a2g);\n        readOnly(this, [\"amplitude\", \"frequency\"]);\n        this.phase = options.phase;\n    }\n    static getDefaults() {\n        return Object.assign(ToneAudioNode.getDefaults(), {\n            amplitude: 1,\n            frequency: \"4n\",\n            max: 1,\n            min: 0,\n            phase: 0,\n            type: \"sine\",\n            units: \"number\",\n        });\n    }\n    /**\n     * Start the LFO.\n     * @param time The time the LFO will start\n     */\n    start(time) {\n        time = this.toSeconds(time);\n        this._stoppedSignal.setValueAtTime(0, time);\n        this._oscillator.start(time);\n        return this;\n    }\n    /**\n     * Stop the LFO.\n     * @param  time The time the LFO will stop\n     */\n    stop(time) {\n        time = this.toSeconds(time);\n        this._stoppedSignal.setValueAtTime(this._stoppedValue, time);\n        this._oscillator.stop(time);\n        return this;\n    }\n    /**\n     * Sync the start/stop/pause to the transport\n     * and the frequency to the bpm of the transport\n     * @example\n     * const lfo = new Tone.LFO(\"8n\");\n     * lfo.sync().start(0);\n     * // the rate of the LFO will always be an eighth note, even as the tempo changes\n     */\n    sync() {\n        this._oscillator.sync();\n        this._oscillator.syncFrequency();\n        return this;\n    }\n    /**\n     * unsync the LFO from transport control\n     */\n    unsync() {\n        this._oscillator.unsync();\n        this._oscillator.unsyncFrequency();\n        return this;\n    }\n    /**\n     * The minimum output of the LFO.\n     */\n    get min() {\n        return this._toType(this._scaler.min);\n    }\n    set min(min) {\n        min = this._fromType(min);\n        this._scaler.min = min;\n    }\n    /**\n     * The maximum output of the LFO.\n     */\n    get max() {\n        return this._toType(this._scaler.max);\n    }\n    set max(max) {\n        max = this._fromType(max);\n        this._scaler.max = max;\n    }\n    /**\n     * The type of the oscillator: See [[Oscillator.type]]\n     */\n    get type() {\n        return this._oscillator.type;\n    }\n    set type(type) {\n        this._oscillator.type = type;\n        this._stoppedValue = this._oscillator.getInitialValue();\n        this._stoppedSignal.value = this._stoppedValue;\n    }\n    /**\n     * The phase of the LFO.\n     */\n    get phase() {\n        return this._oscillator.phase;\n    }\n    set phase(phase) {\n        this._oscillator.phase = phase;\n        this._stoppedValue = this._oscillator.getInitialValue();\n        this._stoppedSignal.value = this._stoppedValue;\n    }\n    /**\n     * The output units of the LFO.\n     */\n    get units() {\n        return this._units;\n    }\n    set units(val) {\n        const currentMin = this.min;\n        const currentMax = this.max;\n        // convert the min and the max\n        this._units = val;\n        this.min = currentMin;\n        this.max = currentMax;\n    }\n    /**\n     * Returns the playback state of the source, either \"started\" or \"stopped\".\n     */\n    get state() {\n        return this._oscillator.state;\n    }\n    /**\n     * @param node the destination to connect to\n     * @param outputNum the optional output number\n     * @param inputNum the input number\n     */\n    connect(node, outputNum, inputNum) {\n        if (node instanceof Param || node instanceof Signal) {\n            this.convert = node.convert;\n            this.units = node.units;\n        }\n        connectSignal(this, node, outputNum, inputNum);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._oscillator.dispose();\n        this._stoppedSignal.dispose();\n        this._zeros.dispose();\n        this._scaler.dispose();\n        this._a2g.dispose();\n        this._amplitudeGain.dispose();\n        this.amplitude.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LFO.js.map","import { __awaiter } from \"tslib\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { isNumber, isString } from \"../../core/util/TypeCheck\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { AMOscillator } from \"./AMOscillator\";\nimport { FatOscillator } from \"./FatOscillator\";\nimport { FMOscillator } from \"./FMOscillator\";\nimport { Oscillator } from \"./Oscillator\";\nimport { generateWaveform } from \"./OscillatorInterface\";\nimport { PulseOscillator } from \"./PulseOscillator\";\nimport { PWMOscillator } from \"./PWMOscillator\";\nconst OmniOscillatorSourceMap = {\n    am: AMOscillator,\n    fat: FatOscillator,\n    fm: FMOscillator,\n    oscillator: Oscillator,\n    pulse: PulseOscillator,\n    pwm: PWMOscillator,\n};\n/**\n * OmniOscillator aggregates all of the oscillator types into one.\n * @offline 0.1 1\n * @example\n * const omniOsc = new Tone.OmniOscillator(\"C#4\", \"pwm\").toDestination().start();\n * @category Source\n */\nexport class OmniOscillator extends Source {\n    constructor() {\n        super(optionsFromArguments(OmniOscillator.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"OmniOscillator\";\n        const options = optionsFromArguments(OmniOscillator.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        readOnly(this, [\"frequency\", \"detune\"]);\n        // set the options\n        this.set(options);\n    }\n    static getDefaults() {\n        return Object.assign(Oscillator.getDefaults(), FMOscillator.getDefaults(), AMOscillator.getDefaults(), FatOscillator.getDefaults(), PulseOscillator.getDefaults(), PWMOscillator.getDefaults());\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._oscillator.start(time);\n    }\n    /**\n     * start the oscillator\n     */\n    _stop(time) {\n        this._oscillator.stop(time);\n    }\n    _restart(time) {\n        this._oscillator.restart(time);\n        return this;\n    }\n    /**\n     * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or\n     * prefix the basic types with \"fm\", \"am\", or \"fat\" to use the FMOscillator, AMOscillator or FatOscillator\n     * types. The oscillator could also be set to \"pwm\" or \"pulse\". All of the parameters of the\n     * oscillator's class are accessible when the oscillator is set to that type, but throws an error\n     * when it's not.\n     * @example\n     * const omniOsc = new Tone.OmniOscillator().toDestination().start();\n     * omniOsc.type = \"pwm\";\n     * // modulationFrequency is parameter which is available\n     * // only when the type is \"pwm\".\n     * omniOsc.modulationFrequency.value = 0.5;\n     */\n    get type() {\n        let prefix = \"\";\n        if ([\"am\", \"fm\", \"fat\"].some(p => this._sourceType === p)) {\n            prefix = this._sourceType;\n        }\n        return prefix + this._oscillator.type;\n    }\n    set type(type) {\n        if (type.substr(0, 2) === \"fm\") {\n            this._createNewOscillator(\"fm\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(2);\n        }\n        else if (type.substr(0, 2) === \"am\") {\n            this._createNewOscillator(\"am\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(2);\n        }\n        else if (type.substr(0, 3) === \"fat\") {\n            this._createNewOscillator(\"fat\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(3);\n        }\n        else if (type === \"pwm\") {\n            this._createNewOscillator(\"pwm\");\n            this._oscillator = this._oscillator;\n        }\n        else if (type === \"pulse\") {\n            this._createNewOscillator(\"pulse\");\n        }\n        else {\n            this._createNewOscillator(\"oscillator\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type;\n        }\n    }\n    /**\n     * The value is an empty array when the type is not \"custom\".\n     * This is not available on \"pwm\" and \"pulse\" oscillator types.\n     * See [[Oscillator.partials]]\n     */\n    get partials() {\n        return this._oscillator.partials;\n    }\n    set partials(partials) {\n        if (!this._getOscType(this._oscillator, \"pulse\") && !this._getOscType(this._oscillator, \"pwm\")) {\n            this._oscillator.partials = partials;\n        }\n    }\n    get partialCount() {\n        return this._oscillator.partialCount;\n    }\n    set partialCount(partialCount) {\n        if (!this._getOscType(this._oscillator, \"pulse\") && !this._getOscType(this._oscillator, \"pwm\")) {\n            this._oscillator.partialCount = partialCount;\n        }\n    }\n    set(props) {\n        // make sure the type is set first\n        if (Reflect.has(props, \"type\") && props.type) {\n            this.type = props.type;\n        }\n        // then set the rest\n        super.set(props);\n        return this;\n    }\n    /**\n     * connect the oscillator to the frequency and detune signals\n     */\n    _createNewOscillator(oscType) {\n        if (oscType !== this._sourceType) {\n            this._sourceType = oscType;\n            const OscConstructor = OmniOscillatorSourceMap[oscType];\n            // short delay to avoid clicks on the change\n            const now = this.now();\n            if (this._oscillator) {\n                const oldOsc = this._oscillator;\n                oldOsc.stop(now);\n                // dispose the old one\n                this.context.setTimeout(() => oldOsc.dispose(), this.blockTime);\n            }\n            this._oscillator = new OscConstructor({\n                context: this.context,\n            });\n            this.frequency.connect(this._oscillator.frequency);\n            this.detune.connect(this._oscillator.detune);\n            this._oscillator.connect(this.output);\n            this._oscillator.onstop = () => this.onstop(this);\n            if (this.state === \"started\") {\n                this._oscillator.start(now);\n            }\n        }\n    }\n    get phase() {\n        return this._oscillator.phase;\n    }\n    set phase(phase) {\n        this._oscillator.phase = phase;\n    }\n    /**\n     * The source type of the oscillator.\n     * @example\n     * const omniOsc = new Tone.OmniOscillator(440, \"fmsquare\");\n     * console.log(omniOsc.sourceType); // 'fm'\n     */\n    get sourceType() {\n        return this._sourceType;\n    }\n    set sourceType(sType) {\n        // the basetype defaults to sine\n        let baseType = \"sine\";\n        if (this._oscillator.type !== \"pwm\" && this._oscillator.type !== \"pulse\") {\n            baseType = this._oscillator.type;\n        }\n        // set the type\n        if (sType === \"fm\") {\n            this.type = \"fm\" + baseType;\n        }\n        else if (sType === \"am\") {\n            this.type = \"am\" + baseType;\n        }\n        else if (sType === \"fat\") {\n            this.type = \"fat\" + baseType;\n        }\n        else if (sType === \"oscillator\") {\n            this.type = baseType;\n        }\n        else if (sType === \"pulse\") {\n            this.type = \"pulse\";\n        }\n        else if (sType === \"pwm\") {\n            this.type = \"pwm\";\n        }\n    }\n    _getOscType(osc, sourceType) {\n        return osc instanceof OmniOscillatorSourceMap[sourceType];\n    }\n    /**\n     * The base type of the oscillator. See [[Oscillator.baseType]]\n     * @example\n     * const omniOsc = new Tone.OmniOscillator(440, \"fmsquare4\");\n     * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);\n     */\n    get baseType() {\n        return this._oscillator.baseType;\n    }\n    set baseType(baseType) {\n        if (!this._getOscType(this._oscillator, \"pulse\") &&\n            !this._getOscType(this._oscillator, \"pwm\") &&\n            baseType !== \"pulse\" && baseType !== \"pwm\") {\n            this._oscillator.baseType = baseType;\n        }\n    }\n    /**\n     * The width of the oscillator when sourceType === \"pulse\".\n     * See [[PWMOscillator.width]]\n     */\n    get width() {\n        if (this._getOscType(this._oscillator, \"pulse\")) {\n            return this._oscillator.width;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * The number of detuned oscillators when sourceType === \"fat\".\n     * See [[FatOscillator.count]]\n     */\n    get count() {\n        if (this._getOscType(this._oscillator, \"fat\")) {\n            return this._oscillator.count;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set count(count) {\n        if (this._getOscType(this._oscillator, \"fat\") && isNumber(count)) {\n            this._oscillator.count = count;\n        }\n    }\n    /**\n     * The detune spread between the oscillators when sourceType === \"fat\".\n     * See [[FatOscillator.count]]\n     */\n    get spread() {\n        if (this._getOscType(this._oscillator, \"fat\")) {\n            return this._oscillator.spread;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set spread(spread) {\n        if (this._getOscType(this._oscillator, \"fat\") && isNumber(spread)) {\n            this._oscillator.spread = spread;\n        }\n    }\n    /**\n     * The type of the modulator oscillator. Only if the oscillator is set to \"am\" or \"fm\" types.\n     * See [[AMOscillator]] or [[FMOscillator]]\n     */\n    get modulationType() {\n        if (this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) {\n            return this._oscillator.modulationType;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set modulationType(mType) {\n        if ((this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) && isString(mType)) {\n            this._oscillator.modulationType = mType;\n        }\n    }\n    /**\n     * The modulation index when the sourceType === \"fm\"\n     * See [[FMOscillator]].\n     */\n    get modulationIndex() {\n        if (this._getOscType(this._oscillator, \"fm\")) {\n            return this._oscillator.modulationIndex;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n     * See [[AMOscillator]] or [[FMOscillator]]\n     */\n    get harmonicity() {\n        if (this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) {\n            return this._oscillator.harmonicity;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * The modulationFrequency Signal of the oscillator when sourceType === \"pwm\"\n     * see [[PWMOscillator]]\n     * @min 0.1\n     * @max 5\n     */\n    get modulationFrequency() {\n        if (this._getOscType(this._oscillator, \"pwm\")) {\n            return this._oscillator.modulationFrequency;\n        }\n        else {\n            return undefined;\n        }\n    }\n    asArray(length = 1024) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return generateWaveform(this, length);\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.detune.dispose();\n        this.frequency.dispose();\n        this._oscillator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=OmniOscillator.js.map","import { __awaiter } from \"tslib\";\nimport { deepEquals, optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { isDefined } from \"../../core/util/TypeCheck\";\nimport { Signal } from \"../../signal/Signal\";\nimport { Source } from \"../Source\";\nimport { generateWaveform } from \"./OscillatorInterface\";\nimport { ToneOscillatorNode } from \"./ToneOscillatorNode\";\nimport { assertRange } from \"../../core/util/Debug\";\nimport { clamp } from \"../../core/util/Math\";\n/**\n * Oscillator supports a number of features including\n * phase rotation, multiple oscillator types (see Oscillator.type),\n * and Transport syncing (see Oscillator.syncFrequency).\n *\n * @example\n * // make and start a 440hz sine tone\n * const osc = new Tone.Oscillator(440, \"sine\").toDestination().start();\n * @category Source\n */\nexport class Oscillator extends Source {\n    constructor() {\n        super(optionsFromArguments(Oscillator.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"Oscillator\";\n        /**\n         * the main oscillator\n         */\n        this._oscillator = null;\n        const options = optionsFromArguments(Oscillator.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this.frequency = new Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        readOnly(this, \"frequency\");\n        this.detune = new Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        readOnly(this, \"detune\");\n        this._partials = options.partials;\n        this._partialCount = options.partialCount;\n        this._type = options.type;\n        if (options.partialCount && options.type !== \"custom\") {\n            this._type = this.baseType + options.partialCount.toString();\n        }\n        this.phase = options.phase;\n    }\n    static getDefaults() {\n        return Object.assign(Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            partialCount: 0,\n            partials: [],\n            phase: 0,\n            type: \"sine\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        const computedTime = this.toSeconds(time);\n        // new oscillator with previous values\n        const oscillator = new ToneOscillatorNode({\n            context: this.context,\n            onended: () => this.onstop(this),\n        });\n        this._oscillator = oscillator;\n        if (this._wave) {\n            this._oscillator.setPeriodicWave(this._wave);\n        }\n        else {\n            this._oscillator.type = this._type;\n        }\n        // connect the control signal to the oscillator frequency & detune\n        this._oscillator.connect(this.output);\n        this.frequency.connect(this._oscillator.frequency);\n        this.detune.connect(this._oscillator.detune);\n        // start the oscillator\n        this._oscillator.start(computedTime);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._oscillator) {\n            this._oscillator.stop(computedTime);\n        }\n    }\n    /**\n     * Restart the oscillator. Does not stop the oscillator, but instead\n     * just cancels any scheduled 'stop' from being invoked.\n     */\n    _restart(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"restart\", computedTime);\n        if (this._oscillator) {\n            this._oscillator.cancelStop();\n        }\n        this._state.cancel(computedTime);\n        return this;\n    }\n    /**\n     * Sync the signal to the Transport's bpm. Any changes to the transports bpm,\n     * will also affect the oscillators frequency.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * osc.frequency.value = 440;\n     * // the ratio between the bpm and the frequency will be maintained\n     * osc.syncFrequency();\n     * // double the tempo\n     * Tone.Transport.bpm.value *= 2;\n     * // the frequency of the oscillator is doubled to 880\n     */\n    syncFrequency() {\n        this.context.transport.syncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Unsync the oscillator's frequency from the Transport.\n     * See Oscillator.syncFrequency\n     */\n    unsyncFrequency() {\n        this.context.transport.unsyncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Get a cached periodic wave. Avoids having to recompute\n     * the oscillator values when they have already been computed\n     * with the same values.\n     */\n    _getCachedPeriodicWave() {\n        if (this._type === \"custom\") {\n            const oscProps = Oscillator._periodicWaveCache.find(description => {\n                return description.phase === this._phase &&\n                    deepEquals(description.partials, this._partials);\n            });\n            return oscProps;\n        }\n        else {\n            const oscProps = Oscillator._periodicWaveCache.find(description => {\n                return description.type === this._type &&\n                    description.phase === this._phase;\n            });\n            this._partialCount = oscProps ? oscProps.partialCount : this._partialCount;\n            return oscProps;\n        }\n    }\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._type = type;\n        const isBasicType = [\"sine\", \"square\", \"sawtooth\", \"triangle\"].indexOf(type) !== -1;\n        if (this._phase === 0 && isBasicType) {\n            this._wave = undefined;\n            this._partialCount = 0;\n            // just go with the basic approach\n            if (this._oscillator !== null) {\n                // already tested that it's a basic type\n                this._oscillator.type = type;\n            }\n        }\n        else {\n            // first check if the value is cached\n            const cache = this._getCachedPeriodicWave();\n            if (isDefined(cache)) {\n                const { partials, wave } = cache;\n                this._wave = wave;\n                this._partials = partials;\n                if (this._oscillator !== null) {\n                    this._oscillator.setPeriodicWave(this._wave);\n                }\n            }\n            else {\n                const [real, imag] = this._getRealImaginary(type, this._phase);\n                const periodicWave = this.context.createPeriodicWave(real, imag);\n                this._wave = periodicWave;\n                if (this._oscillator !== null) {\n                    this._oscillator.setPeriodicWave(this._wave);\n                }\n                // set the cache\n                Oscillator._periodicWaveCache.push({\n                    imag,\n                    partialCount: this._partialCount,\n                    partials: this._partials,\n                    phase: this._phase,\n                    real,\n                    type: this._type,\n                    wave: this._wave,\n                });\n                if (Oscillator._periodicWaveCache.length > 100) {\n                    Oscillator._periodicWaveCache.shift();\n                }\n            }\n        }\n    }\n    get baseType() {\n        return this._type.replace(this.partialCount.toString(), \"\");\n    }\n    set baseType(baseType) {\n        if (this.partialCount && this._type !== \"custom\" && baseType !== \"custom\") {\n            this.type = baseType + this.partialCount;\n        }\n        else {\n            this.type = baseType;\n        }\n    }\n    get partialCount() {\n        return this._partialCount;\n    }\n    set partialCount(p) {\n        assertRange(p, 0);\n        let type = this._type;\n        const partial = /^(sine|triangle|square|sawtooth)(\\d+)$/.exec(this._type);\n        if (partial) {\n            type = partial[1];\n        }\n        if (this._type !== \"custom\") {\n            if (p === 0) {\n                this.type = type;\n            }\n            else {\n                this.type = type + p.toString();\n            }\n        }\n        else {\n            // extend or shorten the partials array\n            const fullPartials = new Float32Array(p);\n            // copy over the partials array\n            this._partials.forEach((v, i) => fullPartials[i] = v);\n            this._partials = Array.from(fullPartials);\n            this.type = this._type;\n        }\n    }\n    /**\n     * Returns the real and imaginary components based\n     * on the oscillator type.\n     * @returns [real: Float32Array, imaginary: Float32Array]\n     */\n    _getRealImaginary(type, phase) {\n        const fftSize = 4096;\n        let periodicWaveSize = fftSize / 2;\n        const real = new Float32Array(periodicWaveSize);\n        const imag = new Float32Array(periodicWaveSize);\n        let partialCount = 1;\n        if (type === \"custom\") {\n            partialCount = this._partials.length + 1;\n            this._partialCount = this._partials.length;\n            periodicWaveSize = partialCount;\n            // if the partial count is 0, don't bother doing any computation\n            if (this._partials.length === 0) {\n                return [real, imag];\n            }\n        }\n        else {\n            const partial = /^(sine|triangle|square|sawtooth)(\\d+)$/.exec(type);\n            if (partial) {\n                partialCount = parseInt(partial[2], 10) + 1;\n                this._partialCount = parseInt(partial[2], 10);\n                type = partial[1];\n                partialCount = Math.max(partialCount, 2);\n                periodicWaveSize = partialCount;\n            }\n            else {\n                this._partialCount = 0;\n            }\n            this._partials = [];\n        }\n        for (let n = 1; n < periodicWaveSize; ++n) {\n            const piFactor = 2 / (n * Math.PI);\n            let b;\n            switch (type) {\n                case \"sine\":\n                    b = (n <= partialCount) ? 1 : 0;\n                    this._partials[n - 1] = b;\n                    break;\n                case \"square\":\n                    b = (n & 1) ? 2 * piFactor : 0;\n                    this._partials[n - 1] = b;\n                    break;\n                case \"sawtooth\":\n                    b = piFactor * ((n & 1) ? 1 : -1);\n                    this._partials[n - 1] = b;\n                    break;\n                case \"triangle\":\n                    if (n & 1) {\n                        b = 2 * (piFactor * piFactor) * ((((n - 1) >> 1) & 1) ? -1 : 1);\n                    }\n                    else {\n                        b = 0;\n                    }\n                    this._partials[n - 1] = b;\n                    break;\n                case \"custom\":\n                    b = this._partials[n - 1];\n                    break;\n                default:\n                    throw new TypeError(\"Oscillator: invalid type: \" + type);\n            }\n            if (b !== 0) {\n                real[n] = -b * Math.sin(phase * n);\n                imag[n] = b * Math.cos(phase * n);\n            }\n            else {\n                real[n] = 0;\n                imag[n] = 0;\n            }\n        }\n        return [real, imag];\n    }\n    /**\n     * Compute the inverse FFT for a given phase.\n     */\n    _inverseFFT(real, imag, phase) {\n        let sum = 0;\n        const len = real.length;\n        for (let i = 0; i < len; i++) {\n            sum += real[i] * Math.cos(i * phase) + imag[i] * Math.sin(i * phase);\n        }\n        return sum;\n    }\n    /**\n     * Returns the initial value of the oscillator when stopped.\n     * E.g. a \"sine\" oscillator with phase = 90 would return an initial value of -1.\n     */\n    getInitialValue() {\n        const [real, imag] = this._getRealImaginary(this._type, 0);\n        let maxValue = 0;\n        const twoPi = Math.PI * 2;\n        const testPositions = 32;\n        // check for peaks in 16 places\n        for (let i = 0; i < testPositions; i++) {\n            maxValue = Math.max(this._inverseFFT(real, imag, (i / testPositions) * twoPi), maxValue);\n        }\n        return clamp(-this._inverseFFT(real, imag, this._phase) / maxValue, -1, 1);\n    }\n    get partials() {\n        return this._partials.slice(0, this.partialCount);\n    }\n    set partials(partials) {\n        this._partials = partials;\n        this._partialCount = this._partials.length;\n        if (partials.length) {\n            this.type = \"custom\";\n        }\n    }\n    get phase() {\n        return this._phase * (180 / Math.PI);\n    }\n    set phase(phase) {\n        this._phase = phase * Math.PI / 180;\n        // reset the type\n        this.type = this._type;\n    }\n    asArray(length = 1024) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return generateWaveform(this, length);\n        });\n    }\n    dispose() {\n        super.dispose();\n        if (this._oscillator !== null) {\n            this._oscillator.dispose();\n        }\n        this._wave = undefined;\n        this.frequency.dispose();\n        this.detune.dispose();\n        return this;\n    }\n}\n/**\n * Cache the periodic waves to avoid having to redo computations\n */\nOscillator._periodicWaveCache = [];\n//# sourceMappingURL=Oscillator.js.map","import { __awaiter } from \"tslib\";\nimport { OfflineContext } from \"../../core/context/OfflineContext\";\n/**\n * Render a segment of the oscillator to an offline context and return the results as an array\n */\nexport function generateWaveform(instance, length) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const duration = length / instance.context.sampleRate;\n        const context = new OfflineContext(1, duration, instance.context.sampleRate);\n        const clone = new instance.constructor(Object.assign(instance.get(), {\n            // should do 2 iterations\n            frequency: 2 / duration,\n            // zero out the detune\n            detune: 0,\n            context\n        })).toDestination();\n        clone.start(0);\n        const buffer = yield context.render();\n        return buffer.getChannelData(0);\n    });\n}\n//# sourceMappingURL=OscillatorInterface.js.map","import { __awaiter } from \"tslib\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { Multiply } from \"../../signal/Multiply\";\nimport { Source } from \"../Source\";\nimport { Oscillator } from \"./Oscillator\";\nimport { generateWaveform } from \"./OscillatorInterface\";\nimport { PulseOscillator } from \"./PulseOscillator\";\n/**\n * PWMOscillator modulates the width of a Tone.PulseOscillator\n * at the modulationFrequency. This has the effect of continuously\n * changing the timbre of the oscillator by altering the harmonics\n * generated.\n * @offline 0.1 1\n * @example\n * const pwm = new Tone.PWMOscillator(60, 0.3).toDestination().start();\n * @category Source\n */\nexport class PWMOscillator extends Source {\n    constructor() {\n        super(optionsFromArguments(PWMOscillator.getDefaults(), arguments, [\"frequency\", \"modulationFrequency\"]));\n        this.name = \"PWMOscillator\";\n        this.sourceType = \"pwm\";\n        /**\n         * Scale the oscillator so it doesn't go silent\n         * at the extreme values.\n         */\n        this._scale = new Multiply({\n            context: this.context,\n            value: 2,\n        });\n        const options = optionsFromArguments(PWMOscillator.getDefaults(), arguments, [\"frequency\", \"modulationFrequency\"]);\n        this._pulse = new PulseOscillator({\n            context: this.context,\n            frequency: options.modulationFrequency,\n        });\n        // change the pulse oscillator type\n        this._pulse.carrierType = \"sine\";\n        this.modulationFrequency = this._pulse.frequency;\n        this._modulator = new Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n        });\n        this.frequency = this._modulator.frequency;\n        this.detune = this._modulator.detune;\n        // connections\n        this._modulator.chain(this._scale, this._pulse.width);\n        this._pulse.connect(this.output);\n        readOnly(this, [\"modulationFrequency\", \"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            modulationFrequency: 0.4,\n            phase: 0,\n            type: \"pwm\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._modulator.start(time);\n        this._pulse.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._modulator.stop(time);\n        this._pulse.stop(time);\n    }\n    /**\n     * restart the oscillator\n     */\n    _restart(time) {\n        this._modulator.restart(time);\n        this._pulse.restart(time);\n    }\n    /**\n     * The type of the oscillator. Always returns \"pwm\".\n     */\n    get type() {\n        return \"pwm\";\n    }\n    /**\n     * The baseType of the oscillator. Always returns \"pwm\".\n     */\n    get baseType() {\n        return \"pwm\";\n    }\n    /**\n     * The partials of the waveform. Cannot set partials for this waveform type\n     */\n    get partials() {\n        return [];\n    }\n    /**\n     * No partials for this waveform type.\n     */\n    get partialCount() {\n        return 0;\n    }\n    /**\n     * The phase of the oscillator in degrees.\n     */\n    get phase() {\n        return this._modulator.phase;\n    }\n    set phase(phase) {\n        this._modulator.phase = phase;\n    }\n    asArray(length = 1024) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return generateWaveform(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._pulse.dispose();\n        this._scale.dispose();\n        this._modulator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PWMOscillator.js.map","import { __awaiter } from \"tslib\";\nimport { Gain } from \"../../core/context/Gain\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { readOnly } from \"../../core/util/Interface\";\nimport { Signal } from \"../../signal/Signal\";\nimport { WaveShaper } from \"../../signal/WaveShaper\";\nimport { Source } from \"../Source\";\nimport { Oscillator } from \"./Oscillator\";\nimport { generateWaveform } from \"./OscillatorInterface\";\n/**\n * PulseOscillator is an oscillator with control over pulse width,\n * also known as the duty cycle. At 50% duty cycle (width = 0) the wave is\n * a square wave.\n * [Read more](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).\n * ```\n *    width = -0.25        width = 0.0          width = 0.25\n *\n *   +-----+            +-------+       +    +-------+     +-+\n *   |     |            |       |       |            |     |\n *   |     |            |       |       |            |     |\n * +-+     +-------+    +       +-------+            +-----+\n *\n *\n *    width = -0.5                              width = 0.5\n *\n *     +---+                                 +-------+   +---+\n *     |   |                                         |   |\n *     |   |                                         |   |\n * +---+   +-------+                                 +---+\n *\n *\n *    width = -0.75                             width = 0.75\n *\n *       +-+                                 +-------+ +-----+\n *       | |                                         | |\n *       | |                                         | |\n * +-----+ +-------+                                 +-+\n * ```\n * @offline 0.1 1\n * @example\n * const pulse = new Tone.PulseOscillator(50, 0.4).toDestination().start();\n * @category Source\n */\nexport class PulseOscillator extends Source {\n    constructor() {\n        super(optionsFromArguments(PulseOscillator.getDefaults(), arguments, [\"frequency\", \"width\"]));\n        this.name = \"PulseOscillator\";\n        /**\n         * gate the width amount\n         */\n        this._widthGate = new Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * Threshold the signal to turn it into a square\n         */\n        this._thresh = new WaveShaper({\n            context: this.context,\n            mapping: val => val <= 0 ? -1 : 1,\n        });\n        const options = optionsFromArguments(PulseOscillator.getDefaults(), arguments, [\"frequency\", \"width\"]);\n        this.width = new Signal({\n            context: this.context,\n            units: \"audioRange\",\n            value: options.width,\n        });\n        this._triangle = new Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: \"triangle\",\n        });\n        this.frequency = this._triangle.frequency;\n        this.detune = this._triangle.detune;\n        // connections\n        this._triangle.chain(this._thresh, this.output);\n        this.width.chain(this._widthGate, this._thresh);\n        readOnly(this, [\"width\", \"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            phase: 0,\n            type: \"pulse\",\n            width: 0.2,\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._triangle.start(time);\n        this._widthGate.gain.setValueAtTime(1, time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._triangle.stop(time);\n        // the width is still connected to the output.\n        // that needs to be stopped also\n        this._widthGate.gain.cancelScheduledValues(time);\n        this._widthGate.gain.setValueAtTime(0, time);\n    }\n    _restart(time) {\n        this._triangle.restart(time);\n        this._widthGate.gain.cancelScheduledValues(time);\n        this._widthGate.gain.setValueAtTime(1, time);\n    }\n    /**\n     * The phase of the oscillator in degrees.\n     */\n    get phase() {\n        return this._triangle.phase;\n    }\n    set phase(phase) {\n        this._triangle.phase = phase;\n    }\n    /**\n     * The type of the oscillator. Always returns \"pulse\".\n     */\n    get type() {\n        return \"pulse\";\n    }\n    /**\n     * The baseType of the oscillator. Always returns \"pulse\".\n     */\n    get baseType() {\n        return \"pulse\";\n    }\n    /**\n     * The partials of the waveform. Cannot set partials for this waveform type\n     */\n    get partials() {\n        return [];\n    }\n    /**\n     * No partials for this waveform type.\n     */\n    get partialCount() {\n        return 0;\n    }\n    /**\n     * *Internal use* The carrier oscillator type is fed through the\n     * waveshaper node to create the pulse. Using different carrier oscillators\n     * changes oscillator's behavior.\n     */\n    set carrierType(type) {\n        this._triangle.type = type;\n    }\n    asArray(length = 1024) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return generateWaveform(this, length);\n        });\n    }\n    /**\n     * Clean up method.\n     */\n    dispose() {\n        super.dispose();\n        this._triangle.dispose();\n        this.width.dispose();\n        this._widthGate.dispose();\n        this._thresh.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PulseOscillator.js.map","import { connect } from \"../../core/context/ToneAudioNode\";\nimport { Param } from \"../../core/context/Param\";\nimport { optionsFromArguments } from \"../../core/util/Defaults\";\nimport { OneShotSource } from \"../OneShotSource\";\nimport { readOnly } from \"../../core/util/Interface\";\n/**\n * Wrapper around the native fire-and-forget OscillatorNode.\n * Adds the ability to reschedule the stop method.\n * ***[[Oscillator]] is better for most use-cases***\n * @category Source\n */\nexport class ToneOscillatorNode extends OneShotSource {\n    constructor() {\n        super(optionsFromArguments(ToneOscillatorNode.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"ToneOscillatorNode\";\n        /**\n         * The oscillator\n         */\n        this._oscillator = this.context.createOscillator();\n        this._internalChannels = [this._oscillator];\n        const options = optionsFromArguments(ToneOscillatorNode.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        connect(this._oscillator, this._gainNode);\n        this.type = options.type;\n        this.frequency = new Param({\n            context: this.context,\n            param: this._oscillator.frequency,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new Param({\n            context: this.context,\n            param: this._oscillator.detune,\n            units: \"cents\",\n            value: options.detune,\n        });\n        readOnly(this, [\"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(OneShotSource.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            type: \"sine\",\n        });\n    }\n    /**\n     * Start the oscillator node at the given time\n     * @param  time When to start the oscillator\n     */\n    start(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        this._startGain(computedTime);\n        this._oscillator.start(computedTime);\n        return this;\n    }\n    _stopSource(time) {\n        this._oscillator.stop(time);\n    }\n    /**\n     * Sets an arbitrary custom periodic waveform given a PeriodicWave.\n     * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave\n     */\n    setPeriodicWave(periodicWave) {\n        this._oscillator.setPeriodicWave(periodicWave);\n        return this;\n    }\n    /**\n     * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'\n     */\n    get type() {\n        return this._oscillator.type;\n    }\n    set type(type) {\n        this._oscillator.type = type;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        if (this.state === \"started\") {\n            this.stop();\n        }\n        this._oscillator.disconnect();\n        this.frequency.dispose();\n        this.detune.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneOscillatorNode.js.map","export const version = \"14.7.2\";\n//# sourceMappingURL=version.js.map","import { Component, HostBinding, HostListener, Inject, Input, NgZone, OnDestroy, OnInit, ViewChild } from '@angular/core';\nimport { Melody } from '../../models/melody/melody.model';\nimport { AUDIFICATION, t, tA11y } from '../../i18n';\nimport { formatX, formatY, humanizeMeasureName } from '../../utils/formatters';\nimport { LineChartComponent } from '../line-chart/line-chart.component';\nimport { takeUntil } from 'rxjs/operators';\nimport { Subject } from 'rxjs';\nimport { AudificationPreference } from '../../services/preference/types';\nimport { ascendingDate, ascendingNumber } from '../../utils/comparators';\nimport { ScreenReaderComponent } from '../screen-reader/screen-reader.component';\n\n@Component({\n  selector: 'app-line-chart-audification',\n  templateUrl: './line-chart-audification.component.html',\n  styleUrls: ['./line-chart-audification.component.scss'],\n})\nexport class LineChartAudificationComponent implements AudificationPreference, OnInit, OnDestroy {\n  @ViewChild(ScreenReaderComponent, { static: true }) screenReaderComponent: ScreenReaderComponent;\n\n  // even though change detection doesn't work for dynamically loaded components, leave @Input() to indicate that they will be injected.\n  @Input() enabled: boolean;\n  @Input() lowestPitch: number;\n  @Input() highestPitch: number;\n  @Input() noteDuration: number;\n  @Input() readBefore: boolean;\n  @Input() readAfter: boolean;\n\n  melody?: Melody;\n  private destroy$ = new Subject();\n  private domain: Date[];\n  private range: number[];\n  @HostBinding('attr.tabindex') private readonly tabindex = 0;\n  private resumeTimeoutId: number | null = null;\n\n  constructor(\n    @Inject('host') private host: LineChartComponent,\n    private zone: NgZone,\n  ) {\n    this.handleSeek = this.handleSeek.bind(this);\n  }\n\n  get INSTRUCTIONS() {\n    return t(AUDIFICATION.INSTRUCTIONS);\n  }\n\n  get INSTRUCTIONS_A11Y() {\n    return tA11y(AUDIFICATION.INSTRUCTIONS);\n  }\n\n  get data() {\n    return this.host.data;\n  }\n\n  get measureNames() {\n    return this.host.measureNames;\n  }\n\n  set activeDatum(activeDatum) {\n    this.host.activeDatum = activeDatum;\n  }\n\n  ngOnInit() {\n    this.host.data$\n      .pipe(takeUntil(this.destroy$))\n      .subscribe(data => {\n        const values = data.map(datum => datum.value);\n        this.domain = data.map(d => d.date).sort(ascendingDate);\n        this.range = data.map(d => d.value).sort(ascendingNumber);\n        this.melody?.dispose();\n        this.melody = new Melody(values, [this.lowestPitch, this.highestPitch], this.noteDuration, this.handleSeek);\n      });\n  }\n\n  ngOnDestroy() {\n    this.destroy$.next();\n    this.destroy$.complete();\n    this.melody?.dispose();\n  }\n\n  handleSeek(index) {\n    // since Tone.js is running outside of the Angular zone, it needs to reenter the zone to trigger change detection.\n    this.zone.run((() => {\n      this.activeDatum = this.data[index];\n    }));\n  }\n\n  @HostListener('keydown', ['$event'])\n  async handleKeyDown($event: KeyboardEvent) {\n    $event.preventDefault();\n    $event.stopPropagation();\n    const { key, shiftKey, repeat } = $event;\n    if (!this.melody || repeat) {\n      return;\n    }\n    if (key === ' ') {\n      this.resumeMelody(shiftKey);\n    } else if (key === 'x') {\n      this.readOutDomain();\n    } else if (key === 'y') {\n      this.readOutRange();\n    } else if (key === 'l') {\n      this.readOutMeasure();\n    } else if ('0' <= key && key <= '9') {\n      const datumIndex = Math.floor(+key / 10 * this.data.length);\n      this.melody.seekTo(datumIndex, true);\n      this.readOutCurrentDatum();\n    }\n  }\n\n  @HostListener('keyup', ['$event'])\n  handleKeyUp($event: KeyboardEvent) {\n    if (!this.melody) {\n      return;\n    }\n    $event.preventDefault();\n    $event.stopPropagation();\n    const { key } = $event;\n    if (key === ' ') {\n      this.pauseMelody();\n    }\n  }\n\n  @HostListener('blur', ['$event'])\n  handleBlur() {\n    this.melody?.pause();\n  }\n\n  private resumeMelody(reversed: boolean) {\n    if (this.readBefore) {\n      const delay = this.readOutCurrentDatum();\n      const duration = 2000; // an estimated upper bound of how long it would take to read out\n      this.resumeTimeoutId = window.setTimeout(async () => {\n        this.resumeTimeoutId = null;\n        this.melody?.resume(reversed);\n      }, delay + duration);\n    } else {\n      this.melody?.resume(reversed);\n    }\n  }\n\n  private pauseMelody() {\n    if (this.resumeTimeoutId !== null) {\n      window.clearTimeout(this.resumeTimeoutId);\n      this.resumeTimeoutId = null;\n    } else {\n      this.melody?.pause();\n      if (this.readAfter) {\n        this.readOutCurrentDatum();\n      }\n    }\n  }\n\n  private readOutDomain() {\n    return this.screenReaderComponent.readOut(t(AUDIFICATION.DOMAIN, {\n      min: formatX(this.domain[0]),\n      max: formatX(this.domain[this.domain.length - 1]),\n    }));\n  }\n\n  private readOutRange() {\n    return this.screenReaderComponent.readOut(t(AUDIFICATION.RANGE, {\n      min: formatY(this.range[0]),\n      max: formatY(this.range[this.range.length - 1]),\n    }));\n  }\n\n  private readOutMeasure() {\n    // TODO: read the entire measureNames\n    return this.screenReaderComponent.readOut(humanizeMeasureName(this.measureNames[0]));\n  }\n\n  private readOutCurrentDatum() {\n    if (!this.melody) {\n      return 0;\n    }\n    const { date, value } = this.data[this.melody.currentDatumIndex];\n    return this.screenReaderComponent.readOut(t(AUDIFICATION.ACTIVE_DATUM, {\n      x: formatX(date),\n      y: formatY(value),\n    }));\n  }\n}\n","<div role=\"img\" class=\"instructions\"\n     [innerHTML]=\"INSTRUCTIONS\"\n     [attr.aria-label]=\"INSTRUCTIONS_A11Y\">\n</div>\n<app-screen-reader></app-screen-reader>\n","import { NgModule } from '@angular/core';\nimport { LineChartAudificationComponent } from './line-chart-audification.component';\nimport { CommonModule } from '@angular/common';\nimport { ScreenReaderModule } from '../screen-reader/screen-reader.module';\nimport { LazyA11yModule } from '../../directives/a11y-placeholder/types';\n\n@NgModule({\n  declarations: [\n    LineChartAudificationComponent,\n  ],\n  imports: [\n    CommonModule,\n    ScreenReaderModule,\n  ],\n  exports: [\n    LineChartAudificationComponent,\n  ],\n})\nexport class LineChartAudificationModule implements LazyA11yModule<LineChartAudificationComponent> {\n  A11yComponent = LineChartAudificationComponent;\n}\n","import { Component, Input } from '@angular/core';\n\n@Component({\n  selector: 'app-screen-reader',\n  templateUrl: './screen-reader.component.html',\n  styleUrls: ['./screen-reader.component.scss'],\n})\nexport class ScreenReaderComponent {\n  @Input() repetitionDelay = 500; // duration (in ms) for which empty the live text when the same text needs to be read out consequently\n\n  liveText: string | null = null;\n  private readOutTimeoutId: number | null = null;\n\n  /**\n   * Make a screen-reader software read out the text.\n   *\n   * @param text The text to read out.\n   * @return The delay before reading out.\n   */\n  readOut(text: string) {\n    if (this.readOutTimeoutId !== null) {\n      window.clearTimeout(this.readOutTimeoutId);\n      this.readOutTimeoutId = null;\n    }\n    const repetitive = this.liveText === text;\n    if (repetitive) {\n      this.liveText = null;\n      this.readOutTimeoutId = window.setTimeout(() => {\n        this.readOutTimeoutId = null;\n        this.readOut(text);\n      }, this.repetitionDelay);\n    } else {\n      this.liveText = text;\n    }\n    return repetitive ? this.repetitionDelay : 0;\n  }\n}\n","<div class=\"live-text\" aria-live=\"assertive\" [innerText]=\"liveText\"></div>\n","import { NgModule } from '@angular/core';\nimport { ScreenReaderComponent } from './screen-reader.component';\n\n@NgModule({\n  declarations: [\n    ScreenReaderComponent,\n  ],\n  exports: [\n    ScreenReaderComponent,\n  ],\n})\nexport class ScreenReaderModule {\n}\n","import * as Tone from 'tone';\n\nexport type OnSeek = (index: number) => void;\n\nexport class Melody {\n  currentDatumIndex = 0;\n  private synth = new Tone.Synth().toDestination();\n  private inclusive = true; // if true, playing the melody starting inclusively from currentDatumIndex\n  private reversed = false; // if true, playing the melody backward\n  private readonly frequencies: number[];\n  private timeoutId: number | null = null;\n\n  constructor(\n    private values: number[],\n    private frequencyRange: [number, number],\n    private noteDuration: number, // duration (in ms) of a note\n    private onSeek?: OnSeek,\n  ) {\n    const minValue = Math.min(...values);\n    const maxValue = Math.max(...values);\n    const [minFrequency, maxFrequency] = this.frequencyRange;\n    const minKeyNumber = Melody.getKeyNumber(minFrequency);\n    const maxKeyNumber = Melody.getKeyNumber(maxFrequency);\n    this.frequencies = values.map(value => {\n      const keyNumber = (value - minValue) / (maxValue - minValue) * (maxKeyNumber - minKeyNumber) + minKeyNumber;\n      return Melody.getFrequency(keyNumber);\n    });\n  }\n\n  get duration() {\n    return this.noteDuration * this.values.length;\n  }\n\n  get isPlaying() {\n    return this.timeoutId !== null;\n  }\n\n  get isEnded() {\n    return (\n      this.reversed && this.currentDatumIndex === 0 ||\n      !this.reversed && this.currentDatumIndex === this.values.length - 1\n    );\n  }\n\n  get nextDatumIndex() {\n    if (this.isEnded) {\n      return this.reverseDatumIndex(this.currentDatumIndex); // bring playhead to the opposite end\n    }\n    const offset = this.inclusive ? 0 : (this.reversed ? -1 : +1);\n    return this.currentDatumIndex + offset;\n  }\n\n  private static getKeyNumber(frequency: number) {\n    return Math.log2(frequency / 440) * 12 + 49;\n  }\n\n  private static getFrequency(keyNumber: number) {\n    return Math.pow(2, (keyNumber - 49) / 12) * 440;\n  }\n\n  async resume(reversed: boolean) {\n    if (Tone.getContext().state === 'suspended') {\n      await Tone.start();\n    }\n    if (!this.isPlaying) {\n      this.reversed = reversed;\n      this.playNextNote();\n    }\n  }\n\n  pause() {\n    if (this.timeoutId !== null) {\n      window.clearInterval(this.timeoutId);\n      this.timeoutId = null;\n    }\n  }\n\n  seekTo(datumIndex: number, inclusive = false) {\n    this.currentDatumIndex = datumIndex;\n    this.inclusive = this.isEnded || inclusive;\n    this.onSeek?.(this.currentDatumIndex);\n  }\n\n  dispose() {\n    this.pause();\n    this.synth.dispose();\n  }\n\n  private playNextNote() {\n    this.seekTo(this.nextDatumIndex);\n    const frequency = this.frequencies[this.currentDatumIndex];\n    this.synth.triggerAttackRelease(frequency, this.noteDuration / 1000);\n    if (!this.isEnded) {\n      this.timeoutId = window.setTimeout(() => {\n        this.timeoutId = null;\n        this.playNextNote();\n      }, this.noteDuration);\n    }\n  }\n\n  private reverseDatumIndex(index: number) {\n    return (this.values.length - 1) - index;\n  }\n}\n","export function ascendingNumber(a: number, b: number) {\n  return a - b;\n}\n\nexport function descendingNumber(a: number, b: number) {\n  return -ascendingNumber(a, b);\n}\n\nexport function ascendingDate(a: Date, b: Date) {\n  return ascendingNumber(a.getTime(), b.getTime());\n}\n\nexport function descendingDate(a: Date, b: Date) {\n  return -ascendingDate(a, b);\n}\n"],"sourceRoot":"webpack:///"}